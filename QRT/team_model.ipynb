{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_team_statistics_df = pd.read_csv('./train_home_team_statistics_df.csv', index_col=0)\n",
    "train_away_team_statistics_df = pd.read_csv('./train_away_team_statistics_df.csv', index_col=0)\n",
    "\n",
    "train_scores = pd.read_csv('./Y_train.csv', index_col=0)\n",
    "\n",
    "train_home_team_statistics_df.columns = 'HOME_' + train_home_team_statistics_df.columns\n",
    "train_away_team_statistics_df.columns = 'AWAY_' + train_away_team_statistics_df.columns\n",
    "\n",
    "train_data = train_home_team_statistics_df.iloc[:,2:].join(train_away_team_statistics_df.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(train_data, train_scores, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class MatchTeamClassifier(nn.Module):\n",
    "    def __init__(self, n_class, n_team_fts, hidden_team):\n",
    "        super().__init__()\n",
    "        self.bc1 = nn.BatchNorm1d(n_team_fts)\n",
    "        self.bc2 = nn.BatchNorm1d(hidden_team[0])\n",
    "        self.bc3 = nn.BatchNorm1d(hidden_team[1])\n",
    "        self.att1 = nn.MultiheadAttention(hidden_team[0], 1, batch_first=True)\n",
    "        self.att2 = nn.MultiheadAttention(hidden_team[0], 1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(n_team_fts, hidden_team[0])\n",
    "        self.fc2 = nn.Linear(hidden_team[0], hidden_team[1])\n",
    "        #self.bc2 = nn.BatchNorm1d(hidden_team)\n",
    "        self.fc3 = nn.Linear(hidden_team[0], n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.bc2(self.fc1(self.bc1(x)))[:,None,:]\n",
    "        res = self.att1(res, res, res, need_weights=False)[0]\n",
    "        #res = self.fc3(F.relu(self.fc2(self.att2(res, res, res, need_weights=False)[0])))\n",
    "        return self.fc3(res)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MatchTeamClassifier(3, 280, (128, 64))\n",
    "\n",
    "x_train = torch.Tensor(X_train.replace({np.nan:0.0}).values)\n",
    "x_valid = torch.Tensor(X_valid.replace({np.nan:0.0}).values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "Y_valid = torch.Tensor(y_valid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2461, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net(x_valid).shape)\n",
    "net.bc1.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 1.12 | Train Accuracy 0.3359073359073359 | Val Accuracy 0.4368143031288094\n",
      "Epoch 1 Loss 1.08 | Train Accuracy 0.45854501117659013 | Val Accuracy 0.46525802519301096\n",
      "Epoch 2 Loss 1.03 | Train Accuracy 0.47297297297297297 | Val Accuracy 0.4660707029662739\n",
      "Epoch 3 Loss 1.04 | Train Accuracy 0.47876447876447875 | Val Accuracy 0.4782608695652174\n",
      "Epoch 4 Loss 1.03 | Train Accuracy 0.4892298313350945 | Val Accuracy 0.47785453067858596\n",
      "Epoch 5 Loss 1.02 | Train Accuracy 0.4895346474293843 | Val Accuracy 0.48029256399837467\n",
      "Epoch 6 Loss 1.02 | Train Accuracy 0.4899410688884373 | Val Accuracy 0.4863876472978464\n",
      "Epoch 7 Loss 1.01 | Train Accuracy 0.49339565129038815 | Val Accuracy 0.4961397805770012\n",
      "Epoch 8 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4928890694839496\n",
      "Epoch 9 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49207639171068673\n",
      "Epoch 10 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49085737505079235\n",
      "Epoch 11 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49085737505079235\n",
      "Epoch 12 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4904510361641609\n",
      "Epoch 13 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49451442503047544\n",
      "Epoch 14 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 15 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49329540837058106\n",
      "Epoch 16 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4928890694839496\n",
      "Epoch 17 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4888256806176351\n",
      "Epoch 18 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4900446972775295\n",
      "Epoch 19 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.48923201950426654\n",
      "Epoch 20 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4937017472572125\n",
      "Epoch 21 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 22 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 23 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49085737505079235\n",
      "Epoch 24 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 25 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4924827305973182\n",
      "Epoch 26 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49207639171068673\n",
      "Epoch 27 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49451442503047544\n",
      "Epoch 28 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 29 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4904510361641609\n",
      "Epoch 30 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4900446972775295\n",
      "Epoch 31 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.48679398618447783\n",
      "Epoch 32 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.46160097521332794\n",
      "Epoch 33 Loss 1.03 | Train Accuracy 0.4794757163178216 | Val Accuracy 0.48435595286468913\n",
      "Epoch 34 Loss 1.02 | Train Accuracy 0.48587685429790695 | Val Accuracy 0.48516863063795207\n",
      "Epoch 35 Loss 1.02 | Train Accuracy 0.48862019914651494 | Val Accuracy 0.49085737505079235\n",
      "Epoch 36 Loss 1.02 | Train Accuracy 0.49136354399512294 | Val Accuracy 0.49410808614384394\n",
      "Epoch 37 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.48963835839089803\n",
      "Epoch 38 Loss 1.02 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.48679398618447783\n",
      "Epoch 39 Loss 1.02 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.48923201950426654\n",
      "Epoch 40 Loss 1.02 | Train Accuracy 0.494513310302784 | Val Accuracy 0.48963835839089803\n",
      "Epoch 41 Loss 1.01 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.48923201950426654\n",
      "Epoch 42 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4961397805770012\n",
      "Epoch 43 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.49329540837058106\n",
      "Epoch 44 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49410808614384394\n",
      "Epoch 45 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4900446972775295\n",
      "Epoch 46 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49207639171068673\n",
      "Epoch 47 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4928890694839496\n",
      "Epoch 48 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4924827305973182\n",
      "Epoch 49 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49167005282405524\n",
      "Epoch 50 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49410808614384394\n",
      "Epoch 51 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.481511580658269\n",
      "Epoch 52 Loss 1.02 | Train Accuracy 0.492176386913229 | Val Accuracy 0.4900446972775295\n",
      "Epoch 53 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4900446972775295\n",
      "Epoch 54 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49695245835026414\n",
      "Epoch 55 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49085737505079235\n",
      "Epoch 56 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4904510361641609\n",
      "Epoch 57 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 58 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49085737505079235\n",
      "Epoch 59 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4965461194636327\n",
      "Epoch 60 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4953271028037383\n",
      "Epoch 61 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4904510361641609\n",
      "Epoch 62 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 63 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4928890694839496\n",
      "Epoch 64 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4904510361641609\n",
      "Epoch 65 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48963835839089803\n",
      "Epoch 66 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.49167005282405524\n",
      "Epoch 67 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49329540837058106\n",
      "Epoch 68 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48760666395774077\n",
      "Epoch 69 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4904510361641609\n",
      "Epoch 70 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48679398618447783\n",
      "Epoch 71 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4953271028037383\n",
      "Epoch 72 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 73 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.48923201950426654\n",
      "Epoch 74 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4904510361641609\n",
      "Epoch 75 Loss 1.01 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.49329540837058106\n",
      "Epoch 76 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4937017472572125\n",
      "Epoch 77 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49167005282405524\n",
      "Epoch 78 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49207639171068673\n",
      "Epoch 79 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4912637139374238\n",
      "Epoch 80 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48435595286468913\n",
      "Epoch 81 Loss 1.01 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.4924827305973182\n",
      "Epoch 82 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.49410808614384394\n",
      "Epoch 83 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 84 Loss 1.01 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.48923201950426654\n",
      "Epoch 85 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48923201950426654\n",
      "Epoch 86 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49167005282405524\n",
      "Epoch 87 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49695245835026414\n",
      "Epoch 88 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4900446972775295\n",
      "Epoch 89 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49167005282405524\n",
      "Epoch 90 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4949207639171069\n",
      "Epoch 91 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48923201950426654\n",
      "Epoch 92 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4855749695245835\n",
      "Epoch 93 Loss 1.01 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.49207639171068673\n",
      "Epoch 94 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 95 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4928890694839496\n",
      "Epoch 96 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49167005282405524\n",
      "Epoch 97 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.48923201950426654\n",
      "Epoch 98 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4953271028037383\n",
      "Epoch 99 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 100 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.48923201950426654\n",
      "Epoch 101 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49573344169036976\n",
      "Epoch 102 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4928890694839496\n",
      "Epoch 103 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49085737505079235\n",
      "Epoch 104 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.477041852905323\n",
      "Epoch 105 Loss 1.02 | Train Accuracy 0.49065230644178015 | Val Accuracy 0.4924827305973182\n",
      "Epoch 106 Loss 1.01 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.49167005282405524\n",
      "Epoch 107 Loss 1.01 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.48963835839089803\n",
      "Epoch 108 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4900446972775295\n",
      "Epoch 109 Loss 1.01 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4900446972775295\n",
      "Epoch 110 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4912637139374238\n",
      "Epoch 111 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4888256806176351\n",
      "Epoch 112 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49410808614384394\n",
      "Epoch 113 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49410808614384394\n",
      "Epoch 114 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.5002031694433158\n",
      "Epoch 115 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4900446972775295\n",
      "Epoch 116 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "Epoch 117 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49451442503047544\n",
      "Epoch 118 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48923201950426654\n",
      "Epoch 119 Loss 1.02 | Train Accuracy 0.4904490957122536 | Val Accuracy 0.48273059731816337\n",
      "Epoch 120 Loss 1.02 | Train Accuracy 0.4904490957122536 | Val Accuracy 0.4900446972775295\n",
      "Epoch 121 Loss 1.02 | Train Accuracy 0.4950213371266003 | Val Accuracy 0.49451442503047544\n",
      "Epoch 122 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.49207639171068673\n",
      "Epoch 123 Loss 1.02 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.48841934173100365\n",
      "Epoch 124 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4888256806176351\n",
      "Epoch 125 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49451442503047544\n",
      "Epoch 126 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.49329540837058106\n",
      "Epoch 127 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4924827305973182\n",
      "Epoch 128 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4937017472572125\n",
      "Epoch 129 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4928890694839496\n",
      "Epoch 130 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 131 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 132 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 133 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4973587972368956\n",
      "Epoch 134 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4912637139374238\n",
      "Epoch 135 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.48232425843153187\n",
      "Epoch 136 Loss 1.02 | Train Accuracy 0.4922779922779923 | Val Accuracy 0.4924827305973182\n",
      "Epoch 137 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.48963835839089803\n",
      "Epoch 138 Loss 1.01 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4937017472572125\n",
      "Epoch 139 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4912637139374238\n",
      "Epoch 140 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4924827305973182\n",
      "Epoch 141 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4912637139374238\n",
      "Epoch 142 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49410808614384394\n",
      "Epoch 143 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49410808614384394\n",
      "Epoch 144 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.48963835839089803\n",
      "Epoch 145 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49451442503047544\n",
      "Epoch 146 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49329540837058106\n",
      "Epoch 147 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4928890694839496\n",
      "Epoch 148 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.47501015847216577\n",
      "Epoch 149 Loss 1.02 | Train Accuracy 0.4897378581589108 | Val Accuracy 0.49329540837058106\n",
      "Epoch 150 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.48679398618447783\n",
      "Epoch 151 Loss 1.02 | Train Accuracy 0.49380207274944116 | Val Accuracy 0.49207639171068673\n",
      "Epoch 152 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49207639171068673\n",
      "Epoch 153 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.48841934173100365\n",
      "Epoch 154 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4924827305973182\n",
      "Epoch 155 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4928890694839496\n",
      "Epoch 156 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4937017472572125\n",
      "Epoch 157 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49410808614384394\n",
      "Epoch 158 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49695245835026414\n",
      "Epoch 159 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.497765136123527\n",
      "Epoch 160 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4928890694839496\n",
      "Epoch 161 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4904510361641609\n",
      "Epoch 162 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49207639171068673\n",
      "Epoch 163 Loss 1.01 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4928890694839496\n",
      "Epoch 164 Loss 1.01 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4912637139374238\n",
      "Epoch 165 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48923201950426654\n",
      "Epoch 166 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4904510361641609\n",
      "Epoch 167 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49085737505079235\n",
      "Epoch 168 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49329540837058106\n",
      "Epoch 169 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49167005282405524\n",
      "Epoch 170 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.48760666395774077\n",
      "Epoch 171 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4928890694839496\n",
      "Epoch 172 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4949207639171069\n",
      "Epoch 173 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4973587972368956\n",
      "Epoch 174 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49207639171068673\n",
      "Epoch 175 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49451442503047544\n",
      "Epoch 176 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49410808614384394\n",
      "Epoch 177 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4839496139780577\n",
      "Epoch 178 Loss 1.02 | Train Accuracy 0.4901442796179638 | Val Accuracy 0.4904510361641609\n",
      "Epoch 179 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.48720032507110933\n",
      "Epoch 180 Loss 1.02 | Train Accuracy 0.4923795976427555 | Val Accuracy 0.49085737505079235\n",
      "Epoch 181 Loss 1.02 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.49573344169036976\n",
      "Epoch 182 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49410808614384394\n",
      "Epoch 183 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4924827305973182\n",
      "Epoch 184 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4904510361641609\n",
      "Epoch 185 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4937017472572125\n",
      "Epoch 186 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49451442503047544\n",
      "Epoch 187 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4928890694839496\n",
      "Epoch 188 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.5010158472165787\n",
      "Epoch 189 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49817147501015846\n",
      "Epoch 190 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 191 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4928890694839496\n",
      "Epoch 192 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4973587972368956\n",
      "Epoch 193 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4900446972775295\n",
      "Epoch 194 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4900446972775295\n",
      "Epoch 195 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4583502641202763\n",
      "Epoch 196 Loss 1.04 | Train Accuracy 0.46545417598049177 | Val Accuracy 0.4985778138967899\n",
      "Epoch 197 Loss 1.02 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.49085737505079235\n",
      "Epoch 198 Loss 1.03 | Train Accuracy 0.492176386913229 | Val Accuracy 0.48476229175132063\n",
      "Epoch 199 Loss 1.03 | Train Accuracy 0.49207478154846573 | Val Accuracy 0.47988622511174317\n",
      "Epoch 200 Loss 1.02 | Train Accuracy 0.49085551717130665 | Val Accuracy 0.48516863063795207\n",
      "Epoch 201 Loss 1.02 | Train Accuracy 0.4922779922779923 | Val Accuracy 0.4900446972775295\n",
      "Epoch 202 Loss 1.02 | Train Accuracy 0.4924812030075188 | Val Accuracy 0.48923201950426654\n",
      "Epoch 203 Loss 1.02 | Train Accuracy 0.49187157081893923 | Val Accuracy 0.49085737505079235\n",
      "Epoch 204 Loss 1.01 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.49410808614384394\n",
      "Epoch 205 Loss 1.02 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.4953271028037383\n",
      "Epoch 206 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4985778138967899\n",
      "Epoch 207 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49695245835026414\n",
      "Epoch 208 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.49939049167005284\n",
      "Epoch 209 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.5002031694433158\n",
      "Epoch 210 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.5026412027631044\n",
      "Epoch 211 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49939049167005284\n",
      "Epoch 212 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49329540837058106\n",
      "Epoch 213 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4965461194636327\n",
      "Epoch 214 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.48760666395774077\n",
      "Epoch 215 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4855749695245835\n",
      "Epoch 216 Loss 1.02 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.48841934173100365\n",
      "Epoch 217 Loss 1.02 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.49451442503047544\n",
      "Epoch 218 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4928890694839496\n",
      "Epoch 219 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49573344169036976\n",
      "Epoch 220 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49329540837058106\n",
      "Epoch 221 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4953271028037383\n",
      "Epoch 222 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49167005282405524\n",
      "Epoch 223 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49410808614384394\n",
      "Epoch 224 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49573344169036976\n",
      "Epoch 225 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4985778138967899\n",
      "Epoch 226 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4961397805770012\n",
      "Epoch 227 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 228 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4912637139374238\n",
      "Epoch 229 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 230 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4949207639171069\n",
      "Epoch 231 Loss 1.02 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4924827305973182\n",
      "Epoch 232 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.48923201950426654\n",
      "Epoch 233 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4912637139374238\n",
      "Epoch 234 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4953271028037383\n",
      "Epoch 235 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 236 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49329540837058106\n",
      "Epoch 237 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 238 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4928890694839496\n",
      "Epoch 239 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4924827305973182\n",
      "Epoch 240 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4937017472572125\n",
      "Epoch 241 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4904510361641609\n",
      "Epoch 242 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4863876472978464\n",
      "Epoch 243 Loss 1.02 | Train Accuracy 0.4909571225360699 | Val Accuracy 0.49207639171068673\n",
      "Epoch 244 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.48923201950426654\n",
      "Epoch 245 Loss 1.02 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.48923201950426654\n",
      "Epoch 246 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49451442503047544\n",
      "Epoch 247 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49207639171068673\n",
      "Epoch 248 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49695245835026414\n",
      "Epoch 249 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49329540837058106\n",
      "Epoch 250 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4965461194636327\n",
      "Epoch 251 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 252 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4953271028037383\n",
      "Epoch 253 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49817147501015846\n",
      "Epoch 254 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4953271028037383\n",
      "Epoch 255 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49451442503047544\n",
      "Epoch 256 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4741974806989029\n",
      "Epoch 257 Loss 1.02 | Train Accuracy 0.4864864864864865 | Val Accuracy 0.48273059731816337\n",
      "Epoch 258 Loss 1.02 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.4839496139780577\n",
      "Epoch 259 Loss 1.02 | Train Accuracy 0.494513310302784 | Val Accuracy 0.49329540837058106\n",
      "Epoch 260 Loss 1.02 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.4985778138967899\n",
      "Epoch 261 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4928890694839496\n",
      "Epoch 262 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 263 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4949207639171069\n",
      "Epoch 264 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49451442503047544\n",
      "Epoch 265 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4953271028037383\n",
      "Epoch 266 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4953271028037383\n",
      "Epoch 267 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.497765136123527\n",
      "Epoch 268 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49939049167005284\n",
      "Epoch 269 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4997968305566843\n",
      "Epoch 270 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.5006095083299472\n",
      "Epoch 271 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49451442503047544\n",
      "Epoch 272 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49573344169036976\n",
      "Epoch 273 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4997968305566843\n",
      "Epoch 274 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4900446972775295\n",
      "Epoch 275 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.47866720845184885\n",
      "Epoch 276 Loss 1.02 | Train Accuracy 0.48892501524080473 | Val Accuracy 0.49451442503047544\n",
      "Epoch 277 Loss 1.02 | Train Accuracy 0.49309083519609836 | Val Accuracy 0.4900446972775295\n",
      "Epoch 278 Loss 1.02 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.49207639171068673\n",
      "Epoch 279 Loss 1.02 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.4989841527834214\n",
      "Epoch 280 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.49410808614384394\n",
      "Epoch 281 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49451442503047544\n",
      "Epoch 282 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49410808614384394\n",
      "Epoch 283 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.497765136123527\n",
      "Epoch 284 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49573344169036976\n",
      "Epoch 285 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 286 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 287 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49817147501015846\n",
      "Epoch 288 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4985778138967899\n",
      "Epoch 289 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.497765136123527\n",
      "Epoch 290 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49451442503047544\n",
      "Epoch 291 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 292 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4912637139374238\n",
      "Epoch 293 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.47866720845184885\n",
      "Epoch 294 Loss 1.02 | Train Accuracy 0.49359886201991465 | Val Accuracy 0.4949207639171069\n",
      "Epoch 295 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.48923201950426654\n",
      "Epoch 296 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4953271028037383\n",
      "Epoch 297 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49207639171068673\n",
      "Epoch 298 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4949207639171069\n",
      "Epoch 299 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.5002031694433158\n",
      "Epoch 300 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4953271028037383\n",
      "Epoch 301 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 302 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 303 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.497765136123527\n",
      "Epoch 304 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.497765136123527\n",
      "Epoch 305 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4985778138967899\n",
      "Epoch 306 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 307 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4924827305973182\n",
      "Epoch 308 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48476229175132063\n",
      "Epoch 309 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.48191791954490043\n",
      "Epoch 310 Loss 1.03 | Train Accuracy 0.49116033326559644 | Val Accuracy 0.4961397805770012\n",
      "Epoch 311 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4973587972368956\n",
      "Epoch 312 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.49573344169036976\n",
      "Epoch 313 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49695245835026414\n",
      "Epoch 314 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 315 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4973587972368956\n",
      "Epoch 316 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4985778138967899\n",
      "Epoch 317 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.497765136123527\n",
      "Epoch 318 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4961397805770012\n",
      "Epoch 319 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49573344169036976\n",
      "Epoch 320 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4973587972368956\n",
      "Epoch 321 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4965461194636327\n",
      "Epoch 322 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.497765136123527\n",
      "Epoch 323 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49410808614384394\n",
      "Epoch 324 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4961397805770012\n",
      "Epoch 325 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49207639171068673\n",
      "Epoch 326 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48516863063795207\n",
      "Epoch 327 Loss 1.02 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.49817147501015846\n",
      "Epoch 328 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49573344169036976\n",
      "Epoch 329 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4965461194636327\n",
      "Epoch 330 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49573344169036976\n",
      "Epoch 331 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "Epoch 332 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49695245835026414\n",
      "Epoch 333 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4961397805770012\n",
      "Epoch 334 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4985778138967899\n",
      "Epoch 335 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49573344169036976\n",
      "Epoch 336 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4961397805770012\n",
      "Epoch 337 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4949207639171069\n",
      "Epoch 338 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4937017472572125\n",
      "Epoch 339 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4973587972368956\n",
      "Epoch 340 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4953271028037383\n",
      "Epoch 341 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 342 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49085737505079235\n",
      "Epoch 343 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4900446972775295\n",
      "Epoch 344 Loss 1.03 | Train Accuracy 0.48831538305222516 | Val Accuracy 0.49817147501015846\n",
      "Epoch 345 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4953271028037383\n",
      "Epoch 346 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.49410808614384394\n",
      "Epoch 347 Loss 1.02 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.4961397805770012\n",
      "Epoch 348 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4973587972368956\n",
      "Epoch 349 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 350 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 351 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49573344169036976\n",
      "Epoch 352 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49939049167005284\n",
      "Epoch 353 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.497765136123527\n",
      "Epoch 354 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4989841527834214\n",
      "Epoch 355 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "Epoch 356 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4949207639171069\n",
      "Epoch 357 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4961397805770012\n",
      "Epoch 358 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4928890694839496\n",
      "Epoch 359 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4880130028443722\n",
      "Epoch 360 Loss 1.03 | Train Accuracy 0.49187157081893923 | Val Accuracy 0.49695245835026414\n",
      "Epoch 361 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4973587972368956\n",
      "Epoch 362 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.5006095083299472\n",
      "Epoch 363 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49817147501015846\n",
      "Epoch 364 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49939049167005284\n",
      "Epoch 365 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.5002031694433158\n",
      "Epoch 366 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.497765136123527\n",
      "Epoch 367 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.497765136123527\n",
      "Epoch 368 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4953271028037383\n",
      "Epoch 369 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 370 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49451442503047544\n",
      "Epoch 371 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49410808614384394\n",
      "Epoch 372 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 373 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49695245835026414\n",
      "Epoch 374 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49695245835026414\n",
      "Epoch 375 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49695245835026414\n",
      "Epoch 376 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.48435595286468913\n",
      "Epoch 377 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.481511580658269\n",
      "Epoch 378 Loss 1.03 | Train Accuracy 0.4904490957122536 | Val Accuracy 0.4973587972368956\n",
      "Epoch 379 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.4912637139374238\n",
      "Epoch 380 Loss 1.02 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.49329540837058106\n",
      "Epoch 381 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4973587972368956\n",
      "Epoch 382 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4985778138967899\n",
      "Epoch 383 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4989841527834214\n",
      "Epoch 384 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.49939049167005284\n",
      "Epoch 385 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4989841527834214\n",
      "Epoch 386 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49817147501015846\n",
      "Epoch 387 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49939049167005284\n",
      "Epoch 388 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4989841527834214\n",
      "Epoch 389 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4961397805770012\n",
      "Epoch 390 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4937017472572125\n",
      "Epoch 391 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4961397805770012\n",
      "Epoch 392 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49167005282405524\n",
      "Epoch 393 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.481511580658269\n",
      "Epoch 394 Loss 1.03 | Train Accuracy 0.4926844137370453 | Val Accuracy 0.4904510361641609\n",
      "Epoch 395 Loss 1.03 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.4880130028443722\n",
      "Epoch 396 Loss 1.03 | Train Accuracy 0.4934972566551514 | Val Accuracy 0.49410808614384394\n",
      "Epoch 397 Loss 1.03 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4937017472572125\n",
      "Epoch 398 Loss 1.03 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4928890694839496\n",
      "Epoch 399 Loss 1.03 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.49695245835026414\n",
      "Epoch 400 Loss 1.03 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4961397805770012\n",
      "Epoch 401 Loss 1.03 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.497765136123527\n",
      "Epoch 402 Loss 1.02 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4973587972368956\n",
      "Epoch 403 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49573344169036976\n",
      "Epoch 404 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.497765136123527\n",
      "Epoch 405 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4965461194636327\n",
      "Epoch 406 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.497765136123527\n",
      "Epoch 407 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4965461194636327\n",
      "Epoch 408 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4953271028037383\n",
      "Epoch 409 Loss 1.02 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49817147501015846\n",
      "Epoch 410 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49573344169036976\n",
      "Epoch 411 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49695245835026414\n",
      "Epoch 412 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49573344169036976\n",
      "Epoch 413 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4937017472572125\n",
      "Epoch 414 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49410808614384394\n",
      "Epoch 415 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4937017472572125\n",
      "Epoch 416 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49573344169036976\n",
      "Epoch 417 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49573344169036976\n",
      "Epoch 418 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4937017472572125\n",
      "Epoch 419 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4924827305973182\n",
      "Epoch 420 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49451442503047544\n",
      "Epoch 421 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.497765136123527\n",
      "Epoch 422 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 423 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49451442503047544\n",
      "Epoch 424 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4985778138967899\n",
      "Epoch 425 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49410808614384394\n",
      "Epoch 426 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.481511580658269\n",
      "Epoch 427 Loss 1.03 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.4839496139780577\n",
      "Epoch 428 Loss 1.03 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.48841934173100365\n",
      "Epoch 429 Loss 1.03 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.49410808614384394\n",
      "Epoch 430 Loss 1.03 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.4949207639171069\n",
      "Epoch 431 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.4937017472572125\n",
      "Epoch 432 Loss 1.03 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4973587972368956\n",
      "Epoch 433 Loss 1.03 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4985778138967899\n",
      "Epoch 434 Loss 1.03 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.5002031694433158\n",
      "Epoch 435 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4973587972368956\n",
      "Epoch 436 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49817147501015846\n",
      "Epoch 437 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4973587972368956\n",
      "Epoch 438 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4973587972368956\n",
      "Epoch 439 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4985778138967899\n",
      "Epoch 440 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49695245835026414\n",
      "Epoch 441 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49410808614384394\n",
      "Epoch 442 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4961397805770012\n",
      "Epoch 443 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4985778138967899\n",
      "Epoch 444 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4928890694839496\n",
      "Epoch 445 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.48923201950426654\n",
      "Epoch 446 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.497765136123527\n",
      "Epoch 447 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.49573344169036976\n",
      "Epoch 448 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4953271028037383\n",
      "Epoch 449 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4961397805770012\n",
      "Epoch 450 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4937017472572125\n",
      "Epoch 451 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4949207639171069\n",
      "Epoch 452 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49167005282405524\n",
      "Epoch 453 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49085737505079235\n",
      "Epoch 454 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49410808614384394\n",
      "Epoch 455 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 456 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49939049167005284\n",
      "Epoch 457 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 458 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4912637139374238\n",
      "Epoch 459 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.4973587972368956\n",
      "Epoch 460 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4965461194636327\n",
      "Epoch 461 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4973587972368956\n",
      "Epoch 462 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.5002031694433158\n",
      "Epoch 463 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49695245835026414\n",
      "Epoch 464 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4961397805770012\n",
      "Epoch 465 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 466 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4953271028037383\n",
      "Epoch 467 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.497765136123527\n",
      "Epoch 468 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4953271028037383\n",
      "Epoch 469 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4961397805770012\n",
      "Epoch 470 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49695245835026414\n",
      "Epoch 471 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49410808614384394\n",
      "Epoch 472 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.48841934173100365\n",
      "Epoch 473 Loss 1.03 | Train Accuracy 0.49105872790083316 | Val Accuracy 0.4965461194636327\n",
      "Epoch 474 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4953271028037383\n",
      "Epoch 475 Loss 1.02 | Train Accuracy 0.49410688884373094 | Val Accuracy 0.49695245835026414\n",
      "Epoch 476 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.497765136123527\n",
      "Epoch 477 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.497765136123527\n",
      "Epoch 478 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4965461194636327\n",
      "Epoch 479 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4973587972368956\n",
      "Epoch 480 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4985778138967899\n",
      "Epoch 481 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49939049167005284\n",
      "Epoch 482 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.497765136123527\n",
      "Epoch 483 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4953271028037383\n",
      "Epoch 484 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49451442503047544\n",
      "Epoch 485 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 486 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 487 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49573344169036976\n",
      "Epoch 488 Loss 1.02 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.497765136123527\n",
      "Epoch 489 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48841934173100365\n",
      "Epoch 490 Loss 1.02 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.49939049167005284\n",
      "Epoch 491 Loss 1.02 | Train Accuracy 0.49563096931517986 | Val Accuracy 0.49695245835026414\n",
      "Epoch 492 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49410808614384394\n",
      "Epoch 493 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49451442503047544\n",
      "Epoch 494 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4973587972368956\n",
      "Epoch 495 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4985778138967899\n",
      "Epoch 496 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4997968305566843\n",
      "Epoch 497 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4985778138967899\n",
      "Epoch 498 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4965461194636327\n",
      "Epoch 499 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4985778138967899\n",
      "Epoch 500 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4953271028037383\n",
      "Epoch 501 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49410808614384394\n",
      "Epoch 502 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4904510361641609\n",
      "Epoch 503 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 504 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4912637139374238\n",
      "Epoch 505 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4924827305973182\n",
      "Epoch 506 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.5006095083299472\n",
      "Epoch 507 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.49410808614384394\n",
      "Epoch 508 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49207639171068673\n",
      "Epoch 509 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4949207639171069\n",
      "Epoch 510 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4928890694839496\n",
      "Epoch 511 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49451442503047544\n",
      "Epoch 512 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49695245835026414\n",
      "Epoch 513 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49329540837058106\n",
      "Epoch 514 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4973587972368956\n",
      "Epoch 515 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4965461194636327\n",
      "Epoch 516 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4989841527834214\n",
      "Epoch 517 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4997968305566843\n",
      "Epoch 518 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4961397805770012\n",
      "Epoch 519 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4949207639171069\n",
      "Epoch 520 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49817147501015846\n",
      "Epoch 521 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4924827305973182\n",
      "Epoch 522 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4949207639171069\n",
      "Epoch 523 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4961397805770012\n",
      "Epoch 524 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4937017472572125\n",
      "Epoch 525 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.48679398618447783\n",
      "Epoch 526 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.48963835839089803\n",
      "Epoch 527 Loss 1.02 | Train Accuracy 0.49380207274944116 | Val Accuracy 0.4989841527834214\n",
      "Epoch 528 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4989841527834214\n",
      "Epoch 529 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.4965461194636327\n",
      "Epoch 530 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.49695245835026414\n",
      "Epoch 531 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49573344169036976\n",
      "Epoch 532 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49695245835026414\n",
      "Epoch 533 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4949207639171069\n",
      "Epoch 534 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 535 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49329540837058106\n",
      "Epoch 536 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 537 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49817147501015846\n",
      "Epoch 538 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4928890694839496\n",
      "Epoch 539 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4888256806176351\n",
      "Epoch 540 Loss 1.02 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.4985778138967899\n",
      "Epoch 541 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4973587972368956\n",
      "Epoch 542 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4985778138967899\n",
      "Epoch 543 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49817147501015846\n",
      "Epoch 544 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4973587972368956\n",
      "Epoch 545 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 546 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4961397805770012\n",
      "Epoch 547 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4953271028037383\n",
      "Epoch 548 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 549 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 550 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4965461194636327\n",
      "Epoch 551 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49573344169036976\n",
      "Epoch 552 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 553 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4904510361641609\n",
      "Epoch 554 Loss 1.03 | Train Accuracy 0.49380207274944116 | Val Accuracy 0.4973587972368956\n",
      "Epoch 555 Loss 1.02 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.49695245835026414\n",
      "Epoch 556 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.49695245835026414\n",
      "Epoch 557 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.497765136123527\n",
      "Epoch 558 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49695245835026414\n",
      "Epoch 559 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4985778138967899\n",
      "Epoch 560 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49939049167005284\n",
      "Epoch 561 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4965461194636327\n",
      "Epoch 562 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49695245835026414\n",
      "Epoch 563 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4965461194636327\n",
      "Epoch 564 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.497765136123527\n",
      "Epoch 565 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49695245835026414\n",
      "Epoch 566 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4985778138967899\n",
      "Epoch 567 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.48679398618447783\n",
      "Epoch 568 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4989841527834214\n",
      "Epoch 569 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4989841527834214\n",
      "Epoch 570 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4965461194636327\n",
      "Epoch 571 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4965461194636327\n",
      "Epoch 572 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49695245835026414\n",
      "Epoch 573 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4985778138967899\n",
      "Epoch 574 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4973587972368956\n",
      "Epoch 575 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4985778138967899\n",
      "Epoch 576 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49695245835026414\n",
      "Epoch 577 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4949207639171069\n",
      "Epoch 578 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 579 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49573344169036976\n",
      "Epoch 580 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 581 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49817147501015846\n",
      "Epoch 582 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 583 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.48679398618447783\n",
      "Epoch 584 Loss 1.03 | Train Accuracy 0.4925828083722821 | Val Accuracy 0.4924827305973182\n",
      "Epoch 585 Loss 1.02 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.4953271028037383\n",
      "Epoch 586 Loss 1.02 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.497765136123527\n",
      "Epoch 587 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4997968305566843\n",
      "Epoch 588 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49695245835026414\n",
      "Epoch 589 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4985778138967899\n",
      "Epoch 590 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4973587972368956\n",
      "Epoch 591 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4997968305566843\n",
      "Epoch 592 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4973587972368956\n",
      "Epoch 593 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49329540837058106\n",
      "Epoch 594 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49410808614384394\n",
      "Epoch 595 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4949207639171069\n",
      "Epoch 596 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49695245835026414\n",
      "Epoch 597 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4965461194636327\n",
      "Epoch 598 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4985778138967899\n",
      "Epoch 599 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.48029256399837467\n",
      "Epoch 600 Loss 1.03 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.4961397805770012\n",
      "Epoch 601 Loss 1.03 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.4973587972368956\n",
      "Epoch 602 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.49695245835026414\n",
      "Epoch 603 Loss 1.03 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.49695245835026414\n",
      "Epoch 604 Loss 1.03 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4989841527834214\n",
      "Epoch 605 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.497765136123527\n",
      "Epoch 606 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.497765136123527\n",
      "Epoch 607 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4953271028037383\n",
      "Epoch 608 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49817147501015846\n",
      "Epoch 609 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4985778138967899\n",
      "Epoch 610 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4953271028037383\n",
      "Epoch 611 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4953271028037383\n",
      "Epoch 612 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49817147501015846\n",
      "Epoch 613 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "Epoch 614 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4985778138967899\n",
      "Epoch 615 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 616 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4949207639171069\n",
      "Epoch 617 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4953271028037383\n",
      "Epoch 618 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4937017472572125\n",
      "Epoch 619 Loss 1.02 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.4949207639171069\n",
      "Epoch 620 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.49207639171068673\n",
      "Epoch 621 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4949207639171069\n",
      "Epoch 622 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4973587972368956\n",
      "Epoch 623 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49695245835026414\n",
      "Epoch 624 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4973587972368956\n",
      "Epoch 625 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4949207639171069\n",
      "Epoch 626 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4937017472572125\n",
      "Epoch 627 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49451442503047544\n",
      "Epoch 628 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4949207639171069\n",
      "Epoch 629 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4900446972775295\n",
      "Epoch 630 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48516863063795207\n",
      "Epoch 631 Loss 1.03 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.48963835839089803\n",
      "Epoch 632 Loss 1.03 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.4928890694839496\n",
      "Epoch 633 Loss 1.03 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.4965461194636327\n",
      "Epoch 634 Loss 1.03 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4973587972368956\n",
      "Epoch 635 Loss 1.03 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4985778138967899\n",
      "Epoch 636 Loss 1.03 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49817147501015846\n",
      "Epoch 637 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.497765136123527\n",
      "Epoch 638 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4973587972368956\n",
      "Epoch 639 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49817147501015846\n",
      "Epoch 640 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4961397805770012\n",
      "Epoch 641 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49817147501015846\n",
      "Epoch 642 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4961397805770012\n",
      "Epoch 643 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49410808614384394\n",
      "Epoch 644 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 645 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "Epoch 646 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4965461194636327\n",
      "Epoch 647 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4924827305973182\n",
      "Epoch 648 Loss 1.02 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.48760666395774077\n",
      "Epoch 649 Loss 1.03 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.49451442503047544\n",
      "Epoch 650 Loss 1.02 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.49695245835026414\n",
      "Epoch 651 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49817147501015846\n",
      "Epoch 652 Loss 1.02 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.4989841527834214\n",
      "Epoch 653 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4965461194636327\n",
      "Epoch 654 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49695245835026414\n",
      "Epoch 655 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49573344169036976\n",
      "Epoch 656 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49695245835026414\n",
      "Epoch 657 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49451442503047544\n",
      "Epoch 658 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4973587972368956\n",
      "Epoch 659 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4953271028037383\n",
      "Epoch 660 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49695245835026414\n",
      "Epoch 661 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49329540837058106\n",
      "Epoch 662 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.48679398618447783\n",
      "Epoch 663 Loss 1.03 | Train Accuracy 0.49055070107701687 | Val Accuracy 0.4961397805770012\n",
      "Epoch 664 Loss 1.02 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.49329540837058106\n",
      "Epoch 665 Loss 1.03 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.4973587972368956\n",
      "Epoch 666 Loss 1.03 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.49695245835026414\n",
      "Epoch 667 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49939049167005284\n",
      "Epoch 668 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4973587972368956\n",
      "Epoch 669 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 670 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49695245835026414\n",
      "Epoch 671 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4965461194636327\n",
      "Epoch 672 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4924827305973182\n",
      "Epoch 673 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49410808614384394\n",
      "Epoch 674 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4953271028037383\n",
      "Epoch 675 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49573344169036976\n",
      "Epoch 676 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49573344169036976\n",
      "Epoch 677 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4912637139374238\n",
      "Epoch 678 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.48841934173100365\n",
      "Epoch 679 Loss 1.03 | Train Accuracy 0.492176386913229 | Val Accuracy 0.49939049167005284\n",
      "Epoch 680 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.4965461194636327\n",
      "Epoch 681 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4985778138967899\n",
      "Epoch 682 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4985778138967899\n",
      "Epoch 683 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4961397805770012\n",
      "Epoch 684 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.497765136123527\n",
      "Epoch 685 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49939049167005284\n",
      "Epoch 686 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4961397805770012\n",
      "Epoch 687 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4953271028037383\n",
      "Epoch 688 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 689 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4961397805770012\n",
      "Epoch 690 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4965461194636327\n",
      "Epoch 691 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4912637139374238\n",
      "Epoch 692 Loss 1.03 | Train Accuracy 0.4922779922779923 | Val Accuracy 0.4953271028037383\n",
      "Epoch 693 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4965461194636327\n",
      "Epoch 694 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.5002031694433158\n",
      "Epoch 695 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4989841527834214\n",
      "Epoch 696 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4985778138967899\n",
      "Epoch 697 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49939049167005284\n",
      "Epoch 698 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.49817147501015846\n",
      "Epoch 699 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49451442503047544\n",
      "Epoch 700 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49695245835026414\n",
      "Epoch 701 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49695245835026414\n",
      "Epoch 702 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4961397805770012\n",
      "Epoch 703 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 704 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.497765136123527\n",
      "Epoch 705 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49817147501015846\n",
      "Epoch 706 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49167005282405524\n",
      "Epoch 707 Loss 1.02 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.49939049167005284\n",
      "Epoch 708 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4985778138967899\n",
      "Epoch 709 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4973587972368956\n",
      "Epoch 710 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4973587972368956\n",
      "Epoch 711 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4973587972368956\n",
      "Epoch 712 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49451442503047544\n",
      "Epoch 713 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 714 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4965461194636327\n",
      "Epoch 715 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "Epoch 716 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4985778138967899\n",
      "Epoch 717 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4961397805770012\n",
      "Epoch 718 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4953271028037383\n",
      "Epoch 719 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.49410808614384394\n",
      "Epoch 720 Loss 1.02 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.49451442503047544\n",
      "Epoch 721 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49695245835026414\n",
      "Epoch 722 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4973587972368956\n",
      "Epoch 723 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.497765136123527\n",
      "Epoch 724 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4973587972368956\n",
      "Epoch 725 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4997968305566843\n",
      "Epoch 726 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4985778138967899\n",
      "Epoch 727 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4997968305566843\n",
      "Epoch 728 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49939049167005284\n",
      "Epoch 729 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.497765136123527\n",
      "Epoch 730 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 731 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4997968305566843\n",
      "Epoch 732 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49695245835026414\n",
      "Epoch 733 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4961397805770012\n",
      "Epoch 734 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49573344169036976\n",
      "Epoch 735 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49329540837058106\n",
      "Epoch 736 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4949207639171069\n",
      "Epoch 737 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4953271028037383\n",
      "Epoch 738 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4989841527834214\n",
      "Epoch 739 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4985778138967899\n",
      "Epoch 740 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.5006095083299472\n",
      "Epoch 741 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 742 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "Epoch 743 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4973587972368956\n",
      "Epoch 744 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49207639171068673\n",
      "Epoch 745 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49817147501015846\n",
      "Epoch 746 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4985778138967899\n",
      "Epoch 747 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4965461194636327\n",
      "Epoch 748 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49817147501015846\n",
      "Epoch 749 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49817147501015846\n",
      "Epoch 750 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4989841527834214\n",
      "Epoch 751 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49451442503047544\n",
      "Epoch 752 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4989841527834214\n",
      "Epoch 753 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49573344169036976\n",
      "Epoch 754 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4953271028037383\n",
      "Epoch 755 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4953271028037383\n",
      "Epoch 756 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 757 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4961397805770012\n",
      "Epoch 758 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.5002031694433158\n",
      "Epoch 759 Loss 1.02 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4973587972368956\n",
      "Epoch 760 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49939049167005284\n",
      "Epoch 761 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4953271028037383\n",
      "Epoch 762 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49573344169036976\n",
      "Epoch 763 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4961397805770012\n",
      "Epoch 764 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49695245835026414\n",
      "Epoch 765 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4985778138967899\n",
      "Epoch 766 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4985778138967899\n",
      "Epoch 767 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4989841527834214\n",
      "Epoch 768 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49695245835026414\n",
      "Epoch 769 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4997968305566843\n",
      "Epoch 770 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49695245835026414\n",
      "Epoch 771 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4985778138967899\n",
      "Epoch 772 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 773 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.497765136123527\n",
      "Epoch 774 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "Epoch 775 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49573344169036976\n",
      "Epoch 776 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4961397805770012\n",
      "Epoch 777 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.5002031694433158\n",
      "Epoch 778 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 779 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.5002031694433158\n",
      "Epoch 780 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4961397805770012\n",
      "Epoch 781 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49695245835026414\n",
      "Epoch 782 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 783 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49573344169036976\n",
      "Epoch 784 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4949207639171069\n",
      "Epoch 785 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.5006095083299472\n",
      "Epoch 786 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49573344169036976\n",
      "Epoch 787 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.4953271028037383\n",
      "Epoch 788 Loss 1.02 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.49939049167005284\n",
      "Epoch 789 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.49817147501015846\n",
      "Epoch 790 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.497765136123527\n",
      "Epoch 791 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4973587972368956\n",
      "Epoch 792 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4989841527834214\n",
      "Epoch 793 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 794 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49573344169036976\n",
      "Epoch 795 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4949207639171069\n",
      "Epoch 796 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49573344169036976\n",
      "Epoch 797 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 798 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.5002031694433158\n",
      "Epoch 799 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "Epoch 800 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4904510361641609\n",
      "Epoch 801 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49167005282405524\n",
      "Epoch 802 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4949207639171069\n",
      "Epoch 803 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49410808614384394\n",
      "Epoch 804 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4949207639171069\n",
      "Epoch 805 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49085737505079235\n",
      "Epoch 806 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49410808614384394\n",
      "Epoch 807 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 808 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49573344169036976\n",
      "Epoch 809 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49817147501015846\n",
      "Epoch 810 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.497765136123527\n",
      "Epoch 811 Loss 1.02 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49451442503047544\n",
      "Epoch 812 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4912637139374238\n",
      "Epoch 813 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.49695245835026414\n",
      "Epoch 814 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49573344169036976\n",
      "Epoch 815 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49695245835026414\n",
      "Epoch 816 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4949207639171069\n",
      "Epoch 817 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.49451442503047544\n",
      "Epoch 818 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49573344169036976\n",
      "Epoch 819 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49329540837058106\n",
      "Epoch 820 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 821 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4965461194636327\n",
      "Epoch 822 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4953271028037383\n",
      "Epoch 823 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4912637139374238\n",
      "Epoch 824 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4839496139780577\n",
      "Epoch 825 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4953271028037383\n",
      "Epoch 826 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.49573344169036976\n",
      "Epoch 827 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.497765136123527\n",
      "Epoch 828 Loss 1.02 | Train Accuracy 0.49563096931517986 | Val Accuracy 0.4985778138967899\n",
      "Epoch 829 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.5006095083299472\n",
      "Epoch 830 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4965461194636327\n",
      "Epoch 831 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49695245835026414\n",
      "Epoch 832 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.497765136123527\n",
      "Epoch 833 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4965461194636327\n",
      "Epoch 834 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49451442503047544\n",
      "Epoch 835 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49695245835026414\n",
      "Epoch 836 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4961397805770012\n",
      "Epoch 837 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49573344169036976\n",
      "Epoch 838 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.48841934173100365\n",
      "Epoch 839 Loss 1.03 | Train Accuracy 0.49085551717130665 | Val Accuracy 0.48232425843153187\n",
      "Epoch 840 Loss 1.03 | Train Accuracy 0.49329404592562487 | Val Accuracy 0.4912637139374238\n",
      "Epoch 841 Loss 1.03 | Train Accuracy 0.4931924405608616 | Val Accuracy 0.49085737505079235\n",
      "Epoch 842 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.49573344169036976\n",
      "Epoch 843 Loss 1.03 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.49410808614384394\n",
      "Epoch 844 Loss 1.03 | Train Accuracy 0.49288762446657186 | Val Accuracy 0.4973587972368956\n",
      "Epoch 845 Loss 1.03 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.4997968305566843\n",
      "Epoch 846 Loss 1.03 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4985778138967899\n",
      "Epoch 847 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.5002031694433158\n",
      "Epoch 848 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49817147501015846\n",
      "Epoch 849 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49817147501015846\n",
      "Epoch 850 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4973587972368956\n",
      "Epoch 851 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49939049167005284\n",
      "Epoch 852 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4965461194636327\n",
      "Epoch 853 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4973587972368956\n",
      "Epoch 854 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4953271028037383\n",
      "Epoch 855 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4900446972775295\n",
      "Epoch 856 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4985778138967899\n",
      "Epoch 857 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4973587972368956\n",
      "Epoch 858 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4989841527834214\n",
      "Epoch 859 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4965461194636327\n",
      "Epoch 860 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4924827305973182\n",
      "Epoch 861 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49329540837058106\n",
      "Epoch 862 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49451442503047544\n",
      "Epoch 863 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49329540837058106\n",
      "Epoch 864 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4953271028037383\n",
      "Epoch 865 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.497765136123527\n",
      "Epoch 866 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49410808614384394\n",
      "Epoch 867 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49410808614384394\n",
      "Epoch 868 Loss 1.02 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.4985778138967899\n",
      "Epoch 869 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49573344169036976\n",
      "Epoch 870 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4985778138967899\n",
      "Epoch 871 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4965461194636327\n",
      "Epoch 872 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4985778138967899\n",
      "Epoch 873 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49410808614384394\n",
      "Epoch 874 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4949207639171069\n",
      "Epoch 875 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4949207639171069\n",
      "Epoch 876 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49817147501015846\n",
      "Epoch 877 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49573344169036976\n",
      "Epoch 878 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4953271028037383\n",
      "Epoch 879 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4973587972368956\n",
      "Epoch 880 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48516863063795207\n",
      "Epoch 881 Loss 1.03 | Train Accuracy 0.49380207274944116 | Val Accuracy 0.49451442503047544\n",
      "Epoch 882 Loss 1.03 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.4928890694839496\n",
      "Epoch 883 Loss 1.03 | Train Accuracy 0.49563096931517986 | Val Accuracy 0.49573344169036976\n",
      "Epoch 884 Loss 1.03 | Train Accuracy 0.4934972566551514 | Val Accuracy 0.497765136123527\n",
      "Epoch 885 Loss 1.03 | Train Accuracy 0.4950213371266003 | Val Accuracy 0.4973587972368956\n",
      "Epoch 886 Loss 1.03 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4961397805770012\n",
      "Epoch 887 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49573344169036976\n",
      "Epoch 888 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.497765136123527\n",
      "Epoch 889 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4973587972368956\n",
      "Epoch 890 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 891 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49695245835026414\n",
      "Epoch 892 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4961397805770012\n",
      "Epoch 893 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4961397805770012\n",
      "Epoch 894 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4937017472572125\n",
      "Epoch 895 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4949207639171069\n",
      "Epoch 896 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49695245835026414\n",
      "Epoch 897 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.48435595286468913\n",
      "Epoch 898 Loss 1.03 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.5006095083299472\n",
      "Epoch 899 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49817147501015846\n",
      "Epoch 900 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.49573344169036976\n",
      "Epoch 901 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4989841527834214\n",
      "Epoch 902 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4961397805770012\n",
      "Epoch 903 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49410808614384394\n",
      "Epoch 904 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49573344169036976\n",
      "Epoch 905 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4953271028037383\n",
      "Epoch 906 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4928890694839496\n",
      "Epoch 907 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4949207639171069\n",
      "Epoch 908 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4937017472572125\n",
      "Epoch 909 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.497765136123527\n",
      "Epoch 910 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4997968305566843\n",
      "Epoch 911 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.481511580658269\n",
      "Epoch 912 Loss 1.03 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.5018285249898415\n",
      "Epoch 913 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4997968305566843\n",
      "Epoch 914 Loss 1.03 | Train Accuracy 0.497256655151392 | Val Accuracy 0.49573344169036976\n",
      "Epoch 915 Loss 1.03 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.49695245835026414\n",
      "Epoch 916 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4973587972368956\n",
      "Epoch 917 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49695245835026414\n",
      "Epoch 918 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4973587972368956\n",
      "Epoch 919 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4997968305566843\n",
      "Epoch 920 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4965461194636327\n",
      "Epoch 921 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "Epoch 922 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4949207639171069\n",
      "Epoch 923 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 924 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4949207639171069\n",
      "Epoch 925 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4973587972368956\n",
      "Epoch 926 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49329540837058106\n",
      "Epoch 927 Loss 1.02 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4985778138967899\n",
      "Epoch 928 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48841934173100365\n",
      "Epoch 929 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4961397805770012\n",
      "Epoch 930 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4953271028037383\n",
      "Epoch 931 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4949207639171069\n",
      "Epoch 932 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4928890694839496\n",
      "Epoch 933 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4973587972368956\n",
      "Epoch 934 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 935 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4965461194636327\n",
      "Epoch 936 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 937 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49573344169036976\n",
      "Epoch 938 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49695245835026414\n",
      "Epoch 939 Loss 1.02 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4888256806176351\n",
      "Epoch 940 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.48110524177163755\n",
      "Epoch 941 Loss 1.03 | Train Accuracy 0.49126193863035966 | Val Accuracy 0.49167005282405524\n",
      "Epoch 942 Loss 1.02 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.4973587972368956\n",
      "Epoch 943 Loss 1.03 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.49695245835026414\n",
      "Epoch 944 Loss 1.03 | Train Accuracy 0.4934972566551514 | Val Accuracy 0.49410808614384394\n",
      "Epoch 945 Loss 1.03 | Train Accuracy 0.49329404592562487 | Val Accuracy 0.4973587972368956\n",
      "Epoch 946 Loss 1.03 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.49573344169036976\n",
      "Epoch 947 Loss 1.03 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4985778138967899\n",
      "Epoch 948 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.497765136123527\n",
      "Epoch 949 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4985778138967899\n",
      "Epoch 950 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4985778138967899\n",
      "Epoch 951 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4989841527834214\n",
      "Epoch 952 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4989841527834214\n",
      "Epoch 953 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 954 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4953271028037383\n",
      "Epoch 955 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4973587972368956\n",
      "Epoch 956 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4949207639171069\n",
      "Epoch 957 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4904510361641609\n",
      "Epoch 958 Loss 1.03 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.4985778138967899\n",
      "Epoch 959 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4949207639171069\n",
      "Epoch 960 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.49451442503047544\n",
      "Epoch 961 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49329540837058106\n",
      "Epoch 962 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4961397805770012\n",
      "Epoch 963 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49695245835026414\n",
      "Epoch 964 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.497765136123527\n",
      "Epoch 965 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49167005282405524\n",
      "Epoch 966 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49451442503047544\n",
      "Epoch 967 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4965461194636327\n",
      "Epoch 968 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4953271028037383\n",
      "Epoch 969 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 970 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49167005282405524\n",
      "Epoch 971 Loss 1.03 | Train Accuracy 0.4925828083722821 | Val Accuracy 0.48232425843153187\n",
      "Epoch 972 Loss 1.03 | Train Accuracy 0.4927860191018086 | Val Accuracy 0.4924827305973182\n",
      "Epoch 973 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.4965461194636327\n",
      "Epoch 974 Loss 1.03 | Train Accuracy 0.49339565129038815 | Val Accuracy 0.49329540837058106\n",
      "Epoch 975 Loss 1.03 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.4965461194636327\n",
      "Epoch 976 Loss 1.03 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.4985778138967899\n",
      "Epoch 977 Loss 1.03 | Train Accuracy 0.49563096931517986 | Val Accuracy 0.49817147501015846\n",
      "Epoch 978 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.497765136123527\n",
      "Epoch 979 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4973587972368956\n",
      "Epoch 980 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4965461194636327\n",
      "Epoch 981 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49573344169036976\n",
      "Epoch 982 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4965461194636327\n",
      "Epoch 983 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4937017472572125\n",
      "Epoch 984 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49573344169036976\n",
      "Epoch 985 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 986 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4973587972368956\n",
      "Epoch 987 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4985778138967899\n",
      "Epoch 988 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4937017472572125\n",
      "Epoch 989 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49817147501015846\n",
      "Epoch 990 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4985778138967899\n",
      "Epoch 991 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.5006095083299472\n",
      "Epoch 992 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49329540837058106\n",
      "Epoch 993 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4928890694839496\n",
      "Epoch 994 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 995 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4949207639171069\n",
      "Epoch 996 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4928890694839496\n",
      "Epoch 997 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49695245835026414\n",
      "Epoch 998 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4965461194636327\n",
      "Epoch 999 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1000 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1001 Loss 1.03 | Train Accuracy 0.494513310302784 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1002 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1003 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1004 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1005 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1006 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1007 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1008 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.497765136123527\n",
      "Epoch 1009 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.497765136123527\n",
      "Epoch 1010 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1011 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1012 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1013 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1014 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1015 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1016 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1017 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1018 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1019 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1020 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1021 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1022 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.497765136123527\n",
      "Epoch 1023 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1024 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1025 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1026 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1027 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1028 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1029 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1030 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1031 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1032 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1033 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1034 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1035 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1036 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1037 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1038 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1039 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1040 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1041 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1042 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1043 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1044 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1045 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1046 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1047 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1048 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1049 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1050 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1051 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1052 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1053 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1054 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1055 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1056 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1057 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1058 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1059 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1060 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1061 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1062 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1063 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1064 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1065 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1066 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1067 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1068 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1069 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1070 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1071 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1072 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1073 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1074 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1075 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1076 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.497765136123527\n",
      "Epoch 1077 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4855749695245835\n",
      "Epoch 1078 Loss 1.03 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1079 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1080 Loss 1.03 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1081 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1082 Loss 1.03 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1083 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1084 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1085 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1086 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1087 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1088 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1089 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1090 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1091 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1092 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1093 Loss 1.03 | Train Accuracy 0.49329404592562487 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1094 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1095 Loss 1.02 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1096 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1097 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1098 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1099 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1100 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1101 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1102 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1103 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1104 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1105 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1106 Loss 1.02 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1107 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1108 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1109 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.497765136123527\n",
      "Epoch 1110 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.497765136123527\n",
      "Epoch 1111 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1112 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1113 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.497765136123527\n",
      "Epoch 1114 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1115 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1116 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1117 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1118 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1119 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1120 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1121 Loss 1.02 | Train Accuracy 0.4950213371266003 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1122 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1123 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1124 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1125 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1126 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1127 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1128 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1129 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1130 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1131 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.5006095083299472\n",
      "Epoch 1132 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1133 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1134 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1135 Loss 1.02 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1136 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.497765136123527\n",
      "Epoch 1137 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1138 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1139 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1140 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1141 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1142 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1143 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1144 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1145 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1146 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1147 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1148 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1149 Loss 1.03 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1150 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1151 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1152 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1153 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.497765136123527\n",
      "Epoch 1154 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1155 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1156 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1157 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1158 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1159 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1160 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1161 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4855749695245835\n",
      "Epoch 1162 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1163 Loss 1.03 | Train Accuracy 0.4934972566551514 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1164 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1165 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.497765136123527\n",
      "Epoch 1166 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1167 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1168 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1169 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1170 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.497765136123527\n",
      "Epoch 1171 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1172 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1173 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1174 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.497765136123527\n",
      "Epoch 1175 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1176 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1177 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1178 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1179 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1180 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1181 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1182 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1183 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1184 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1185 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1186 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1187 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1188 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1189 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1190 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1191 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1192 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.497765136123527\n",
      "Epoch 1193 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1194 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1195 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1196 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.497765136123527\n",
      "Epoch 1197 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.5006095083299472\n",
      "Epoch 1198 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1199 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1200 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1201 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1202 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1203 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1204 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1205 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1206 Loss 1.02 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1207 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1208 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1209 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1210 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1211 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1212 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1213 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1214 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1215 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.497765136123527\n",
      "Epoch 1216 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1217 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1218 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1219 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1220 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1221 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1222 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1223 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1224 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1225 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1226 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.497765136123527\n",
      "Epoch 1227 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1228 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1229 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1230 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1231 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1232 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1233 Loss 1.03 | Train Accuracy 0.49410688884373094 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1234 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1235 Loss 1.03 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.497765136123527\n",
      "Epoch 1236 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1237 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.497765136123527\n",
      "Epoch 1238 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1239 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1240 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1241 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1242 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1243 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1244 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1245 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1246 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.48679398618447783\n",
      "Epoch 1247 Loss 1.03 | Train Accuracy 0.49105872790083316 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1248 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1249 Loss 1.03 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1250 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1251 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1252 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1253 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.497765136123527\n",
      "Epoch 1254 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1255 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1256 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1257 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1258 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.497765136123527\n",
      "Epoch 1259 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1260 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.48598130841121495\n",
      "Epoch 1261 Loss 1.03 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1262 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.497765136123527\n",
      "Epoch 1263 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1264 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1265 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1266 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1267 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1268 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1269 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1270 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1271 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1272 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1273 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.497765136123527\n",
      "Epoch 1274 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.5010158472165787\n",
      "Epoch 1275 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1276 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1277 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.497765136123527\n",
      "Epoch 1278 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1279 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1280 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1281 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1282 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1283 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1284 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1285 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1286 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1287 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.497765136123527\n",
      "Epoch 1288 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1289 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1290 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1291 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1292 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1293 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1294 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1295 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1296 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.497765136123527\n",
      "Epoch 1297 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1298 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1299 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1300 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1301 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1302 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1303 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.497765136123527\n",
      "Epoch 1304 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1305 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1306 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1307 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1308 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1309 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1310 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1311 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1312 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1313 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1314 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1315 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1316 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1317 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1318 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1319 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1320 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1321 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1322 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1323 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1324 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1325 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1326 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1327 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1328 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.497765136123527\n",
      "Epoch 1329 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.497765136123527\n",
      "Epoch 1330 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1331 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1332 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1333 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1334 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1335 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1336 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1337 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1338 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1339 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1340 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1341 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1342 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.497765136123527\n",
      "Epoch 1343 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1344 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1345 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1346 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1347 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1348 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1349 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1350 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1351 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1352 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1353 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1354 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1355 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1356 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1357 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1358 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1359 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1360 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1361 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1362 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.497765136123527\n",
      "Epoch 1363 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1364 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1365 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1366 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1367 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1368 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1369 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1370 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1371 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1372 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1373 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1374 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1375 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1376 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1377 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1378 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1379 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1380 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.497765136123527\n",
      "Epoch 1381 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1382 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1383 Loss 1.02 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1384 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1385 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1386 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1387 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1388 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1389 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1390 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1391 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1392 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1393 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1394 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1395 Loss 1.02 | Train Accuracy 0.4931924405608616 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1396 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.5006095083299472\n",
      "Epoch 1397 Loss 1.02 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1398 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1399 Loss 1.02 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1400 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1401 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.497765136123527\n",
      "Epoch 1402 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1403 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1404 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1405 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1406 Loss 1.02 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1407 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1408 Loss 1.02 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1409 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1410 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.48476229175132063\n",
      "Epoch 1411 Loss 1.03 | Train Accuracy 0.49288762446657186 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1412 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1413 Loss 1.02 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1414 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1415 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1416 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1417 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1418 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.497765136123527\n",
      "Epoch 1419 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1420 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1421 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1422 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1423 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1424 Loss 1.02 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1425 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4839496139780577\n",
      "Epoch 1426 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1427 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1428 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1429 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1430 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1431 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1432 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1433 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1434 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1435 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1436 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1437 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1438 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1439 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1440 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1441 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1442 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1443 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1444 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.497765136123527\n",
      "Epoch 1445 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1446 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1447 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1448 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1449 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1450 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1451 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1452 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1453 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1454 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1455 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1456 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1457 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1458 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1459 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.497765136123527\n",
      "Epoch 1460 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1461 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.497765136123527\n",
      "Epoch 1462 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1463 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1464 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1465 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1466 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1467 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1468 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1469 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1470 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1471 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1472 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1473 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1474 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1475 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1476 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1477 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1478 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1479 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1480 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1481 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1482 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1483 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1484 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.497765136123527\n",
      "Epoch 1485 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.497765136123527\n",
      "Epoch 1486 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1487 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1488 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1489 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1490 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1491 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.497765136123527\n",
      "Epoch 1492 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1493 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1494 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1495 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1496 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1497 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1498 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1499 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1500 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1501 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.5018285249898415\n",
      "Epoch 1502 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1503 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1504 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1505 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1506 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1507 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1508 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1509 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1510 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1511 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1512 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4839496139780577\n",
      "Epoch 1513 Loss 1.03 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1514 Loss 1.03 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1515 Loss 1.03 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1516 Loss 1.03 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1517 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1518 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1519 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1520 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1521 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1522 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1523 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1524 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1525 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1526 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1527 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1528 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1529 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1530 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1531 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1532 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.497765136123527\n",
      "Epoch 1533 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1534 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1535 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1536 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.497765136123527\n",
      "Epoch 1537 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1538 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1539 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1540 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1541 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1542 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1543 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1544 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1545 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1546 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1547 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1548 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1549 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1550 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1551 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1552 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1553 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1554 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1555 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1556 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1557 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1558 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1559 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1560 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1561 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1562 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.497765136123527\n",
      "Epoch 1563 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1564 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.497765136123527\n",
      "Epoch 1565 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.497765136123527\n",
      "Epoch 1566 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1567 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.497765136123527\n",
      "Epoch 1568 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1569 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1570 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1571 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1572 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1573 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1574 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1575 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1576 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.497765136123527\n",
      "Epoch 1577 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1578 Loss 1.02 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.497765136123527\n",
      "Epoch 1579 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1580 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1581 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1582 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1583 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1584 Loss 1.03 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1585 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1586 Loss 1.03 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1587 Loss 1.03 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1588 Loss 1.03 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1589 Loss 1.02 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1590 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1591 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1592 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1593 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1594 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.497765136123527\n",
      "Epoch 1595 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1596 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1597 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.497765136123527\n",
      "Epoch 1598 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1599 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1600 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1601 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48516863063795207\n",
      "Epoch 1602 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1603 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1604 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1605 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1606 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1607 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1608 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1609 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1610 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1611 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1612 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.497765136123527\n",
      "Epoch 1613 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1614 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1615 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1616 Loss 1.02 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1617 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1618 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1619 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1620 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1621 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1622 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1623 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1624 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1625 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1626 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1627 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1628 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1629 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1630 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1631 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1632 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1633 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1634 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1635 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1636 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1637 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1638 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1639 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.497765136123527\n",
      "Epoch 1640 Loss 1.02 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1641 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1642 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1643 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1644 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1645 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1646 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4729784640390085\n",
      "Epoch 1647 Loss 1.03 | Train Accuracy 0.4806949806949807 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1648 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1649 Loss 1.03 | Train Accuracy 0.4931924405608616 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1650 Loss 1.03 | Train Accuracy 0.4926844137370453 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1651 Loss 1.03 | Train Accuracy 0.49034749034749037 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1652 Loss 1.03 | Train Accuracy 0.49207478154846573 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1653 Loss 1.03 | Train Accuracy 0.494919731761837 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1654 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1655 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1656 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1657 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1658 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.497765136123527\n",
      "Epoch 1659 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1660 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1661 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.497765136123527\n",
      "Epoch 1662 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1663 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1664 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1665 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1666 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1667 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1668 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1669 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.497765136123527\n",
      "Epoch 1670 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1671 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1672 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1673 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1674 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1675 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1676 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1677 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1678 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1679 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1680 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1681 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1682 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1683 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1684 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1685 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.497765136123527\n",
      "Epoch 1686 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1687 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1688 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4855749695245835\n",
      "Epoch 1689 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1690 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1691 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1692 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1693 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1694 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1695 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1696 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1697 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1698 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1699 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1700 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1701 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1702 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1703 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1704 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1705 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1706 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1707 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1708 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1709 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1710 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1711 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1712 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1713 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1714 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1715 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1716 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1717 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1718 Loss 1.02 | Train Accuracy 0.494919731761837 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1719 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1720 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1721 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1722 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.497765136123527\n",
      "Epoch 1723 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1724 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1725 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1726 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1727 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1728 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1729 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1730 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1731 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1732 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1733 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1734 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1735 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1736 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1737 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1738 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1739 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.48598130841121495\n",
      "Epoch 1740 Loss 1.03 | Train Accuracy 0.4926844137370453 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1741 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1742 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1743 Loss 1.03 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1744 Loss 1.03 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.497765136123527\n",
      "Epoch 1745 Loss 1.03 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1746 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1747 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1748 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1749 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1750 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1751 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1752 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1753 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1754 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1755 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1756 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1757 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1758 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1759 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1760 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1761 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1762 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4839496139780577\n",
      "Epoch 1763 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1764 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1765 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1766 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1767 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1768 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1769 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1770 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1771 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1772 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1773 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1774 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1775 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1776 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1777 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1778 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1779 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1780 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1781 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1782 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.48679398618447783\n",
      "Epoch 1783 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1784 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1785 Loss 1.02 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1786 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1787 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1788 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1789 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1790 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1791 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1792 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1793 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1794 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1795 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1796 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1797 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1798 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1799 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1800 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1801 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1802 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1803 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1804 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1805 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1806 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1807 Loss 1.02 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.497765136123527\n",
      "Epoch 1808 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1809 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1810 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1811 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1812 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.497765136123527\n",
      "Epoch 1813 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1814 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1815 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1816 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1817 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1818 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1819 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1820 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1821 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1822 Loss 1.03 | Train Accuracy 0.4914651493598862 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1823 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1824 Loss 1.03 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1825 Loss 1.03 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1826 Loss 1.03 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1827 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1828 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1829 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1830 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1831 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.5006095083299472\n",
      "Epoch 1832 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1833 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1834 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1835 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1836 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1837 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1838 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1839 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1840 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1841 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1842 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1843 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1844 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1845 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1846 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.47947988622511173\n",
      "Epoch 1847 Loss 1.03 | Train Accuracy 0.49034749034749037 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1848 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1849 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1850 Loss 1.03 | Train Accuracy 0.4919731761837025 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1851 Loss 1.03 | Train Accuracy 0.4927860191018086 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1852 Loss 1.03 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1853 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1854 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1855 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1856 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1857 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1858 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1859 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1860 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1861 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1862 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1863 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1864 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1865 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1866 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1867 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1868 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1869 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1870 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1871 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1872 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1873 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1874 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.497765136123527\n",
      "Epoch 1875 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1876 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.497765136123527\n",
      "Epoch 1877 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1878 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1879 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1880 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1881 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1882 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1883 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1884 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1885 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1886 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1887 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1888 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1889 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1890 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1891 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1892 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1893 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1894 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1895 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1896 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1897 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.497765136123527\n",
      "Epoch 1898 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1899 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1900 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1901 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1902 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1903 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1904 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1905 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1906 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1907 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1908 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1909 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1910 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1911 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1912 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1913 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1914 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4782608695652174\n",
      "Epoch 1915 Loss 1.03 | Train Accuracy 0.4926844137370453 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1916 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1917 Loss 1.03 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.497765136123527\n",
      "Epoch 1918 Loss 1.03 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1919 Loss 1.03 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.497765136123527\n",
      "Epoch 1920 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1921 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1922 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1923 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1924 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1925 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1926 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1927 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1928 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1929 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1930 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1931 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1932 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1933 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1934 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1935 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1936 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1937 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1938 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1939 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1940 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1941 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1942 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.48516863063795207\n",
      "Epoch 1943 Loss 1.02 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1944 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1945 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1946 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1947 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1948 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1949 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1950 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1951 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1952 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1953 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1954 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1955 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1956 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1957 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1958 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1959 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1960 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1961 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1962 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1963 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1964 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1965 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1966 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1967 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1968 Loss 1.02 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.47947988622511173\n",
      "Epoch 1969 Loss 1.03 | Train Accuracy 0.49309083519609836 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1970 Loss 1.02 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1971 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1972 Loss 1.03 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1973 Loss 1.03 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1974 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1975 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1976 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1977 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1978 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1979 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1980 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1981 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1982 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1983 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1984 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1985 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1986 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1987 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1988 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1989 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1990 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1991 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1992 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1993 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1994 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1995 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1996 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1997 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1998 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1999 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2000 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2001 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2002 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.47947988622511173\n",
      "Epoch 2003 Loss 1.03 | Train Accuracy 0.4927860191018086 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2004 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2005 Loss 1.03 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.497765136123527\n",
      "Epoch 2006 Loss 1.03 | Train Accuracy 0.4950213371266003 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2007 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2008 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2009 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.497765136123527\n",
      "Epoch 2010 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2011 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.497765136123527\n",
      "Epoch 2012 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2013 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2014 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2015 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.497765136123527\n",
      "Epoch 2016 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2017 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2018 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2019 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2020 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2021 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2022 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2023 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2024 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2025 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2026 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2027 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2028 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2029 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2030 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2031 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2032 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2033 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2034 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2035 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2036 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2037 Loss 1.02 | Train Accuracy 0.4931924405608616 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2038 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2039 Loss 1.02 | Train Accuracy 0.494513310302784 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2040 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2041 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.497765136123527\n",
      "Epoch 2042 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2043 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2044 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2045 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2046 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2047 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2048 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2049 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2050 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2051 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2052 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2053 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2054 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2055 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2056 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2057 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2058 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2059 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2060 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2061 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2062 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2063 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2064 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2065 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2066 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2067 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2068 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2069 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2070 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2071 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2072 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2073 Loss 1.02 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2074 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2075 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2076 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2077 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2078 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2079 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2080 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2081 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2082 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2083 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2084 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2085 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2086 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2087 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2088 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2089 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2090 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2091 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2092 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2093 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2094 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2095 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2096 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2097 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2098 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2099 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2100 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2101 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2102 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2103 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2104 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2105 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2106 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2107 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2108 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2109 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2110 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2111 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2112 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2113 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2114 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2115 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2116 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2117 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2118 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2119 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2120 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2121 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2122 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2123 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2124 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2125 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2126 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2127 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2128 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2129 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2130 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2131 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2132 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2133 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2134 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2135 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2136 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2137 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2138 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2139 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2140 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.497765136123527\n",
      "Epoch 2141 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2142 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2143 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2144 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2145 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2146 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2147 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2148 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2149 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2150 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2151 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2152 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2153 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2154 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2155 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2156 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2157 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2158 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2159 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2160 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2161 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2162 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2163 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2164 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2165 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2166 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2167 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2168 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2169 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2170 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2171 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2172 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2173 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48720032507110933\n",
      "Epoch 2174 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2175 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2176 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2177 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2178 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2179 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2180 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2181 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2182 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2183 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2184 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2185 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2186 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2187 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2188 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2189 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2190 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2191 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2192 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2193 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2194 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2195 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2196 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2197 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2198 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2199 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2200 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2201 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2202 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2203 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2204 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2205 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2206 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2207 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2208 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2209 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2210 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2211 Loss 1.02 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2212 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2213 Loss 1.02 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2214 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.497765136123527\n",
      "Epoch 2215 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2216 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2217 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2218 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2219 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2220 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2221 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2222 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.48679398618447783\n",
      "Epoch 2223 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2224 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2225 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48679398618447783\n",
      "Epoch 2226 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.48598130841121495\n",
      "Epoch 2227 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2228 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2229 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2230 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2231 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2232 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2233 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2234 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2235 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2236 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2237 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2238 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2239 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2240 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2241 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2242 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2243 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2244 Loss 1.02 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2245 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2246 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49939049167005284\n",
      "Epoch 2247 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2248 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2249 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2250 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2251 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2252 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2253 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2254 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2255 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2256 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2257 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2258 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2259 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2260 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2261 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2262 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2263 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2264 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2265 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2266 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2267 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2268 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2269 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2270 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2271 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2272 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2273 Loss 1.02 | Train Accuracy 0.49309083519609836 | Val Accuracy 0.48273059731816337\n",
      "Epoch 2274 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2275 Loss 1.03 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.497765136123527\n",
      "Epoch 2276 Loss 1.03 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.49939049167005284\n",
      "Epoch 2277 Loss 1.03 | Train Accuracy 0.4934972566551514 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2278 Loss 1.03 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.497765136123527\n",
      "Epoch 2279 Loss 1.03 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2280 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2281 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2282 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2283 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2284 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2285 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2286 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2287 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2288 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2289 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2290 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2291 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2292 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2293 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2294 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.497765136123527\n",
      "Epoch 2295 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2296 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2297 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2298 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2299 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2300 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2301 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2302 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2303 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2304 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2305 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2306 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2307 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2308 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2309 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2310 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2311 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2312 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2313 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2314 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2315 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2316 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2317 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2318 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2319 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2320 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2321 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2322 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2323 Loss 1.02 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2324 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2325 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2326 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2327 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2328 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2329 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2330 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2331 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2332 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2333 Loss 1.02 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2334 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.497765136123527\n",
      "Epoch 2335 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2336 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2337 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2338 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2339 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2340 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2341 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2342 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2343 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2344 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2345 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2346 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2347 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2348 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2349 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2350 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2351 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2352 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2353 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2354 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2355 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2356 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2357 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2358 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2359 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2360 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2361 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2362 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2363 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2364 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2365 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2366 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48435595286468913\n",
      "Epoch 2367 Loss 1.02 | Train Accuracy 0.49126193863035966 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2368 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.48598130841121495\n",
      "Epoch 2369 Loss 1.03 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2370 Loss 1.03 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2371 Loss 1.03 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.497765136123527\n",
      "Epoch 2372 Loss 1.03 | Train Accuracy 0.494919731761837 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2373 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2374 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2375 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2376 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2377 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2378 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2379 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2380 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2381 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2382 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2383 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2384 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2385 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2386 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2387 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2388 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2389 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2390 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2391 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2392 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2393 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2394 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2395 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2396 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2397 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2398 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2399 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2400 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2401 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2402 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2403 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2404 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2405 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2406 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2407 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2408 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2409 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2410 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2411 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2412 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2413 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2414 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2415 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2416 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2417 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.47866720845184885\n",
      "Epoch 2418 Loss 1.03 | Train Accuracy 0.4896362527941475 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2419 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2420 Loss 1.03 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2421 Loss 1.03 | Train Accuracy 0.49126193863035966 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2422 Loss 1.03 | Train Accuracy 0.49116033326559644 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2423 Loss 1.03 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.497765136123527\n",
      "Epoch 2424 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2425 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.497765136123527\n",
      "Epoch 2426 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2427 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.497765136123527\n",
      "Epoch 2428 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2429 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2430 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2431 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2432 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2433 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2434 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2435 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4997968305566843\n",
      "Epoch 2436 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.497765136123527\n",
      "Epoch 2437 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2438 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2439 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2440 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2441 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2442 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2443 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2444 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2445 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2446 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2447 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2448 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2449 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2450 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2451 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2452 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2453 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2454 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2455 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2456 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2457 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2458 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2459 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2460 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2461 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2462 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2463 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2464 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2465 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2466 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2467 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2468 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2469 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2470 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2471 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.48516863063795207\n",
      "Epoch 2472 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2473 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2474 Loss 1.02 | Train Accuracy 0.494919731761837 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2475 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2476 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2477 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2478 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2479 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2480 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2481 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2482 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2483 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2484 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2485 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2486 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2487 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2488 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2489 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2490 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2491 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2492 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2493 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2494 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2495 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2496 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2497 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2498 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2499 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2500 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2501 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2502 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2503 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2504 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2505 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2506 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2507 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2508 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2509 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2510 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2511 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2512 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2513 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2514 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2515 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2516 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2517 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2518 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.48354327509142625\n",
      "Epoch 2519 Loss 1.02 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2520 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2521 Loss 1.02 | Train Accuracy 0.494919731761837 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2522 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2523 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2524 Loss 1.02 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2525 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2526 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2527 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2528 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2529 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2530 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4997968305566843\n",
      "Epoch 2531 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2532 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2533 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2534 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2535 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2536 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2537 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2538 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2539 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.497765136123527\n",
      "Epoch 2540 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2541 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2542 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2543 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2544 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2545 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2546 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2547 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2548 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2549 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2550 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2551 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2552 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2553 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2554 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2555 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2556 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2557 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2558 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2559 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2560 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2561 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2562 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2563 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2564 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2565 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2566 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2567 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2568 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2569 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4806989028850061\n",
      "Epoch 2570 Loss 1.03 | Train Accuracy 0.492176386913229 | Val Accuracy 0.4806989028850061\n",
      "Epoch 2571 Loss 1.03 | Train Accuracy 0.4869945133103028 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2572 Loss 1.03 | Train Accuracy 0.48872180451127817 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2573 Loss 1.03 | Train Accuracy 0.487096118675066 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2574 Loss 1.03 | Train Accuracy 0.4850640113798009 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2575 Loss 1.03 | Train Accuracy 0.4875025401341191 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2576 Loss 1.03 | Train Accuracy 0.49034749034749037 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2577 Loss 1.03 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2578 Loss 1.03 | Train Accuracy 0.49410688884373094 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2579 Loss 1.02 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2580 Loss 1.02 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2581 Loss 1.02 | Train Accuracy 0.49390367811420444 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2582 Loss 1.02 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.49939049167005284\n",
      "Epoch 2583 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.497765136123527\n",
      "Epoch 2584 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2585 Loss 1.02 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2586 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2587 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2588 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.497765136123527\n",
      "Epoch 2589 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.497765136123527\n",
      "Epoch 2590 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2591 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2592 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2593 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2594 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2595 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2596 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.5002031694433158\n",
      "Epoch 2597 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2598 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.5006095083299472\n",
      "Epoch 2599 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.5010158472165787\n",
      "Epoch 2600 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49939049167005284\n",
      "Epoch 2601 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49939049167005284\n",
      "Epoch 2602 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4997968305566843\n",
      "Epoch 2603 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4997968305566843\n",
      "Epoch 2604 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2605 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2606 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2607 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2608 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2609 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2610 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2611 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2612 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2613 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2614 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2615 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2616 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2617 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2618 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2619 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2620 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2621 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2622 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2623 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2624 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2625 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2626 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2627 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2628 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2629 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2630 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2631 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2632 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2633 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2634 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2635 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2636 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2637 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2638 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2639 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2640 Loss 1.02 | Train Accuracy 0.494513310302784 | Val Accuracy 0.48273059731816337\n",
      "Epoch 2641 Loss 1.03 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2642 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2643 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2644 Loss 1.03 | Train Accuracy 0.49329404592562487 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2645 Loss 1.03 | Train Accuracy 0.49309083519609836 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2646 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2647 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2648 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2649 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2650 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2651 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2652 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2653 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2654 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2655 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.497765136123527\n",
      "Epoch 2656 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49939049167005284\n",
      "Epoch 2657 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2658 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2659 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2660 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.497765136123527\n",
      "Epoch 2661 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2662 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2663 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2664 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2665 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2666 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2667 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2668 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2669 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2670 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2671 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2672 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2673 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2674 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2675 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2676 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2677 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2678 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2679 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2680 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2681 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2682 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2683 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2684 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2685 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2686 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2687 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2688 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2689 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2690 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2691 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2692 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2693 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2694 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2695 Loss 1.02 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2696 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2697 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2698 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2699 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2700 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2701 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2702 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2703 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2704 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2705 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2706 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4997968305566843\n",
      "Epoch 2707 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4997968305566843\n",
      "Epoch 2708 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2709 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2710 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2711 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2712 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2713 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2714 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2715 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2716 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2717 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2718 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2719 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2720 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2721 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2722 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2723 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2724 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2725 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2726 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2727 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2728 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2729 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2730 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2731 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2732 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2733 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2734 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2735 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2736 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2737 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2738 Loss 1.02 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2739 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2740 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2741 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2742 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2743 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2744 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2745 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2746 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2747 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2748 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2749 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2750 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2751 Loss 1.02 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2752 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2753 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2754 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2755 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2756 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2757 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2758 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2759 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2760 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2761 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2762 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2763 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2764 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2765 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2766 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2767 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2768 Loss 1.02 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4855749695245835\n",
      "Epoch 2769 Loss 1.02 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2770 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2771 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2772 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2773 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2774 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2775 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2776 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2777 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2778 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2779 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2780 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.5002031694433158\n",
      "Epoch 2781 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2782 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2783 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2784 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2785 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2786 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2787 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2788 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2789 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2790 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2791 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2792 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2793 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2794 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2795 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2796 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2797 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2798 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2799 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2800 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2801 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2802 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2803 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2804 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2805 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2806 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2807 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2808 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2809 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2810 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2811 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2812 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49939049167005284\n",
      "Epoch 2813 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2814 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2815 Loss 1.02 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2816 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2817 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2818 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2819 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2820 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2821 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2822 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2823 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2824 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.497765136123527\n",
      "Epoch 2825 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2826 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2827 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2828 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2829 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2830 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2831 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2832 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2833 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2834 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2835 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2836 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2837 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2838 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2839 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2840 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2841 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2842 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2843 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2844 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2845 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2846 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2847 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2848 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2849 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2850 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.47257212515237706\n",
      "Epoch 2851 Loss 1.03 | Train Accuracy 0.486689697216013 | Val Accuracy 0.497765136123527\n",
      "Epoch 2852 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2853 Loss 1.03 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2854 Loss 1.03 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2855 Loss 1.03 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2856 Loss 1.03 | Train Accuracy 0.49563096931517986 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2857 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2858 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2859 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2860 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2861 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2862 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2863 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2864 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.497765136123527\n",
      "Epoch 2865 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2866 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2867 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2868 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2869 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2870 Loss 1.02 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2871 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2872 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2873 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2874 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2875 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2876 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2877 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2878 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2879 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2880 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2881 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2882 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2883 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2884 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2885 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2886 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2887 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2888 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2889 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2890 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2891 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2892 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2893 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2894 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2895 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2896 Loss 1.02 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2897 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2898 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2899 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2900 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2901 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2902 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2903 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2904 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2905 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2906 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2907 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2908 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2909 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2910 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2911 Loss 1.02 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2912 Loss 1.02 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2913 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2914 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2915 Loss 1.02 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2916 Loss 1.02 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2917 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4997968305566843\n",
      "Epoch 2918 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2919 Loss 1.02 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2920 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2921 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2922 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2923 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2924 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2925 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2926 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2927 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2928 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2929 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2930 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2931 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2932 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2933 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2934 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2935 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2936 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2937 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2938 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2939 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2940 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2941 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2942 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2943 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2944 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2945 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2946 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2947 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2948 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.48720032507110933\n",
      "Epoch 2949 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2950 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2951 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2952 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2953 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2954 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2955 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2956 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2957 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2958 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2959 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2960 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2961 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2962 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2963 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2964 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2965 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4997968305566843\n",
      "Epoch 2966 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2967 Loss 1.02 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2968 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2969 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2970 Loss 1.02 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2971 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.5006095083299472\n",
      "Epoch 2972 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2973 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2974 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2975 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2976 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2977 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.497765136123527\n",
      "Epoch 2978 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2979 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2980 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2981 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2982 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2983 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2984 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2985 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2986 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2987 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2988 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2989 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2990 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2991 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2992 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2993 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2994 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2995 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2996 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2997 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2998 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2999 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3000 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3001 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3002 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3003 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3004 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3005 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3006 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3007 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3008 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3009 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3010 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4831369362047948\n",
      "Epoch 3011 Loss 1.02 | Train Accuracy 0.48851859378175166 | Val Accuracy 0.47988622511174317\n",
      "Epoch 3012 Loss 1.03 | Train Accuracy 0.4868929079455395 | Val Accuracy 0.48110524177163755\n",
      "Epoch 3013 Loss 1.03 | Train Accuracy 0.49105872790083316 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3014 Loss 1.03 | Train Accuracy 0.49085551717130665 | Val Accuracy 0.4863876472978464\n",
      "Epoch 3015 Loss 1.04 | Train Accuracy 0.48536882747409066 | Val Accuracy 0.48435595286468913\n",
      "Epoch 3016 Loss 1.04 | Train Accuracy 0.48353993090835196 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3017 Loss 1.03 | Train Accuracy 0.48323511481406217 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3018 Loss 1.03 | Train Accuracy 0.49055070107701687 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3019 Loss 1.03 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3020 Loss 1.03 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3021 Loss 1.02 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.497765136123527\n",
      "Epoch 3022 Loss 1.02 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3023 Loss 1.02 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3024 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3025 Loss 1.03 | Train Accuracy 0.49563096931517986 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3026 Loss 1.03 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3027 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3028 Loss 1.03 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.497765136123527\n",
      "Epoch 3029 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3030 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.497765136123527\n",
      "Epoch 3031 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3032 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3033 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3034 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3035 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3036 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3037 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3038 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3039 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3040 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3041 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.497765136123527\n",
      "Epoch 3042 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3043 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.497765136123527\n",
      "Epoch 3044 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3045 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3046 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3047 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3048 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3049 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3050 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.497765136123527\n",
      "Epoch 3051 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3052 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3053 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3054 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3055 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3056 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3057 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3058 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3059 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3060 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3061 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3062 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3063 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3064 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3065 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3066 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3067 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3068 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3069 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3070 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3071 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3072 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3073 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3074 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3075 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3076 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3077 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3078 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3079 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3080 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3081 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3082 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3083 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3084 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3085 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3086 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3087 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3088 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3089 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3090 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3091 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4831369362047948\n",
      "Epoch 3092 Loss 1.02 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.4790735473384803\n",
      "Epoch 3093 Loss 1.03 | Train Accuracy 0.4895346474293843 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3094 Loss 1.03 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3095 Loss 1.03 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3096 Loss 1.03 | Train Accuracy 0.4934972566551514 | Val Accuracy 0.48679398618447783\n",
      "Epoch 3097 Loss 1.03 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3098 Loss 1.03 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3099 Loss 1.03 | Train Accuracy 0.494513310302784 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3100 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3101 Loss 1.02 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3102 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3103 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3104 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3105 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3106 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3107 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3108 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3109 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3110 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3111 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.497765136123527\n",
      "Epoch 3112 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3113 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3114 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.5002031694433158\n",
      "Epoch 3115 Loss 1.02 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3116 Loss 1.02 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3117 Loss 1.02 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3118 Loss 1.02 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3119 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3120 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3121 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3122 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3123 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3124 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3125 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3126 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3127 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3128 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3129 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3130 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3131 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3132 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3133 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3134 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3135 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3136 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3137 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3138 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3139 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3140 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3141 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3142 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3143 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3144 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3145 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3146 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3147 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3148 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3149 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3150 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3151 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3152 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3153 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3154 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3155 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3156 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3157 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3158 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3159 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3160 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48476229175132063\n",
      "Epoch 3161 Loss 1.02 | Train Accuracy 0.49136354399512294 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3162 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3163 Loss 1.02 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3164 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.497765136123527\n",
      "Epoch 3165 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3166 Loss 1.02 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3167 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3168 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3169 Loss 1.02 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3170 Loss 1.02 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3171 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3172 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3173 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3174 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3175 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3176 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3177 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.5002031694433158\n",
      "Epoch 3178 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3179 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3180 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3181 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3182 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3183 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3184 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3185 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3186 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3187 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3188 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3189 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3190 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3191 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3192 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3193 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3194 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3195 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3196 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3197 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3198 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3199 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3200 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3201 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3202 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3203 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3204 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3205 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3206 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3207 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3208 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3209 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3210 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3211 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3212 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3213 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.48720032507110933\n",
      "Epoch 3214 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3215 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3216 Loss 1.02 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.497765136123527\n",
      "Epoch 3217 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3218 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3219 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3220 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3221 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.497765136123527\n",
      "Epoch 3222 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.497765136123527\n",
      "Epoch 3223 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3224 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3225 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3226 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3227 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3228 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3229 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3230 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3231 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3232 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3233 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3234 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3235 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3236 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3237 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3238 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3239 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3240 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3241 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3242 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3243 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3244 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.48720032507110933\n",
      "Epoch 3245 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3246 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3247 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3248 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3249 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3250 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3251 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3252 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3253 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3254 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3255 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3256 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3257 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3258 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3259 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3260 Loss 1.02 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3261 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3262 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3263 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3264 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3265 Loss 1.02 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3266 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3267 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.497765136123527\n",
      "Epoch 3268 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3269 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3270 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3271 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3272 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3273 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3274 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3275 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3276 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3277 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3278 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3279 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3280 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3281 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3282 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3283 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3284 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3285 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3286 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3287 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3288 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3289 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3290 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3291 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3292 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3293 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3294 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3295 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3296 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3297 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3298 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3299 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3300 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3301 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3302 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3303 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3304 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.48354327509142625\n",
      "Epoch 3305 Loss 1.02 | Train Accuracy 0.4896362527941475 | Val Accuracy 0.48029256399837467\n",
      "Epoch 3306 Loss 1.03 | Train Accuracy 0.48597845966267017 | Val Accuracy 0.48273059731816337\n",
      "Epoch 3307 Loss 1.03 | Train Accuracy 0.49116033326559644 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3308 Loss 1.03 | Train Accuracy 0.4916683600894127 | Val Accuracy 0.48679398618447783\n",
      "Epoch 3309 Loss 1.03 | Train Accuracy 0.4877057508636456 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3310 Loss 1.03 | Train Accuracy 0.4841495630969315 | Val Accuracy 0.48679398618447783\n",
      "Epoch 3311 Loss 1.03 | Train Accuracy 0.4848608006502743 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3312 Loss 1.03 | Train Accuracy 0.4902458849827271 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3313 Loss 1.03 | Train Accuracy 0.49207478154846573 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3314 Loss 1.03 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3315 Loss 1.02 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3316 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.497765136123527\n",
      "Epoch 3317 Loss 1.02 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3318 Loss 1.02 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3319 Loss 1.03 | Train Accuracy 0.497256655151392 | Val Accuracy 0.5010158472165787\n",
      "Epoch 3320 Loss 1.03 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3321 Loss 1.03 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3322 Loss 1.03 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.497765136123527\n",
      "Epoch 3323 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3324 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3325 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3326 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3327 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3328 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3329 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3330 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3331 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.5002031694433158\n",
      "Epoch 3332 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3333 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3334 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.497765136123527\n",
      "Epoch 3335 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.497765136123527\n",
      "Epoch 3336 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3337 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.497765136123527\n",
      "Epoch 3338 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3339 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.497765136123527\n",
      "Epoch 3340 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3341 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3342 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3343 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3344 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3345 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3346 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3347 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.497765136123527\n",
      "Epoch 3348 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3349 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3350 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3351 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3352 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3353 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3354 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3355 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3356 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3357 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3358 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3359 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3360 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3361 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3362 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3363 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3364 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3365 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3366 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3367 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3368 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3369 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3370 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3371 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3372 Loss 1.02 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3373 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3374 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3375 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3376 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3377 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3378 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3379 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3380 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3381 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3382 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3383 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3384 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3385 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3386 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3387 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3388 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.481511580658269\n",
      "Epoch 3389 Loss 1.03 | Train Accuracy 0.4848608006502743 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3390 Loss 1.02 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3391 Loss 1.03 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3392 Loss 1.03 | Train Accuracy 0.4900426742532006 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3393 Loss 1.03 | Train Accuracy 0.48862019914651494 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3394 Loss 1.03 | Train Accuracy 0.48933143669985774 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3395 Loss 1.03 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3396 Loss 1.03 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3397 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3398 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3399 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.497765136123527\n",
      "Epoch 3400 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.497765136123527\n",
      "Epoch 3401 Loss 1.02 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3402 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.5006095083299472\n",
      "Epoch 3403 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.5014221861032101\n",
      "Epoch 3404 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.5002031694433158\n",
      "Epoch 3405 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3406 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3407 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3408 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.497765136123527\n",
      "Epoch 3409 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.497765136123527\n",
      "Epoch 3410 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3411 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3412 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3413 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3414 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3415 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3416 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3417 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3418 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3419 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3420 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3421 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3422 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3423 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3424 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3425 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3426 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3427 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3428 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3429 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3430 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3431 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3432 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3433 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3434 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3435 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3436 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3437 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3438 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3439 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3440 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3441 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3442 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3443 Loss 1.02 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3444 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3445 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3446 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3447 Loss 1.02 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3448 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3449 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3450 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3451 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3452 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3453 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3454 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3455 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3456 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3457 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3458 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3459 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3460 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3461 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.47379114181227144\n",
      "Epoch 3462 Loss 1.03 | Train Accuracy 0.48079658605974396 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3463 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3464 Loss 1.03 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.497765136123527\n",
      "Epoch 3465 Loss 1.03 | Train Accuracy 0.49156675472464945 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3466 Loss 1.03 | Train Accuracy 0.49187157081893923 | Val Accuracy 0.497765136123527\n",
      "Epoch 3467 Loss 1.03 | Train Accuracy 0.4922779922779923 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3468 Loss 1.03 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3469 Loss 1.03 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3470 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.497765136123527\n",
      "Epoch 3471 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.5006095083299472\n",
      "Epoch 3472 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3473 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.497765136123527\n",
      "Epoch 3474 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3475 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3476 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3477 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3478 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3479 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3480 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3481 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3482 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3483 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3484 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3485 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3486 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3487 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3488 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3489 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3490 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3491 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3492 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3493 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3494 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3495 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3496 Loss 1.02 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3497 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3498 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3499 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3500 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3501 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3502 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3503 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3504 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3505 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3506 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3507 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3508 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3509 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3510 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3511 Loss 1.02 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3512 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3513 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3514 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3515 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3516 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3517 Loss 1.02 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3518 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3519 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3520 Loss 1.02 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3521 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3522 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3523 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3524 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3525 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3526 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3527 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3528 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3529 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3530 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3531 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3532 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3533 Loss 1.02 | Train Accuracy 0.497663076610445 | Val Accuracy 0.48110524177163755\n",
      "Epoch 3534 Loss 1.03 | Train Accuracy 0.4842511684616948 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3535 Loss 1.02 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3536 Loss 1.03 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3537 Loss 1.03 | Train Accuracy 0.49034749034749037 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3538 Loss 1.03 | Train Accuracy 0.4879089615931721 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3539 Loss 1.03 | Train Accuracy 0.4880105669579354 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3540 Loss 1.03 | Train Accuracy 0.49359886201991465 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3541 Loss 1.03 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3542 Loss 1.03 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3543 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3544 Loss 1.02 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3545 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3546 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3547 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.5010158472165787\n",
      "Epoch 3548 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.5014221861032101\n",
      "Epoch 3549 Loss 1.02 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.5010158472165787\n",
      "Epoch 3550 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.5018285249898415\n",
      "Epoch 3551 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.5002031694433158\n",
      "Epoch 3552 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3553 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3554 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3555 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3556 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3557 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3558 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3559 Loss 1.02 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3560 Loss 1.02 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3561 Loss 1.02 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3562 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3563 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3564 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3565 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3566 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3567 Loss 1.02 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3568 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3569 Loss 1.02 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3570 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3571 Loss 1.02 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3572 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3573 Loss 1.02 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3574 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3575 Loss 1.02 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3576 Loss 1.02 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3577 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3578 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3579 Loss 1.02 | Train Accuracy 0.5 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3580 Loss 1.02 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3581 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3582 Loss 1.02 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3583 Loss 1.02 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3584 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3585 Loss 1.02 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3586 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3587 Loss 1.02 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3588 Loss 1.02 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3589 Loss 1.02 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3590 Loss 1.02 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3591 Loss 1.02 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3592 Loss 1.02 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3593 Loss 1.02 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3594 Loss 1.02 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3595 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3596 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3597 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3598 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3599 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3600 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3601 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3602 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3603 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3604 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3605 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3606 Loss 1.02 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48191791954490043\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5592\\1867317596.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[1;32m--> 488\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "N_EPOCHS = 10000 # + 100\n",
    "net.train()\n",
    "criterion = nn.CrossEntropyLoss() # loss\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.005, weight_decay=5e-2)\n",
    "\n",
    "train_accuracies = [1.0]\n",
    "val_accuracies = [1.0]\n",
    "val_check = 1\n",
    "best_state, best_val = None, 0.0\n",
    "for epoch in range(N_EPOCHS):  # loop over the dataset multiple times\n",
    "    # Iterate over batches and perform SGD step.\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net(x_train)\n",
    "    loss = criterion(y_pred, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_acc, val_acc = accuracy_score(torch.argmax(y_pred, axis=1), torch.argmax(Y_train, axis=1)), val_accuracies[-1]\n",
    "    if(epoch % val_check == 0):\n",
    "        hat_y_val = net(x_valid)\n",
    "        #val_loss = criterion(hat_y_val, y_val)\n",
    "        val_acc = accuracy_score(torch.argmax(hat_y_val, axis=1), torch.argmax(Y_valid, axis=1))\n",
    "        if(val_acc > best_val):\n",
    "            best_val = val_acc\n",
    "            best_state = copy.deepcopy(net.state_dict())\n",
    "\n",
    "    val_accuracies.append(val_acc)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(f\"Epoch {epoch} Loss {loss.detach().cpu().numpy():.2f} | Train Accuracy {train_acc} | Val Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('bc1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bc1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bc1.running_mean', tensor([4.3127, 3.8142, 4.5145, 4.1650, 4.0310, 3.8391, 3.6512, 4.3655, 4.4977,\n",
      "        4.8130, 4.8084, 3.7348, 4.1707, 4.7308, 3.7663, 6.6849, 4.9655, 4.4066,\n",
      "        3.4827, 3.9846, 4.1583, 4.5667, 4.7229, 3.9060, 3.4319, 4.0530, 3.7421,\n",
      "        3.6611, 3.3647, 3.2946, 4.0803, 4.0839, 4.0596, 4.0257, 4.2763, 4.4196,\n",
      "        3.4702, 3.8874, 3.9460, 3.5594, 6.1130, 4.1858, 3.8524, 3.4421, 3.7260,\n",
      "        3.9196, 4.2590, 4.4952, 3.9870, 3.6484, 4.0034, 3.8297, 3.4501, 3.6179,\n",
      "        3.6606, 3.7400, 3.8054, 4.2066, 4.5206, 4.1222, 4.1338, 4.3875, 3.6781,\n",
      "        3.9866, 4.5376, 3.9405, 3.6440, 3.8830, 3.0501, 3.7342, 3.7903, 3.3948,\n",
      "        4.0503, 3.8587, 3.6098, 3.3781, 3.3258, 3.9142, 4.0559, 4.1363, 4.3496,\n",
      "        2.4663, 3.6894, 4.0994, 2.7569, 6.5624, 4.0029, 3.9040, 3.0512, 3.7979,\n",
      "        4.1250, 3.9151, 4.3522, 3.7818, 3.3711, 4.0278, 3.8353, 3.5882, 3.3564,\n",
      "        3.3156, 4.2014, 3.8913, 4.0328, 4.2388, 4.1299, 4.3040, 2.4656, 3.6355,\n",
      "        4.0801, 2.7563, 6.4939, 4.0403, 3.8833, 3.1131, 3.7449, 4.1229, 3.9150,\n",
      "        4.3500, 3.5557, 3.3399, 3.8066, 3.7664, 3.3211, 3.4202, 3.4081, 3.2808,\n",
      "        3.4773, 3.8021, 4.2609, 3.7644, 3.9681, 2.9197, 3.3056, 3.9097, 3.5277,\n",
      "        3.2702, 3.2347, 3.6700, 2.8147, 3.6176, 4.3686, 3.8601, 4.5755, 4.2199,\n",
      "        4.0627, 3.8412, 3.6522, 4.3376, 4.5482, 4.8230, 4.7489, 3.6901, 4.1790,\n",
      "        4.7656, 3.8121, 6.7284, 4.8965, 4.4870, 3.4456, 4.0137, 4.2008, 4.5700,\n",
      "        4.6746, 3.9705, 3.4695, 4.1127, 3.8067, 3.6973, 3.3705, 3.2935, 4.0976,\n",
      "        4.0397, 4.1093, 4.0369, 4.2657, 4.3548, 3.4254, 3.8903, 3.9788, 3.6081,\n",
      "        6.1541, 4.0935, 3.9257, 3.4109, 3.7589, 3.9679, 4.2664, 4.4491, 4.0077,\n",
      "        3.6805, 4.0223, 3.8620, 3.4681, 3.6376, 3.6965, 3.7588, 3.8145, 4.2446,\n",
      "        4.5483, 4.1087, 4.1005, 4.3624, 3.6997, 4.0262, 4.5784, 3.8946, 3.6893,\n",
      "        3.9329, 3.0397, 3.7517, 3.9476, 3.5356, 4.1783, 4.0439, 3.7097, 3.4174,\n",
      "        3.3689, 3.8036, 4.2100, 4.1255, 4.2182, 2.3260, 3.7037, 4.2048, 2.8972,\n",
      "        6.6320, 3.9257, 4.0916, 3.0076, 3.9484, 4.3122, 3.8581, 4.2005, 3.9401,\n",
      "        3.5071, 4.1554, 4.0198, 3.6869, 3.3975, 3.3534, 4.2439, 3.7747, 4.1881,\n",
      "        4.3134, 4.1123, 4.1755, 2.3253, 3.6467, 4.1857, 2.8969, 6.5645, 3.9744,\n",
      "        4.0716, 3.0767, 3.8981, 4.3095, 3.8580, 4.1983, 3.5984, 3.3841, 3.8128,\n",
      "        3.8486, 3.3544, 3.4842, 3.4838, 3.3080, 3.4503, 3.8550, 4.2798, 3.7403,\n",
      "        3.8730, 2.7936, 3.3195, 3.9301, 3.6942, 3.2025, 3.2486, 3.7420, 2.8189,\n",
      "        3.6972])), ('bc1.running_var', tensor([ 8.4745,  9.4395,  7.8447,  8.1238,  9.2344,  9.4517,  9.1968,  8.9583,\n",
      "         7.8418,  9.0963,  7.9124, 10.1655,  9.1178,  7.7517,  8.7165,  8.7004,\n",
      "         8.8692,  8.1039,  9.6466,  8.0926,  8.4318,  8.3774,  8.5222,  7.9295,\n",
      "         8.7146,  7.5986,  7.6815,  8.5592,  8.7469,  8.7058,  9.3846,  8.4668,\n",
      "         7.4546,  7.9579,  8.5584,  7.5168,  9.3387,  8.5420,  7.5060,  8.2072,\n",
      "         9.7933,  7.7441,  7.6799,  9.0723,  7.7564,  7.9986,  7.8064,  8.0874,\n",
      "         8.2888,  8.4700,  7.7008,  7.4684,  8.3373,  8.6798,  8.6036,  8.5820,\n",
      "         8.1855,  7.7645,  7.7014,  8.6399,  7.6234,  9.6752,  8.3985,  7.6739,\n",
      "         8.0223,  9.3417,  8.3874,  7.8838,  8.9912,  7.7601,  8.3268,  8.4415,\n",
      "         7.8169,  7.6954,  8.6615,  8.6806,  8.5407,  8.7393,  7.6160,  8.5605,\n",
      "         8.0087, 12.4677,  8.5464,  7.6887, 10.6609, 11.2675,  8.8666,  7.6025,\n",
      "         9.2682,  7.8496,  8.8974,  9.6455,  8.8880,  8.2649,  8.4527,  7.8262,\n",
      "         7.7136,  8.6433,  8.6282,  8.5601,  9.4000,  8.7060,  7.6330,  7.8740,\n",
      "         8.5379,  8.0741, 12.4423,  8.4882,  7.6787, 10.6477, 11.5241,  8.6761,\n",
      "         7.5965,  9.1975,  7.9030,  8.8957,  9.6453,  8.8873,  8.3237,  8.5479,\n",
      "         7.7553,  7.7343,  8.4728,  8.5302,  8.4418,  8.4624,  8.3557,  7.7116,\n",
      "         7.9641,  8.5136,  8.2069, 14.6753,  8.3177,  7.9610, 13.3701, 11.1247,\n",
      "         8.7607,  7.6355,  8.5549,  8.1215,  8.5055,  9.4445,  7.7932,  8.2164,\n",
      "         9.3163,  9.4485,  9.1774,  9.0281,  7.9978,  9.1712,  8.0290,  9.9998,\n",
      "         9.1818,  7.6843,  8.8068,  8.8173,  8.9741,  8.1104,  9.6012,  8.0878,\n",
      "         8.3990,  8.3184,  8.4901,  8.0658,  8.7613,  7.6431,  7.8203,  8.5679,\n",
      "         8.6473,  8.5759,  9.3545,  8.4405,  7.7029,  7.9126,  8.6301,  7.6804,\n",
      "         9.1509,  8.7067,  7.4656,  8.3121,  9.8576,  7.7395,  7.7314,  9.1167,\n",
      "         7.8095,  8.0440,  7.7897,  8.0579,  8.4776,  8.5207,  7.8854,  7.5061,\n",
      "         8.4067,  8.8236,  8.6938,  8.6181,  8.3423,  7.7156,  7.7295,  8.7719,\n",
      "         7.6497,  9.6709,  8.4982,  7.7672,  8.0907,  9.3638,  8.3997,  7.8684,\n",
      "         9.1498,  7.6272,  8.6328,  8.7063,  8.1240,  8.0388,  8.9091,  8.6325,\n",
      "         8.5352,  8.4688,  7.8841,  8.5492,  8.0004, 11.6742,  8.6029,  7.7200,\n",
      "        10.9841, 11.1181,  8.9625,  7.8510,  9.2307,  8.0486,  9.0659,  9.6450,\n",
      "         8.6878,  8.5809,  8.6807,  8.1334,  8.0606,  8.9040,  8.5701,  8.5108,\n",
      "         9.4390,  8.3890,  7.9063,  7.7869,  8.5268,  8.0751, 11.6529,  8.5768,\n",
      "         7.7150, 10.9683, 11.3748,  8.7885,  7.8512,  9.1944,  8.1256,  9.0649,\n",
      "         9.6449,  8.6865,  8.4659,  8.7372,  7.8863,  7.9394,  8.5935,  8.8346,\n",
      "         8.8117,  8.4302,  8.2850,  7.7796,  8.2338,  8.7414,  7.9715, 14.1667,\n",
      "         8.3873,  7.9269, 13.5970, 11.0845,  8.8564,  7.9076,  8.7130,  8.1275])), ('bc1.num_batches_tracked', tensor(702)), ('bc2.weight', tensor([0.0534, 0.0534, 0.0537, 0.0534, 0.0536, 0.0536, 0.0539, 0.0535, 0.0539,\n",
      "        0.0533, 0.0535, 0.0535, 0.0536, 0.0532, 0.0534, 0.0537, 0.0531, 0.0535,\n",
      "        0.0530, 0.0538, 0.0535, 0.0538, 0.0536, 0.0535, 0.0536, 0.0530, 0.0532,\n",
      "        0.0535, 0.0534, 0.0530, 0.0536, 0.0536, 0.0539, 0.0533, 0.0536, 0.0532,\n",
      "        0.0537, 0.0533, 0.0534, 0.0531, 0.0534, 0.0535, 0.0535, 0.0533, 0.0538,\n",
      "        0.0532, 0.0535, 0.0529, 0.0536, 0.0536, 0.0535, 0.0527, 0.0536, 0.0534,\n",
      "        0.0535, 0.0536, 0.0533, 0.0537, 0.0538, 0.0535, 0.0530, 0.0539, 0.0529,\n",
      "        0.0539, 0.0534, 0.0535, 0.0537, 0.0534, 0.0536, 0.0533, 0.0534, 0.0536,\n",
      "        0.0535, 0.0530, 0.0532, 0.0536, 0.0533, 0.0534, 0.0535, 0.0536, 0.0531,\n",
      "        0.0533, 0.0535, 0.0535, 0.0534, 0.0536, 0.0534, 0.0532, 0.0535, 0.0531,\n",
      "        0.0534, 0.0536, 0.0536, 0.0538, 0.0533, 0.0531, 0.0538, 0.0535, 0.0532,\n",
      "        0.0534, 0.0537, 0.0537, 0.0537, 0.0534, 0.0527, 0.0534, 0.0536, 0.0534,\n",
      "        0.0534, 0.0529, 0.0538, 0.0534, 0.0532, 0.0532, 0.0534, 0.0533, 0.0535,\n",
      "        0.0536, 0.0536, 0.0534, 0.0537, 0.0529, 0.0535, 0.0536, 0.0534, 0.0537,\n",
      "        0.0538, 0.0536])), ('bc2.bias', tensor([-8.6741e-06,  9.1720e-06,  8.2630e-06,  1.0579e-05,  1.0865e-05,\n",
      "        -1.2051e-06,  9.1277e-06,  4.4369e-06,  1.0361e-05, -1.0407e-05,\n",
      "        -9.9071e-06, -1.0783e-05,  1.0852e-05,  2.6633e-06, -4.4722e-06,\n",
      "        -4.2690e-06, -6.0495e-06,  7.3089e-06, -7.4290e-06,  8.2198e-06,\n",
      "         5.5113e-06,  7.4829e-06,  5.8374e-06,  3.9319e-06,  9.0535e-06,\n",
      "         9.7181e-06, -1.0360e-06, -2.1016e-06, -7.9048e-06,  1.2253e-05,\n",
      "         9.6321e-06,  5.5759e-06, -8.8751e-06, -9.7006e-06,  6.5651e-06,\n",
      "         5.7889e-06,  1.0926e-05, -6.1742e-06,  4.3396e-06, -1.1096e-05,\n",
      "        -1.6578e-06, -1.1947e-05, -7.3691e-06, -7.5437e-06, -3.8789e-06,\n",
      "        -8.8523e-06, -4.4811e-06,  4.7054e-06,  5.6763e-06, -6.7821e-06,\n",
      "        -3.7029e-06, -1.2104e-05, -8.1869e-06, -8.1532e-06,  8.7955e-06,\n",
      "        -9.4835e-06,  6.5845e-06, -1.0640e-05,  1.1577e-05, -8.4390e-06,\n",
      "         3.9104e-07, -7.1807e-06,  2.1718e-06, -5.1716e-06,  8.7022e-06,\n",
      "         2.4536e-06,  9.8958e-06, -9.0999e-06, -1.0307e-05, -9.3869e-07,\n",
      "        -6.2328e-06, -5.8295e-06,  7.9516e-06,  3.3771e-06,  8.9495e-07,\n",
      "        -6.6413e-06,  5.2248e-06,  1.2291e-05,  7.3850e-06, -8.0353e-06,\n",
      "         6.0454e-06,  1.2216e-05,  2.7271e-06,  6.4222e-07,  8.2372e-06,\n",
      "         6.2729e-06,  1.0056e-05, -5.0854e-06,  1.1427e-05, -6.7526e-06,\n",
      "         4.6765e-06, -8.7202e-06, -6.5525e-06, -5.2503e-06,  9.1959e-06,\n",
      "        -9.0494e-06,  1.0910e-05,  1.1886e-05,  1.0993e-05,  7.9766e-06,\n",
      "         5.6418e-06, -1.2364e-05,  1.1076e-05, -1.1802e-05,  7.5128e-06,\n",
      "        -4.6492e-08,  1.2044e-05,  6.4842e-06,  1.1139e-05, -6.3036e-06,\n",
      "        -1.2373e-05, -7.8843e-06, -7.6574e-06, -1.1316e-05, -3.9031e-07,\n",
      "         1.2604e-05,  5.1470e-06, -3.2250e-06, -6.1832e-06, -1.0298e-05,\n",
      "         9.4647e-06, -1.2000e-06, -1.5622e-06, -1.3740e-06, -5.5856e-06,\n",
      "         4.7122e-06, -9.2339e-06,  7.9814e-06])), ('bc2.running_mean', tensor([-1.5839e-10,  2.7291e-11, -2.1756e-11, -4.6507e-11,  1.5827e-10,\n",
      "         2.5405e-10,  6.8017e-11,  6.5099e-12, -1.6033e-10,  1.1327e-10,\n",
      "         1.0899e-10, -3.2604e-11, -3.9062e-10,  8.8530e-11, -1.7688e-10,\n",
      "        -8.6213e-11, -1.2678e-11, -2.0742e-11,  1.5182e-10, -3.6134e-10,\n",
      "        -1.2832e-11,  2.2164e-11,  2.4621e-11, -3.5914e-10, -1.2326e-10,\n",
      "        -2.3164e-10,  8.9354e-12, -1.8654e-10,  1.0027e-10,  2.7147e-11,\n",
      "        -2.7373e-12,  9.0463e-11, -8.6657e-11,  7.3836e-11,  2.1487e-10,\n",
      "         3.7026e-10, -3.0918e-11, -1.0966e-10, -5.9570e-11, -7.0917e-12,\n",
      "        -6.9025e-12,  2.1590e-11, -6.6406e-11,  3.6090e-10,  3.7248e-11,\n",
      "         3.8153e-11, -1.4246e-11,  2.2179e-10,  3.1892e-12,  2.3138e-10,\n",
      "         9.0862e-11,  1.2540e-11, -2.8242e-11,  5.8668e-11, -5.0371e-12,\n",
      "        -6.1440e-11,  3.1358e-13, -4.8977e-11, -2.1198e-10, -1.7853e-10,\n",
      "        -2.5111e-11,  3.9025e-11, -1.4669e-10, -5.1507e-11,  4.4859e-11,\n",
      "         1.5638e-11,  1.7113e-11,  5.3726e-11,  1.1114e-10, -1.3287e-11,\n",
      "         1.0997e-10,  3.8658e-10,  3.4149e-10, -7.1593e-11, -4.1496e-11,\n",
      "         2.6169e-10, -4.0554e-11,  1.1506e-10, -1.1570e-10, -2.2400e-10,\n",
      "         2.2114e-10,  1.8881e-11,  8.0658e-12, -3.6034e-11,  1.3768e-10,\n",
      "         9.0077e-11,  1.7182e-10, -5.1926e-11,  5.8977e-11,  4.3057e-12,\n",
      "         1.7699e-10, -3.1004e-10,  5.9713e-11,  1.5004e-10,  6.8184e-12,\n",
      "        -3.6855e-10, -4.0376e-11, -1.6833e-10, -5.4232e-11, -6.3700e-11,\n",
      "         1.8813e-10, -2.7569e-10, -5.9580e-11, -1.0937e-10, -5.4143e-11,\n",
      "         1.2177e-10, -1.7297e-10, -5.3212e-11, -4.6126e-11, -5.6172e-11,\n",
      "        -3.9794e-11, -3.0520e-10, -6.0707e-11,  1.1111e-10,  1.1697e-10,\n",
      "         2.9205e-12,  3.2705e-10, -3.0614e-10,  1.1894e-11, -9.2539e-11,\n",
      "        -2.8841e-10,  1.1643e-10, -1.0578e-10, -1.0012e-10,  3.0679e-11,\n",
      "        -7.6947e-11,  1.3326e-10,  9.8455e-11])), ('bc2.running_var', tensor([2.3877e-07, 1.3785e-07, 2.1868e-07, 3.9864e-07, 1.8095e-07, 1.0475e-06,\n",
      "        2.6386e-07, 1.0427e-07, 1.1383e-07, 1.3759e-07, 1.1303e-07, 1.7331e-07,\n",
      "        2.8131e-07, 1.0744e-06, 1.8550e-07, 4.5038e-07, 1.3878e-07, 3.0635e-07,\n",
      "        1.3315e-07, 2.8169e-07, 1.6867e-07, 2.2207e-07, 3.4851e-07, 2.1483e-07,\n",
      "        1.7577e-07, 1.1878e-07, 1.6487e-07, 1.3281e-07, 1.0271e-06, 2.9993e-07,\n",
      "        3.0061e-07, 8.6568e-08, 2.8732e-07, 5.3168e-07, 5.5057e-07, 6.8462e-07,\n",
      "        2.2511e-07, 1.4517e-07, 2.4877e-07, 1.5313e-07, 3.8461e-07, 7.0189e-07,\n",
      "        3.7722e-07, 1.8480e-07, 4.7455e-07, 2.2232e-07, 1.2407e-06, 1.4763e-07,\n",
      "        2.4787e-07, 1.3933e-07, 7.6835e-07, 3.4584e-07, 2.0206e-07, 2.9801e-07,\n",
      "        3.7937e-07, 1.6235e-07, 1.3641e-07, 1.1519e-07, 1.1927e-07, 3.2621e-07,\n",
      "        2.9619e-07, 7.8335e-07, 1.9437e-07, 1.5978e-07, 2.9804e-07, 1.5213e-07,\n",
      "        5.9742e-07, 7.9079e-07, 3.3326e-07, 2.3850e-07, 6.0901e-07, 1.5179e-07,\n",
      "        1.5901e-07, 1.6480e-06, 2.2983e-07, 1.7845e-07, 3.6879e-07, 1.3291e-07,\n",
      "        1.8480e-07, 6.6275e-07, 2.5178e-07, 1.1747e-07, 1.1280e-07, 1.1036e-07,\n",
      "        6.7275e-07, 1.3912e-07, 2.1025e-07, 1.1055e-07, 1.3788e-07, 4.2893e-07,\n",
      "        4.0279e-07, 9.2559e-08, 1.4765e-07, 9.2683e-08, 4.8760e-07, 2.8655e-07,\n",
      "        1.7594e-07, 3.2855e-07, 2.1860e-07, 1.1048e-07, 1.1652e-07, 1.4394e-07,\n",
      "        2.2915e-07, 2.3756e-07, 8.6834e-07, 3.2147e-07, 1.2537e-07, 1.5847e-07,\n",
      "        9.3945e-08, 2.8562e-07, 1.2869e-07, 3.5846e-07, 3.5232e-07, 4.2597e-07,\n",
      "        1.0241e-07, 5.5175e-07, 2.2026e-07, 1.0447e-07, 2.2763e-07, 1.5582e-07,\n",
      "        1.3753e-07, 1.8140e-07, 1.2323e-07, 2.4970e-07, 3.1509e-07, 1.4309e-07,\n",
      "        2.5906e-07, 4.3852e-07])), ('bc2.num_batches_tracked', tensor(702)), ('bc3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bc3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bc3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bc3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bc3.num_batches_tracked', tensor(0)), ('att1.in_proj_weight', tensor([[ 5.1652e-10, -2.0531e-10,  4.0480e-10,  ...,  3.4132e-11,\n",
      "         -1.5073e-10,  2.3779e-10],\n",
      "        [-9.6102e-10,  2.6405e-10,  7.9392e-10,  ...,  3.7283e-10,\n",
      "          4.5383e-10,  1.0554e-10],\n",
      "        [-3.6554e-10, -6.5998e-10, -1.5079e-10,  ...,  7.8878e-10,\n",
      "          3.0901e-10, -5.9247e-10],\n",
      "        ...,\n",
      "        [ 2.4661e-07,  5.4755e-07, -5.2252e-07,  ...,  2.8743e-07,\n",
      "          5.7997e-07, -2.2379e-08],\n",
      "        [ 1.1847e-05,  1.1499e-05, -5.2575e-05,  ...,  3.6113e-05,\n",
      "          3.2668e-06, -2.1245e-05],\n",
      "        [-2.6121e-05,  6.0302e-05,  8.9575e-05,  ...,  6.0677e-05,\n",
      "          3.2533e-05,  1.0385e-06]])), ('att1.in_proj_bias', tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -3.2699e-06,  1.7757e-09,  1.3085e-05,  9.4854e-06,\n",
      "        -8.3611e-06, -2.7274e-06,  8.9205e-08,  7.4800e-06,  1.7723e-05,\n",
      "         2.9740e-05,  2.2279e-06,  1.3522e-05,  1.2448e-06,  1.1703e-05,\n",
      "        -3.4537e-05,  2.1779e-06, -7.0060e-07, -5.2265e-06, -9.9898e-06,\n",
      "        -3.4425e-05,  5.9527e-07,  9.1598e-07, -6.5047e-06, -1.6562e-05,\n",
      "         1.9115e-06, -2.2540e-05, -2.9642e-05,  2.4852e-05, -1.3926e-05,\n",
      "        -8.9922e-07,  2.2293e-06,  2.7937e-05, -3.0754e-06, -4.5340e-06,\n",
      "         1.1120e-06,  6.0727e-06, -2.7323e-06, -2.0496e-06, -1.7336e-05,\n",
      "         3.2168e-05, -3.6445e-06, -1.1529e-05,  1.0988e-05, -1.5044e-05,\n",
      "        -3.4921e-06, -1.0585e-05, -2.1358e-07,  4.9165e-06,  6.1851e-06,\n",
      "         1.6236e-05, -1.5848e-05, -3.9892e-07,  1.6609e-05,  1.8526e-05,\n",
      "         1.4249e-05, -8.7337e-06, -3.1192e-06, -2.9579e-05, -3.8933e-05,\n",
      "         4.5283e-06,  5.2982e-07, -3.0858e-06, -3.5885e-06, -8.0146e-07,\n",
      "         4.7498e-05,  1.6747e-05, -3.8189e-07, -1.3927e-05, -1.7438e-05,\n",
      "         1.4613e-05,  2.0401e-05,  6.4422e-06, -4.4796e-06, -4.2213e-07,\n",
      "         6.8186e-06, -1.5799e-05,  2.3908e-05,  1.7852e-06,  4.7968e-05,\n",
      "         3.1493e-06,  9.4937e-06,  2.5638e-06, -8.0994e-06,  7.6427e-06,\n",
      "        -1.4016e-05,  5.3618e-05, -3.9865e-05, -9.5661e-07,  5.6761e-06,\n",
      "         3.3185e-05, -7.2042e-06,  3.6082e-05, -8.8536e-06, -1.1651e-05,\n",
      "         2.1485e-06,  5.7057e-06,  5.0300e-06,  1.0314e-05,  8.8355e-07,\n",
      "        -6.6613e-06, -4.8739e-06, -2.9862e-06,  5.1649e-06, -3.5329e-06,\n",
      "         6.0289e-06, -1.6180e-07,  7.7453e-09, -2.0561e-05, -1.2875e-05,\n",
      "        -8.4288e-06, -4.1492e-05, -3.6567e-05, -7.2931e-06, -3.8715e-07,\n",
      "         4.2130e-05, -3.0515e-05,  2.7380e-06,  2.6567e-06, -5.3408e-06,\n",
      "        -2.9501e-06, -1.7385e-06, -1.3688e-06, -8.8199e-06, -4.6075e-05,\n",
      "         5.2307e-06, -2.7711e-07,  1.4351e-05,  9.4358e-06])), ('att1.out_proj.weight', tensor([[-8.5667e-06, -3.4704e-06, -3.9701e-05,  ..., -1.3816e-07,\n",
      "          3.7513e-05,  7.7113e-05],\n",
      "        [ 3.6359e-06, -4.4930e-07,  1.5985e-05,  ..., -2.4853e-07,\n",
      "          9.5094e-06,  2.7005e-05],\n",
      "        [ 4.2323e-07,  4.6164e-07,  5.0557e-06,  ..., -7.1281e-08,\n",
      "         -4.0918e-06,  5.3894e-07],\n",
      "        ...,\n",
      "        [-4.0927e-06, -3.6545e-07, -4.7564e-06,  ...,  3.8971e-08,\n",
      "          2.4104e-06, -7.8704e-06],\n",
      "        [-4.8193e-06,  3.1220e-06,  1.7347e-05,  ...,  5.8439e-07,\n",
      "         -1.2338e-05, -5.1879e-05],\n",
      "        [ 1.5548e-05,  2.4124e-06,  5.6330e-06,  ...,  5.4704e-08,\n",
      "         -1.8072e-05, -1.5523e-05]])), ('att1.out_proj.bias', tensor([ 2.8353e-05,  1.0547e-06,  3.3201e-06, -1.1752e-05, -2.6344e-05,\n",
      "        -3.5966e-06,  2.7395e-05,  7.2665e-06,  1.1276e-05, -6.6169e-06,\n",
      "         2.9037e-06, -8.9710e-06, -3.0655e-06, -1.0269e-05,  3.5913e-05,\n",
      "         1.8962e-05,  4.2523e-05,  4.7033e-06, -1.5130e-05,  1.9830e-05,\n",
      "         1.4690e-05, -5.5760e-06,  1.7433e-05,  5.9392e-06,  1.8821e-05,\n",
      "        -1.6163e-05, -5.2148e-05,  2.9916e-06, -2.8032e-06,  3.8855e-05,\n",
      "        -2.0248e-06,  6.6918e-07, -2.6005e-05, -1.5466e-07, -8.0823e-08,\n",
      "         2.4723e-05,  4.0516e-05,  1.3657e-05, -4.2486e-06,  5.0544e-05,\n",
      "        -8.1383e-06, -1.6173e-05, -1.5129e-05, -1.7294e-05,  4.0460e-05,\n",
      "        -5.4872e-06,  8.8357e-06,  3.0040e-05,  2.2764e-05, -4.3269e-05,\n",
      "         4.2017e-05,  1.0061e-05, -3.7079e-05,  3.5274e-06, -1.4412e-05,\n",
      "         2.4957e-05, -1.5514e-05, -1.9175e-05, -5.5488e-05,  7.3553e-06,\n",
      "         3.1280e-05, -2.2149e-05, -3.4386e-05, -9.5439e-05, -8.0904e-06,\n",
      "        -3.7695e-05,  2.2015e-07, -3.7089e-05, -6.6113e-05, -2.0122e-07,\n",
      "        -7.4640e-05, -3.6510e-05, -1.5296e-05,  1.1824e-05, -7.2956e-05,\n",
      "        -4.0007e-06,  1.5657e-05, -1.1846e-05,  3.0981e-06,  6.9551e-06,\n",
      "         1.5556e-05, -9.8178e-07, -1.1210e-05,  6.4369e-05, -5.8360e-05,\n",
      "        -2.6663e-05,  2.4500e-05,  5.3120e-06,  7.2166e-05, -9.0234e-06,\n",
      "         2.3555e-05,  1.5392e-05, -3.1227e-05, -7.6331e-07,  1.7364e-05,\n",
      "         8.8985e-06,  1.5835e-05, -5.1819e-05,  4.2551e-05,  2.3291e-05,\n",
      "        -3.2765e-05,  1.0045e-05,  2.8236e-05,  1.2051e-04, -2.6335e-05,\n",
      "        -7.3161e-06, -5.5459e-05,  4.0224e-05,  1.7153e-05,  1.1775e-05,\n",
      "        -9.0464e-06, -7.4314e-06,  1.3019e-04, -7.6157e-05, -3.3488e-05,\n",
      "        -1.0883e-05, -4.8961e-07, -4.7997e-06,  6.9904e-06, -4.6226e-05,\n",
      "        -3.3042e-06, -1.0509e-05,  3.3838e-07,  3.4397e-05,  6.8683e-05,\n",
      "         2.2629e-06, -2.5961e-05,  2.0705e-07])), ('att2.in_proj_weight', tensor([[-3.0878e-10, -8.1102e-10,  4.2796e-10,  ...,  1.0456e-09,\n",
      "         -9.5413e-11, -3.2150e-10],\n",
      "        [ 3.8675e-11,  2.2454e-10, -5.6780e-10,  ..., -3.8079e-11,\n",
      "         -3.1643e-10, -4.0400e-10],\n",
      "        [-9.5990e-11, -9.1284e-11, -2.4821e-10,  ...,  3.2835e-10,\n",
      "         -2.6882e-10,  9.6115e-10],\n",
      "        ...,\n",
      "        [-4.9376e-05, -1.6052e-05,  7.3208e-06,  ...,  1.1102e-05,\n",
      "          2.9126e-05, -6.6692e-05],\n",
      "        [-1.7043e-05,  9.9425e-07,  2.8617e-06,  ...,  2.4905e-06,\n",
      "         -1.8541e-05, -1.2308e-05],\n",
      "        [ 2.0224e-06,  5.5813e-06,  9.8274e-07,  ...,  1.2475e-06,\n",
      "         -8.1921e-06, -1.6467e-06]])), ('att2.in_proj_bias', tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -5.2609e-05, -8.5408e-05,  3.2214e-05,  5.2662e-06,\n",
      "         6.3741e-05,  8.4967e-05,  1.2796e-04, -1.4606e-04,  7.4474e-05,\n",
      "         2.3898e-06,  9.9401e-05, -1.1949e-05,  2.8375e-05,  1.2954e-04,\n",
      "        -8.0600e-06, -1.5847e-06, -1.9553e-06, -5.5611e-05, -2.1452e-05,\n",
      "         9.0587e-05,  4.3950e-05,  5.0589e-05,  5.6148e-07,  6.6041e-05,\n",
      "         1.6062e-05, -3.6370e-05, -1.4131e-05, -1.7247e-04, -6.9910e-05,\n",
      "         5.4943e-05,  7.3470e-05, -1.7232e-05,  2.1503e-05, -1.4979e-05,\n",
      "         3.4171e-05, -1.5250e-05, -1.9671e-05, -1.5774e-05,  8.7805e-05,\n",
      "        -6.2130e-06, -6.8345e-05, -4.6715e-05, -5.7528e-05,  6.6052e-06,\n",
      "        -1.3267e-05, -2.9511e-05, -5.9993e-06,  6.4381e-05,  1.8974e-04,\n",
      "         3.4892e-05,  9.2887e-06,  1.5272e-05,  1.1171e-04, -2.3631e-05,\n",
      "        -5.1132e-06,  3.8654e-05, -1.1206e-05,  2.7329e-06, -9.8104e-05,\n",
      "         1.2501e-04,  2.9318e-05,  5.7626e-05, -5.8982e-05,  1.1404e-05,\n",
      "         1.6101e-05,  5.7702e-06,  9.5367e-05, -5.5436e-06,  1.8388e-05,\n",
      "         4.4209e-05,  4.2712e-05, -2.6861e-05, -8.9538e-06,  7.3014e-06,\n",
      "         1.0605e-04,  3.3795e-05, -2.1449e-05, -2.0134e-05, -1.0836e-05,\n",
      "        -1.7221e-05, -1.0069e-04,  6.4043e-05, -2.1005e-05, -3.5188e-05,\n",
      "        -1.4840e-06, -2.7866e-05,  1.1820e-04,  1.3753e-05, -5.9155e-06,\n",
      "         5.3512e-05,  5.9414e-05,  9.9857e-05,  2.0682e-04, -3.9142e-05,\n",
      "         1.7834e-04,  2.9982e-05,  1.2014e-04, -6.8442e-05,  6.3269e-05,\n",
      "         4.2064e-05,  1.2958e-04, -1.5245e-04, -5.3370e-05,  2.8799e-05,\n",
      "        -3.6244e-06,  4.8204e-05, -6.5477e-05, -3.8428e-05, -9.6387e-06,\n",
      "        -5.7504e-05,  4.3859e-05,  1.8800e-05,  3.9536e-05,  3.0956e-05,\n",
      "        -1.5838e-04,  5.1635e-05, -1.1532e-05, -1.3050e-04, -1.4344e-05,\n",
      "         1.2655e-05,  3.4262e-07, -5.8197e-05, -7.1899e-06, -4.6689e-05,\n",
      "         8.0730e-05, -1.8452e-05, -5.4912e-05,  1.1996e-05])), ('att2.out_proj.weight', tensor([[ 4.2737e-06, -7.7824e-05,  6.6210e-05,  ..., -3.7549e-05,\n",
      "         -2.1263e-05,  1.5282e-05],\n",
      "        [-6.2232e-06,  2.6081e-05,  6.0937e-06,  ..., -4.2468e-06,\n",
      "         -8.8451e-06,  3.4501e-06],\n",
      "        [-1.4151e-05, -2.3114e-06, -7.4231e-06,  ..., -1.4326e-05,\n",
      "          1.6069e-05,  7.8439e-06],\n",
      "        ...,\n",
      "        [-1.2214e-05,  5.3358e-06,  2.4966e-05,  ..., -8.9582e-05,\n",
      "          1.8148e-05, -4.2465e-07],\n",
      "        [-1.0596e-06,  3.6298e-05, -1.9268e-05,  ..., -1.2133e-05,\n",
      "          1.7244e-05,  6.3718e-06],\n",
      "        [ 2.8986e-06,  2.7291e-06, -7.3172e-06,  ...,  2.4023e-05,\n",
      "          5.1656e-06, -7.8114e-09]])), ('att2.out_proj.bias', tensor([ 3.9838e-04,  6.5739e-05,  9.9116e-05,  2.6174e-05,  8.2921e-05,\n",
      "        -2.3349e-05,  1.3960e-04,  1.3409e-05, -8.3604e-05, -1.0299e-06,\n",
      "        -6.8364e-06,  1.0637e-04, -9.7799e-05,  2.0556e-05, -1.7757e-04,\n",
      "         3.6089e-05,  2.1751e-04,  1.5831e-04,  5.8958e-05,  2.9653e-04,\n",
      "         3.0383e-04, -1.7169e-05,  2.1014e-05, -7.5866e-05, -4.4924e-04,\n",
      "         5.1176e-05, -1.1374e-05,  3.6292e-04, -2.5388e-05,  8.2900e-05,\n",
      "         9.9186e-05,  3.5500e-04,  9.7125e-08,  1.9309e-04,  8.6201e-06,\n",
      "        -2.2822e-06, -1.1721e-04, -1.9521e-05, -3.8561e-04, -1.8934e-04,\n",
      "         3.5065e-05,  3.3807e-04,  4.5976e-05, -2.6629e-04, -1.2537e-04,\n",
      "        -1.6943e-05, -2.0807e-04,  5.9132e-05, -3.8618e-04,  5.1813e-05,\n",
      "        -2.2624e-04, -6.8869e-04, -5.0405e-05, -2.7739e-04, -2.3684e-05,\n",
      "         6.6789e-05, -1.3408e-04, -1.7546e-04,  4.6534e-05, -6.9915e-05,\n",
      "         3.0767e-04, -1.4650e-04, -4.0162e-04, -4.1273e-04, -3.6852e-04,\n",
      "         4.1159e-04, -1.1033e-04, -1.3766e-04,  4.7907e-05, -6.3909e-06,\n",
      "        -1.9043e-07, -5.3700e-04, -3.9270e-05, -1.3816e-04, -5.7915e-05,\n",
      "         9.0676e-07, -1.2831e-05,  1.1282e-04, -7.8634e-05,  1.5919e-04,\n",
      "         8.6504e-05, -2.3140e-04,  9.7620e-05,  1.1699e-04,  7.2874e-05,\n",
      "        -5.2463e-05, -3.5827e-05,  4.6416e-04, -1.8431e-04, -2.4934e-04,\n",
      "        -1.5472e-05,  8.5292e-04, -2.1939e-04,  1.8888e-04, -1.8857e-05,\n",
      "         4.7128e-04, -7.5020e-06,  1.7998e-07, -1.4130e-04,  9.0953e-05,\n",
      "        -7.1855e-05, -3.2190e-04, -2.9172e-04, -1.8755e-04,  1.9609e-04,\n",
      "        -7.6941e-05,  4.7059e-04, -1.8198e-04,  4.0398e-05, -5.5219e-04,\n",
      "        -4.2067e-05,  1.9533e-05, -1.2725e-04,  6.7067e-05,  7.7220e-04,\n",
      "         6.2982e-06,  3.9118e-05,  1.9364e-05, -3.0148e-06, -1.0226e-04,\n",
      "         3.0075e-05, -3.2828e-04, -8.2880e-05, -3.4857e-06,  5.2486e-05,\n",
      "        -1.0373e-05, -1.0113e-04,  2.4455e-05])), ('fc1.weight', tensor([[ 1.2942e-05,  1.6680e-05, -1.6544e-05,  ...,  2.5455e-05,\n",
      "         -6.4649e-06,  3.3333e-05],\n",
      "        [-1.4716e-05, -1.7025e-05,  2.5115e-05,  ...,  6.1294e-06,\n",
      "          2.5610e-06, -2.3090e-05],\n",
      "        [ 7.2900e-06, -2.5040e-07,  1.2184e-05,  ...,  8.7884e-06,\n",
      "          1.1767e-05, -4.1437e-07],\n",
      "        ...,\n",
      "        [-1.4128e-05, -1.6805e-05,  1.4650e-05,  ...,  2.5517e-06,\n",
      "         -4.5039e-06, -8.5368e-06],\n",
      "        [ 4.8534e-06, -6.2177e-06,  1.4460e-05,  ...,  1.8200e-05,\n",
      "          4.8719e-06,  1.3301e-05],\n",
      "        [ 1.4910e-05,  2.1317e-05, -1.2877e-06,  ...,  1.6520e-05,\n",
      "         -2.3359e-06, -1.5355e-05]])), ('fc1.bias', tensor([-2.8721e-10,  8.9128e-11,  4.1203e-14,  2.7486e-11,  6.1460e-10,\n",
      "         1.6970e-10,  3.3496e-10,  6.0494e-11, -1.9063e-10,  3.4227e-10,\n",
      "        -2.2186e-10,  1.3319e-10, -5.5251e-10,  1.1585e-10,  6.3230e-11,\n",
      "        -1.6234e-10,  2.3118e-10,  8.4444e-11,  3.8850e-12, -6.4590e-10,\n",
      "        -1.2906e-10,  2.1252e-10, -7.3387e-11, -4.9390e-10, -6.4923e-10,\n",
      "        -3.1392e-10,  4.6194e-10, -1.1181e-10,  7.0753e-11,  1.6664e-10,\n",
      "        -6.3043e-11,  3.5136e-10, -3.7716e-12,  2.8053e-10,  2.8499e-10,\n",
      "         4.0702e-10,  1.3769e-10, -2.8881e-10,  8.5021e-12,  8.7039e-11,\n",
      "        -2.0764e-10,  1.9909e-11,  1.1073e-11,  1.7639e-10,  3.8541e-10,\n",
      "         2.8287e-11,  2.3591e-10,  2.3875e-11,  2.2575e-11,  2.7259e-10,\n",
      "         3.9917e-10,  8.7597e-11,  1.2760e-10, -1.4881e-10,  1.2058e-10,\n",
      "        -8.4264e-11, -1.3200e-10,  2.3392e-11, -1.6754e-10,  3.5185e-11,\n",
      "         1.4230e-10, -9.5956e-11, -3.0751e-10,  3.9031e-10,  1.3404e-10,\n",
      "        -2.3485e-10,  6.9084e-11,  2.2697e-10,  2.3948e-10,  2.4946e-10,\n",
      "         4.4162e-10,  2.9158e-10,  4.1452e-10, -1.7346e-10,  1.2160e-10,\n",
      "        -6.1019e-12,  1.2641e-10, -1.9452e-10,  6.6191e-11, -5.3846e-10,\n",
      "        -1.9314e-10, -2.0470e-10,  3.1398e-10,  2.2231e-10,  4.4711e-10,\n",
      "         3.1639e-10, -1.9557e-10,  9.3424e-11,  1.7051e-10, -8.0452e-11,\n",
      "         5.2041e-10, -3.1272e-10,  5.2353e-10,  1.7126e-10,  5.1948e-10,\n",
      "        -5.4732e-10,  2.4789e-11,  8.1142e-11,  3.2462e-11, -3.6322e-11,\n",
      "        -1.7242e-10,  3.7314e-11, -3.4288e-10, -2.7737e-10, -1.6020e-10,\n",
      "         3.8115e-10, -1.6860e-10, -2.1354e-10, -3.4152e-10, -2.3903e-10,\n",
      "        -3.3477e-12, -2.4602e-10, -5.0677e-10,  3.8641e-10, -2.7353e-10,\n",
      "        -3.2221e-12,  2.9809e-10, -3.3573e-10, -4.2942e-10, -6.8436e-11,\n",
      "        -4.7129e-10, -3.4254e-10, -6.2848e-12,  2.7293e-10,  1.0025e-11,\n",
      "        -7.4733e-11,  1.5063e-10,  4.4227e-10])), ('fc2.weight', tensor([[ 3.0015e-08, -9.0471e-09, -3.4562e-08,  ...,  9.0549e-08,\n",
      "         -2.9733e-11,  3.9933e-09],\n",
      "        [ 1.4063e-07,  1.2307e-08, -4.2270e-08,  ...,  8.7498e-08,\n",
      "         -7.9359e-08,  5.0505e-09],\n",
      "        [-1.1956e-06, -5.1514e-07, -5.2435e-06,  ...,  1.2400e-06,\n",
      "          6.0251e-06, -6.4830e-07],\n",
      "        ...,\n",
      "        [ 1.5546e-04,  2.4831e-05, -5.7062e-05,  ...,  5.4910e-05,\n",
      "          5.1260e-05,  3.2659e-05],\n",
      "        [-9.7800e-07,  6.4957e-08,  2.1701e-07,  ..., -2.0913e-07,\n",
      "          4.2860e-07, -8.3204e-08],\n",
      "        [ 1.1595e-06,  3.3740e-07,  7.5975e-07,  ..., -2.6544e-07,\n",
      "          9.4773e-07, -8.7219e-08]])), ('fc2.bias', tensor([ 5.5325e-07, -6.3809e-07, -2.1514e-05,  3.2518e-04, -5.0783e-05,\n",
      "         1.6839e-07,  5.9747e-06,  9.7315e-07, -1.5067e-03,  3.0731e-07,\n",
      "         7.1673e-04,  2.5750e-04, -8.2832e-08,  1.1271e-07, -3.0003e-04,\n",
      "        -1.2969e-06, -1.3135e-06, -8.3207e-05, -1.0521e-03, -1.1868e-06,\n",
      "        -1.2573e-06, -1.8769e-05,  3.8829e-04,  8.9993e-04,  6.8805e-06,\n",
      "         9.4875e-07, -1.2261e-03, -5.9934e-07,  9.0377e-04,  5.6147e-06,\n",
      "         2.2954e-06, -1.3685e-08,  7.3442e-09,  6.2887e-08,  3.4360e-06,\n",
      "         2.7651e-04,  2.4460e-04, -1.1614e-05,  5.0811e-04,  4.0957e-03,\n",
      "         1.9225e-05,  9.5407e-06,  3.9631e-06, -3.0994e-05, -6.7815e-05,\n",
      "         3.0080e-04, -1.0391e-03,  4.1172e-04, -2.9935e-04,  2.3005e-05,\n",
      "        -5.2572e-04, -1.4610e-03, -1.5338e-04,  2.4036e-05, -3.1563e-04,\n",
      "        -1.1893e-06, -1.4991e-03, -5.3307e-06, -2.1802e-04, -6.1232e-08,\n",
      "        -3.0672e-06, -1.1794e-03, -1.8143e-06, -4.9447e-06])), ('fc3.weight', tensor([[ 3.6154e-07, -1.7531e-07, -5.6042e-05,  1.3737e-04,  2.7476e-05,\n",
      "          2.8301e-07,  4.5026e-06, -7.1339e-07, -3.7963e-04,  1.1171e-07,\n",
      "          5.7897e-04, -4.6065e-04, -1.1189e-07,  1.9260e-07,  2.7489e-04,\n",
      "         -3.8166e-07, -4.0440e-06, -4.3156e-04, -2.3123e-07,  1.5735e-06,\n",
      "         -2.4341e-06, -7.9070e-06, -1.1919e-05,  6.4676e-05,  3.9840e-06,\n",
      "         -3.3488e-07,  6.7077e-05,  1.2834e-06,  2.6514e-03,  6.0715e-07,\n",
      "          1.0661e-05,  1.0786e-08,  4.7234e-08,  7.3674e-07, -6.4985e-06,\n",
      "         -2.1952e-05,  1.1107e-04, -8.7381e-06,  2.4692e-04,  2.0599e-03,\n",
      "          3.0760e-04,  5.8357e-06,  2.2313e-06,  4.2675e-05,  1.1827e-04,\n",
      "         -1.0005e-03,  1.5512e-03, -1.1373e-04,  1.3248e-04,  2.2857e-06,\n",
      "         -4.9642e-04, -1.8473e-04,  3.9766e-05, -8.0653e-06,  6.1898e-04,\n",
      "         -2.1248e-06,  1.4517e-04, -9.8206e-06, -4.5823e-04, -1.6723e-07,\n",
      "          1.2903e-06,  5.1220e-04, -3.9968e-06, -4.0715e-06],\n",
      "        [ 4.5180e-07,  1.1751e-07, -1.5939e-06, -2.0206e-04,  1.1913e-05,\n",
      "         -7.1101e-08, -1.3772e-06,  1.7923e-06,  3.4222e-04, -1.8871e-06,\n",
      "         -1.1793e-04, -1.4052e-04, -1.6722e-08, -2.2814e-07,  3.6019e-05,\n",
      "          4.8850e-07,  2.4826e-06, -2.9033e-04,  8.6087e-04, -8.1804e-07,\n",
      "         -1.1704e-06,  1.5672e-05, -1.8956e-04, -6.3318e-04,  1.6995e-06,\n",
      "         -4.3725e-07,  3.2403e-04,  8.1552e-07, -1.9496e-03,  1.8867e-06,\n",
      "         -6.3518e-06, -3.5314e-08,  3.6106e-09,  7.5034e-08, -9.2862e-06,\n",
      "         -7.1891e-05, -4.4841e-05, -1.9497e-07, -1.1420e-04,  3.5409e-04,\n",
      "         -1.5545e-04, -1.8647e-06, -2.5257e-06,  3.0877e-05,  1.3786e-05,\n",
      "         -1.2432e-04, -3.1205e-04, -2.7672e-04,  3.9670e-04, -3.7732e-06,\n",
      "         -1.9525e-04,  6.1803e-04, -3.6729e-06, -1.4820e-05,  2.7502e-04,\n",
      "          2.6021e-07,  7.7546e-05,  3.7625e-08,  3.8250e-05, -5.8841e-07,\n",
      "          9.7038e-08, -2.8728e-05,  9.1466e-07, -3.7956e-06],\n",
      "        [ 2.6681e-07,  6.4736e-07, -5.5924e-06,  1.1445e-04, -4.7767e-05,\n",
      "         -1.2553e-07,  3.1946e-08,  1.3361e-08,  4.4662e-04, -1.1271e-06,\n",
      "         -1.6927e-05,  2.0967e-04, -5.4565e-09,  1.0367e-07, -1.8702e-05,\n",
      "          4.5630e-07, -3.5084e-07, -3.0629e-04,  9.2316e-05, -5.8950e-07,\n",
      "          1.6637e-06, -3.8551e-06,  1.2647e-04,  3.1178e-05, -1.7694e-06,\n",
      "          9.2264e-07,  2.9356e-04, -1.9685e-06,  5.6329e-04,  3.4407e-06,\n",
      "         -6.3821e-06, -2.5987e-08,  8.3100e-09, -7.4596e-07,  4.5685e-06,\n",
      "         -2.2867e-04, -6.9391e-05,  5.5912e-06, -1.3987e-04, -1.0514e-03,\n",
      "          1.1104e-04, -4.5132e-08,  2.1823e-06, -1.0200e-05, -1.1356e-05,\n",
      "         -3.6541e-04,  2.3496e-05, -3.1497e-04,  1.0325e-04, -3.4214e-06,\n",
      "         -7.6284e-05,  4.4685e-04, -1.5292e-04, -1.8891e-05,  1.1401e-04,\n",
      "         -1.9520e-07, -8.4679e-05, -1.8403e-06,  1.5797e-06, -1.4606e-07,\n",
      "         -4.0736e-06, -2.8673e-05,  1.1141e-06,  1.3672e-06]])), ('fc3.bias', tensor([ 0.2524, -0.1923, -0.0627]))])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(len(train_accuracies[1:])), train_accuracies[1:], label = \"train\")\n",
    "plt.plot(np.arange(len(train_accuracies[1:])), val_accuracies[1:], label = \"val\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0.47, 0.52)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(val_accuracies)\n",
    "#print(train_accuracies)\n",
    "torch.save(best_state, \"MCT_params_best2\")\n",
    "#torch.save(net.state_dict(), \"MCT_params_last\")\n",
    "#net = MatchClassifier(3,4,302,278,300)\n",
    "#net.load_state_dict(torch.load(\"MC1_params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5030475416497359\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#print(val_accuracies)\n",
    "#print(train_accuracies)\n",
    "#torch.save(net.state_dict(), \"MC1_params\")\n",
    "net = MatchTeamClassifier(3,280,(512,64))\n",
    "net.load_state_dict(torch.load(\"MCT_params_best2\"))\n",
    "\n",
    "hat_y_val = torch.argmax(net(x_valid), axis=1)\n",
    "y_val = torch.argmax(Y_valid, axis=1)\n",
    "#print(confusion_matrix(y_val, hat_y_val, normalize=\"pred\"))\n",
    "#print(np.unique(torch.argmax(Y_valid, axis=1), return_counts=True))\n",
    "print(accuracy_score(y_val, hat_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_home_team_statistics_df = pd.read_csv('./test_home_team_statistics_df.csv', index_col=0)\n",
    "test_away_team_statistics_df = pd.read_csv('./test_away_team_statistics_df.csv', index_col=0)\n",
    "\n",
    "test_home_team_statistics_df.columns = 'HOME_' + test_home_team_statistics_df.columns\n",
    "test_away_team_statistics_df.columns = 'AWAY_' + test_away_team_statistics_df.columns\n",
    "\n",
    "test_data = test_home_team_statistics_df.join(test_away_team_statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "d = {'HOME_WINS':[0 for i in range(len(test_data))], 'DRAW':[0 for i in range(len(test_data))], \"AWAY_WINS\":[0 for i in range(len(test_data))]}\n",
    "test_score = pd.DataFrame(data=d, index=test_home_team_statistics_df.index)\n",
    "y_pred = net(torch.Tensor(test_data.replace({np.nan:0.0}).values))\n",
    "scores = torch.argmax(y_pred, axis=1)\n",
    "test_score.iloc[scores == 0, 0] = 1\n",
    "test_score.iloc[scores == 1, 1] = 1\n",
    "test_score.iloc[scores == 2, 2] = 1\n",
    "test_score.reset_index(inplace=True)\n",
    "test_score.to_csv(\"MCT.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
