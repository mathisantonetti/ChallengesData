{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_team_statistics_df = pd.read_csv('./train_home_team_statistics_df.csv', index_col=0)\n",
    "train_away_team_statistics_df = pd.read_csv('./train_away_team_statistics_df.csv', index_col=0)\n",
    "\n",
    "train_scores = pd.read_csv('./Y_train.csv', index_col=0)\n",
    "\n",
    "train_home_team_statistics_df.columns = 'HOME_' + train_home_team_statistics_df.columns\n",
    "train_away_team_statistics_df.columns = 'AWAY_' + train_away_team_statistics_df.columns\n",
    "\n",
    "train_data = train_home_team_statistics_df.iloc[:,2:].join(train_away_team_statistics_df.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(train_data, train_scores, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class MatchTeamClassifier(nn.Module):\n",
    "    def __init__(self, n_class, n_team_fts, hidden_team):\n",
    "        super().__init__()\n",
    "        self.hidden = hidden_team\n",
    "        self.bc1 = nn.BatchNorm1d(n_team_fts)\n",
    "        self.bc2 = nn.BatchNorm1d(hidden_team[0])\n",
    "        self.att1 = nn.MultiheadAttention(hidden_team[0], 1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(n_team_fts, hidden_team[0])\n",
    "        self.fc2 = nn.Linear(hidden_team[0], hidden_team[1])\n",
    "        self.bc3 = nn.BatchNorm1d(hidden_team[1])\n",
    "        self.att2 = nn.MultiheadAttention(hidden_team[1], 1, batch_first=True)\n",
    "        self.fc3 = nn.Linear(hidden_team[1], hidden_team[2])\n",
    "        self.bc4 = nn.BatchNorm1d(hidden_team[2])\n",
    "        self.att3 = nn.MultiheadAttention(hidden_team[2], 1, batch_first=True)\n",
    "        self.fc4 = nn.Linear(hidden_team[2], n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.bc2(self.fc1(self.bc1(x)))[:,None,:]\n",
    "        res = self.att1(res, res, res, need_weights=False)[0]\n",
    "        res = self.bc3(self.fc2(res)[:,0,:]).reshape(-1, 1, self.hidden[1])\n",
    "        res = self.att2(res, res, res, need_weights=False)[0]\n",
    "        res = self.bc4(self.fc3(res)[:,0,:]).reshape(-1, 1, self.hidden[2])\n",
    "        res = self.att3(res, res, res, need_weights=False)[0]\n",
    "        return self.fc4(res)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MatchTeamClassifier(3, 280, (128, 64, 32))\n",
    "\n",
    "x_train = torch.Tensor(X_train.replace({np.nan:0.0}).values)\n",
    "x_valid = torch.Tensor(X_valid.replace({np.nan:0.0}).values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "Y_valid = torch.Tensor(y_valid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2461, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net(x_valid).shape)\n",
    "net.bc1.requires_grad_(False)\n",
    "net.bc3.requires_grad_(False)\n",
    "net.bc4.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 1.10 | Train Accuracy 0.382137776874619 | Val Accuracy 0.47013409183258836\n",
      "Epoch 1 Loss 1.05 | Train Accuracy 0.46403170087380613 | Val Accuracy 0.4790735473384803\n",
      "Epoch 2 Loss 1.03 | Train Accuracy 0.48384474700264174 | Val Accuracy 0.48679398618447783\n",
      "Epoch 3 Loss 1.02 | Train Accuracy 0.49126193863035966 | Val Accuracy 0.4863876472978464\n",
      "Epoch 4 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4904510361641609\n",
      "Epoch 5 Loss 1.01 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.49207639171068673\n",
      "Epoch 6 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4904510361641609\n",
      "Epoch 7 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4965461194636327\n",
      "Epoch 8 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4989841527834214\n",
      "Epoch 9 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.5002031694433158\n",
      "Epoch 10 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49410808614384394\n",
      "Epoch 11 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4766355140186916\n",
      "Epoch 12 Loss 1.02 | Train Accuracy 0.48536882747409066 | Val Accuracy 0.46891507517269404\n",
      "Epoch 13 Loss 1.04 | Train Accuracy 0.47551310709205447 | Val Accuracy 0.4912637139374238\n",
      "Epoch 14 Loss 1.02 | Train Accuracy 0.4927860191018086 | Val Accuracy 0.49329540837058106\n",
      "Epoch 15 Loss 1.02 | Train Accuracy 0.48831538305222516 | Val Accuracy 0.4937017472572125\n",
      "Epoch 16 Loss 1.01 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.49573344169036976\n",
      "Epoch 17 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.48923201950426654\n",
      "Epoch 18 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4863876472978464\n",
      "Epoch 19 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4904510361641609\n",
      "Epoch 20 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.477041852905323\n",
      "Epoch 21 Loss 1.02 | Train Accuracy 0.48587685429790695 | Val Accuracy 0.48191791954490043\n",
      "Epoch 22 Loss 1.02 | Train Accuracy 0.48618167039219673 | Val Accuracy 0.49167005282405524\n",
      "Epoch 23 Loss 1.01 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.4949207639171069\n",
      "Epoch 24 Loss 1.01 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.48923201950426654\n",
      "Epoch 25 Loss 1.02 | Train Accuracy 0.4931924405608616 | Val Accuracy 0.49451442503047544\n",
      "Epoch 26 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4928890694839496\n",
      "Epoch 27 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49410808614384394\n",
      "Epoch 28 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4949207639171069\n",
      "Epoch 29 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49451442503047544\n",
      "Epoch 30 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49167005282405524\n",
      "Epoch 31 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4900446972775295\n",
      "Epoch 32 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49329540837058106\n",
      "Epoch 33 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49167005282405524\n",
      "Epoch 34 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49167005282405524\n",
      "Epoch 35 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4831369362047948\n",
      "Epoch 36 Loss 1.02 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.4961397805770012\n",
      "Epoch 37 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49410808614384394\n",
      "Epoch 38 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4924827305973182\n",
      "Epoch 39 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.49207639171068673\n",
      "Epoch 40 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4900446972775295\n",
      "Epoch 41 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4904510361641609\n",
      "Epoch 42 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4985778138967899\n",
      "Epoch 43 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49085737505079235\n",
      "Epoch 44 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49410808614384394\n",
      "Epoch 45 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4928890694839496\n",
      "Epoch 46 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4912637139374238\n",
      "Epoch 47 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 48 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49410808614384394\n",
      "Epoch 49 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4953271028037383\n",
      "Epoch 50 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.47866720845184885\n",
      "Epoch 51 Loss 1.02 | Train Accuracy 0.492176386913229 | Val Accuracy 0.48963835839089803\n",
      "Epoch 52 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4928890694839496\n",
      "Epoch 53 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4924827305973182\n",
      "Epoch 54 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4961397805770012\n",
      "Epoch 55 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4904510361641609\n",
      "Epoch 56 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49167005282405524\n",
      "Epoch 57 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 58 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49451442503047544\n",
      "Epoch 59 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4863876472978464\n",
      "Epoch 60 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49329540837058106\n",
      "Epoch 61 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4937017472572125\n",
      "Epoch 62 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48923201950426654\n",
      "Epoch 63 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4912637139374238\n",
      "Epoch 64 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4912637139374238\n",
      "Epoch 65 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4928890694839496\n",
      "Epoch 66 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4880130028443722\n",
      "Epoch 67 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.48760666395774077\n",
      "Epoch 68 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.47622917513206015\n",
      "Epoch 69 Loss 1.02 | Train Accuracy 0.4924812030075188 | Val Accuracy 0.49410808614384394\n",
      "Epoch 70 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4880130028443722\n",
      "Epoch 71 Loss 1.01 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.4928890694839496\n",
      "Epoch 72 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48841934173100365\n",
      "Epoch 73 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49451442503047544\n",
      "Epoch 74 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4924827305973182\n",
      "Epoch 75 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4937017472572125\n",
      "Epoch 76 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4961397805770012\n",
      "Epoch 77 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.48963835839089803\n",
      "Epoch 78 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49573344169036976\n",
      "Epoch 79 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49167005282405524\n",
      "Epoch 80 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49451442503047544\n",
      "Epoch 81 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49167005282405524\n",
      "Epoch 82 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4900446972775295\n",
      "Epoch 83 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.48963835839089803\n",
      "Epoch 84 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4900446972775295\n",
      "Epoch 85 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4904510361641609\n",
      "Epoch 86 Loss 1.01 | Train Accuracy 0.49563096931517986 | Val Accuracy 0.4953271028037383\n",
      "Epoch 87 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49329540837058106\n",
      "Epoch 88 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49207639171068673\n",
      "Epoch 89 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49167005282405524\n",
      "Epoch 90 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 91 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49573344169036976\n",
      "Epoch 92 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4880130028443722\n",
      "Epoch 93 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4912637139374238\n",
      "Epoch 94 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4924827305973182\n",
      "Epoch 95 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49167005282405524\n",
      "Epoch 96 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.48760666395774077\n",
      "Epoch 97 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49085737505079235\n",
      "Epoch 98 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48923201950426654\n",
      "Epoch 99 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4888256806176351\n",
      "Epoch 100 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.48923201950426654\n",
      "Epoch 101 Loss 1.01 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4928890694839496\n",
      "Epoch 102 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49410808614384394\n",
      "Epoch 103 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4924827305973182\n",
      "Epoch 104 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 105 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49329540837058106\n",
      "Epoch 106 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4900446972775295\n",
      "Epoch 107 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 108 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4953271028037383\n",
      "Epoch 109 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4924827305973182\n",
      "Epoch 110 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4912637139374238\n",
      "Epoch 111 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 112 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4904510361641609\n",
      "Epoch 113 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.47744819179195447\n",
      "Epoch 114 Loss 1.02 | Train Accuracy 0.49105872790083316 | Val Accuracy 0.48760666395774077\n",
      "Epoch 115 Loss 1.02 | Train Accuracy 0.489839463523674 | Val Accuracy 0.4937017472572125\n",
      "Epoch 116 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4924827305973182\n",
      "Epoch 117 Loss 1.01 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.4900446972775295\n",
      "Epoch 118 Loss 1.02 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.4924827305973182\n",
      "Epoch 119 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49167005282405524\n",
      "Epoch 120 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4912637139374238\n",
      "Epoch 121 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4912637139374238\n",
      "Epoch 122 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4953271028037383\n",
      "Epoch 123 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4965461194636327\n",
      "Epoch 124 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "Epoch 125 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49410808614384394\n",
      "Epoch 126 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 127 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4937017472572125\n",
      "Epoch 128 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4912637139374238\n",
      "Epoch 129 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4924827305973182\n",
      "Epoch 130 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.48923201950426654\n",
      "Epoch 131 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4912637139374238\n",
      "Epoch 132 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4900446972775295\n",
      "Epoch 133 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4863876472978464\n",
      "Epoch 134 Loss 1.01 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4839496139780577\n",
      "Epoch 135 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4924827305973182\n",
      "Epoch 136 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 137 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4949207639171069\n",
      "Epoch 138 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49207639171068673\n",
      "Epoch 139 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49410808614384394\n",
      "Epoch 140 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49167005282405524\n",
      "Epoch 141 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48923201950426654\n",
      "Epoch 142 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 143 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49329540837058106\n",
      "Epoch 144 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4900446972775295\n",
      "Epoch 145 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4912637139374238\n",
      "Epoch 146 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4880130028443722\n",
      "Epoch 147 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4953271028037383\n",
      "Epoch 148 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49207639171068673\n",
      "Epoch 149 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4900446972775295\n",
      "Epoch 150 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "Epoch 151 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48841934173100365\n",
      "Epoch 152 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4904510361641609\n",
      "Epoch 153 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4961397805770012\n",
      "Epoch 154 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4924827305973182\n",
      "Epoch 155 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49329540837058106\n",
      "Epoch 156 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 157 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 158 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4965461194636327\n",
      "Epoch 159 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49573344169036976\n",
      "Epoch 160 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49451442503047544\n",
      "Epoch 161 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4912637139374238\n",
      "Epoch 162 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4880130028443722\n",
      "Epoch 163 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4900446972775295\n",
      "Epoch 164 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4863876472978464\n",
      "Epoch 165 Loss 1.01 | Train Accuracy 0.4934972566551514 | Val Accuracy 0.4900446972775295\n",
      "Epoch 166 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49207639171068673\n",
      "Epoch 167 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4928890694839496\n",
      "Epoch 168 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4949207639171069\n",
      "Epoch 169 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4928890694839496\n",
      "Epoch 170 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4904510361641609\n",
      "Epoch 171 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 172 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4953271028037383\n",
      "Epoch 173 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49329540837058106\n",
      "Epoch 174 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49451442503047544\n",
      "Epoch 175 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.48923201950426654\n",
      "Epoch 176 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48963835839089803\n",
      "Epoch 177 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4888256806176351\n",
      "Epoch 178 Loss 1.01 | Train Accuracy 0.49359886201991465 | Val Accuracy 0.4900446972775295\n",
      "Epoch 179 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48963835839089803\n",
      "Epoch 180 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4912637139374238\n",
      "Epoch 181 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4912637139374238\n",
      "Epoch 182 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49207639171068673\n",
      "Epoch 183 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 184 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4965461194636327\n",
      "Epoch 185 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4900446972775295\n",
      "Epoch 186 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 187 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4953271028037383\n",
      "Epoch 188 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4900446972775295\n",
      "Epoch 189 Loss 1.01 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.4888256806176351\n",
      "Epoch 190 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4904510361641609\n",
      "Epoch 191 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49085737505079235\n",
      "Epoch 192 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4937017472572125\n",
      "Epoch 193 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4924827305973182\n",
      "Epoch 194 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49085737505079235\n",
      "Epoch 195 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49167005282405524\n",
      "Epoch 196 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49085737505079235\n",
      "Epoch 197 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4928890694839496\n",
      "Epoch 198 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49207639171068673\n",
      "Epoch 199 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 200 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49167005282405524\n",
      "Epoch 201 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.481511580658269\n",
      "Epoch 202 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4924827305973182\n",
      "Epoch 203 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49167005282405524\n",
      "Epoch 204 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4949207639171069\n",
      "Epoch 205 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4904510361641609\n",
      "Epoch 206 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4888256806176351\n",
      "Epoch 207 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4900446972775295\n",
      "Epoch 208 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49573344169036976\n",
      "Epoch 209 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4900446972775295\n",
      "Epoch 210 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49207639171068673\n",
      "Epoch 211 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 212 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48760666395774077\n",
      "Epoch 213 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.477041852905323\n",
      "Epoch 214 Loss 1.02 | Train Accuracy 0.4878073562284089 | Val Accuracy 0.48963835839089803\n",
      "Epoch 215 Loss 1.01 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4904510361641609\n",
      "Epoch 216 Loss 1.02 | Train Accuracy 0.494919731761837 | Val Accuracy 0.49329540837058106\n",
      "Epoch 217 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4900446972775295\n",
      "Epoch 218 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4912637139374238\n",
      "Epoch 219 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.49167005282405524\n",
      "Epoch 220 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4900446972775295\n",
      "Epoch 221 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48841934173100365\n",
      "Epoch 222 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4904510361641609\n",
      "Epoch 223 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49573344169036976\n",
      "Epoch 224 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4937017472572125\n",
      "Epoch 225 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4965461194636327\n",
      "Epoch 226 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49167005282405524\n",
      "Epoch 227 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 228 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49329540837058106\n",
      "Epoch 229 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49451442503047544\n",
      "Epoch 230 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4863876472978464\n",
      "Epoch 231 Loss 1.01 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.48476229175132063\n",
      "Epoch 232 Loss 1.02 | Train Accuracy 0.48892501524080473 | Val Accuracy 0.4961397805770012\n",
      "Epoch 233 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4900446972775295\n",
      "Epoch 234 Loss 1.02 | Train Accuracy 0.49359886201991465 | Val Accuracy 0.49329540837058106\n",
      "Epoch 235 Loss 1.02 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.49329540837058106\n",
      "Epoch 236 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4912637139374238\n",
      "Epoch 237 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4912637139374238\n",
      "Epoch 238 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49207639171068673\n",
      "Epoch 239 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 240 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 241 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49167005282405524\n",
      "Epoch 242 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48963835839089803\n",
      "Epoch 243 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 244 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4937017472572125\n",
      "Epoch 245 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4912637139374238\n",
      "Epoch 246 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4888256806176351\n",
      "Epoch 247 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4937017472572125\n",
      "Epoch 248 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.48476229175132063\n",
      "Epoch 249 Loss 1.02 | Train Accuracy 0.49126193863035966 | Val Accuracy 0.47541649735879726\n",
      "Epoch 250 Loss 1.02 | Train Accuracy 0.4874009347693558 | Val Accuracy 0.48760666395774077\n",
      "Epoch 251 Loss 1.02 | Train Accuracy 0.491769965454176 | Val Accuracy 0.49451442503047544\n",
      "Epoch 252 Loss 1.02 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4904510361641609\n",
      "Epoch 253 Loss 1.02 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4888256806176351\n",
      "Epoch 254 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4900446972775295\n",
      "Epoch 255 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49329540837058106\n",
      "Epoch 256 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49207639171068673\n",
      "Epoch 257 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4924827305973182\n",
      "Epoch 258 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49410808614384394\n",
      "Epoch 259 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4904510361641609\n",
      "Epoch 260 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49329540837058106\n",
      "Epoch 261 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4928890694839496\n",
      "Epoch 262 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49695245835026414\n",
      "Epoch 263 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4888256806176351\n",
      "Epoch 264 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4997968305566843\n",
      "Epoch 265 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4953271028037383\n",
      "Epoch 266 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49085737505079235\n",
      "Epoch 267 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4583502641202763\n",
      "Epoch 268 Loss 1.03 | Train Accuracy 0.4786628733997155 | Val Accuracy 0.4888256806176351\n",
      "Epoch 269 Loss 1.02 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.48679398618447783\n",
      "Epoch 270 Loss 1.02 | Train Accuracy 0.49207478154846573 | Val Accuracy 0.49207639171068673\n",
      "Epoch 271 Loss 1.02 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4928890694839496\n",
      "Epoch 272 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48963835839089803\n",
      "Epoch 273 Loss 1.01 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.49085737505079235\n",
      "Epoch 274 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.48760666395774077\n",
      "Epoch 275 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49207639171068673\n",
      "Epoch 276 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 277 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49817147501015846\n",
      "Epoch 278 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49451442503047544\n",
      "Epoch 279 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4924827305973182\n",
      "Epoch 280 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4949207639171069\n",
      "Epoch 281 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4900446972775295\n",
      "Epoch 282 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4924827305973182\n",
      "Epoch 283 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4949207639171069\n",
      "Epoch 284 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49207639171068673\n",
      "Epoch 285 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4949207639171069\n",
      "Epoch 286 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4928890694839496\n",
      "Epoch 287 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4961397805770012\n",
      "Epoch 288 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4888256806176351\n",
      "Epoch 289 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4693214140593255\n",
      "Epoch 290 Loss 1.02 | Train Accuracy 0.48587685429790695 | Val Accuracy 0.49451442503047544\n",
      "Epoch 291 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4900446972775295\n",
      "Epoch 292 Loss 1.01 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4928890694839496\n",
      "Epoch 293 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4961397805770012\n",
      "Epoch 294 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4961397805770012\n",
      "Epoch 295 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49167005282405524\n",
      "Epoch 296 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48760666395774077\n",
      "Epoch 297 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4961397805770012\n",
      "Epoch 298 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49451442503047544\n",
      "Epoch 299 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49207639171068673\n",
      "Epoch 300 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49329540837058106\n",
      "Epoch 301 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4904510361641609\n",
      "Epoch 302 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4937017472572125\n",
      "Epoch 303 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4937017472572125\n",
      "Epoch 304 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4961397805770012\n",
      "Epoch 305 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49085737505079235\n",
      "Epoch 306 Loss 1.01 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.48760666395774077\n",
      "Epoch 307 Loss 1.01 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.49573344169036976\n",
      "Epoch 308 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49329540837058106\n",
      "Epoch 309 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49329540837058106\n",
      "Epoch 310 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4924827305973182\n",
      "Epoch 311 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48679398618447783\n",
      "Epoch 312 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 313 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49329540837058106\n",
      "Epoch 314 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4928890694839496\n",
      "Epoch 315 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4924827305973182\n",
      "Epoch 316 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4953271028037383\n",
      "Epoch 317 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4928890694839496\n",
      "Epoch 318 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4928890694839496\n",
      "Epoch 319 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49167005282405524\n",
      "Epoch 320 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48760666395774077\n",
      "Epoch 321 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.49410808614384394\n",
      "Epoch 322 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 323 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4912637139374238\n",
      "Epoch 324 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48923201950426654\n",
      "Epoch 325 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.48598130841121495\n",
      "Epoch 326 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49410808614384394\n",
      "Epoch 327 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4900446972775295\n",
      "Epoch 328 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49167005282405524\n",
      "Epoch 329 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49329540837058106\n",
      "Epoch 330 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4961397805770012\n",
      "Epoch 331 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 332 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.48435595286468913\n",
      "Epoch 333 Loss 1.01 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4912637139374238\n",
      "Epoch 334 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4928890694839496\n",
      "Epoch 335 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49451442503047544\n",
      "Epoch 336 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4912637139374238\n",
      "Epoch 337 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49207639171068673\n",
      "Epoch 338 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4900446972775295\n",
      "Epoch 339 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 340 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4900446972775295\n",
      "Epoch 341 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49451442503047544\n",
      "Epoch 342 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4949207639171069\n",
      "Epoch 343 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48516863063795207\n",
      "Epoch 344 Loss 1.01 | Train Accuracy 0.49563096931517986 | Val Accuracy 0.4855749695245835\n",
      "Epoch 345 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.48963835839089803\n",
      "Epoch 346 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 347 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4912637139374238\n",
      "Epoch 348 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4924827305973182\n",
      "Epoch 349 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4904510361641609\n",
      "Epoch 350 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48963835839089803\n",
      "Epoch 351 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.497765136123527\n",
      "Epoch 352 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4924827305973182\n",
      "Epoch 353 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4924827305973182\n",
      "Epoch 354 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4912637139374238\n",
      "Epoch 355 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.49167005282405524\n",
      "Epoch 356 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.48963835839089803\n",
      "Epoch 357 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.47541649735879726\n",
      "Epoch 358 Loss 1.02 | Train Accuracy 0.4869945133103028 | Val Accuracy 0.48963835839089803\n",
      "Epoch 359 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4888256806176351\n",
      "Epoch 360 Loss 1.02 | Train Accuracy 0.49329404592562487 | Val Accuracy 0.49085737505079235\n",
      "Epoch 361 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4888256806176351\n",
      "Epoch 362 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.48923201950426654\n",
      "Epoch 363 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4928890694839496\n",
      "Epoch 364 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49167005282405524\n",
      "Epoch 365 Loss 1.01 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4888256806176351\n",
      "Epoch 366 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49207639171068673\n",
      "Epoch 367 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4937017472572125\n",
      "Epoch 368 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4888256806176351\n",
      "Epoch 369 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4928890694839496\n",
      "Epoch 370 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 371 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4949207639171069\n",
      "Epoch 372 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4880130028443722\n",
      "Epoch 373 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49085737505079235\n",
      "Epoch 374 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 375 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.48963835839089803\n",
      "Epoch 376 Loss 1.01 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.46891507517269404\n",
      "Epoch 377 Loss 1.02 | Train Accuracy 0.49136354399512294 | Val Accuracy 0.4937017472572125\n",
      "Epoch 378 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.48963835839089803\n",
      "Epoch 379 Loss 1.02 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.48923201950426654\n",
      "Epoch 380 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49167005282405524\n",
      "Epoch 381 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4928890694839496\n",
      "Epoch 382 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49451442503047544\n",
      "Epoch 383 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49329540837058106\n",
      "Epoch 384 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4904510361641609\n",
      "Epoch 385 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4924827305973182\n",
      "Epoch 386 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49410808614384394\n",
      "Epoch 387 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49573344169036976\n",
      "Epoch 388 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4912637139374238\n",
      "Epoch 389 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4949207639171069\n",
      "Epoch 390 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49573344169036976\n",
      "Epoch 391 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4928890694839496\n",
      "Epoch 392 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4961397805770012\n",
      "Epoch 393 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49085737505079235\n",
      "Epoch 394 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4900446972775295\n",
      "Epoch 395 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4668833807395368\n",
      "Epoch 396 Loss 1.03 | Train Accuracy 0.47876447876447875 | Val Accuracy 0.497765136123527\n",
      "Epoch 397 Loss 1.02 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4900446972775295\n",
      "Epoch 398 Loss 1.02 | Train Accuracy 0.49390367811420444 | Val Accuracy 0.49085737505079235\n",
      "Epoch 399 Loss 1.02 | Train Accuracy 0.49187157081893923 | Val Accuracy 0.4924827305973182\n",
      "Epoch 400 Loss 1.01 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.49167005282405524\n",
      "Epoch 401 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49410808614384394\n",
      "Epoch 402 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.4900446972775295\n",
      "Epoch 403 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49329540837058106\n",
      "Epoch 404 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4912637139374238\n",
      "Epoch 405 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4924827305973182\n",
      "Epoch 406 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4904510361641609\n",
      "Epoch 407 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4912637139374238\n",
      "Epoch 408 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49207639171068673\n",
      "Epoch 409 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4973587972368956\n",
      "Epoch 410 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49939049167005284\n",
      "Epoch 411 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4937017472572125\n",
      "Epoch 412 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49573344169036976\n",
      "Epoch 413 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49410808614384394\n",
      "Epoch 414 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49573344169036976\n",
      "Epoch 415 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49085737505079235\n",
      "Epoch 416 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4912637139374238\n",
      "Epoch 417 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48476229175132063\n",
      "Epoch 418 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.47379114181227144\n",
      "Epoch 419 Loss 1.02 | Train Accuracy 0.4872993294045926 | Val Accuracy 0.49085737505079235\n",
      "Epoch 420 Loss 1.02 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4928890694839496\n",
      "Epoch 421 Loss 1.02 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4863876472978464\n",
      "Epoch 422 Loss 1.01 | Train Accuracy 0.4950213371266003 | Val Accuracy 0.48679398618447783\n",
      "Epoch 423 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.49207639171068673\n",
      "Epoch 424 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49451442503047544\n",
      "Epoch 425 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49410808614384394\n",
      "Epoch 426 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4961397805770012\n",
      "Epoch 427 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4912637139374238\n",
      "Epoch 428 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4912637139374238\n",
      "Epoch 429 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49207639171068673\n",
      "Epoch 430 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49817147501015846\n",
      "Epoch 431 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4985778138967899\n",
      "Epoch 432 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49085737505079235\n",
      "Epoch 433 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4965461194636327\n",
      "Epoch 434 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49207639171068673\n",
      "Epoch 435 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4904510361641609\n",
      "Epoch 436 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.48963835839089803\n",
      "Epoch 437 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49573344169036976\n",
      "Epoch 438 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49451442503047544\n",
      "Epoch 439 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4965461194636327\n",
      "Epoch 440 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 441 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4880130028443722\n",
      "Epoch 442 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49167005282405524\n",
      "Epoch 443 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4973587972368956\n",
      "Epoch 444 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.48720032507110933\n",
      "Epoch 445 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49695245835026414\n",
      "Epoch 446 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4973587972368956\n",
      "Epoch 447 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4900446972775295\n",
      "Epoch 448 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49573344169036976\n",
      "Epoch 449 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49695245835026414\n",
      "Epoch 450 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.48923201950426654\n",
      "Epoch 451 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49085737505079235\n",
      "Epoch 452 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49939049167005284\n",
      "Epoch 453 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.48720032507110933\n",
      "Epoch 454 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.47988622511174317\n",
      "Epoch 455 Loss 1.02 | Train Accuracy 0.49339565129038815 | Val Accuracy 0.48963835839089803\n",
      "Epoch 456 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48963835839089803\n",
      "Epoch 457 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49085737505079235\n",
      "Epoch 458 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4937017472572125\n",
      "Epoch 459 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4937017472572125\n",
      "Epoch 460 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49085737505079235\n",
      "Epoch 461 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4888256806176351\n",
      "Epoch 462 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48923201950426654\n",
      "Epoch 463 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4965461194636327\n",
      "Epoch 464 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4965461194636327\n",
      "Epoch 465 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 466 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48963835839089803\n",
      "Epoch 467 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4904510361641609\n",
      "Epoch 468 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49939049167005284\n",
      "Epoch 469 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49207639171068673\n",
      "Epoch 470 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48923201950426654\n",
      "Epoch 471 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49695245835026414\n",
      "Epoch 472 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4924827305973182\n",
      "Epoch 473 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48760666395774077\n",
      "Epoch 474 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49817147501015846\n",
      "Epoch 475 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49085737505079235\n",
      "Epoch 476 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4904510361641609\n",
      "Epoch 477 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4953271028037383\n",
      "Epoch 478 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48720032507110933\n",
      "Epoch 479 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.47947988622511173\n",
      "Epoch 480 Loss 1.02 | Train Accuracy 0.49207478154846573 | Val Accuracy 0.49573344169036976\n",
      "Epoch 481 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4904510361641609\n",
      "Epoch 482 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4900446972775295\n",
      "Epoch 483 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.48923201950426654\n",
      "Epoch 484 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 485 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49410808614384394\n",
      "Epoch 486 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49329540837058106\n",
      "Epoch 487 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4924827305973182\n",
      "Epoch 488 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4880130028443722\n",
      "Epoch 489 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4912637139374238\n",
      "Epoch 490 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49329540837058106\n",
      "Epoch 491 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49695245835026414\n",
      "Epoch 492 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49695245835026414\n",
      "Epoch 493 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49207639171068673\n",
      "Epoch 494 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.48963835839089803\n",
      "Epoch 495 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4912637139374238\n",
      "Epoch 496 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4949207639171069\n",
      "Epoch 497 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49695245835026414\n",
      "Epoch 498 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49085737505079235\n",
      "Epoch 499 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 500 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49573344169036976\n",
      "Epoch 501 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49695245835026414\n",
      "Epoch 502 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48598130841121495\n",
      "Epoch 503 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49207639171068673\n",
      "Epoch 504 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4937017472572125\n",
      "Epoch 505 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4880130028443722\n",
      "Epoch 506 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49167005282405524\n",
      "Epoch 507 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49410808614384394\n",
      "Epoch 508 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49695245835026414\n",
      "Epoch 509 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49451442503047544\n",
      "Epoch 510 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4965461194636327\n",
      "Epoch 511 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.48963835839089803\n",
      "Epoch 512 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49410808614384394\n",
      "Epoch 513 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49410808614384394\n",
      "Epoch 514 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48720032507110933\n",
      "Epoch 515 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4900446972775295\n",
      "Epoch 516 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4953271028037383\n",
      "Epoch 517 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49085737505079235\n",
      "Epoch 518 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49167005282405524\n",
      "Epoch 519 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49695245835026414\n",
      "Epoch 520 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 521 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 522 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4961397805770012\n",
      "Epoch 523 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.48435595286468913\n",
      "Epoch 524 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.48598130841121495\n",
      "Epoch 525 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4924827305973182\n",
      "Epoch 526 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49085737505079235\n",
      "Epoch 527 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.497765136123527\n",
      "Epoch 528 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4985778138967899\n",
      "Epoch 529 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48963835839089803\n",
      "Epoch 530 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.48963835839089803\n",
      "Epoch 531 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.5018285249898415\n",
      "Epoch 532 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49817147501015846\n",
      "Epoch 533 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4912637139374238\n",
      "Epoch 534 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4888256806176351\n",
      "Epoch 535 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49207639171068673\n",
      "Epoch 536 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4965461194636327\n",
      "Epoch 537 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4912637139374238\n",
      "Epoch 538 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4904510361641609\n",
      "Epoch 539 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4997968305566843\n",
      "Epoch 540 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4937017472572125\n",
      "Epoch 541 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4900446972775295\n",
      "Epoch 542 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.5018285249898415\n",
      "Epoch 543 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4904510361641609\n",
      "Epoch 544 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4924827305973182\n",
      "Epoch 545 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49329540837058106\n",
      "Epoch 546 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4900446972775295\n",
      "Epoch 547 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49817147501015846\n",
      "Epoch 548 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.5006095083299472\n",
      "Epoch 549 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 550 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4937017472572125\n",
      "Epoch 551 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4973587972368956\n",
      "Epoch 552 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4937017472572125\n",
      "Epoch 553 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4937017472572125\n",
      "Epoch 554 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4949207639171069\n",
      "Epoch 555 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 556 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 557 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4989841527834214\n",
      "Epoch 558 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49329540837058106\n",
      "Epoch 559 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4900446972775295\n",
      "Epoch 560 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.5006095083299472\n",
      "Epoch 561 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 562 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49451442503047544\n",
      "Epoch 563 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49167005282405524\n",
      "Epoch 564 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4900446972775295\n",
      "Epoch 565 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4973587972368956\n",
      "Epoch 566 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4924827305973182\n",
      "Epoch 567 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4949207639171069\n",
      "Epoch 568 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4961397805770012\n",
      "Epoch 569 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49329540837058106\n",
      "Epoch 570 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4965461194636327\n",
      "Epoch 571 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49573344169036976\n",
      "Epoch 572 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 573 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4973587972368956\n",
      "Epoch 574 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4953271028037383\n",
      "Epoch 575 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49410808614384394\n",
      "Epoch 576 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49451442503047544\n",
      "Epoch 577 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4888256806176351\n",
      "Epoch 578 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49573344169036976\n",
      "Epoch 579 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49451442503047544\n",
      "Epoch 580 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49451442503047544\n",
      "Epoch 581 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4953271028037383\n",
      "Epoch 582 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49573344169036976\n",
      "Epoch 583 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4928890694839496\n",
      "Epoch 584 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49410808614384394\n",
      "Epoch 585 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49573344169036976\n",
      "Epoch 586 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4928890694839496\n",
      "Epoch 587 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4924827305973182\n",
      "Epoch 588 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49451442503047544\n",
      "Epoch 589 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49817147501015846\n",
      "Epoch 590 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49329540837058106\n",
      "Epoch 591 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.48963835839089803\n",
      "Epoch 592 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49695245835026414\n",
      "Epoch 593 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4928890694839496\n",
      "Epoch 594 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4937017472572125\n",
      "Epoch 595 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49451442503047544\n",
      "Epoch 596 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49167005282405524\n",
      "Epoch 597 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 598 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4900446972775295\n",
      "Epoch 599 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.497765136123527\n",
      "Epoch 600 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4904510361641609\n",
      "Epoch 601 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4904510361641609\n",
      "Epoch 602 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4912637139374238\n",
      "Epoch 603 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4924827305973182\n",
      "Epoch 604 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49695245835026414\n",
      "Epoch 605 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4949207639171069\n",
      "Epoch 606 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49329540837058106\n",
      "Epoch 607 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 608 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49167005282405524\n",
      "Epoch 609 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49207639171068673\n",
      "Epoch 610 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4912637139374238\n",
      "Epoch 611 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4928890694839496\n",
      "Epoch 612 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49451442503047544\n",
      "Epoch 613 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49329540837058106\n",
      "Epoch 614 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 615 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4953271028037383\n",
      "Epoch 616 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49410808614384394\n",
      "Epoch 617 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49451442503047544\n",
      "Epoch 618 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4937017472572125\n",
      "Epoch 619 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4924827305973182\n",
      "Epoch 620 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49451442503047544\n",
      "Epoch 621 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4937017472572125\n",
      "Epoch 622 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4953271028037383\n",
      "Epoch 623 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.48963835839089803\n",
      "Epoch 624 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49167005282405524\n",
      "Epoch 625 Loss 1.01 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.4961397805770012\n",
      "Epoch 626 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4900446972775295\n",
      "Epoch 627 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 628 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4924827305973182\n",
      "Epoch 629 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4937017472572125\n",
      "Epoch 630 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4904510361641609\n",
      "Epoch 631 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 632 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4937017472572125\n",
      "Epoch 633 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4953271028037383\n",
      "Epoch 634 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49329540837058106\n",
      "Epoch 635 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49085737505079235\n",
      "Epoch 636 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49207639171068673\n",
      "Epoch 637 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4997968305566843\n",
      "Epoch 638 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49167005282405524\n",
      "Epoch 639 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49329540837058106\n",
      "Epoch 640 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49410808614384394\n",
      "Epoch 641 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4989841527834214\n",
      "Epoch 642 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49085737505079235\n",
      "Epoch 643 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48841934173100365\n",
      "Epoch 644 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4961397805770012\n",
      "Epoch 645 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4928890694839496\n",
      "Epoch 646 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.48963835839089803\n",
      "Epoch 647 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4973587972368956\n",
      "Epoch 648 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 649 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4888256806176351\n",
      "Epoch 650 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49695245835026414\n",
      "Epoch 651 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4937017472572125\n",
      "Epoch 652 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49817147501015846\n",
      "Epoch 653 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 654 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49167005282405524\n",
      "Epoch 655 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4961397805770012\n",
      "Epoch 656 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 657 Loss 1.00 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48760666395774077\n",
      "Epoch 658 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4766355140186916\n",
      "Epoch 659 Loss 1.03 | Train Accuracy 0.48862019914651494 | Val Accuracy 0.49573344169036976\n",
      "Epoch 660 Loss 1.02 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49329540837058106\n",
      "Epoch 661 Loss 1.01 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.48516863063795207\n",
      "Epoch 662 Loss 1.01 | Train Accuracy 0.49359886201991465 | Val Accuracy 0.4863876472978464\n",
      "Epoch 663 Loss 1.01 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.49085737505079235\n",
      "Epoch 664 Loss 1.01 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.4912637139374238\n",
      "Epoch 665 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4937017472572125\n",
      "Epoch 666 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49207639171068673\n",
      "Epoch 667 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4888256806176351\n",
      "Epoch 668 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.48841934173100365\n",
      "Epoch 669 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4888256806176351\n",
      "Epoch 670 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.48760666395774077\n",
      "Epoch 671 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48760666395774077\n",
      "Epoch 672 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.48923201950426654\n",
      "Epoch 673 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48923201950426654\n",
      "Epoch 674 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4924827305973182\n",
      "Epoch 675 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49329540837058106\n",
      "Epoch 676 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49410808614384394\n",
      "Epoch 677 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 678 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4937017472572125\n",
      "Epoch 679 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 680 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4965461194636327\n",
      "Epoch 681 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49451442503047544\n",
      "Epoch 682 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4928890694839496\n",
      "Epoch 683 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49167005282405524\n",
      "Epoch 684 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4928890694839496\n",
      "Epoch 685 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4924827305973182\n",
      "Epoch 686 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4949207639171069\n",
      "Epoch 687 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4953271028037383\n",
      "Epoch 688 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4953271028037383\n",
      "Epoch 689 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49410808614384394\n",
      "Epoch 690 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49573344169036976\n",
      "Epoch 691 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4961397805770012\n",
      "Epoch 692 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4949207639171069\n",
      "Epoch 693 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4949207639171069\n",
      "Epoch 694 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49329540837058106\n",
      "Epoch 695 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49085737505079235\n",
      "Epoch 696 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4912637139374238\n",
      "Epoch 697 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4924827305973182\n",
      "Epoch 698 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4928890694839496\n",
      "Epoch 699 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49167005282405524\n",
      "Epoch 700 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 701 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49329540837058106\n",
      "Epoch 702 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49207639171068673\n",
      "Epoch 703 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 704 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49207639171068673\n",
      "Epoch 705 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 706 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49410808614384394\n",
      "Epoch 707 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4949207639171069\n",
      "Epoch 708 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49207639171068673\n",
      "Epoch 709 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.48760666395774077\n",
      "Epoch 710 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4904510361641609\n",
      "Epoch 711 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4904510361641609\n",
      "Epoch 712 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 713 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.48963835839089803\n",
      "Epoch 714 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4880130028443722\n",
      "Epoch 715 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 716 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4912637139374238\n",
      "Epoch 717 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4880130028443722\n",
      "Epoch 718 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4900446972775295\n",
      "Epoch 719 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4928890694839496\n",
      "Epoch 720 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4928890694839496\n",
      "Epoch 721 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49085737505079235\n",
      "Epoch 722 Loss 1.00 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4953271028037383\n",
      "Epoch 723 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49167005282405524\n",
      "Epoch 724 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4985778138967899\n",
      "Epoch 725 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48841934173100365\n",
      "Epoch 726 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49167005282405524\n",
      "Epoch 727 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48679398618447783\n",
      "Epoch 728 Loss 1.02 | Train Accuracy 0.48912822597033123 | Val Accuracy 0.4973587972368956\n",
      "Epoch 729 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48720032507110933\n",
      "Epoch 730 Loss 1.02 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4880130028443722\n",
      "Epoch 731 Loss 1.01 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4928890694839496\n",
      "Epoch 732 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.48516863063795207\n",
      "Epoch 733 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4880130028443722\n",
      "Epoch 734 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48841934173100365\n",
      "Epoch 735 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 736 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4888256806176351\n",
      "Epoch 737 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49329540837058106\n",
      "Epoch 738 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49451442503047544\n",
      "Epoch 739 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4937017472572125\n",
      "Epoch 740 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49207639171068673\n",
      "Epoch 741 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4949207639171069\n",
      "Epoch 742 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4965461194636327\n",
      "Epoch 743 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49410808614384394\n",
      "Epoch 744 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4949207639171069\n",
      "Epoch 745 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49329540837058106\n",
      "Epoch 746 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4928890694839496\n",
      "Epoch 747 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4965461194636327\n",
      "Epoch 748 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49695245835026414\n",
      "Epoch 749 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49695245835026414\n",
      "Epoch 750 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49573344169036976\n",
      "Epoch 751 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4953271028037383\n",
      "Epoch 752 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4953271028037383\n",
      "Epoch 753 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 754 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49207639171068673\n",
      "Epoch 755 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4928890694839496\n",
      "Epoch 756 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49451442503047544\n",
      "Epoch 757 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49329540837058106\n",
      "Epoch 758 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49410808614384394\n",
      "Epoch 759 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4949207639171069\n",
      "Epoch 760 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.49167005282405524\n",
      "Epoch 761 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49329540837058106\n",
      "Epoch 762 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49207639171068673\n",
      "Epoch 763 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 764 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.49573344169036976\n",
      "Epoch 765 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.49329540837058106\n",
      "Epoch 766 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4900446972775295\n",
      "Epoch 767 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 768 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 769 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 770 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.48963835839089803\n",
      "Epoch 771 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4880130028443722\n",
      "Epoch 772 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48923201950426654\n",
      "Epoch 773 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4928890694839496\n",
      "Epoch 774 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49085737505079235\n",
      "Epoch 775 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4900446972775295\n",
      "Epoch 776 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49329540837058106\n",
      "Epoch 777 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4924827305973182\n",
      "Epoch 778 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4904510361641609\n",
      "Epoch 779 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 780 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48923201950426654\n",
      "Epoch 781 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 782 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4900446972775295\n",
      "Epoch 783 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4949207639171069\n",
      "Epoch 784 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 785 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49695245835026414\n",
      "Epoch 786 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4880130028443722\n",
      "Epoch 787 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.44900446972775293\n",
      "Epoch 788 Loss 1.04 | Train Accuracy 0.4671814671814672 | Val Accuracy 0.4989841527834214\n",
      "Epoch 789 Loss 1.02 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4888256806176351\n",
      "Epoch 790 Loss 1.02 | Train Accuracy 0.4914651493598862 | Val Accuracy 0.4900446972775295\n",
      "Epoch 791 Loss 1.02 | Train Accuracy 0.4907539118065434 | Val Accuracy 0.4880130028443722\n",
      "Epoch 792 Loss 1.02 | Train Accuracy 0.4899410688884373 | Val Accuracy 0.4888256806176351\n",
      "Epoch 793 Loss 1.02 | Train Accuracy 0.49126193863035966 | Val Accuracy 0.4900446972775295\n",
      "Epoch 794 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4924827305973182\n",
      "Epoch 795 Loss 1.02 | Train Accuracy 0.49410688884373094 | Val Accuracy 0.49329540837058106\n",
      "Epoch 796 Loss 1.02 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.49573344169036976\n",
      "Epoch 797 Loss 1.02 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.49410808614384394\n",
      "Epoch 798 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4912637139374238\n",
      "Epoch 799 Loss 1.01 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.48963835839089803\n",
      "Epoch 800 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4904510361641609\n",
      "Epoch 801 Loss 1.01 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 802 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4928890694839496\n",
      "Epoch 803 Loss 1.01 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4900446972775295\n",
      "Epoch 804 Loss 1.01 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4904510361641609\n",
      "Epoch 805 Loss 1.01 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4912637139374238\n",
      "Epoch 806 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49085737505079235\n",
      "Epoch 807 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4900446972775295\n",
      "Epoch 808 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48841934173100365\n",
      "Epoch 809 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.48923201950426654\n",
      "Epoch 810 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4888256806176351\n",
      "Epoch 811 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.48760666395774077\n",
      "Epoch 812 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48963835839089803\n",
      "Epoch 813 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.48841934173100365\n",
      "Epoch 814 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.48760666395774077\n",
      "Epoch 815 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48760666395774077\n",
      "Epoch 816 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4880130028443722\n",
      "Epoch 817 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4904510361641609\n",
      "Epoch 818 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4928890694839496\n",
      "Epoch 819 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49167005282405524\n",
      "Epoch 820 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49085737505079235\n",
      "Epoch 821 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49085737505079235\n",
      "Epoch 822 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 823 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49329540837058106\n",
      "Epoch 824 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 825 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 826 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4949207639171069\n",
      "Epoch 827 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49410808614384394\n",
      "Epoch 828 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 829 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 830 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4949207639171069\n",
      "Epoch 831 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49451442503047544\n",
      "Epoch 832 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49329540837058106\n",
      "Epoch 833 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49410808614384394\n",
      "Epoch 834 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4949207639171069\n",
      "Epoch 835 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4949207639171069\n",
      "Epoch 836 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49410808614384394\n",
      "Epoch 837 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4949207639171069\n",
      "Epoch 838 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49451442503047544\n",
      "Epoch 839 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49410808614384394\n",
      "Epoch 840 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 841 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4937017472572125\n",
      "Epoch 842 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4928890694839496\n",
      "Epoch 843 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4924827305973182\n",
      "Epoch 844 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4937017472572125\n",
      "Epoch 845 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4937017472572125\n",
      "Epoch 846 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4928890694839496\n",
      "Epoch 847 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49329540837058106\n",
      "Epoch 848 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4924827305973182\n",
      "Epoch 849 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 850 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49207639171068673\n",
      "Epoch 851 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49167005282405524\n",
      "Epoch 852 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4912637139374238\n",
      "Epoch 853 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 854 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49207639171068673\n",
      "Epoch 855 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4900446972775295\n",
      "Epoch 856 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4900446972775295\n",
      "Epoch 857 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4900446972775295\n",
      "Epoch 858 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4900446972775295\n",
      "Epoch 859 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4900446972775295\n",
      "Epoch 860 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4900446972775295\n",
      "Epoch 861 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49167005282405524\n",
      "Epoch 862 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.48923201950426654\n",
      "Epoch 863 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 864 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4928890694839496\n",
      "Epoch 865 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4904510361641609\n",
      "Epoch 866 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4900446972775295\n",
      "Epoch 867 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4949207639171069\n",
      "Epoch 868 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4904510361641609\n",
      "Epoch 869 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4928890694839496\n",
      "Epoch 870 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49167005282405524\n",
      "Epoch 871 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.48923201950426654\n",
      "Epoch 872 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4953271028037383\n",
      "Epoch 873 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 874 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4989841527834214\n",
      "Epoch 875 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.48841934173100365\n",
      "Epoch 876 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.47947988622511173\n",
      "Epoch 877 Loss 1.01 | Train Accuracy 0.49410688884373094 | Val Accuracy 0.48963835839089803\n",
      "Epoch 878 Loss 1.02 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.49167005282405524\n",
      "Epoch 879 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4937017472572125\n",
      "Epoch 880 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4888256806176351\n",
      "Epoch 881 Loss 1.01 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.4900446972775295\n",
      "Epoch 882 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49207639171068673\n",
      "Epoch 883 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4912637139374238\n",
      "Epoch 884 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4924827305973182\n",
      "Epoch 885 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49167005282405524\n",
      "Epoch 886 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4912637139374238\n",
      "Epoch 887 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4937017472572125\n",
      "Epoch 888 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49167005282405524\n",
      "Epoch 889 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 890 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4953271028037383\n",
      "Epoch 891 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49167005282405524\n",
      "Epoch 892 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4965461194636327\n",
      "Epoch 893 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.49207639171068673\n",
      "Epoch 894 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4912637139374238\n",
      "Epoch 895 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4900446972775295\n",
      "Epoch 896 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49207639171068673\n",
      "Epoch 897 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49695245835026414\n",
      "Epoch 898 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49451442503047544\n",
      "Epoch 899 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4928890694839496\n",
      "Epoch 900 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4928890694839496\n",
      "Epoch 901 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.49329540837058106\n",
      "Epoch 902 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49410808614384394\n",
      "Epoch 903 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49207639171068673\n",
      "Epoch 904 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4937017472572125\n",
      "Epoch 905 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4965461194636327\n",
      "Epoch 906 Loss 1.01 | Train Accuracy 0.5059947165210323 | Val Accuracy 0.497765136123527\n",
      "Epoch 907 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4961397805770012\n",
      "Epoch 908 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49329540837058106\n",
      "Epoch 909 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 910 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4937017472572125\n",
      "Epoch 911 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4961397805770012\n",
      "Epoch 912 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.49451442503047544\n",
      "Epoch 913 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.4904510361641609\n",
      "Epoch 914 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4880130028443722\n",
      "Epoch 915 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.48841934173100365\n",
      "Epoch 916 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49410808614384394\n",
      "Epoch 917 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.48963835839089803\n",
      "Epoch 918 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48720032507110933\n",
      "Epoch 919 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4904510361641609\n",
      "Epoch 920 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 921 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4924827305973182\n",
      "Epoch 922 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 923 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 924 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 925 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 926 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4953271028037383\n",
      "Epoch 927 Loss 1.00 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4900446972775295\n",
      "Epoch 928 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4888256806176351\n",
      "Epoch 929 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4989841527834214\n",
      "Epoch 930 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48963835839089803\n",
      "Epoch 931 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.48232425843153187\n",
      "Epoch 932 Loss 1.01 | Train Accuracy 0.49563096931517986 | Val Accuracy 0.48841934173100365\n",
      "Epoch 933 Loss 1.02 | Train Accuracy 0.49065230644178015 | Val Accuracy 0.4937017472572125\n",
      "Epoch 934 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49410808614384394\n",
      "Epoch 935 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.48963835839089803\n",
      "Epoch 936 Loss 1.01 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.48923201950426654\n",
      "Epoch 937 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.48963835839089803\n",
      "Epoch 938 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49085737505079235\n",
      "Epoch 939 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4880130028443722\n",
      "Epoch 940 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4888256806176351\n",
      "Epoch 941 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.48841934173100365\n",
      "Epoch 942 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4904510361641609\n",
      "Epoch 943 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49451442503047544\n",
      "Epoch 944 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49410808614384394\n",
      "Epoch 945 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4965461194636327\n",
      "Epoch 946 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49573344169036976\n",
      "Epoch 947 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4928890694839496\n",
      "Epoch 948 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49573344169036976\n",
      "Epoch 949 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49451442503047544\n",
      "Epoch 950 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 951 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4912637139374238\n",
      "Epoch 952 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49167005282405524\n",
      "Epoch 953 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4949207639171069\n",
      "Epoch 954 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4953271028037383\n",
      "Epoch 955 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4953271028037383\n",
      "Epoch 956 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49329540837058106\n",
      "Epoch 957 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49451442503047544\n",
      "Epoch 958 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49451442503047544\n",
      "Epoch 959 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49451442503047544\n",
      "Epoch 960 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4928890694839496\n",
      "Epoch 961 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4924827305973182\n",
      "Epoch 962 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 963 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4961397805770012\n",
      "Epoch 964 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4961397805770012\n",
      "Epoch 965 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4949207639171069\n",
      "Epoch 966 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49167005282405524\n",
      "Epoch 967 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 968 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4953271028037383\n",
      "Epoch 969 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49573344169036976\n",
      "Epoch 970 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4961397805770012\n",
      "Epoch 971 Loss 1.01 | Train Accuracy 0.5064011379800853 | Val Accuracy 0.4912637139374238\n",
      "Epoch 972 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48923201950426654\n",
      "Epoch 973 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4880130028443722\n",
      "Epoch 974 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49167005282405524\n",
      "Epoch 975 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4924827305973182\n",
      "Epoch 976 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49085737505079235\n",
      "Epoch 977 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4880130028443722\n",
      "Epoch 978 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 979 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4924827305973182\n",
      "Epoch 980 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 981 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48963835839089803\n",
      "Epoch 982 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 983 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 984 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 985 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 986 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 987 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4888256806176351\n",
      "Epoch 988 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4985778138967899\n",
      "Epoch 989 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.48963835839089803\n",
      "Epoch 990 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4831369362047948\n",
      "Epoch 991 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48598130841121495\n",
      "Epoch 992 Loss 1.02 | Train Accuracy 0.49116033326559644 | Val Accuracy 0.4953271028037383\n",
      "Epoch 993 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.49085737505079235\n",
      "Epoch 994 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4912637139374238\n",
      "Epoch 995 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4924827305973182\n",
      "Epoch 996 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48841934173100365\n",
      "Epoch 997 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48760666395774077\n",
      "Epoch 998 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.48963835839089803\n",
      "Epoch 999 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1000 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1001 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1002 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1003 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1004 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1005 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1006 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1007 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1008 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1009 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1010 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1011 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1012 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1013 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1014 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1015 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1016 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1017 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1018 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.497765136123527\n",
      "Epoch 1019 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1020 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1021 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1022 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1023 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1024 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1025 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1026 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1027 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1028 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1029 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1030 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1031 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1032 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1033 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1034 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1035 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1036 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1037 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1038 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1039 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1040 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1041 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1042 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1043 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1044 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1045 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1046 Loss 1.01 | Train Accuracy 0.49329404592562487 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1047 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1048 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1049 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48720032507110933\n",
      "Epoch 1050 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1051 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1052 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1053 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1054 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1055 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1056 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1057 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1058 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1059 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1060 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1061 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1062 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1063 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1064 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1065 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1066 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1067 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1068 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1069 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1070 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1071 Loss 1.00 | Train Accuracy 0.5061979272505588 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1072 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1073 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1074 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1075 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1076 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1077 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1078 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1079 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1080 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1081 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1082 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1083 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1084 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1085 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1086 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1087 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1088 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.48435595286468913\n",
      "Epoch 1089 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1090 Loss 1.01 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1091 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1092 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1093 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1094 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.48720032507110933\n",
      "Epoch 1095 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1096 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1097 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1098 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1099 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1100 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1101 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1102 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1103 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1104 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1105 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1106 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1107 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1108 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1109 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1110 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1111 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1112 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1113 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.497765136123527\n",
      "Epoch 1114 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1115 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1116 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1117 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1118 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1119 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1120 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1121 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1122 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1123 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1124 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1125 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1126 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1127 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1128 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1129 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1130 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1131 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1132 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1133 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1134 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1135 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1136 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1137 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1138 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49939049167005284\n",
      "Epoch 1139 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48679398618447783\n",
      "Epoch 1140 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.46403900853311664\n",
      "Epoch 1141 Loss 1.03 | Train Accuracy 0.48150782361308675 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1142 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1143 Loss 1.01 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1144 Loss 1.01 | Train Accuracy 0.4947165210323105 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1145 Loss 1.01 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1146 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1147 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1148 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1149 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1150 Loss 1.01 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1151 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1152 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1153 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1154 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1155 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1156 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1157 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1158 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1159 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1160 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1161 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1162 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1163 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1164 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1165 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1166 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1167 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1168 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1169 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1170 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1171 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1172 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1173 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1174 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1175 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1176 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1177 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1178 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1179 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1180 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1181 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1182 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1183 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1184 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1185 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1186 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1187 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1188 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1189 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1190 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1191 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1192 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1193 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1194 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1195 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1196 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1197 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1198 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1199 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1200 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1201 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1202 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1203 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1204 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1205 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1206 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1207 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1208 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1209 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1210 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1211 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1212 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1213 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1214 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1215 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1216 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48720032507110933\n",
      "Epoch 1217 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4790735473384803\n",
      "Epoch 1218 Loss 1.02 | Train Accuracy 0.4856736435683804 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1219 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1220 Loss 1.02 | Train Accuracy 0.49359886201991465 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1221 Loss 1.02 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1222 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1223 Loss 1.01 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1224 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1225 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1226 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1227 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1228 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1229 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1230 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48720032507110933\n",
      "Epoch 1231 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1232 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1233 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1234 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1235 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1236 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1237 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1238 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1239 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1240 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1241 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1242 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1243 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1244 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1245 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1246 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1247 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1248 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1249 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1250 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1251 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1252 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1253 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1254 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1255 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1256 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1257 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1258 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1259 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1260 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1261 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1262 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1263 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1264 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1265 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1266 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1267 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1268 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1269 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1270 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1271 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1272 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1273 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1274 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1275 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1276 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1277 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1278 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1279 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1280 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1281 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1282 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1283 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1284 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1285 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1286 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1287 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1288 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1289 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4997968305566843\n",
      "Epoch 1290 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.48598130841121495\n",
      "Epoch 1291 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4697277529459569\n",
      "Epoch 1292 Loss 1.02 | Train Accuracy 0.48577524893314367 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1293 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1294 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1295 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1296 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1297 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1298 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1299 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1300 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1301 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1302 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1303 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1304 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1305 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1306 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1307 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1308 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1309 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1310 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1311 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1312 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1313 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1314 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1315 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1316 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1317 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1318 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1319 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1320 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1321 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1322 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1323 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1324 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1325 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1326 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1327 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1328 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1329 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1330 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1331 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1332 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1333 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1334 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1335 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1336 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1337 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1338 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1339 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1340 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1341 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1342 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1343 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1344 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1345 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1346 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1347 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1348 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1349 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1350 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1351 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1352 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1353 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1354 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1355 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1356 Loss 1.00 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1357 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1358 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1359 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1360 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1361 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1362 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1363 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1364 Loss 1.01 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.4648516863063795\n",
      "Epoch 1365 Loss 1.03 | Train Accuracy 0.4854704328388539 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1366 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1367 Loss 1.01 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1368 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1369 Loss 1.01 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1370 Loss 1.01 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1371 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1372 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1373 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1374 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1375 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1376 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1377 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1378 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1379 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1380 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1381 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1382 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1383 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1384 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1385 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1386 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1387 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1388 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1389 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1390 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1391 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1392 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1393 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1394 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1395 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1396 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1397 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1398 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1399 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1400 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1401 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1402 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1403 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1404 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1405 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1406 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1407 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1408 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1409 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1410 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1411 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1412 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1413 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1414 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1415 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1416 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1417 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1418 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1419 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1420 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1421 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1422 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1423 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1424 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1425 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1426 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1427 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1428 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1429 Loss 1.00 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1430 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1431 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1432 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1433 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1434 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1435 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1436 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1437 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1438 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1439 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1440 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.47866720845184885\n",
      "Epoch 1441 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.477041852905323\n",
      "Epoch 1442 Loss 1.03 | Train Accuracy 0.48638488112172323 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1443 Loss 1.02 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1444 Loss 1.02 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1445 Loss 1.01 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.4839496139780577\n",
      "Epoch 1446 Loss 1.01 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1447 Loss 1.01 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1448 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1449 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1450 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1451 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1452 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1453 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1454 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1455 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1456 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48679398618447783\n",
      "Epoch 1457 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1458 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1459 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1460 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1461 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1462 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1463 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1464 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1465 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1466 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1467 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1468 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1469 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1470 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1471 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1472 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1473 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1474 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1475 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1476 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1477 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1478 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1479 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1480 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1481 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1482 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1483 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1484 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1485 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1486 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1487 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1488 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1489 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1490 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1491 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1492 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1493 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1494 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1495 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1496 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1497 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1498 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1499 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1500 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1501 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1502 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1503 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1504 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1505 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1506 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1507 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1508 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1509 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1510 Loss 1.00 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1511 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1512 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1513 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1514 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1515 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1516 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1517 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1518 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1519 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1520 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4831369362047948\n",
      "Epoch 1521 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.48435595286468913\n",
      "Epoch 1522 Loss 1.02 | Train Accuracy 0.4895346474293843 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1523 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1524 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1525 Loss 1.01 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1526 Loss 1.01 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1527 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1528 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1529 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.48679398618447783\n",
      "Epoch 1530 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1531 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1532 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48598130841121495\n",
      "Epoch 1533 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1534 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1535 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1536 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1537 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1538 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1539 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1540 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1541 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1542 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1543 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1544 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1545 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1546 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1547 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1548 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.497765136123527\n",
      "Epoch 1549 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1550 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1551 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1552 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1553 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1554 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1555 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1556 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1557 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1558 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1559 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1560 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1561 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1562 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1563 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1564 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1565 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1566 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1567 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1568 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1569 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1570 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1571 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1572 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1573 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1574 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1575 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1576 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1577 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1578 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1579 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1580 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1581 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1582 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1583 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1584 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1585 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1586 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1587 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1588 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.497765136123527\n",
      "Epoch 1589 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1590 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1591 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.481511580658269\n",
      "Epoch 1592 Loss 1.02 | Train Accuracy 0.4900426742532006 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1593 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.48598130841121495\n",
      "Epoch 1594 Loss 1.02 | Train Accuracy 0.4924812030075188 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1595 Loss 1.01 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1596 Loss 1.01 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1597 Loss 1.01 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1598 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.48598130841121495\n",
      "Epoch 1599 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1600 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1601 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1602 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1603 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1604 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1605 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1606 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1607 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1608 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1609 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1610 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1611 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1612 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1613 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1614 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1615 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1616 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1617 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.497765136123527\n",
      "Epoch 1618 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1619 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1620 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1621 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1622 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1623 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1624 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1625 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1626 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1627 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1628 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1629 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1630 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1631 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1632 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1633 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1634 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1635 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1636 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1637 Loss 1.01 | Train Accuracy 0.5061979272505588 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1638 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1639 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1640 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1641 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1642 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1643 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1644 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1645 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1646 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1647 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1648 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1649 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1650 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1651 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1652 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1653 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1654 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1655 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1656 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1657 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1658 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1659 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1660 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1661 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1662 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4989841527834214\n",
      "Epoch 1663 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48679398618447783\n",
      "Epoch 1664 Loss 1.01 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.46769605851279966\n",
      "Epoch 1665 Loss 1.03 | Train Accuracy 0.4821174558016663 | Val Accuracy 0.48191791954490043\n",
      "Epoch 1666 Loss 1.02 | Train Accuracy 0.49085551717130665 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1667 Loss 1.02 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1668 Loss 1.01 | Train Accuracy 0.4953261532208901 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1669 Loss 1.01 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1670 Loss 1.01 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1671 Loss 1.01 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1672 Loss 1.01 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1673 Loss 1.02 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1674 Loss 1.02 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1675 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1676 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1677 Loss 1.01 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.48720032507110933\n",
      "Epoch 1678 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1679 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1680 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1681 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1682 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1683 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1684 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1685 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1686 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1687 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1688 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1689 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1690 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1691 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1692 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1693 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1694 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1695 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1696 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1697 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1698 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.497765136123527\n",
      "Epoch 1699 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1700 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1701 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1702 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1703 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1704 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1705 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1706 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1707 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1708 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1709 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1710 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1711 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1712 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1713 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1714 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1715 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1716 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1717 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1718 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1719 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1720 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1721 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1722 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1723 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1724 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1725 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1726 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1727 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1728 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1729 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1730 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1731 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1732 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1733 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1734 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1735 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1736 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1737 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1738 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1739 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1740 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1741 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1742 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1743 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1744 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1745 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1746 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1747 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1748 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4806989028850061\n",
      "Epoch 1749 Loss 1.03 | Train Accuracy 0.491769965454176 | Val Accuracy 0.497765136123527\n",
      "Epoch 1750 Loss 1.01 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1751 Loss 1.02 | Train Accuracy 0.492176386913229 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1752 Loss 1.02 | Train Accuracy 0.4919731761837025 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1753 Loss 1.01 | Train Accuracy 0.494919731761837 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1754 Loss 1.01 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1755 Loss 1.01 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1756 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1757 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1758 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1759 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1760 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1761 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1762 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1763 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1764 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1765 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1766 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1767 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1768 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1769 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1770 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1771 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1772 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1773 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1774 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1775 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1776 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1777 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1778 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1779 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1780 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1781 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1782 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1783 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1784 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1785 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1786 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1787 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1788 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1789 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1790 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1791 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1792 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1793 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1794 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1795 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1796 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1797 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1798 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1799 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1800 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1801 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1802 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1803 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1804 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1805 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1806 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1807 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1808 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1809 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1810 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1811 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1812 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1813 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1814 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1815 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1816 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1817 Loss 1.00 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1818 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1819 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1820 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1821 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1822 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1823 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1824 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1825 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48760666395774077\n",
      "Epoch 1826 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.5002031694433158\n",
      "Epoch 1827 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48598130841121495\n",
      "Epoch 1828 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4717594473791142\n",
      "Epoch 1829 Loss 1.02 | Train Accuracy 0.48760414549888237 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1830 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1831 Loss 1.02 | Train Accuracy 0.4924812030075188 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1832 Loss 1.02 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1833 Loss 1.01 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.48841934173100365\n",
      "Epoch 1834 Loss 1.01 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1835 Loss 1.01 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1836 Loss 1.01 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1837 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1838 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1839 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1840 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1841 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1842 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4855749695245835\n",
      "Epoch 1843 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1844 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1845 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1846 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1847 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1848 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1849 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1850 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1851 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1852 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1853 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1854 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1855 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1856 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1857 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1858 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1859 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1860 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1861 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1862 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1863 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1864 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1865 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1866 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1867 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1868 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1869 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1870 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1871 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1872 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1873 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1874 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1875 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1876 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1877 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1878 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1879 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1880 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1881 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1882 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1883 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1884 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1885 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1886 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1887 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1888 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1889 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1890 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1891 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1892 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1893 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1894 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1895 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1896 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1897 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1898 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1899 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1900 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1901 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1902 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1903 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1904 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49817147501015846\n",
      "Epoch 1905 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1906 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.47622917513206015\n",
      "Epoch 1907 Loss 1.01 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1908 Loss 1.02 | Train Accuracy 0.4909571225360699 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1909 Loss 1.02 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1910 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1911 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1912 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1913 Loss 1.01 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1914 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1915 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1916 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1917 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1918 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48679398618447783\n",
      "Epoch 1919 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.48516863063795207\n",
      "Epoch 1920 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1921 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1922 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1923 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1924 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1925 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1926 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1927 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1928 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1929 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1930 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1931 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1932 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1933 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4985778138967899\n",
      "Epoch 1934 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4965461194636327\n",
      "Epoch 1935 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1936 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1937 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1938 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1939 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1940 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1941 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1942 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1943 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49451442503047544\n",
      "Epoch 1944 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1945 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1946 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1947 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1948 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1949 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1950 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1951 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49695245835026414\n",
      "Epoch 1952 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1953 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1954 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1955 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1956 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1957 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1958 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4904510361641609\n",
      "Epoch 1959 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1960 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1961 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1962 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1963 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1964 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1965 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 1966 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1967 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1968 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1969 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49085737505079235\n",
      "Epoch 1970 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1971 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4973587972368956\n",
      "Epoch 1972 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1973 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.497765136123527\n",
      "Epoch 1974 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48923201950426654\n",
      "Epoch 1975 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1976 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4839496139780577\n",
      "Epoch 1977 Loss 1.02 | Train Accuracy 0.4902458849827271 | Val Accuracy 0.4928890694839496\n",
      "Epoch 1978 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4855749695245835\n",
      "Epoch 1979 Loss 1.02 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.4900446972775295\n",
      "Epoch 1980 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.49207639171068673\n",
      "Epoch 1981 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.49167005282405524\n",
      "Epoch 1982 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4880130028443722\n",
      "Epoch 1983 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4863876472978464\n",
      "Epoch 1984 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.48598130841121495\n",
      "Epoch 1985 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48963835839089803\n",
      "Epoch 1986 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48720032507110933\n",
      "Epoch 1987 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4888256806176351\n",
      "Epoch 1988 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4912637139374238\n",
      "Epoch 1989 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1990 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1991 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4937017472572125\n",
      "Epoch 1992 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4961397805770012\n",
      "Epoch 1993 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1994 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49573344169036976\n",
      "Epoch 1995 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4949207639171069\n",
      "Epoch 1996 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4953271028037383\n",
      "Epoch 1997 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4924827305973182\n",
      "Epoch 1998 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49410808614384394\n",
      "Epoch 1999 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2000 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2001 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2002 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2003 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2004 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.497765136123527\n",
      "Epoch 2005 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2006 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2007 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2008 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2009 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2010 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2011 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2012 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2013 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2014 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2015 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2016 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2017 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2018 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2019 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2020 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2021 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2022 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2023 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2024 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2025 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2026 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2027 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2028 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2029 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2030 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2031 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2032 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2033 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2034 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2035 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2036 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2037 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2038 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2039 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2040 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2041 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2042 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2043 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2044 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2045 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2046 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2047 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48720032507110933\n",
      "Epoch 2048 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4660707029662739\n",
      "Epoch 2049 Loss 1.02 | Train Accuracy 0.4846575899207478 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2050 Loss 1.01 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2051 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2052 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2053 Loss 1.01 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2054 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2055 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2056 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2057 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2058 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2059 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2060 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2061 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2062 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2063 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2064 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2065 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2066 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2067 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2068 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2069 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2070 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2071 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2072 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2073 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2074 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2075 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2076 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2077 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2078 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2079 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2080 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2081 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2082 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2083 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2084 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2085 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2086 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2087 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2088 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2089 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2090 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2091 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2092 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2093 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2094 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2095 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2096 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2097 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2098 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2099 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2100 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2101 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2102 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2103 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2104 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2105 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2106 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2107 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2108 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2109 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2110 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2111 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2112 Loss 1.00 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2113 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2114 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2115 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2116 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2117 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2118 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2119 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2120 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2121 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2122 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2123 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2124 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.47988622511174317\n",
      "Epoch 2125 Loss 1.02 | Train Accuracy 0.4897378581589108 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2126 Loss 1.02 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.48476229175132063\n",
      "Epoch 2127 Loss 1.02 | Train Accuracy 0.4899410688884373 | Val Accuracy 0.48679398618447783\n",
      "Epoch 2128 Loss 1.02 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2129 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2130 Loss 1.01 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2131 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2132 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2133 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2134 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2135 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2136 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.48679398618447783\n",
      "Epoch 2137 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2138 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2139 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2140 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2141 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2142 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2143 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2144 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2145 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2146 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2147 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2148 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2149 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2150 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2151 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2152 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2153 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2154 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2155 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2156 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2157 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2158 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2159 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2160 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2161 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2162 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2163 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2164 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2165 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2166 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2167 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2168 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2169 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2170 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2171 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2172 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2173 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2174 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2175 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2176 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2177 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2178 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2179 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2180 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2181 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2182 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2183 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2184 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2185 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2186 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2187 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2188 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2189 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2190 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2191 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2192 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2193 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2194 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2195 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2196 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2197 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2198 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2199 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2200 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2201 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2202 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2203 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2204 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2205 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2206 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.47744819179195447\n",
      "Epoch 2207 Loss 1.03 | Train Accuracy 0.4892298313350945 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2208 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.48598130841121495\n",
      "Epoch 2209 Loss 1.02 | Train Accuracy 0.489433042064621 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2210 Loss 1.02 | Train Accuracy 0.49116033326559644 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2211 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2212 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2213 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2214 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2215 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2216 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2217 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2218 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.48720032507110933\n",
      "Epoch 2219 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2220 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2221 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2222 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2223 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2224 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2225 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2226 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2227 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2228 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2229 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2230 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2231 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2232 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2233 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2234 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2235 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2236 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2237 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2238 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2239 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2240 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2241 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2242 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2243 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2244 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2245 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2246 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2247 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2248 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2249 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2250 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2251 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2252 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2253 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2254 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2255 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2256 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2257 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2258 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2259 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2260 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2261 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2262 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2263 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2264 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2265 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2266 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2267 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2268 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2269 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2270 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2271 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2272 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2273 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2274 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2275 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2276 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2277 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2278 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2279 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2280 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2281 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2282 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2283 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2284 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2285 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2286 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2287 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2288 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2289 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2290 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2291 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.5006095083299472\n",
      "Epoch 2292 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48516863063795207\n",
      "Epoch 2293 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4668833807395368\n",
      "Epoch 2294 Loss 1.02 | Train Accuracy 0.4841495630969315 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2295 Loss 1.02 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.48720032507110933\n",
      "Epoch 2296 Loss 1.02 | Train Accuracy 0.4926844137370453 | Val Accuracy 0.4855749695245835\n",
      "Epoch 2297 Loss 1.02 | Train Accuracy 0.4929892298313351 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2298 Loss 1.01 | Train Accuracy 0.4954277585856533 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2299 Loss 1.01 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2300 Loss 1.01 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2301 Loss 1.01 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2302 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2303 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2304 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2305 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2306 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2307 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2308 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2309 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2310 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48679398618447783\n",
      "Epoch 2311 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2312 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2313 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2314 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2315 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2316 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2317 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2318 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2319 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.497765136123527\n",
      "Epoch 2320 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2321 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2322 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2323 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2324 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2325 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2326 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2327 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2328 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2329 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2330 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2331 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2332 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2333 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2334 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2335 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2336 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2337 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2338 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2339 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2340 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2341 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2342 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2343 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2344 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2345 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2346 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2347 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2348 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2349 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2350 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2351 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2352 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2353 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2354 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2355 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2356 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2357 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2358 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2359 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2360 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2361 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2362 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2363 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2364 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2365 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2366 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2367 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2368 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2369 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2370 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2371 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2372 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2373 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2374 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2375 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2376 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2377 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2378 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.48720032507110933\n",
      "Epoch 2379 Loss 1.02 | Train Accuracy 0.4925828083722821 | Val Accuracy 0.4729784640390085\n",
      "Epoch 2380 Loss 1.02 | Train Accuracy 0.48597845966267017 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2381 Loss 1.02 | Train Accuracy 0.4925828083722821 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2382 Loss 1.01 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2383 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2384 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2385 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2386 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2387 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2388 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2389 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2390 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2391 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2392 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2393 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2394 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2395 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2396 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2397 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2398 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2399 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2400 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2401 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2402 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2403 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2404 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2405 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2406 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2407 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2408 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2409 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2410 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2411 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2412 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2413 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2414 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2415 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2416 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2417 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2418 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2419 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2420 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2421 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2422 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2423 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2424 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2425 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2426 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2427 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2428 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2429 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2430 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2431 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2432 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2433 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2434 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2435 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2436 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2437 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2438 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2439 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2440 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2441 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2442 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2443 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2444 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2445 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2446 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2447 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2448 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2449 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2450 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2451 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2452 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2453 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2454 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2455 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2456 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2457 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.481511580658269\n",
      "Epoch 2458 Loss 1.01 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.47988622511174317\n",
      "Epoch 2459 Loss 1.03 | Train Accuracy 0.487096118675066 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2460 Loss 1.02 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2461 Loss 1.02 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2462 Loss 1.01 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2463 Loss 1.01 | Train Accuracy 0.49390367811420444 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2464 Loss 1.01 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2465 Loss 1.01 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2466 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2467 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2468 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2469 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2470 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2471 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2472 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2473 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2474 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2475 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2476 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2477 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2478 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2479 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2480 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2481 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2482 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2483 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2484 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2485 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2486 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2487 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2488 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2489 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2490 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2491 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.497765136123527\n",
      "Epoch 2492 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2493 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2494 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.497765136123527\n",
      "Epoch 2495 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2496 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2497 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2498 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2499 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2500 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2501 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2502 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2503 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2504 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2505 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2506 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2507 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2508 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2509 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2510 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2511 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2512 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2513 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2514 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2515 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2516 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2517 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2518 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2519 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2520 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2521 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2522 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2523 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2524 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2525 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2526 Loss 1.00 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2527 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2528 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2529 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2530 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2531 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2532 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2533 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2534 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49817147501015846\n",
      "Epoch 2535 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2536 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2537 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4839496139780577\n",
      "Epoch 2538 Loss 1.02 | Train Accuracy 0.48882340987604145 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2539 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2540 Loss 1.02 | Train Accuracy 0.494919731761837 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2541 Loss 1.01 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2542 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2543 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2544 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.48516863063795207\n",
      "Epoch 2545 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2546 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2547 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2548 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2549 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2550 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2551 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2552 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2553 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2554 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2555 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2556 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2557 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2558 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2559 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2560 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2561 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2562 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2563 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2564 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2565 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2566 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2567 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2568 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2569 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2570 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2571 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2572 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2573 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2574 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2575 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2576 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2577 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2578 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2579 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2580 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2581 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2582 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2583 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2584 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2585 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2586 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2587 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2588 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2589 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2590 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2591 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2592 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2593 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2594 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2595 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2596 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2597 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2598 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2599 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2600 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2601 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49939049167005284\n",
      "Epoch 2602 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2603 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2604 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48435595286468913\n",
      "Epoch 2605 Loss 1.02 | Train Accuracy 0.4914651493598862 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2606 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2607 Loss 1.02 | Train Accuracy 0.4950213371266003 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2608 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2609 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.48720032507110933\n",
      "Epoch 2610 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2611 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2612 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2613 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2614 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2615 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2616 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2617 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2618 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2619 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2620 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2621 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2622 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2623 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2624 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.497765136123527\n",
      "Epoch 2625 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2626 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2627 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2628 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2629 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2630 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2631 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2632 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2633 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2634 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2635 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2636 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2637 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2638 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2639 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2640 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2641 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2642 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2643 Loss 1.01 | Train Accuracy 0.5059947165210323 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2644 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2645 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2646 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2647 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2648 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2649 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2650 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2651 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2652 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2653 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2654 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2655 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2656 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2657 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2658 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2659 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2660 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2661 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2662 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2663 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2664 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2665 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4989841527834214\n",
      "Epoch 2666 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2667 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2668 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2669 Loss 1.02 | Train Accuracy 0.4926844137370453 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2670 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2671 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48679398618447783\n",
      "Epoch 2672 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2673 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2674 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2675 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2676 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2677 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2678 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2679 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2680 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2681 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2682 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2683 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2684 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2685 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2686 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2687 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2688 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2689 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2690 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2691 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2692 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2693 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2694 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2695 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.497765136123527\n",
      "Epoch 2696 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2697 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2698 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2699 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2700 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2701 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2702 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2703 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2704 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2705 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2706 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2707 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2708 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2709 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2710 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2711 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2712 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2713 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2714 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2715 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2716 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2717 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2718 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2719 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2720 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2721 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2722 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2723 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2724 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2725 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.477041852905323\n",
      "Epoch 2726 Loss 1.02 | Train Accuracy 0.48892501524080473 | Val Accuracy 0.497765136123527\n",
      "Epoch 2727 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2728 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2729 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2730 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2731 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2732 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2733 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2734 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2735 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2736 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2737 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2738 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2739 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2740 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2741 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2742 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2743 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2744 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2745 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2746 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2747 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2748 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2749 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2750 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2751 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2752 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2753 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2754 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2755 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2756 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2757 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2758 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2759 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2760 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2761 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2762 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2763 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2764 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2765 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2766 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2767 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48720032507110933\n",
      "Epoch 2768 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2769 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2770 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2771 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2772 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2773 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2774 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2775 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2776 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2777 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2778 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2779 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2780 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2781 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2782 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2783 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2784 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.48679398618447783\n",
      "Epoch 2785 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2786 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.48516863063795207\n",
      "Epoch 2787 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.48435595286468913\n",
      "Epoch 2788 Loss 1.01 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2789 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2790 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2791 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2792 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2793 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2794 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2795 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2796 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2797 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2798 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2799 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2800 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2801 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2802 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2803 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2804 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2805 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2806 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2807 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2808 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2809 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2810 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2811 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2812 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2813 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2814 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2815 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2816 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2817 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2818 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2819 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2820 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2821 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2822 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2823 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2824 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2825 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2826 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2827 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2828 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2829 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2830 Loss 1.00 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2831 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2832 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2833 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2834 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2835 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2836 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2837 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2838 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2839 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4985778138967899\n",
      "Epoch 2840 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48598130841121495\n",
      "Epoch 2841 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.47379114181227144\n",
      "Epoch 2842 Loss 1.02 | Train Accuracy 0.4897378581589108 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2843 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2844 Loss 1.02 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2845 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2846 Loss 1.01 | Train Accuracy 0.49664702296281243 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2847 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2848 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2849 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2850 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2851 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2852 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2853 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.48760666395774077\n",
      "Epoch 2854 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.48841934173100365\n",
      "Epoch 2855 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2856 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2857 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2858 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2859 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2860 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2861 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2862 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2863 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2864 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2865 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2866 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2867 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2868 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2869 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2870 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2871 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2872 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2873 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2874 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2875 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2876 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2877 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2878 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2879 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2880 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2881 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2882 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2883 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2884 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2885 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2886 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2887 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2888 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2889 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2890 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2891 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2892 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2893 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2894 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2895 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2896 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2897 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2898 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2899 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2900 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2901 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2902 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2903 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2904 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2905 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48963835839089803\n",
      "Epoch 2906 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2907 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2908 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49695245835026414\n",
      "Epoch 2909 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2910 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.47622917513206015\n",
      "Epoch 2911 Loss 1.02 | Train Accuracy 0.491769965454176 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2912 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4863876472978464\n",
      "Epoch 2913 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2914 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2915 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2916 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2917 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2918 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2919 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2920 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2921 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2922 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2923 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2924 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2925 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2926 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2927 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4965461194636327\n",
      "Epoch 2928 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2929 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2930 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2931 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2932 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2933 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2934 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2935 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2936 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2937 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2938 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2939 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2940 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2941 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2942 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2943 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2944 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2945 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2946 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2947 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4937017472572125\n",
      "Epoch 2948 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2949 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2950 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2951 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48923201950426654\n",
      "Epoch 2952 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4880130028443722\n",
      "Epoch 2953 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2954 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2955 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2956 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2957 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2958 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4912637139374238\n",
      "Epoch 2959 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2960 Loss 1.00 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2961 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4900446972775295\n",
      "Epoch 2962 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2963 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2964 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2965 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2966 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2967 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4888256806176351\n",
      "Epoch 2968 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.497765136123527\n",
      "Epoch 2969 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4904510361641609\n",
      "Epoch 2970 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.497765136123527\n",
      "Epoch 2971 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.48598130841121495\n",
      "Epoch 2972 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.48029256399837467\n",
      "Epoch 2973 Loss 1.02 | Train Accuracy 0.4922779922779923 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2974 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2975 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2976 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2977 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49451442503047544\n",
      "Epoch 2978 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49573344169036976\n",
      "Epoch 2979 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4928890694839496\n",
      "Epoch 2980 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2981 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2982 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2983 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2984 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2985 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4953271028037383\n",
      "Epoch 2986 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4973587972368956\n",
      "Epoch 2987 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2988 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2989 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49167005282405524\n",
      "Epoch 2990 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2991 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49410808614384394\n",
      "Epoch 2992 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2993 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4924827305973182\n",
      "Epoch 2994 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4949207639171069\n",
      "Epoch 2995 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.49207639171068673\n",
      "Epoch 2996 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49329540837058106\n",
      "Epoch 2997 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49085737505079235\n",
      "Epoch 2998 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4961397805770012\n",
      "Epoch 2999 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.497765136123527\n",
      "Epoch 3000 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3001 Loss 1.01 | Train Accuracy 0.5064011379800853 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3002 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3003 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3004 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3005 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3006 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3007 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3008 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3009 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3010 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3011 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3012 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3013 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3014 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3015 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3016 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3017 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3018 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3019 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3020 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3021 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3022 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.497765136123527\n",
      "Epoch 3023 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3024 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3025 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.48720032507110933\n",
      "Epoch 3026 Loss 1.01 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3027 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3028 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3029 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3030 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3031 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3032 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3033 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3034 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3035 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3036 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3037 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3038 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.497765136123527\n",
      "Epoch 3039 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3040 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3041 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3042 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3043 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3044 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.5002031694433158\n",
      "Epoch 3045 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3046 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3047 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3048 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3049 Loss 1.00 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3050 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3051 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3052 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3053 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3054 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3055 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3056 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3057 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3058 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48720032507110933\n",
      "Epoch 3059 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3060 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3061 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3062 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3063 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3064 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3065 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3066 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3067 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3068 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.497765136123527\n",
      "Epoch 3069 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3070 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.481511580658269\n",
      "Epoch 3071 Loss 1.02 | Train Accuracy 0.49359886201991465 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3072 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3073 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3074 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3075 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3076 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3077 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3078 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3079 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3080 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3081 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3082 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3083 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3084 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3085 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3086 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3087 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3088 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3089 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3090 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3091 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3092 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3093 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3094 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3095 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3096 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3097 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3098 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3099 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.497765136123527\n",
      "Epoch 3100 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.497765136123527\n",
      "Epoch 3101 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.497765136123527\n",
      "Epoch 3102 Loss 1.01 | Train Accuracy 0.5061979272505588 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3103 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3104 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3105 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3106 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3107 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3108 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3109 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3110 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3111 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3112 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3113 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3114 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3115 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3116 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3117 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3118 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3119 Loss 1.00 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3120 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3121 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3122 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3123 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.497765136123527\n",
      "Epoch 3124 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3125 Loss 1.00 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3126 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3127 Loss 1.02 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3128 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4880130028443722\n",
      "Epoch 3129 Loss 1.01 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3130 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4880130028443722\n",
      "Epoch 3131 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3132 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3133 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3134 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3135 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3136 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3137 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3138 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3139 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3140 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3141 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3142 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3143 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3144 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3145 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3146 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3147 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3148 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3149 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3150 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3151 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3152 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3153 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3154 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3155 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3156 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3157 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3158 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3159 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3160 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3161 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3162 Loss 1.00 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3163 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3164 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3165 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3166 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3167 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3168 Loss 1.00 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3169 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3170 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3171 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3172 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3173 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3174 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3175 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3176 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3177 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3178 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3179 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3180 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3181 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3182 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3183 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3184 Loss 1.01 | Train Accuracy 0.49461491566754723 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3185 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3186 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3187 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3188 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3189 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3190 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3191 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3192 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3193 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3194 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3195 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3196 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3197 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3198 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3199 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3200 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3201 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3202 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3203 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3204 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3205 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3206 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3207 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3208 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3209 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3210 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3211 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3212 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3213 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3214 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3215 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3216 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3217 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3218 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3219 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3220 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3221 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3222 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3223 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3224 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3225 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3226 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3227 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3228 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48598130841121495\n",
      "Epoch 3229 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4831369362047948\n",
      "Epoch 3230 Loss 1.01 | Train Accuracy 0.49593578540946964 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3231 Loss 1.01 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3232 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3233 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3234 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3235 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3236 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3237 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3238 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3239 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3240 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3241 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3242 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3243 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3244 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3245 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3246 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3247 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3248 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3249 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3250 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3251 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3252 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3253 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3254 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3255 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3256 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3257 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3258 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3259 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3260 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3261 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3262 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3263 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3264 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3265 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3266 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3267 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3268 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3269 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3270 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3271 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3272 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3273 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3274 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3275 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3276 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3277 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3278 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3279 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3280 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3281 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3282 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3283 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3284 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48679398618447783\n",
      "Epoch 3285 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4863876472978464\n",
      "Epoch 3286 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3287 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3288 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3289 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3290 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.497765136123527\n",
      "Epoch 3291 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3292 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3293 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3294 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3295 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3296 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3297 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3298 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3299 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3300 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3301 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3302 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3303 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3304 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3305 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.497765136123527\n",
      "Epoch 3306 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3307 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3308 Loss 1.00 | Train Accuracy 0.5065027433448486 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3309 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3310 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3311 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3312 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3313 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3314 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3315 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3316 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3317 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3318 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3319 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3320 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3321 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3322 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3323 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3324 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3325 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3326 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3327 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3328 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.48029256399837467\n",
      "Epoch 3329 Loss 1.01 | Train Accuracy 0.49410688884373094 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3330 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3331 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3332 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3333 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3334 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3335 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3336 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3337 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3338 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3339 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3340 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3341 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3342 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3343 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3344 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3345 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3346 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3347 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3348 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3349 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3350 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3351 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3352 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3353 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3354 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3355 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3356 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3357 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3358 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3359 Loss 1.01 | Train Accuracy 0.5060963218857956 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3360 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3361 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3362 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3363 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3364 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3365 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3366 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3367 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3368 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3369 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3370 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3371 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3372 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3373 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3374 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3375 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3376 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3377 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3378 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3379 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48720032507110933\n",
      "Epoch 3380 Loss 1.01 | Train Accuracy 0.494919731761837 | Val Accuracy 0.47622917513206015\n",
      "Epoch 3381 Loss 1.02 | Train Accuracy 0.49034749034749037 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3382 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3383 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3384 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3385 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3386 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3387 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3388 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3389 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3390 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3391 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3392 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3393 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3394 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3395 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3396 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3397 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3398 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3399 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3400 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3401 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3402 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3403 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3404 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3405 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3406 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3407 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3408 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3409 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3410 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3411 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3412 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3413 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3414 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3415 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3416 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3417 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3418 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3419 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3420 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3421 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3422 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3423 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3424 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3425 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3426 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3427 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3428 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3429 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3430 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3431 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3432 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3433 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3434 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3435 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3436 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3437 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3438 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3439 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3440 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3441 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3442 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3443 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48720032507110933\n",
      "Epoch 3444 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.47257212515237706\n",
      "Epoch 3445 Loss 1.02 | Train Accuracy 0.4872993294045926 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3446 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3447 Loss 1.02 | Train Accuracy 0.49644381223328593 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3448 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3449 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3450 Loss 1.01 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3451 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3452 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3453 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3454 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3455 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3456 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3457 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3458 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3459 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3460 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3461 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3462 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3463 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3464 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3465 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3466 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3467 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3468 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3469 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3470 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3471 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3472 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3473 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3474 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3475 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3476 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3477 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3478 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3479 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3480 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3481 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3482 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3483 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3484 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3485 Loss 1.01 | Train Accuracy 0.5059947165210323 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3486 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3487 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3488 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3489 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3490 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3491 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3492 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3493 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3494 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3495 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3496 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3497 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3498 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3499 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3500 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3501 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3502 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3503 Loss 1.00 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3504 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3505 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3506 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3507 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3508 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3509 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3510 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3511 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3512 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3513 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.5002031694433158\n",
      "Epoch 3514 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3515 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.48029256399837467\n",
      "Epoch 3516 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3517 Loss 1.02 | Train Accuracy 0.49156675472464945 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3518 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3519 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3520 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3521 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4880130028443722\n",
      "Epoch 3522 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3523 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3524 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3525 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3526 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3527 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3528 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3529 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3530 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3531 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3532 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3533 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3534 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3535 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3536 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3537 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3538 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3539 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3540 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3541 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3542 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3543 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3544 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3545 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3546 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3547 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3548 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3549 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3550 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3551 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3552 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3553 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3554 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3555 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3556 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3557 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3558 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3559 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3560 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3561 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3562 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3563 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3564 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3565 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3566 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3567 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3568 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3569 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3570 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3571 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3572 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3573 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3574 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3575 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3576 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3577 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48273059731816337\n",
      "Epoch 3578 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3579 Loss 1.01 | Train Accuracy 0.49288762446657186 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3580 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3581 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3582 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3583 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4880130028443722\n",
      "Epoch 3584 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3585 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3586 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3587 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3588 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3589 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3590 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3591 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3592 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3593 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3594 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3595 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3596 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3597 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3598 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3599 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3600 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3601 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3602 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3603 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3604 Loss 1.01 | Train Accuracy 0.5059947165210323 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3605 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3606 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3607 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3608 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3609 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3610 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3611 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3612 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3613 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3614 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3615 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3616 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3617 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3618 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3619 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3620 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3621 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3622 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3623 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3624 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3625 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3626 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3627 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3628 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3629 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3630 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3631 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4863876472978464\n",
      "Epoch 3632 Loss 1.01 | Train Accuracy 0.4955293639504166 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3633 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3634 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3635 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3636 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3637 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3638 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3639 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3640 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3641 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3642 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3643 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3644 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3645 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3646 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3647 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3648 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3649 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3650 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3651 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3652 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3653 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3654 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3655 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.5002031694433158\n",
      "Epoch 3656 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3657 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3658 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3659 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3660 Loss 1.00 | Train Accuracy 0.5060963218857956 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3661 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3662 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3663 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3664 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3665 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3666 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3667 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3668 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3669 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3670 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3671 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3672 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3673 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3674 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3675 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3676 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3677 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3678 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3679 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3680 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3681 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3682 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3683 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3684 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3685 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3686 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3687 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3688 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3689 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3690 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3691 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3692 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.5006095083299472\n",
      "Epoch 3693 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3694 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3695 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.5006095083299472\n",
      "Epoch 3696 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3697 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3698 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3699 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3700 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3701 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3702 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3703 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3704 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3705 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3706 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3707 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3708 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3709 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3710 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3711 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3712 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3713 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3714 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3715 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3716 Loss 1.00 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3717 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3718 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3719 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3720 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.5010158472165787\n",
      "Epoch 3721 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3722 Loss 1.00 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.497765136123527\n",
      "Epoch 3723 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3724 Loss 1.00 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3725 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3726 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3727 Loss 1.00 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3728 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3729 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.497765136123527\n",
      "Epoch 3730 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3731 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3732 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3733 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3734 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3735 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3736 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3737 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3738 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3739 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3740 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3741 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3742 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3743 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3744 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3745 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.48760666395774077\n",
      "Epoch 3746 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.497765136123527\n",
      "Epoch 3747 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3748 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3749 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3750 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3751 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3752 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3753 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3754 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3755 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3756 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3757 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3758 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3759 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3760 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3761 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3762 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3763 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3764 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3765 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3766 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3767 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3768 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3769 Loss 1.00 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3770 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3771 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3772 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3773 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3774 Loss 1.00 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3775 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3776 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3777 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3778 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48679398618447783\n",
      "Epoch 3779 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3780 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3781 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3782 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3783 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3784 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3785 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3786 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3787 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3788 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3789 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3790 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3791 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.5010158472165787\n",
      "Epoch 3792 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3793 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3794 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3795 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3796 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3797 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3798 Loss 1.00 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3799 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3800 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3801 Loss 1.00 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3802 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3803 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3804 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3805 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3806 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3807 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.497765136123527\n",
      "Epoch 3808 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48720032507110933\n",
      "Epoch 3809 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3810 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3811 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3812 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.497765136123527\n",
      "Epoch 3813 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3814 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48841934173100365\n",
      "Epoch 3815 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3816 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.497765136123527\n",
      "Epoch 3817 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3818 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3819 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3820 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3821 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3822 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3823 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4985778138967899\n",
      "Epoch 3824 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3825 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3826 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3827 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3828 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3829 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3830 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3831 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3832 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3833 Loss 1.00 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3834 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3835 Loss 1.00 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3836 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3837 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3838 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3839 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3840 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3841 Loss 1.01 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3842 Loss 1.01 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3843 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3844 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4855749695245835\n",
      "Epoch 3845 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3846 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3847 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3848 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3849 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3850 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3851 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3852 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3853 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3854 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3855 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3856 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3857 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3858 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3859 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3860 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3861 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3862 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3863 Loss 1.00 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.49939049167005284\n",
      "Epoch 3864 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3865 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3866 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3867 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3868 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3869 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3870 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3871 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3872 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3873 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3874 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3875 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3876 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3877 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3878 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3879 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3880 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3881 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.497765136123527\n",
      "Epoch 3882 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3883 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49573344169036976\n",
      "Epoch 3884 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4863876472978464\n",
      "Epoch 3885 Loss 1.01 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.48720032507110933\n",
      "Epoch 3886 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3887 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3888 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3889 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3890 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3891 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3892 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3893 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3894 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3895 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3896 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3897 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3898 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3899 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3900 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3901 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3902 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3903 Loss 1.00 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3904 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3905 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3906 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3907 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3908 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3909 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3910 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49695245835026414\n",
      "Epoch 3911 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48963835839089803\n",
      "Epoch 3912 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3913 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4989841527834214\n",
      "Epoch 3914 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4937017472572125\n",
      "Epoch 3915 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3916 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4997968305566843\n",
      "Epoch 3917 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3918 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3919 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3920 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3921 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4973587972368956\n",
      "Epoch 3922 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3923 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48516863063795207\n",
      "Epoch 3924 Loss 1.01 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.4839496139780577\n",
      "Epoch 3925 Loss 1.02 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3926 Loss 1.01 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3927 Loss 1.01 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4880130028443722\n",
      "Epoch 3928 Loss 1.01 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3929 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3930 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3931 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3932 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3933 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3934 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3935 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3936 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.497765136123527\n",
      "Epoch 3937 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49817147501015846\n",
      "Epoch 3938 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3939 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3940 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3941 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3942 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3943 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3944 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3945 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3946 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3947 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3948 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3949 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3950 Loss 1.01 | Train Accuracy 0.5059947165210323 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3951 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3952 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3953 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3954 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3955 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3956 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3957 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3958 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3959 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3960 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49410808614384394\n",
      "Epoch 3961 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3962 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3963 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4965461194636327\n",
      "Epoch 3964 Loss 1.00 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3965 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3966 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3967 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3968 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4924827305973182\n",
      "Epoch 3969 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3970 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3971 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3972 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3973 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3974 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3975 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48923201950426654\n",
      "Epoch 3976 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3977 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3978 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3979 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4900446972775295\n",
      "Epoch 3980 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3981 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 3982 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4888256806176351\n",
      "Epoch 3983 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49207639171068673\n",
      "Epoch 3984 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49451442503047544\n",
      "Epoch 3985 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3986 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4961397805770012\n",
      "Epoch 3987 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4912637139374238\n",
      "Epoch 3988 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3989 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.48679398618447783\n",
      "Epoch 3990 Loss 1.01 | Train Accuracy 0.49431009957325744 | Val Accuracy 0.48516863063795207\n",
      "Epoch 3991 Loss 1.01 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3992 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49085737505079235\n",
      "Epoch 3993 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4880130028443722\n",
      "Epoch 3994 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49167005282405524\n",
      "Epoch 3995 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4904510361641609\n",
      "Epoch 3996 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4928890694839496\n",
      "Epoch 3997 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4949207639171069\n",
      "Epoch 3998 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4953271028037383\n",
      "Epoch 3999 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4000 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4001 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4002 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4003 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4004 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4005 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4006 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4007 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4008 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4009 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4010 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4011 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4012 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4013 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4014 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4015 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4016 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4017 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4018 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4019 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4020 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.5006095083299472\n",
      "Epoch 4021 Loss 1.01 | Train Accuracy 0.5068075594391384 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4022 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4023 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4024 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4025 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4026 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4027 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48841934173100365\n",
      "Epoch 4028 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4029 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4030 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4031 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48841934173100365\n",
      "Epoch 4032 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4033 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4034 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4035 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4036 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4037 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4038 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4039 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48841934173100365\n",
      "Epoch 4040 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.497765136123527\n",
      "Epoch 4041 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4042 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4043 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4044 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4045 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4046 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.48679398618447783\n",
      "Epoch 4047 Loss 1.01 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4048 Loss 1.01 | Train Accuracy 0.49583418004470636 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4049 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4050 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4051 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.48760666395774077\n",
      "Epoch 4052 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4053 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4054 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4055 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4056 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4057 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4058 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4059 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4060 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4061 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4062 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4063 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4064 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4065 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4066 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4067 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4068 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4069 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4070 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4071 Loss 1.01 | Train Accuracy 0.505893111156269 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4072 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.497765136123527\n",
      "Epoch 4073 Loss 1.00 | Train Accuracy 0.5069091648039017 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4074 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4075 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4076 Loss 1.00 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4077 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4078 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4079 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4080 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4081 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4082 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48841934173100365\n",
      "Epoch 4083 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4084 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4085 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4086 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4087 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4088 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4089 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4090 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.5006095083299472\n",
      "Epoch 4091 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4092 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4093 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4863876472978464\n",
      "Epoch 4094 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4095 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.48720032507110933\n",
      "Epoch 4096 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4097 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4098 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4099 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4100 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4101 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4102 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4103 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4104 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4105 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4106 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4107 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4108 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4109 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4110 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4111 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4112 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4113 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4114 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48841934173100365\n",
      "Epoch 4115 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4116 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4117 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4118 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4119 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4120 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4121 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4122 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.497765136123527\n",
      "Epoch 4123 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4124 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4125 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4126 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4127 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4128 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4129 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4130 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4131 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4132 Loss 1.00 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4133 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4134 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4135 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48679398618447783\n",
      "Epoch 4136 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4137 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4138 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4139 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.497765136123527\n",
      "Epoch 4140 Loss 1.00 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4141 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4142 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4143 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4144 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4145 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4146 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4147 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4148 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4149 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4150 Loss 1.00 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4151 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4152 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4153 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4154 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4155 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4156 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4157 Loss 1.00 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4880130028443722\n",
      "Epoch 4158 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4159 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4160 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4161 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4162 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4163 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4164 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4165 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4166 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4167 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4168 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4169 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4170 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4171 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4172 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4997968305566843\n",
      "Epoch 4173 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4174 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4175 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4997968305566843\n",
      "Epoch 4176 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4177 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4178 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4179 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4180 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4181 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4182 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4183 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4184 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.497765136123527\n",
      "Epoch 4185 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4186 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4187 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.497765136123527\n",
      "Epoch 4188 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4189 Loss 1.00 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4190 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4191 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4192 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4193 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4194 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4195 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4196 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4197 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4198 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4199 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4200 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4201 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4202 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4203 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.5002031694433158\n",
      "Epoch 4204 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4205 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4206 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4207 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4208 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4209 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4210 Loss 1.00 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4211 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4212 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4213 Loss 1.00 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4214 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4215 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4216 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4217 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4218 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4219 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4220 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4221 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4222 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4223 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4224 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4225 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4226 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4227 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4228 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4229 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4230 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4231 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4232 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4233 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4234 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.497765136123527\n",
      "Epoch 4235 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4236 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4237 Loss 1.00 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4238 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4239 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4240 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4241 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4242 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4243 Loss 1.00 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4244 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4245 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4246 Loss 1.00 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4247 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4248 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4249 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4250 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4251 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4252 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4253 Loss 1.00 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4254 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4255 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4256 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4257 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4258 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4259 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4260 Loss 1.00 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4261 Loss 1.00 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4262 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4263 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4264 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4265 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4266 Loss 1.00 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4267 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4268 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4269 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4270 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4271 Loss 1.00 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4272 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4273 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4274 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4275 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4276 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4277 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4278 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4279 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4280 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4281 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4282 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4283 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4284 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4285 Loss 1.00 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4286 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4287 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4288 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4289 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4290 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4291 Loss 1.00 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4292 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4293 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4294 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4295 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4296 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4297 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4298 Loss 1.00 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4299 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4880130028443722\n",
      "Epoch 4300 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4301 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4302 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4303 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4304 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4305 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4306 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4307 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4308 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4309 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4310 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4311 Loss 1.00 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4312 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4313 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4314 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4315 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4880130028443722\n",
      "Epoch 4316 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4317 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4318 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4319 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4320 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4321 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4322 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4323 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4324 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4325 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4326 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4327 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4328 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4329 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4330 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4331 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4332 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4333 Loss 1.00 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4334 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4335 Loss 1.00 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4336 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4337 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4338 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4339 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4340 Loss 1.00 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.497765136123527\n",
      "Epoch 4341 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4342 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4343 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4344 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.497765136123527\n",
      "Epoch 4345 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4346 Loss 1.00 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.48679398618447783\n",
      "Epoch 4347 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4348 Loss 1.01 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4349 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4350 Loss 1.01 | Train Accuracy 0.497256655151392 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4351 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4352 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4353 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4354 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4355 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4356 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4357 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4358 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4359 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4360 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4361 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4362 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4363 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4364 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4365 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4366 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4367 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4368 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4369 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4370 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4371 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4372 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4373 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4374 Loss 1.00 | Train Accuracy 0.5061979272505588 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4375 Loss 1.00 | Train Accuracy 0.5059947165210323 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4376 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4377 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4378 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4379 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4380 Loss 1.00 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4381 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4382 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4383 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4384 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4385 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4386 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4387 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4388 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4389 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4390 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4391 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4392 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4393 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4394 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4395 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.497765136123527\n",
      "Epoch 4396 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4397 Loss 1.00 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4398 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.48841934173100365\n",
      "Epoch 4399 Loss 1.01 | Train Accuracy 0.49634220686852265 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4400 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.497765136123527\n",
      "Epoch 4401 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4402 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4403 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4404 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4405 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4406 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4407 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4408 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4409 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4410 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4411 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4412 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4413 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4414 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4415 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4416 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.497765136123527\n",
      "Epoch 4417 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4418 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4419 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4420 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4421 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4422 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4423 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4424 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4425 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4426 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4427 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4428 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4429 Loss 1.00 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4430 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4431 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4432 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4433 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4434 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4435 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4436 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4437 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4438 Loss 1.01 | Train Accuracy 0.4969518390571022 | Val Accuracy 0.47501015847216577\n",
      "Epoch 4439 Loss 1.02 | Train Accuracy 0.4872993294045926 | Val Accuracy 0.497765136123527\n",
      "Epoch 4440 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4441 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4442 Loss 1.01 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4443 Loss 1.01 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4444 Loss 1.01 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4445 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4446 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4447 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4448 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4449 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4450 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4451 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4452 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4453 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4454 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4455 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4456 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4457 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4458 Loss 1.01 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4459 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4460 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4461 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4462 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4463 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4464 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4465 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4466 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4467 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4468 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4469 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4470 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4471 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4472 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4473 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4474 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4475 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4476 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4477 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4478 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4479 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4480 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4481 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4482 Loss 1.01 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4483 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4484 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4485 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4486 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4487 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4488 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4489 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4490 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4491 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4492 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4493 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4494 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4495 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4496 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4497 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4498 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4499 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4500 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4501 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4502 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4503 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4504 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4505 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4506 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4507 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4508 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4509 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4510 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4511 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4512 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4513 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4514 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4515 Loss 1.00 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4839496139780577\n",
      "Epoch 4516 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4517 Loss 1.02 | Train Accuracy 0.492176386913229 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4518 Loss 1.01 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4519 Loss 1.01 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.48760666395774077\n",
      "Epoch 4520 Loss 1.01 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4521 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4522 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4523 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4524 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4525 Loss 1.01 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4526 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4527 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4528 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4529 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4530 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4531 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4532 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4533 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4534 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4535 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4536 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4537 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4538 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4539 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4540 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4541 Loss 1.01 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4542 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4543 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4544 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4545 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4546 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4547 Loss 1.01 | Train Accuracy 0.505486689697216 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4548 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4549 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4550 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4551 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4552 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4553 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4554 Loss 1.01 | Train Accuracy 0.5065027433448486 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4555 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4556 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4557 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4558 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4559 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4560 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4561 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4562 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4563 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4564 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4565 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4566 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4567 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4568 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4569 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4570 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4571 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4572 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4573 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4574 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4575 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4576 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4577 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4578 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4579 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4580 Loss 1.00 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4581 Loss 1.01 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.48760666395774077\n",
      "Epoch 4582 Loss 1.02 | Train Accuracy 0.49370046738467793 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4583 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4584 Loss 1.01 | Train Accuracy 0.4957325746799431 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4585 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4586 Loss 1.01 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.48760666395774077\n",
      "Epoch 4587 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4588 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4589 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4590 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4591 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4592 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4593 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4594 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4595 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4596 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4597 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4598 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4599 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4600 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4601 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4602 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4603 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4604 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4605 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4606 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4607 Loss 1.01 | Train Accuracy 0.5051818736029262 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4608 Loss 1.01 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4609 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4610 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4611 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4612 Loss 1.01 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4613 Loss 1.01 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4614 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4615 Loss 1.00 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4616 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4617 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4618 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4619 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4620 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4621 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4622 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4623 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4624 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4625 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4626 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4627 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4628 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4629 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4630 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4631 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4632 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4633 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4634 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4635 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4636 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4637 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4638 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4639 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4640 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4641 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.48476229175132063\n",
      "Epoch 4642 Loss 1.01 | Train Accuracy 0.49390367811420444 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4643 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4880130028443722\n",
      "Epoch 4644 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4645 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4646 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4647 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4648 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4649 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4650 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4651 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4652 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4653 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4654 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4655 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4656 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4657 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4658 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4659 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4660 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4661 Loss 1.01 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4662 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4663 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4664 Loss 1.00 | Train Accuracy 0.5055882950619792 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4665 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4666 Loss 1.01 | Train Accuracy 0.5057915057915058 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4667 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4668 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4669 Loss 1.00 | Train Accuracy 0.5052834789676895 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4670 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4671 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4672 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4673 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4674 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4675 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4676 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4677 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4678 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4679 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4680 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4681 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4682 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4683 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4684 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4685 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.48841934173100365\n",
      "Epoch 4686 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4687 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4688 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4689 Loss 1.00 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4690 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4691 Loss 1.01 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4855749695245835\n",
      "Epoch 4692 Loss 1.01 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4693 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4694 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4695 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4696 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4697 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4698 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4699 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4700 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4701 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4702 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4703 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4704 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4705 Loss 1.01 | Train Accuracy 0.5056899004267426 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4706 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4707 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4708 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4709 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.5010158472165787\n",
      "Epoch 4710 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4997968305566843\n",
      "Epoch 4711 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4712 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4713 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4714 Loss 1.00 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4715 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4716 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4717 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4718 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4719 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4720 Loss 1.00 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4721 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4722 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4723 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4724 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4725 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4726 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4727 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4728 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4729 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4730 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4731 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4855749695245835\n",
      "Epoch 4732 Loss 1.01 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4733 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4734 Loss 1.01 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4735 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4736 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4737 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4738 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4739 Loss 1.01 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4740 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4741 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4742 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4743 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4744 Loss 1.01 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4745 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4746 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4747 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4748 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4749 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4750 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4751 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4752 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4753 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4754 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4755 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4756 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4757 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4758 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4759 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4760 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4761 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4762 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.48720032507110933\n",
      "Epoch 4763 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.497765136123527\n",
      "Epoch 4764 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4765 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4766 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48720032507110933\n",
      "Epoch 4767 Loss 1.01 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.48720032507110933\n",
      "Epoch 4768 Loss 1.01 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4769 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4880130028443722\n",
      "Epoch 4770 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4771 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4772 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4773 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4774 Loss 1.01 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4775 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4776 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4777 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.497765136123527\n",
      "Epoch 4778 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4779 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4780 Loss 1.01 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4781 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4782 Loss 1.01 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4783 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4784 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4785 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4786 Loss 1.01 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4787 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4788 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4789 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4790 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4791 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4792 Loss 1.00 | Train Accuracy 0.505080268238163 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4793 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4794 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.48841934173100365\n",
      "Epoch 4795 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4796 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4797 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4798 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4799 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4800 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4801 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4802 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4803 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4804 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4805 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4806 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4807 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4808 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4809 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4810 Loss 1.00 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4811 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4812 Loss 1.01 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4813 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4814 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4815 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4816 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4817 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4818 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4819 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4820 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4821 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4822 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4823 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4824 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.497765136123527\n",
      "Epoch 4825 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4826 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4827 Loss 1.00 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4828 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4829 Loss 1.00 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4830 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4831 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4832 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4833 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4834 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4835 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4836 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4837 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4838 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4880130028443722\n",
      "Epoch 4839 Loss 1.01 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4840 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4841 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4842 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4843 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4844 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4845 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4846 Loss 1.00 | Train Accuracy 0.5053850843324528 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4847 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4848 Loss 1.00 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4849 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4850 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4851 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.5014221861032101\n",
      "Epoch 4852 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4853 Loss 1.00 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4854 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4855 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4856 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4857 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.48679398618447783\n",
      "Epoch 4858 Loss 1.01 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4859 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4860 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4861 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4862 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4863 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4864 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4865 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4866 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4867 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4868 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4869 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4870 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4871 Loss 1.00 | Train Accuracy 0.500406421459053 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4872 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4873 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.48679398618447783\n",
      "Epoch 4874 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.497765136123527\n",
      "Epoch 4875 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4876 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4877 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.497765136123527\n",
      "Epoch 4878 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4879 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4880 Loss 1.00 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4881 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4882 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4883 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4884 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4885 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4886 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4880130028443722\n",
      "Epoch 4887 Loss 1.01 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4888 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4889 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4890 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4891 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4892 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4893 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4894 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4895 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4896 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.497765136123527\n",
      "Epoch 4897 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4898 Loss 1.00 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4899 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49451442503047544\n",
      "Epoch 4900 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4901 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4902 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.48435595286468913\n",
      "Epoch 4903 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4904 Loss 1.01 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4905 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4906 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4907 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4908 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4909 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4910 Loss 1.01 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4911 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4912 Loss 1.00 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4913 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4914 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4915 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4916 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4917 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4918 Loss 1.00 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4919 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4888256806176351\n",
      "Epoch 4920 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4921 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4922 Loss 1.00 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4923 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49939049167005284\n",
      "Epoch 4924 Loss 1.00 | Train Accuracy 0.50467384677911 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4925 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4926 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4927 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4928 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4929 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4930 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4931 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4932 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4933 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4989841527834214\n",
      "Epoch 4934 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4912637139374238\n",
      "Epoch 4935 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4936 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4937 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4938 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4939 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4940 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4941 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4942 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4943 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4944 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4945 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4924827305973182\n",
      "Epoch 4946 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4947 Loss 1.01 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4948 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4949 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4950 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4951 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4997968305566843\n",
      "Epoch 4952 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4953 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4954 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49410808614384394\n",
      "Epoch 4955 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4956 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49695245835026414\n",
      "Epoch 4957 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4958 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4959 Loss 1.00 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4960 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4961 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4962 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.497765136123527\n",
      "Epoch 4963 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4964 Loss 1.01 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4985778138967899\n",
      "Epoch 4965 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4966 Loss 1.00 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4928890694839496\n",
      "Epoch 4967 Loss 1.00 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4968 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4969 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4970 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4971 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4972 Loss 1.00 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4973 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49167005282405524\n",
      "Epoch 4974 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4975 Loss 1.00 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 4976 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.48923201950426654\n",
      "Epoch 4977 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4965461194636327\n",
      "Epoch 4978 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4979 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4980 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4981 Loss 1.01 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4863876472978464\n",
      "Epoch 4982 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.497765136123527\n",
      "Epoch 4983 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.497765136123527\n",
      "Epoch 4984 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4904510361641609\n",
      "Epoch 4985 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4997968305566843\n",
      "Epoch 4986 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4949207639171069\n",
      "Epoch 4987 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49329540837058106\n",
      "Epoch 4988 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4973587972368956\n",
      "Epoch 4989 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.4961397805770012\n",
      "Epoch 4990 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.48963835839089803\n",
      "Epoch 4991 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.497765136123527\n",
      "Epoch 4992 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4993 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49207639171068673\n",
      "Epoch 4994 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49817147501015846\n",
      "Epoch 4995 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49085737505079235\n",
      "Epoch 4996 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4937017472572125\n",
      "Epoch 4997 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4953271028037383\n",
      "Epoch 4998 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4900446972775295\n",
      "Epoch 4999 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49573344169036976\n",
      "Epoch 5000 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5001 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49329540837058106\n",
      "Epoch 5002 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4973587972368956\n",
      "Epoch 5003 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5004 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49695245835026414\n",
      "Epoch 5005 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4949207639171069\n",
      "Epoch 5006 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49410808614384394\n",
      "Epoch 5007 Loss 1.00 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49451442503047544\n",
      "Epoch 5008 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 5009 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5010 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4989841527834214\n",
      "Epoch 5011 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.48963835839089803\n",
      "Epoch 5012 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49410808614384394\n",
      "Epoch 5013 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5014 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4904510361641609\n",
      "Epoch 5015 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5016 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.48760666395774077\n",
      "Epoch 5017 Loss 1.01 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49939049167005284\n",
      "Epoch 5018 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5019 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49207639171068673\n",
      "Epoch 5020 Loss 1.00 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49695245835026414\n",
      "Epoch 5021 Loss 1.00 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5022 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5023 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49817147501015846\n",
      "Epoch 5024 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.49451442503047544\n",
      "Epoch 5025 Loss 1.00 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49573344169036976\n",
      "Epoch 5026 Loss 1.00 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5027 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5028 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.497765136123527\n",
      "Epoch 5029 Loss 1.01 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.48841934173100365\n",
      "Epoch 5030 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.4961397805770012\n",
      "Epoch 5031 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5032 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5033 Loss 1.01 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.4985778138967899\n",
      "Epoch 5034 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5035 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4900446972775295\n",
      "Epoch 5036 Loss 1.01 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.497765136123527\n",
      "Epoch 5037 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.49695245835026414\n",
      "Epoch 5038 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5039 Loss 1.00 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5040 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49817147501015846\n",
      "Epoch 5041 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4904510361641609\n",
      "Epoch 5042 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4985778138967899\n",
      "Epoch 5043 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5044 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5045 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4961397805770012\n",
      "Epoch 5046 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49085737505079235\n",
      "Epoch 5047 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5048 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5049 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4904510361641609\n",
      "Epoch 5050 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49695245835026414\n",
      "Epoch 5051 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4888256806176351\n",
      "Epoch 5052 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5053 Loss 1.01 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5054 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49410808614384394\n",
      "Epoch 5055 Loss 1.01 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49451442503047544\n",
      "Epoch 5056 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49329540837058106\n",
      "Epoch 5057 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4924827305973182\n",
      "Epoch 5058 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49695245835026414\n",
      "Epoch 5059 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5060 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5061 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4973587972368956\n",
      "Epoch 5062 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5063 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4949207639171069\n",
      "Epoch 5064 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4985778138967899\n",
      "Epoch 5065 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4863876472978464\n",
      "Epoch 5066 Loss 1.00 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.497765136123527\n",
      "Epoch 5067 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5068 Loss 1.01 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5069 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49695245835026414\n",
      "Epoch 5070 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.48841934173100365\n",
      "Epoch 5071 Loss 1.00 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.497765136123527\n",
      "Epoch 5072 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4985778138967899\n",
      "Epoch 5073 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49329540837058106\n",
      "Epoch 5074 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4961397805770012\n",
      "Epoch 5075 Loss 1.00 | Train Accuracy 0.5048770575086364 | Val Accuracy 0.4924827305973182\n",
      "Epoch 5076 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.49451442503047544\n",
      "Epoch 5077 Loss 1.00 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49695245835026414\n",
      "Epoch 5078 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4888256806176351\n",
      "Epoch 5079 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4973587972368956\n",
      "Epoch 5080 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5081 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49207639171068673\n",
      "Epoch 5082 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5083 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.48963835839089803\n",
      "Epoch 5084 Loss 1.01 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.497765136123527\n",
      "Epoch 5085 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5086 Loss 1.01 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49329540837058106\n",
      "Epoch 5087 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5088 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5089 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4949207639171069\n",
      "Epoch 5090 Loss 1.01 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5091 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5092 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5093 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5094 Loss 1.00 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5095 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4961397805770012\n",
      "Epoch 5096 Loss 1.00 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.48963835839089803\n",
      "Epoch 5097 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4985778138967899\n",
      "Epoch 5098 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49329540837058106\n",
      "Epoch 5099 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4900446972775295\n",
      "Epoch 5100 Loss 1.00 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4949207639171069\n",
      "Epoch 5101 Loss 1.00 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5102 Loss 1.00 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49207639171068673\n",
      "Epoch 5103 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49573344169036976\n",
      "Epoch 5104 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4904510361641609\n",
      "Epoch 5105 Loss 1.00 | Train Accuracy 0.49918715708189393 | Val Accuracy 0.49695245835026414\n",
      "Epoch 5106 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5107 Loss 1.00 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.497765136123527\n",
      "Epoch 5108 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49207639171068673\n",
      "Epoch 5109 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5110 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49410808614384394\n",
      "Epoch 5111 Loss 1.01 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4888256806176351\n",
      "Epoch 5112 Loss 1.01 | Train Accuracy 0.49817110343426135 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5113 Loss 1.01 | Train Accuracy 0.5 | Val Accuracy 0.49410808614384394\n",
      "Epoch 5114 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49085737505079235\n",
      "Epoch 5115 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5116 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.49817147501015846\n",
      "Epoch 5117 Loss 1.01 | Train Accuracy 0.5044706360495834 | Val Accuracy 0.5010158472165787\n",
      "Epoch 5118 Loss 1.01 | Train Accuracy 0.50467384677911 | Val Accuracy 0.49207639171068673\n",
      "Epoch 5119 Loss 1.01 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4904510361641609\n",
      "Epoch 5120 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4965461194636327\n",
      "Epoch 5121 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49817147501015846\n",
      "Epoch 5122 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.4904510361641609\n",
      "Epoch 5123 Loss 1.01 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4924827305973182\n",
      "Epoch 5124 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49939049167005284\n",
      "Epoch 5125 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.4985778138967899\n",
      "Epoch 5126 Loss 1.00 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5127 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49451442503047544\n",
      "Epoch 5128 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4973587972368956\n",
      "Epoch 5129 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49329540837058106\n",
      "Epoch 5130 Loss 1.00 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.49085737505079235\n",
      "Epoch 5131 Loss 1.00 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.4961397805770012\n",
      "Epoch 5132 Loss 1.00 | Train Accuracy 0.5037593984962406 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5133 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.48923201950426654\n",
      "Epoch 5134 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49817147501015846\n",
      "Epoch 5135 Loss 1.00 | Train Accuracy 0.5043690306848202 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5136 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5137 Loss 1.00 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4961397805770012\n",
      "Epoch 5138 Loss 1.00 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5139 Loss 1.00 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.4924827305973182\n",
      "Epoch 5140 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49817147501015846\n",
      "Epoch 5141 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5142 Loss 1.00 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4949207639171069\n",
      "Epoch 5143 Loss 1.01 | Train Accuracy 0.5026417394838447 | Val Accuracy 0.4900446972775295\n",
      "Epoch 5144 Loss 1.01 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4989841527834214\n",
      "Epoch 5145 Loss 1.00 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4973587972368956\n",
      "Epoch 5146 Loss 1.00 | Train Accuracy 0.5042674253200569 | Val Accuracy 0.48923201950426654\n",
      "Epoch 5147 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49085737505079235\n",
      "Epoch 5148 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5149 Loss 1.01 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49207639171068673\n",
      "Epoch 5150 Loss 1.01 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49329540837058106\n",
      "Epoch 5151 Loss 1.01 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5152 Loss 1.00 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.4888256806176351\n",
      "Epoch 5153 Loss 1.01 | Train Accuracy 0.5023369233895549 | Val Accuracy 0.49695245835026414\n",
      "Epoch 5154 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4989841527834214\n",
      "Epoch 5155 Loss 1.01 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4949207639171069\n",
      "Epoch 5156 Loss 1.01 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5157 Loss 1.00 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.4965461194636327\n",
      "Epoch 5158 Loss 1.00 | Train Accuracy 0.5045722414143466 | Val Accuracy 0.4973587972368956\n",
      "Epoch 5159 Loss 1.00 | Train Accuracy 0.5032513716724243 | Val Accuracy 0.49167005282405524\n",
      "Epoch 5160 Loss 1.01 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49207639171068673\n",
      "Epoch 5161 Loss 1.00 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49939049167005284\n",
      "Epoch 5162 Loss 1.00 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4924827305973182\n",
      "Epoch 5163 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4900446972775295\n",
      "Epoch 5164 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.497765136123527\n",
      "Epoch 5165 Loss 1.00 | Train Accuracy 0.5047754521438732 | Val Accuracy 0.4953271028037383\n",
      "Epoch 5166 Loss 1.00 | Train Accuracy 0.5040642145905304 | Val Accuracy 0.48963835839089803\n",
      "Epoch 5167 Loss 1.00 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5168 Loss 1.00 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.49329540837058106\n",
      "Epoch 5169 Loss 1.00 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.4904510361641609\n",
      "Epoch 5170 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4973587972368956\n",
      "Epoch 5171 Loss 1.00 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.4937017472572125\n",
      "Epoch 5172 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4900446972775295\n",
      "Epoch 5173 Loss 1.00 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49451442503047544\n",
      "Epoch 5174 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.49410808614384394\n",
      "Epoch 5175 Loss 1.00 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.497765136123527\n",
      "Epoch 5176 Loss 1.00 | Train Accuracy 0.5031497663076611 | Val Accuracy 0.4924827305973182\n",
      "Epoch 5177 Loss 1.00 | Train Accuracy 0.5033529770371875 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5178 Loss 1.00 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5179 Loss 1.00 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.4924827305973182\n",
      "Epoch 5180 Loss 1.00 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49451442503047544\n",
      "Epoch 5181 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.48679398618447783\n",
      "Epoch 5182 Loss 1.01 | Train Accuracy 0.494919731761837 | Val Accuracy 0.4928890694839496\n",
      "Epoch 5183 Loss 1.01 | Train Accuracy 0.49685023369233894 | Val Accuracy 0.49085737505079235\n",
      "Epoch 5184 Loss 1.01 | Train Accuracy 0.49624060150375937 | Val Accuracy 0.49207639171068673\n",
      "Epoch 5185 Loss 1.01 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.48923201950426654\n",
      "Epoch 5186 Loss 1.01 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4863876472978464\n",
      "Epoch 5187 Loss 1.01 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4904510361641609\n",
      "Epoch 5188 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.48963835839089803\n",
      "Epoch 5189 Loss 1.01 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4973587972368956\n",
      "Epoch 5190 Loss 1.01 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49573344169036976\n",
      "Epoch 5191 Loss 1.01 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.4973587972368956\n",
      "Epoch 5192 Loss 1.01 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49451442503047544\n",
      "Epoch 5193 Loss 1.01 | Train Accuracy 0.5049786628733998 | Val Accuracy 0.49451442503047544\n",
      "Epoch 5194 Loss 1.01 | Train Accuracy 0.5035561877667141 | Val Accuracy 0.4900446972775295\n",
      "Epoch 5195 Loss 1.01 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4912637139374238\n",
      "Epoch 5196 Loss 1.01 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.4924827305973182\n",
      "Epoch 5197 Loss 1.01 | Train Accuracy 0.5036577931314773 | Val Accuracy 0.49573344169036976\n",
      "Epoch 5198 Loss 1.01 | Train Accuracy 0.5041658199552936 | Val Accuracy 0.49695245835026414\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "torch.set_flush_denormal(True)\n",
    "N_EPOCHS = 10000 # + 100\n",
    "net.train()\n",
    "criterion = nn.CrossEntropyLoss() # loss\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.005, weight_decay=5e-2)\n",
    "\n",
    "train_accuracies = [1.0]\n",
    "val_accuracies = [1.0]\n",
    "val_check = 1\n",
    "best_state, best_val = None, 0.0\n",
    "for epoch in range(N_EPOCHS):  # loop over the dataset multiple times\n",
    "    # Iterate over batches and perform SGD step.\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net(x_train)\n",
    "    loss = criterion(y_pred, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_acc, val_acc = accuracy_score(torch.argmax(y_pred, axis=1), torch.argmax(Y_train, axis=1)), val_accuracies[-1]\n",
    "    if(epoch % val_check == 0):\n",
    "        hat_y_val = net(x_valid)\n",
    "        #val_loss = criterion(hat_y_val, y_val)\n",
    "        val_acc = accuracy_score(torch.argmax(hat_y_val, axis=1), torch.argmax(Y_valid, axis=1))\n",
    "        if(val_acc > best_val):\n",
    "            best_val = val_acc\n",
    "            best_state = copy.deepcopy(net.state_dict())\n",
    "\n",
    "    val_accuracies.append(val_acc)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(f\"Epoch {epoch} Loss {loss.detach().cpu().numpy():.2f} | Train Accuracy {train_acc} | Val Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('bc1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bc1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bc1.running_mean', tensor([4.3127, 3.8142, 4.5145, 4.1650, 4.0310, 3.8391, 3.6512, 4.3655, 4.4977,\n",
      "        4.8130, 4.8084, 3.7348, 4.1707, 4.7308, 3.7663, 6.6849, 4.9655, 4.4066,\n",
      "        3.4827, 3.9846, 4.1583, 4.5667, 4.7229, 3.9060, 3.4319, 4.0530, 3.7421,\n",
      "        3.6611, 3.3647, 3.2946, 4.0803, 4.0839, 4.0596, 4.0257, 4.2763, 4.4196,\n",
      "        3.4702, 3.8874, 3.9460, 3.5594, 6.1130, 4.1858, 3.8524, 3.4421, 3.7260,\n",
      "        3.9196, 4.2590, 4.4952, 3.9870, 3.6484, 4.0034, 3.8297, 3.4501, 3.6179,\n",
      "        3.6606, 3.7400, 3.8054, 4.2066, 4.5206, 4.1222, 4.1338, 4.3875, 3.6781,\n",
      "        3.9866, 4.5376, 3.9405, 3.6440, 3.8830, 3.0501, 3.7342, 3.7903, 3.3948,\n",
      "        4.0503, 3.8587, 3.6098, 3.3781, 3.3258, 3.9142, 4.0559, 4.1363, 4.3496,\n",
      "        2.4663, 3.6894, 4.0994, 2.7569, 6.5624, 4.0029, 3.9040, 3.0512, 3.7979,\n",
      "        4.1250, 3.9151, 4.3522, 3.7818, 3.3711, 4.0278, 3.8353, 3.5882, 3.3564,\n",
      "        3.3156, 4.2014, 3.8913, 4.0328, 4.2388, 4.1299, 4.3040, 2.4656, 3.6355,\n",
      "        4.0801, 2.7563, 6.4939, 4.0403, 3.8833, 3.1131, 3.7449, 4.1229, 3.9150,\n",
      "        4.3500, 3.5557, 3.3399, 3.8066, 3.7664, 3.3211, 3.4202, 3.4081, 3.2808,\n",
      "        3.4773, 3.8021, 4.2609, 3.7644, 3.9681, 2.9197, 3.3056, 3.9097, 3.5277,\n",
      "        3.2702, 3.2347, 3.6700, 2.8147, 3.6176, 4.3686, 3.8601, 4.5755, 4.2199,\n",
      "        4.0627, 3.8412, 3.6522, 4.3376, 4.5482, 4.8230, 4.7489, 3.6901, 4.1790,\n",
      "        4.7656, 3.8121, 6.7284, 4.8965, 4.4870, 3.4456, 4.0137, 4.2008, 4.5700,\n",
      "        4.6746, 3.9705, 3.4695, 4.1127, 3.8067, 3.6973, 3.3705, 3.2935, 4.0976,\n",
      "        4.0397, 4.1093, 4.0369, 4.2657, 4.3548, 3.4254, 3.8903, 3.9788, 3.6081,\n",
      "        6.1541, 4.0935, 3.9257, 3.4109, 3.7589, 3.9679, 4.2664, 4.4491, 4.0077,\n",
      "        3.6805, 4.0223, 3.8620, 3.4681, 3.6376, 3.6965, 3.7588, 3.8145, 4.2446,\n",
      "        4.5483, 4.1087, 4.1005, 4.3624, 3.6997, 4.0262, 4.5784, 3.8946, 3.6893,\n",
      "        3.9329, 3.0397, 3.7517, 3.9476, 3.5356, 4.1783, 4.0439, 3.7097, 3.4174,\n",
      "        3.3689, 3.8036, 4.2100, 4.1255, 4.2182, 2.3260, 3.7037, 4.2048, 2.8972,\n",
      "        6.6320, 3.9257, 4.0916, 3.0076, 3.9484, 4.3122, 3.8581, 4.2005, 3.9401,\n",
      "        3.5071, 4.1554, 4.0198, 3.6869, 3.3975, 3.3534, 4.2439, 3.7747, 4.1881,\n",
      "        4.3134, 4.1123, 4.1755, 2.3253, 3.6467, 4.1857, 2.8969, 6.5645, 3.9744,\n",
      "        4.0716, 3.0767, 3.8981, 4.3095, 3.8580, 4.1983, 3.5984, 3.3841, 3.8128,\n",
      "        3.8486, 3.3544, 3.4842, 3.4838, 3.3080, 3.4503, 3.8550, 4.2798, 3.7403,\n",
      "        3.8730, 2.7936, 3.3195, 3.9301, 3.6942, 3.2025, 3.2486, 3.7420, 2.8189,\n",
      "        3.6972])), ('bc1.running_var', tensor([ 8.4745,  9.4395,  7.8447,  8.1238,  9.2344,  9.4517,  9.1968,  8.9583,\n",
      "         7.8418,  9.0963,  7.9124, 10.1655,  9.1178,  7.7517,  8.7165,  8.7004,\n",
      "         8.8692,  8.1039,  9.6466,  8.0926,  8.4318,  8.3774,  8.5222,  7.9295,\n",
      "         8.7146,  7.5986,  7.6815,  8.5592,  8.7469,  8.7058,  9.3846,  8.4668,\n",
      "         7.4546,  7.9579,  8.5584,  7.5168,  9.3387,  8.5420,  7.5060,  8.2072,\n",
      "         9.7933,  7.7441,  7.6799,  9.0723,  7.7564,  7.9986,  7.8064,  8.0874,\n",
      "         8.2888,  8.4700,  7.7008,  7.4684,  8.3373,  8.6798,  8.6036,  8.5820,\n",
      "         8.1855,  7.7645,  7.7014,  8.6399,  7.6234,  9.6752,  8.3985,  7.6739,\n",
      "         8.0223,  9.3417,  8.3874,  7.8838,  8.9912,  7.7601,  8.3268,  8.4415,\n",
      "         7.8169,  7.6954,  8.6615,  8.6806,  8.5407,  8.7393,  7.6160,  8.5605,\n",
      "         8.0087, 12.4677,  8.5464,  7.6887, 10.6609, 11.2675,  8.8666,  7.6025,\n",
      "         9.2682,  7.8496,  8.8974,  9.6455,  8.8880,  8.2649,  8.4527,  7.8262,\n",
      "         7.7136,  8.6433,  8.6282,  8.5601,  9.4000,  8.7060,  7.6330,  7.8740,\n",
      "         8.5379,  8.0741, 12.4423,  8.4882,  7.6787, 10.6477, 11.5241,  8.6761,\n",
      "         7.5965,  9.1975,  7.9030,  8.8957,  9.6453,  8.8873,  8.3237,  8.5479,\n",
      "         7.7553,  7.7343,  8.4728,  8.5302,  8.4418,  8.4624,  8.3557,  7.7116,\n",
      "         7.9641,  8.5136,  8.2069, 14.6753,  8.3177,  7.9610, 13.3701, 11.1247,\n",
      "         8.7607,  7.6355,  8.5549,  8.1215,  8.5055,  9.4445,  7.7932,  8.2164,\n",
      "         9.3163,  9.4485,  9.1774,  9.0281,  7.9978,  9.1712,  8.0290,  9.9998,\n",
      "         9.1818,  7.6843,  8.8068,  8.8173,  8.9741,  8.1104,  9.6012,  8.0878,\n",
      "         8.3990,  8.3184,  8.4901,  8.0658,  8.7613,  7.6431,  7.8203,  8.5679,\n",
      "         8.6473,  8.5759,  9.3545,  8.4405,  7.7029,  7.9126,  8.6301,  7.6804,\n",
      "         9.1509,  8.7067,  7.4656,  8.3121,  9.8576,  7.7395,  7.7314,  9.1167,\n",
      "         7.8095,  8.0440,  7.7897,  8.0579,  8.4776,  8.5207,  7.8854,  7.5061,\n",
      "         8.4067,  8.8236,  8.6938,  8.6181,  8.3423,  7.7156,  7.7295,  8.7719,\n",
      "         7.6497,  9.6709,  8.4982,  7.7672,  8.0907,  9.3638,  8.3997,  7.8684,\n",
      "         9.1498,  7.6272,  8.6328,  8.7063,  8.1240,  8.0388,  8.9091,  8.6325,\n",
      "         8.5352,  8.4688,  7.8841,  8.5492,  8.0004, 11.6742,  8.6029,  7.7200,\n",
      "        10.9841, 11.1181,  8.9625,  7.8510,  9.2307,  8.0486,  9.0659,  9.6450,\n",
      "         8.6878,  8.5809,  8.6807,  8.1334,  8.0606,  8.9040,  8.5701,  8.5108,\n",
      "         9.4390,  8.3890,  7.9063,  7.7869,  8.5268,  8.0751, 11.6529,  8.5768,\n",
      "         7.7150, 10.9683, 11.3748,  8.7885,  7.8512,  9.1944,  8.1256,  9.0649,\n",
      "         9.6449,  8.6865,  8.4659,  8.7372,  7.8863,  7.9394,  8.5935,  8.8346,\n",
      "         8.8117,  8.4302,  8.2850,  7.7796,  8.2338,  8.7414,  7.9715, 14.1667,\n",
      "         8.3873,  7.9269, 13.5970, 11.0845,  8.8564,  7.9076,  8.7130,  8.1275])), ('bc1.num_batches_tracked', tensor(4902)), ('bc2.weight', tensor([ 3.3668e-10,  3.0463e-09,  2.9181e-02, -3.3760e-08, -1.6518e-12,\n",
      "        -4.4925e-08,  2.0130e-06, -6.2101e-08, -1.0012e-07,  7.9468e-01,\n",
      "        -8.5207e-11,  1.5976e-06,  8.5817e-04, -9.8671e-08, -1.3239e-10,\n",
      "         2.5716e-09,  2.3078e-06,  1.1654e-02, -5.1449e-08,  9.3123e-10,\n",
      "         2.7558e-02, -4.9923e-05,  2.3221e-06,  3.7875e-09,  1.3396e-09,\n",
      "         7.6444e-07,  1.2480e-03,  1.0446e-09, -9.7587e-08, -1.3732e-10,\n",
      "         5.0579e-07, -1.0997e-10, -6.5228e-08,  1.0505e-03,  2.3934e-06,\n",
      "        -4.7203e-09,  3.2958e-09,  3.8227e-02, -7.0325e-08,  7.5730e-07,\n",
      "        -6.6756e-08,  7.2637e-09, -5.0039e-05, -3.7511e-05,  2.4536e-03,\n",
      "        -4.9041e-08, -8.9121e-08,  5.1373e-07,  1.9242e-07,  1.6655e-09,\n",
      "         3.9262e-09,  3.2993e-09, -3.0130e-08, -2.8426e-08, -4.2758e-05,\n",
      "         4.4778e-04,  2.3383e-07,  2.1749e-06, -1.8542e-08,  5.1351e-04,\n",
      "        -1.0218e-07, -6.7834e-08, -9.6178e-08, -2.1018e-08])), ('bc2.bias', tensor([ 7.7779e-12,  2.4987e-11,  2.0456e-03, -1.3713e-11, -2.7606e-15,\n",
      "        -3.6939e-10, -2.3972e-10, -1.9040e-10, -2.1439e-09,  5.9026e-02,\n",
      "        -2.4948e-12,  8.4312e-09,  4.0310e-05, -4.2979e-10,  1.5821e-12,\n",
      "         4.9049e-11, -3.3589e-08,  7.7243e-04, -1.3113e-09,  1.4827e-11,\n",
      "         1.8645e-03, -7.4625e-07, -3.6672e-08, -2.4756e-11,  1.7928e-11,\n",
      "         9.3254e-09, -6.3674e-05, -2.3565e-11,  8.9801e-11,  1.7933e-12,\n",
      "        -4.9803e-09,  2.3569e-12, -1.7245e-10, -4.4288e-05,  3.9981e-08,\n",
      "        -1.0097e-10, -4.8265e-11, -2.7356e-03, -9.2376e-10, -5.0737e-09,\n",
      "        -5.1117e-10, -1.1313e-09, -3.5615e-07, -1.9796e-06, -1.4335e-04,\n",
      "         6.4638e-10,  3.9666e-10,  8.9730e-10,  1.7720e-09, -1.2729e-11,\n",
      "        -3.7168e-11,  5.6792e-12, -2.9416e-10,  1.1356e-10,  8.1996e-07,\n",
      "         1.3145e-05,  8.9268e-10, -6.5826e-09,  3.3888e-10,  1.1744e-05,\n",
      "         1.9722e-09,  7.5483e-10,  2.0990e-09,  1.8781e-10])), ('bc2.running_mean', tensor([-2.7186e-09, -7.4640e-14,  3.6835e-10,  2.2924e-15,  2.2317e-21,\n",
      "         7.7050e-17,  2.3359e-14,  1.3541e-15, -4.5708e-07,  1.0520e-09,\n",
      "        -1.9913e-17,  1.3913e-07,  1.5635e-11,  2.5725e-15,  5.5183e-19,\n",
      "        -2.6036e-16, -2.4225e-07, -1.0691e-09, -1.1738e-16,  4.8369e-18,\n",
      "        -5.1197e-09, -1.2132e-12, -8.3045e-14, -2.1484e-16, -5.9067e-17,\n",
      "        -1.1268e-05, -5.0159e-11,  1.7250e-16,  5.1399e-07,  2.6874e-08,\n",
      "        -3.5629e-14,  7.9341e-07, -1.2278e-15,  5.1269e-11, -1.0054e-13,\n",
      "        -1.8100e-16,  1.6913e-16, -1.9729e-06, -7.7021e-15,  3.6599e-14,\n",
      "         1.9117e-15,  8.3873e-15, -3.3458e-12, -1.7818e-12, -9.2569e-08,\n",
      "         2.9677e-16, -2.7490e-15, -5.2090e-15, -2.3126e-14, -1.2036e-16,\n",
      "         7.0571e-17, -1.5274e-16,  1.0797e-15, -8.1118e-17, -2.6734e-13,\n",
      "         7.3455e-12, -2.2628e-15, -7.1159e-14, -2.3555e-16,  3.4451e-11,\n",
      "        -1.2531e-15,  8.4871e-15,  1.5761e-15,  5.2203e-16])), ('bc2.running_var', tensor([1.6394e-19, 3.0108e-18, 3.7024e-04, 3.1809e-16, 4.2077e-23, 4.1748e-16,\n",
      "        2.1359e-12, 6.7807e-16, 3.9111e-15, 4.0906e-02, 2.2809e-20, 1.3299e-12,\n",
      "        6.5331e-06, 5.7489e-15, 6.3364e-21, 2.3172e-17, 3.7570e-12, 1.2204e-04,\n",
      "        1.8097e-14, 4.0713e-19, 3.4822e-04, 1.4142e-08, 1.2540e-11, 1.0506e-17,\n",
      "        5.4440e-19, 2.3450e-13, 1.1718e-05, 3.9540e-17, 2.9101e-15, 8.9145e-21,\n",
      "        1.5642e-13, 1.3177e-20, 7.8189e-16, 9.1007e-06, 7.5124e-12, 5.9575e-17,\n",
      "        3.2428e-18, 6.4484e-04, 1.2523e-14, 2.3363e-13, 7.7681e-16, 3.4874e-14,\n",
      "        1.3532e-08, 2.3688e-08, 2.7230e-05, 4.7665e-16, 1.8753e-15, 1.6985e-13,\n",
      "        6.2070e-14, 9.2219e-19, 7.3934e-18, 1.8316e-17, 2.6382e-16, 2.1713e-16,\n",
      "        2.1497e-08, 1.7907e-06, 6.8023e-14, 2.6355e-12, 1.6557e-16, 2.4534e-06,\n",
      "        3.6347e-15, 1.7667e-14, 7.6645e-15, 1.8390e-16])), ('bc2.num_batches_tracked', tensor(4902)), ('att1.in_proj_weight', tensor([[-2.8488e-42, -7.0051e-42, -6.5174e-42,  ...,  9.4167e-43,\n",
      "         -2.3723e-41, -2.4537e-42],\n",
      "        [-2.5841e-41, -1.8536e-41, -1.1168e-42,  ...,  1.1294e-42,\n",
      "         -2.2371e-40,  9.9352e-43],\n",
      "        [-1.5458e-41, -8.4919e-43,  9.3873e-42,  ..., -1.3116e-42,\n",
      "          1.8534e-41, -5.6739e-42],\n",
      "        ...,\n",
      "        [-8.1382e-13,  2.1276e-12, -4.4047e-04,  ...,  2.7758e-10,\n",
      "          1.2228e-10,  1.3471e-11],\n",
      "        [ 1.6746e-14, -1.0643e-13, -9.0585e-05,  ...,  4.6806e-11,\n",
      "          1.1268e-11,  1.5009e-11],\n",
      "        [ 3.1240e-13, -1.9287e-13,  2.2800e-04,  ...,  5.5688e-11,\n",
      "          4.7651e-11, -1.5461e-12]])), ('att1.in_proj_bias', tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4580e-03,  8.3558e-05,\n",
      "         2.6503e-04,  3.1196e-02,  4.7484e-03,  4.5059e-04,  8.0451e-05,\n",
      "         1.4453e-03, -4.5493e-04, -7.2773e-04,  1.1892e-03,  1.0370e-05,\n",
      "         3.6509e-05, -9.0788e-03, -1.9770e-02,  2.4641e-03,  1.2031e-02,\n",
      "        -1.0377e-02, -7.9305e-05, -1.1629e-03,  7.3450e-04, -2.3000e-02,\n",
      "         2.5477e-03, -1.5079e-04,  4.2085e-04, -4.4575e-04, -2.4526e-03,\n",
      "         7.1519e-03, -3.3593e-03, -1.5076e-02,  7.1670e-04,  7.9488e-04,\n",
      "        -5.8858e-04, -3.9981e-04,  3.3330e-03, -1.4841e-03,  1.1251e-02,\n",
      "        -9.4833e-03, -1.6927e-03, -1.4393e-02,  7.2912e-05,  7.5076e-04,\n",
      "         1.6217e-04,  3.4576e-03, -1.7003e-02, -4.3644e-03, -3.9041e-03,\n",
      "        -3.5274e-06, -6.5489e-03, -2.4299e-03, -5.6894e-04,  1.2626e-04,\n",
      "         2.7271e-04,  6.9506e-03, -6.5029e-05, -9.6176e-04, -6.6155e-05,\n",
      "         6.7427e-04,  6.5479e-05,  3.7714e-02,  2.0690e-02, -1.1201e-03,\n",
      "        -2.4070e-04,  6.0209e-04])), ('att1.out_proj.weight', tensor([[-2.3888e-03, -3.1940e-05, -9.4858e-05,  ...,  4.2159e-04,\n",
      "          8.0615e-05, -2.2201e-04],\n",
      "        [-6.9856e-03, -7.5441e-05, -2.5090e-04,  ...,  1.1196e-03,\n",
      "          2.4210e-04, -5.8775e-04],\n",
      "        [ 6.6817e-04,  7.5510e-06,  2.3245e-05,  ..., -1.0634e-04,\n",
      "         -2.2997e-05,  5.4756e-05],\n",
      "        ...,\n",
      "        [ 1.4886e-02,  1.7164e-04,  5.2616e-04,  ..., -2.4155e-03,\n",
      "         -5.0667e-04,  1.2889e-03],\n",
      "        [-1.0929e-02, -1.2436e-04, -3.5641e-04,  ...,  1.7176e-03,\n",
      "          3.6474e-04, -9.2029e-04],\n",
      "        [ 1.2477e-02,  1.4242e-04,  4.4861e-04,  ..., -1.9639e-03,\n",
      "         -4.2414e-04,  1.0558e-03]])), ('att1.out_proj.bias', tensor([-2.9475e-03, -7.8713e-03,  8.0026e-04,  4.0468e-05,  3.5492e-04,\n",
      "        -1.5535e-03,  2.7021e-03,  5.3504e-03,  1.5293e-02,  5.2201e-03,\n",
      "         1.1886e-02, -8.7207e-03,  6.3219e-04, -9.4126e-03,  2.0894e-02,\n",
      "        -1.1582e-02, -7.2427e-03,  1.5165e-02,  1.4601e-02,  3.1554e-03,\n",
      "         1.3757e-02,  6.1070e-03, -2.3139e-02, -1.2018e-02,  1.6612e-02,\n",
      "         5.6174e-03,  3.3447e-03,  1.0952e-02, -1.8242e-02, -1.0170e-03,\n",
      "         1.5274e-02,  6.8759e-03,  3.1431e-03, -3.6245e-04,  1.2025e-02,\n",
      "         1.0299e-02, -5.2351e-03,  2.5698e-02,  6.9499e-03, -2.0087e-02,\n",
      "         1.4608e-02, -6.5927e-03, -1.3894e-02,  6.7711e-03,  1.0313e-02,\n",
      "         2.9214e-03,  7.4389e-03, -6.9758e-03,  1.8135e-02, -1.4728e-02,\n",
      "        -1.8811e-04, -3.4823e-03,  4.9762e-03, -1.9313e-03, -1.1222e-02,\n",
      "         4.3976e-03, -1.7345e-02, -7.8959e-04,  2.8672e-03, -3.3188e-03,\n",
      "        -2.6164e-02,  1.6946e-02, -1.2781e-02,  1.4064e-02])), ('fc1.weight', tensor([[-3.3991e-11,  1.0820e-12,  1.1216e-11,  ...,  3.3634e-12,\n",
      "         -2.3002e-14, -1.3321e-11],\n",
      "        [-7.3234e-11, -1.4285e-10,  7.1925e-11,  ..., -2.3657e-12,\n",
      "          4.3662e-14,  2.3734e-11],\n",
      "        [ 4.0008e-04,  2.7561e-04,  5.1899e-04,  ..., -3.6358e-04,\n",
      "          2.1255e-04,  2.0958e-05],\n",
      "        ...,\n",
      "        [-1.0109e-08, -8.4058e-09, -2.0538e-10,  ..., -5.1334e-10,\n",
      "         -4.5620e-10,  2.6022e-09],\n",
      "        [-7.1248e-09, -1.9005e-09,  1.6723e-09,  ..., -6.1863e-10,\n",
      "          6.2522e-11,  1.6225e-09],\n",
      "        [ 1.1790e-09,  1.1451e-09,  8.6955e-10,  ...,  2.2044e-10,\n",
      "          6.5390e-11,  2.3016e-10]])), ('fc1.bias', tensor([-2.4855e-08, -6.5099e-13, -2.4626e-09,  7.9315e-15,  4.0277e-19,\n",
      "         2.8363e-15, -3.5618e-13,  4.8604e-15, -6.0466e-06,  2.6301e-07,\n",
      "        -1.1020e-16,  1.2018e-06,  1.1969e-10,  1.3177e-14, -5.2383e-18,\n",
      "         5.6451e-16, -5.2012e-06, -6.4643e-10,  8.0959e-15,  1.5026e-17,\n",
      "        -7.8148e-09, -1.9704e-11,  4.2523e-15, -9.3633e-16,  6.5257e-17,\n",
      "        -2.0274e-05, -1.0468e-12, -3.8465e-16,  5.4682e-06,  2.6965e-07,\n",
      "        -3.0037e-13,  8.6614e-06, -2.5070e-15, -2.5098e-11, -5.1921e-13,\n",
      "        -1.5422e-15,  1.5410e-15, -1.7489e-05, -3.8879e-15,  3.5904e-13,\n",
      "         9.9018e-15, -2.9046e-14, -5.1624e-12,  2.7688e-12, -8.9047e-07,\n",
      "         4.8321e-16, -8.6396e-15, -1.3676e-13, -7.5625e-14, -1.0216e-15,\n",
      "        -5.1277e-17, -2.7044e-15,  1.0254e-15,  8.2243e-16,  3.1396e-12,\n",
      "         5.8489e-11, -1.6923e-15, -1.4479e-13,  2.7465e-15, -3.1865e-11,\n",
      "        -2.1879e-14,  1.0648e-14,  1.7433e-14,  3.7040e-16])), ('fc3.weight', tensor([[-1.9357e-02, -5.2646e-02,  5.0562e-03,  2.1480e-04,  2.3616e-03,\n",
      "         -1.0605e-02,  1.8409e-02,  3.2525e-02,  1.0226e-01,  3.4737e-02,\n",
      "          7.8781e-02, -5.7544e-02,  4.1275e-03, -6.2930e-02,  1.4032e-01,\n",
      "         -7.8148e-02, -4.9667e-02,  1.0040e-01,  9.7642e-02,  2.1041e-02,\n",
      "          9.2497e-02,  4.1324e-02, -1.5251e-01, -7.8151e-02,  1.1125e-01,\n",
      "          3.7239e-02,  2.0714e-02,  7.3407e-02, -1.2263e-01, -6.8343e-03,\n",
      "          9.9974e-02,  4.6879e-02,  2.1018e-02, -2.3936e-03,  8.0539e-02,\n",
      "          6.7820e-02, -3.4458e-02,  1.7195e-01,  4.5959e-02, -1.3225e-01,\n",
      "          9.4459e-02, -4.3013e-02, -9.1778e-02,  4.5684e-02,  6.6762e-02,\n",
      "          1.6357e-02,  5.0292e-02, -4.6697e-02,  1.2115e-01, -9.6688e-02,\n",
      "         -1.1212e-03, -2.2901e-02,  3.3400e-02, -1.3005e-02, -7.4928e-02,\n",
      "          2.6215e-02, -1.1470e-01, -5.0275e-03,  1.9150e-02, -2.1720e-02,\n",
      "         -1.7386e-01,  1.1391e-01, -8.2869e-02,  9.4734e-02],\n",
      "        [ 2.1820e-03,  5.7475e-03, -4.4724e-04, -1.5160e-05, -2.6964e-04,\n",
      "          1.1715e-03, -2.0046e-03, -3.7210e-03, -1.1407e-02, -3.9119e-03,\n",
      "         -9.0775e-03,  6.5140e-03, -4.7222e-04,  7.0919e-03, -1.5183e-02,\n",
      "          8.7231e-03,  5.5522e-03, -1.0763e-02, -1.1138e-02, -2.4210e-03,\n",
      "         -1.0555e-02, -4.7552e-03,  1.6331e-02,  8.9219e-03, -1.2279e-02,\n",
      "         -4.3200e-03, -2.3306e-03, -8.1182e-03,  1.3924e-02,  7.2035e-04,\n",
      "         -1.1486e-02, -5.4425e-03, -2.4323e-03,  2.7291e-04, -9.2011e-03,\n",
      "         -7.8436e-03,  3.8113e-03, -1.8517e-02, -5.1437e-03,  1.4391e-02,\n",
      "         -1.0810e-02,  4.5946e-03,  1.0010e-02, -5.3052e-03, -7.5629e-03,\n",
      "         -1.8158e-03, -5.8236e-03,  5.1594e-03, -1.2997e-02,  1.0722e-02,\n",
      "          9.7469e-05,  2.6177e-03, -3.8737e-03,  1.4378e-03,  8.5426e-03,\n",
      "         -2.9614e-03,  1.2471e-02,  5.1317e-04, -2.2157e-03,  2.5130e-03,\n",
      "          1.8442e-02, -1.2923e-02,  9.5159e-03, -1.0535e-02],\n",
      "        [ 1.7120e-02,  4.7124e-02, -4.5950e-03, -1.9984e-04, -2.0708e-03,\n",
      "          9.4265e-03, -1.6326e-02, -2.8827e-02, -9.1487e-02, -3.0774e-02,\n",
      "         -6.9663e-02,  5.0918e-02, -3.6628e-03,  5.5781e-02, -1.2509e-01,\n",
      "          6.9038e-02,  4.3954e-02, -8.9422e-02, -8.6490e-02, -1.8885e-02,\n",
      "         -8.1897e-02, -3.6492e-02,  1.3624e-01,  6.9155e-02, -9.8944e-02,\n",
      "         -3.2930e-02, -1.8320e-02, -6.5619e-02,  1.0900e-01,  6.1017e-03,\n",
      "         -8.9124e-02, -4.1763e-02, -1.8605e-02,  2.1507e-03, -7.1393e-02,\n",
      "         -6.0141e-02,  3.0516e-02, -1.5345e-01, -4.0648e-02,  1.1812e-01,\n",
      "         -8.3808e-02,  3.8267e-02,  8.1920e-02, -4.0374e-02, -5.9304e-02,\n",
      "         -1.4508e-02, -4.4415e-02,  4.1776e-02, -1.0796e-01,  8.5948e-02,\n",
      "          1.0272e-03,  2.0252e-02, -2.9523e-02,  1.1546e-02,  6.6298e-02,\n",
      "         -2.3192e-02,  1.0236e-01,  4.4927e-03, -1.6924e-02,  1.9330e-02,\n",
      "          1.5534e-01, -1.0124e-01,  7.3503e-02, -8.3928e-02]])), ('fc3.bias', tensor([ 0.1473, -0.1587,  0.0099]))])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(len(train_accuracies[1:])), train_accuracies[1:], label = \"train\")\n",
    "plt.plot(np.arange(len(train_accuracies[1:])), val_accuracies[1:], label = \"val\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0.44, 0.57)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(train_accuracies[1:])), np.minimum(val_accuracies[1:], train_accuracies[1:]), label = \"train\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0.44, 0.57)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(val_accuracies)\n",
    "#print(train_accuracies)\n",
    "torch.save(best_state, \"MCT_params_best2\")\n",
    "#torch.save(net.state_dict(), \"MCT_params_last\")\n",
    "#net = MatchClassifier(3,4,302,278,300)\n",
    "#net.load_state_dict(torch.load(\"MC1_params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5030475416497359\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#print(val_accuracies)\n",
    "#print(train_accuracies)\n",
    "#torch.save(net.state_dict(), \"MC1_params\")\n",
    "net = MatchTeamClassifier(3,280,(512,64))\n",
    "net.load_state_dict(torch.load(\"MCT_params_best\"))\n",
    "\n",
    "hat_y_val = torch.argmax(net(x_valid), axis=1)\n",
    "y_val = torch.argmax(Y_valid, axis=1)\n",
    "#print(confusion_matrix(y_val, hat_y_val, normalize=\"pred\"))\n",
    "#print(np.unique(torch.argmax(Y_valid, axis=1), return_counts=True))\n",
    "print(accuracy_score(y_val, hat_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player data\n",
    "To ameliorate the performance, we take the player individual data into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_player_statistics_df = pd.read_csv('./train_home_player_statistics_df.csv', index_col=0)\n",
    "train_away_player_statistics_df = pd.read_csv('./train_away_player_statistics_df.csv', index_col=0)\n",
    "train_home_team_statistics_df = pd.read_csv('./train_home_team_statistics_df.csv', index_col=0)\n",
    "train_away_team_statistics_df = pd.read_csv('./train_away_team_statistics_df.csv', index_col=0)\n",
    "train_home_team_statistics_df.columns = 'HOME_' + train_home_team_statistics_df.columns\n",
    "train_away_team_statistics_df.columns = 'AWAY_' + train_away_team_statistics_df.columns\n",
    "\n",
    "\n",
    "train_scores = pd.read_csv('./Y_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PLAYER_CAPTAIN_5_last_match_average', 'PLAYER_CAPTAIN_5_last_match_std', 'PLAYER_CAPTAIN_season_average', 'PLAYER_CAPTAIN_season_std', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_average', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_std', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_sum', 'PLAYER_LONG_BALLS_5_last_match_average', 'PLAYER_LONG_BALLS_5_last_match_std', 'PLAYER_LONG_BALLS_5_last_match_sum', 'PLAYER_LONG_BALLS_WON_5_last_match_average', 'PLAYER_LONG_BALLS_WON_5_last_match_std', 'PLAYER_LONG_BALLS_WON_5_last_match_sum', 'PLAYER_LONG_BALLS_WON_season_average', 'PLAYER_LONG_BALLS_WON_season_std', 'PLAYER_LONG_BALLS_WON_season_sum', 'PLAYER_LONG_BALLS_season_average', 'PLAYER_LONG_BALLS_season_std', 'PLAYER_LONG_BALLS_season_sum', 'PLAYER_PENALTIES_SAVED_5_last_match_average', 'PLAYER_PENALTIES_SAVED_5_last_match_std', 'PLAYER_PENALTIES_SAVED_5_last_match_sum', 'PLAYER_PENALTIES_SAVED_season_average', 'PLAYER_PENALTIES_SAVED_season_std', 'PLAYER_PENALTIES_SAVED_season_sum', 'PLAYER_PENALTIES_WON_5_last_match_average', 'PLAYER_PENALTIES_WON_5_last_match_std', 'PLAYER_PENALTIES_WON_5_last_match_sum', 'PLAYER_PENALTIES_WON_season_average', 'PLAYER_PENALTIES_WON_season_std', 'PLAYER_PENALTIES_WON_season_sum', 'PLAYER_PUNCHES_5_last_match_average', 'PLAYER_PUNCHES_5_last_match_std', 'PLAYER_PUNCHES_5_last_match_sum', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_average', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_std', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_sum', 'PLAYER_SAVES_INSIDE_BOX_season_average', 'PLAYER_SAVES_INSIDE_BOX_season_std', 'PLAYER_SAVES_INSIDE_BOX_season_sum', 'PLAYER_SAVES_season_average', 'PLAYER_SAVES_season_sum', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_average', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_std', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_sum', 'PLAYER_SHOTS_OFF_TARGET_season_average', 'PLAYER_SHOTS_OFF_TARGET_season_std', 'PLAYER_SHOTS_OFF_TARGET_season_sum']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "lin_model_position = pickle.load(open(\"pos_model\", \"rb\"))\n",
    "encoding = [\"attacker\", \"defender\", \"goalkeeper\", \"midfielder\"]\n",
    "\n",
    "\n",
    "train_home_player_statistics_df.loc[train_home_player_statistics_df.isna()[\"POSITION\"],\"POSITION\"] = (np.array(encoding)[lin_model_position.predict(train_home_player_statistics_df.iloc[:,4:].replace({np.nan:0.0}))])[train_home_player_statistics_df.isna()[\"POSITION\"]]\n",
    "train_away_player_statistics_df.loc[train_away_player_statistics_df.isna()[\"POSITION\"],\"POSITION\"] = (np.array(encoding)[lin_model_position.predict(train_away_player_statistics_df.iloc[:,4:].replace({np.nan:0.0}))])[train_away_player_statistics_df.isna()[\"POSITION\"]]\n",
    "\n",
    "df = train_away_player_statistics_df.reset_index().groupby([\"POSITION\", \"ID\"], as_index=False).sum()\n",
    "gb_away = df.set_index(\"ID\").groupby(\"POSITION\")\n",
    "positions = [\"attacker\", \"goalkeeper\", \"midfielder\", \"defender\"]\n",
    "m1 = np.intersect1d(gb_away.get_group(positions[0]).index, gb_away.get_group(positions[1]).index)\n",
    "m2 = np.intersect1d(gb_away.get_group(positions[2]).index, gb_away.get_group(positions[3]).index)\n",
    "away_m = np.intersect1d(m1, m2)\n",
    "\n",
    "df = train_home_player_statistics_df.reset_index().groupby([\"POSITION\", \"ID\"], as_index=False).sum()\n",
    "gb_home = df.set_index(\"ID\").groupby(\"POSITION\")\n",
    "m1 = np.intersect1d(gb_home.get_group(positions[0]).index, gb_home.get_group(positions[1]).index)\n",
    "m2 = np.intersect1d(gb_home.get_group(positions[2]).index, gb_home.get_group(positions[3]).index)\n",
    "home_m = np.intersect1d(m1, m2)\n",
    "\n",
    "m = np.intersect1d(away_m, home_m)\n",
    "\n",
    "train_player_data = []\n",
    "useless_features = open(\"lines.txt\", \"r\").readlines()\n",
    "useless_features = [ft[:-1] for ft in useless_features]\n",
    "print(useless_features)\n",
    "for pos in positions:\n",
    "    df_home_pos = gb_home.get_group(pos).drop(useless_features, axis=1)\n",
    "    df_away_pos = gb_away.get_group(pos).drop(useless_features, axis=1)\n",
    "    df_home_pos.columns = 'HOME_' + df_home_pos.columns\n",
    "    df_away_pos.columns = 'AWAY_' + df_away_pos.columns\n",
    "    train_player_data.append(df_home_pos.iloc[:,1:].join(df_away_pos.iloc[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_player_data[0].columns = \"ATTACK_\" + train_player_data[0].columns\n",
    "train_player_data[1].columns = \"GOALKEEP_\" + train_player_data[1].columns\n",
    "train_player_data[2].columns = \"MIDFIELD_\" + train_player_data[2].columns\n",
    "train_player_data[3].columns = \"DEFEND_\" + train_player_data[3].columns\n",
    "\n",
    "X_train = train_home_team_statistics_df.iloc[m,2:].join(train_away_team_statistics_df.iloc[m,2:].join(train_player_data[0].loc[m,:].join(train_player_data[1].loc[m,:].join(train_player_data[2].loc[m,:].join(train_player_data[3].loc[m,:])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       HOME_TEAM_SHOTS_INSIDEBOX_season_sum  \\\n",
      "ID                                            \n",
      "0                                       2.0   \n",
      "1                                       8.0   \n",
      "2                                       2.0   \n",
      "3                                       5.0   \n",
      "4                                       3.0   \n",
      "...                                     ...   \n",
      "12296                                   0.0   \n",
      "12297                                   NaN   \n",
      "12299                                   2.0   \n",
      "12300                                   3.0   \n",
      "12302                                   3.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_TOTAL_5_last_match_sum  HOME_TEAM_GAME_LOST_season_sum  \\\n",
      "ID                                                                              \n",
      "0                                         4.0                            10.0   \n",
      "1                                         5.0                             1.0   \n",
      "2                                         5.0                             8.0   \n",
      "3                                         3.0                             0.0   \n",
      "4                                         3.0                             4.0   \n",
      "...                                       ...                             ...   \n",
      "12296                                     0.0                             4.0   \n",
      "12297                                     6.0                             4.0   \n",
      "12299                                     6.0                             6.0   \n",
      "12300                                     2.0                             8.0   \n",
      "12302                                     1.0                             3.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_INSIDEBOX_season_average  \\\n",
      "ID                                                \n",
      "0                                           2.0   \n",
      "1                                           7.0   \n",
      "2                                           2.0   \n",
      "3                                           5.0   \n",
      "4                                           3.0   \n",
      "...                                         ...   \n",
      "12296                                       0.0   \n",
      "12297                                       NaN   \n",
      "12299                                       2.0   \n",
      "12300                                       3.0   \n",
      "12302                                       2.0   \n",
      "\n",
      "       HOME_TEAM_GAME_WON_5_last_match_sum  \\\n",
      "ID                                           \n",
      "0                                      2.0   \n",
      "1                                      8.0   \n",
      "2                                      4.0   \n",
      "3                                      7.0   \n",
      "4                                      2.0   \n",
      "...                                    ...   \n",
      "12296                                  2.0   \n",
      "12297                                  2.0   \n",
      "12299                                  4.0   \n",
      "12300                                  0.0   \n",
      "12302                                  6.0   \n",
      "\n",
      "       AWAY_TEAM_SHOTS_TOTAL_5_last_match_average  \\\n",
      "ID                                                  \n",
      "0                                             2.0   \n",
      "1                                             3.0   \n",
      "2                                             7.0   \n",
      "3                                             7.0   \n",
      "4                                             6.0   \n",
      "...                                           ...   \n",
      "12296                                         2.0   \n",
      "12297                                         5.0   \n",
      "12299                                         1.0   \n",
      "12300                                         5.0   \n",
      "12302                                         4.0   \n",
      "\n",
      "       HOME_TEAM_GOALS_season_average  HOME_TEAM_PASSES_season_sum  \\\n",
      "ID                                                                   \n",
      "0                                 3.0                          2.0   \n",
      "1                                 9.0                          8.0   \n",
      "2                                 1.0                          1.0   \n",
      "3                                 5.0                          9.0   \n",
      "4                                 2.0                          4.0   \n",
      "...                               ...                          ...   \n",
      "12296                             5.0                          8.0   \n",
      "12297                             2.0                          NaN   \n",
      "12299                             0.0                          1.0   \n",
      "12300                             1.0                          1.0   \n",
      "12302                             4.0                          3.0   \n",
      "\n",
      "       AWAY_TEAM_SUCCESSFUL_PASSES_PERCENTAGE_season_average  \\\n",
      "ID                                                             \n",
      "0                                                    5.0       \n",
      "1                                                    5.0       \n",
      "2                                                    5.0       \n",
      "3                                                    5.0       \n",
      "4                                                    6.0       \n",
      "...                                                  ...       \n",
      "12296                                                7.0       \n",
      "12297                                                NaN       \n",
      "12299                                                6.0       \n",
      "12300                                                1.0       \n",
      "12302                                               10.0       \n",
      "\n",
      "       AWAY_TEAM_PASSES_season_average  ...  \\\n",
      "ID                                      ...   \n",
      "0                                  3.0  ...   \n",
      "1                                  4.0  ...   \n",
      "2                                  4.0  ...   \n",
      "3                                  4.0  ...   \n",
      "4                                  6.0  ...   \n",
      "...                                ...  ...   \n",
      "12296                              5.0  ...   \n",
      "12297                              NaN  ...   \n",
      "12299                              3.0  ...   \n",
      "12300                              3.0  ...   \n",
      "12302                             10.0  ...   \n",
      "\n",
      "       GOALKEEP_HOME_PLAYER_ASSISTS_5_last_match_sum  \\\n",
      "ID                                                     \n",
      "0                                                0.0   \n",
      "1                                                0.0   \n",
      "2                                                0.0   \n",
      "3                                                0.0   \n",
      "4                                                0.0   \n",
      "...                                              ...   \n",
      "12296                                            0.0   \n",
      "12297                                            0.0   \n",
      "12299                                            0.0   \n",
      "12300                                            0.0   \n",
      "12302                                            0.0   \n",
      "\n",
      "       DEFEND_HOME_PLAYER_ACCURATE_PASSES_PERCENTAGE_season_average  \\\n",
      "ID                                                                    \n",
      "0                                                  356.0              \n",
      "1                                                  443.0              \n",
      "2                                                  447.0              \n",
      "3                                                  201.0              \n",
      "4                                                  278.0              \n",
      "...                                                  ...              \n",
      "12296                                                0.0              \n",
      "12297                                                0.0              \n",
      "12299                                              286.0              \n",
      "12300                                              328.0              \n",
      "12302                                              438.0              \n",
      "\n",
      "       ATTACK_HOME_PLAYER_DUELS_LOST_5_last_match_average  \\\n",
      "ID                                                          \n",
      "0                                                  145.0    \n",
      "1                                                   81.0    \n",
      "2                                                   49.0    \n",
      "3                                                   56.0    \n",
      "4                                                  145.0    \n",
      "...                                                  ...    \n",
      "12296                                               94.0    \n",
      "12297                                                0.0    \n",
      "12299                                              117.0    \n",
      "12300                                              233.0    \n",
      "12302                                              137.0    \n",
      "\n",
      "       MIDFIELD_AWAY_PLAYER_ERROR_LEAD_TO_GOAL_5_last_match_sum  \\\n",
      "ID                                                                \n",
      "0                                                    0.0          \n",
      "1                                                    0.0          \n",
      "2                                                    0.0          \n",
      "3                                                    0.0          \n",
      "4                                                    0.0          \n",
      "...                                                  ...          \n",
      "12296                                                0.0          \n",
      "12297                                                0.0          \n",
      "12299                                                0.0          \n",
      "12300                                                0.0          \n",
      "12302                                                0.0          \n",
      "\n",
      "       MIDFIELD_HOME_PLAYER_BLOCKED_SHOTS_5_last_match_average  \\\n",
      "ID                                                               \n",
      "0                                                   36.0         \n",
      "1                                                   70.0         \n",
      "2                                                   44.0         \n",
      "3                                                   32.0         \n",
      "4                                                   77.0         \n",
      "...                                                  ...         \n",
      "12296                                               22.0         \n",
      "12297                                                0.0         \n",
      "12299                                               31.0         \n",
      "12300                                               99.0         \n",
      "12302                                               48.0         \n",
      "\n",
      "       ATTACK_AWAY_PLAYER_BIG_CHANCES_CREATED_5_last_match_sum  \\\n",
      "ID                                                               \n",
      "0                                                    0.0         \n",
      "1                                                   20.0         \n",
      "2                                                  100.0         \n",
      "3                                                    0.0         \n",
      "4                                                   80.0         \n",
      "...                                                  ...         \n",
      "12296                                               60.0         \n",
      "12297                                                0.0         \n",
      "12299                                               40.0         \n",
      "12300                                               80.0         \n",
      "12302                                              125.0         \n",
      "\n",
      "       MIDFIELD_HOME_PLAYER_GOALS_CONCEDED_season_average  \\\n",
      "ID                                                          \n",
      "0                                                  298.0    \n",
      "1                                                  177.0    \n",
      "2                                                  416.0    \n",
      "3                                                  188.0    \n",
      "4                                                  135.0    \n",
      "...                                                  ...    \n",
      "12296                                              123.0    \n",
      "12297                                              365.0    \n",
      "12299                                              134.0    \n",
      "12300                                              192.0    \n",
      "12302                                              190.0    \n",
      "\n",
      "       GOALKEEP_AWAY_PLAYER_SHOTS_ON_TARGET_5_last_match_std  \\\n",
      "ID                                                             \n",
      "0                                                    0.0       \n",
      "1                                                    0.0       \n",
      "2                                                    0.0       \n",
      "3                                                    0.0       \n",
      "4                                                    0.0       \n",
      "...                                                  ...       \n",
      "12296                                                0.0       \n",
      "12297                                                0.0       \n",
      "12299                                                0.0       \n",
      "12300                                                0.0       \n",
      "12302                                                0.0       \n",
      "\n",
      "       HOME_TEAM_BALL_SAFE_season_sum  MIDFIELD_AWAY_PLAYER_SAVES_season_std  \n",
      "ID                                                                            \n",
      "0                                 4.0                                    0.0  \n",
      "1                                 9.0                                    0.0  \n",
      "2                                 5.0                                    0.0  \n",
      "3                                 3.0                                    0.0  \n",
      "4                                 5.0                                    0.0  \n",
      "...                               ...                                    ...  \n",
      "12296                             9.0                                    0.0  \n",
      "12297                             8.0                                    0.0  \n",
      "12299                             0.0                                    0.0  \n",
      "12300                             6.0                                    0.0  \n",
      "12302                             3.0                                    0.0  \n",
      "\n",
      "[10624 rows x 512 columns]\n"
     ]
    }
   ],
   "source": [
    "select_fts = open(\"feature_selection.txt\", \"r\").readlines()\n",
    "select_fts = [ft[:-1] for ft in select_fts]\n",
    "X_train = X_train[select_fts]\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X_train, train_scores.loc[m,:], train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2125, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MatchTeamClassifier(3, 512, (256,))\n",
    "\n",
    "x_train = torch.Tensor(X_train.replace({np.nan:0.0}).values)\n",
    "x_valid = torch.Tensor(X_valid.replace({np.nan:0.0}).values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "Y_valid = torch.Tensor(y_valid.values)\n",
    "\n",
    "print(net(x_valid).shape)\n",
    "net.bc1.requires_grad_(False)\n",
    "torch.set_flush_denormal(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.4258823529411765\n",
      "Epoch 1 Loss 1.10 | Train Accuracy 0.4180491822567361 | Val Accuracy 0.45647058823529413\n",
      "Epoch 2 Loss 1.06 | Train Accuracy 0.4464054594658195 | Val Accuracy 0.4814117647058824\n",
      "Epoch 3 Loss 1.04 | Train Accuracy 0.4741734321684904 | Val Accuracy 0.4955294117647059\n",
      "Epoch 4 Loss 1.02 | Train Accuracy 0.48982233203906345 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5 Loss 1.02 | Train Accuracy 0.49676432521473113 | Val Accuracy 0.5134117647058823\n",
      "Epoch 6 Loss 1.02 | Train Accuracy 0.49641134251088365 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7 Loss 1.02 | Train Accuracy 0.4955877162019061 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8 Loss 1.02 | Train Accuracy 0.4952347334980586 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9 Loss 1.02 | Train Accuracy 0.4952347334980586 | Val Accuracy 0.5129411764705882\n",
      "Epoch 10 Loss 1.02 | Train Accuracy 0.4955877162019061 | Val Accuracy 0.5152941176470588\n",
      "Epoch 11 Loss 1.02 | Train Accuracy 0.4955877162019061 | Val Accuracy 0.5124705882352941\n",
      "Epoch 12 Loss 1.03 | Train Accuracy 0.4959406989057536 | Val Accuracy 0.5134117647058823\n",
      "Epoch 13 Loss 1.03 | Train Accuracy 0.4961760207083186 | Val Accuracy 0.5124705882352941\n",
      "Epoch 14 Loss 1.03 | Train Accuracy 0.4959406989057536 | Val Accuracy 0.5110588235294118\n",
      "Epoch 15 Loss 1.02 | Train Accuracy 0.4961760207083186 | Val Accuracy 0.5138823529411765\n",
      "Epoch 16 Loss 1.02 | Train Accuracy 0.49641134251088365 | Val Accuracy 0.5129411764705882\n",
      "Epoch 17 Loss 1.02 | Train Accuracy 0.49817625603012117 | Val Accuracy 0.5143529411764706\n",
      "Epoch 18 Loss 1.02 | Train Accuracy 0.4982939169314037 | Val Accuracy 0.516235294117647\n",
      "Epoch 19 Loss 1.02 | Train Accuracy 0.49747029062242615 | Val Accuracy 0.5157647058823529\n",
      "Epoch 20 Loss 1.02 | Train Accuracy 0.49758795152370866 | Val Accuracy 0.5148235294117647\n",
      "Epoch 21 Loss 1.02 | Train Accuracy 0.49817625603012117 | Val Accuracy 0.516235294117647\n",
      "Epoch 22 Loss 1.02 | Train Accuracy 0.49958818684551126 | Val Accuracy 0.516235294117647\n",
      "Epoch 23 Loss 1.02 | Train Accuracy 0.5002941522532063 | Val Accuracy 0.5171764705882353\n",
      "Epoch 24 Loss 1.01 | Train Accuracy 0.5005294740557713 | Val Accuracy 0.5176470588235295\n",
      "Epoch 25 Loss 1.01 | Train Accuracy 0.5005294740557713 | Val Accuracy 0.5176470588235295\n",
      "Epoch 26 Loss 1.01 | Train Accuracy 0.5010001176609012 | Val Accuracy 0.516235294117647\n",
      "Epoch 27 Loss 1.02 | Train Accuracy 0.5011177785621838 | Val Accuracy 0.5148235294117647\n",
      "Epoch 28 Loss 1.02 | Train Accuracy 0.5015884221673138 | Val Accuracy 0.5148235294117647\n",
      "Epoch 29 Loss 1.02 | Train Accuracy 0.5012354394634663 | Val Accuracy 0.5152941176470588\n",
      "Epoch 30 Loss 1.02 | Train Accuracy 0.5013531003647488 | Val Accuracy 0.5138823529411765\n",
      "Epoch 31 Loss 1.02 | Train Accuracy 0.5014707612660313 | Val Accuracy 0.5138823529411765\n",
      "Epoch 32 Loss 1.02 | Train Accuracy 0.5017060830685963 | Val Accuracy 0.5110588235294118\n",
      "Epoch 33 Loss 1.02 | Train Accuracy 0.5017060830685963 | Val Accuracy 0.5115294117647059\n",
      "Epoch 34 Loss 1.02 | Train Accuracy 0.5030003529827038 | Val Accuracy 0.5110588235294118\n",
      "Epoch 35 Loss 1.02 | Train Accuracy 0.5026473702788563 | Val Accuracy 0.5105882352941177\n",
      "Epoch 36 Loss 1.02 | Train Accuracy 0.5027650311801388 | Val Accuracy 0.5096470588235295\n",
      "Epoch 37 Loss 1.01 | Train Accuracy 0.5030003529827038 | Val Accuracy 0.5101176470588236\n",
      "Epoch 38 Loss 1.01 | Train Accuracy 0.5032356747852689 | Val Accuracy 0.5096470588235295\n",
      "Epoch 39 Loss 1.01 | Train Accuracy 0.5040593010942463 | Val Accuracy 0.5091764705882353\n",
      "Epoch 40 Loss 1.01 | Train Accuracy 0.5048829274032239 | Val Accuracy 0.512\n",
      "Epoch 41 Loss 1.01 | Train Accuracy 0.5054712319096364 | Val Accuracy 0.5124705882352941\n",
      "Epoch 42 Loss 1.01 | Train Accuracy 0.506059536416049 | Val Accuracy 0.5134117647058823\n",
      "Epoch 43 Loss 1.01 | Train Accuracy 0.506765501823744 | Val Accuracy 0.5134117647058823\n",
      "Epoch 44 Loss 1.01 | Train Accuracy 0.5070008236263089 | Val Accuracy 0.512\n",
      "Epoch 45 Loss 1.01 | Train Accuracy 0.5078244499352865 | Val Accuracy 0.5101176470588236\n",
      "Epoch 46 Loss 1.01 | Train Accuracy 0.5082950935404165 | Val Accuracy 0.508235294117647\n",
      "Epoch 47 Loss 1.01 | Train Accuracy 0.5092363807506766 | Val Accuracy 0.5063529411764706\n",
      "Epoch 48 Loss 1.01 | Train Accuracy 0.5097070243558066 | Val Accuracy 0.5063529411764706\n",
      "Epoch 49 Loss 1.01 | Train Accuracy 0.5092363807506766 | Val Accuracy 0.5021176470588236\n",
      "Epoch 50 Loss 1.01 | Train Accuracy 0.510060007059654 | Val Accuracy 0.49929411764705883\n",
      "Epoch 51 Loss 1.01 | Train Accuracy 0.5106483115660666 | Val Accuracy 0.4978823529411765\n",
      "Epoch 52 Loss 1.00 | Train Accuracy 0.5111189551711967 | Val Accuracy 0.4969411764705882\n",
      "Epoch 53 Loss 1.00 | Train Accuracy 0.5112366160724792 | Val Accuracy 0.49976470588235294\n",
      "Epoch 54 Loss 1.00 | Train Accuracy 0.5127662077891517 | Val Accuracy 0.49929411764705883\n",
      "Epoch 55 Loss 1.00 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5011764705882353\n",
      "Epoch 56 Loss 1.00 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.49929411764705883\n",
      "Epoch 57 Loss 1.00 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5002352941176471\n",
      "Epoch 58 Loss 1.00 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5011764705882353\n",
      "Epoch 59 Loss 1.00 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5035294117647059\n",
      "Epoch 60 Loss 1.00 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5058823529411764\n",
      "Epoch 61 Loss 1.00 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5058823529411764\n",
      "Epoch 62 Loss 1.00 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5007058823529412\n",
      "Epoch 63 Loss 1.00 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.49929411764705883\n",
      "Epoch 64 Loss 1.00 | Train Accuracy 0.5140604777032592 | Val Accuracy 0.49929411764705883\n",
      "Epoch 65 Loss 1.00 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.4950588235294118\n",
      "Epoch 66 Loss 1.00 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5021176470588236\n",
      "Epoch 67 Loss 1.00 | Train Accuracy 0.5120602423814566 | Val Accuracy 0.5025882352941177\n",
      "Epoch 68 Loss 1.00 | Train Accuracy 0.5131191904929991 | Val Accuracy 0.5016470588235294\n",
      "Epoch 69 Loss 1.00 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5058823529411764\n",
      "Epoch 70 Loss 1.00 | Train Accuracy 0.5134721731968467 | Val Accuracy 0.5021176470588236\n",
      "Epoch 71 Loss 1.00 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.49929411764705883\n",
      "Epoch 72 Loss 1.00 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.49976470588235294\n",
      "Epoch 73 Loss 1.00 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5021176470588236\n",
      "Epoch 74 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.49976470588235294\n",
      "Epoch 75 Loss 1.00 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 76 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5016470588235294\n",
      "Epoch 77 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5007058823529412\n",
      "Epoch 78 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.4988235294117647\n",
      "Epoch 79 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5011764705882353\n",
      "Epoch 80 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.4969411764705882\n",
      "Epoch 81 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5025882352941177\n",
      "Epoch 82 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5021176470588236\n",
      "Epoch 83 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.504\n",
      "Epoch 84 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5054117647058823\n",
      "Epoch 85 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5002352941176471\n",
      "Epoch 86 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5011764705882353\n",
      "Epoch 87 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5115294117647059\n",
      "Epoch 88 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5072941176470588\n",
      "Epoch 89 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5072941176470588\n",
      "Epoch 90 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5044705882352941\n",
      "Epoch 91 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 92 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5025882352941177\n",
      "Epoch 93 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5030588235294118\n",
      "Epoch 94 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 95 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.4988235294117647\n",
      "Epoch 96 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5096470588235295\n",
      "Epoch 97 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5072941176470588\n",
      "Epoch 98 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.4978823529411765\n",
      "Epoch 99 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.508235294117647\n",
      "Epoch 100 Loss 1.00 | Train Accuracy 0.5135898340981292 | Val Accuracy 0.508235294117647\n",
      "Epoch 101 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 102 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.508235294117647\n",
      "Epoch 103 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.508235294117647\n",
      "Epoch 104 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5002352941176471\n",
      "Epoch 105 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5011764705882353\n",
      "Epoch 106 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5091764705882353\n",
      "Epoch 107 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.508235294117647\n",
      "Epoch 108 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5054117647058823\n",
      "Epoch 109 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5091764705882353\n",
      "Epoch 110 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 111 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 112 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 113 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5091764705882353\n",
      "Epoch 114 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5063529411764706\n",
      "Epoch 115 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.504\n",
      "Epoch 116 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5068235294117647\n",
      "Epoch 117 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5016470588235294\n",
      "Epoch 118 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 119 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.512\n",
      "Epoch 120 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5054117647058823\n",
      "Epoch 121 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5016470588235294\n",
      "Epoch 122 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5058823529411764\n",
      "Epoch 123 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.49976470588235294\n",
      "Epoch 124 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5091764705882353\n",
      "Epoch 125 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.512\n",
      "Epoch 126 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5063529411764706\n",
      "Epoch 127 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 128 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 129 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5011764705882353\n",
      "Epoch 130 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5096470588235295\n",
      "Epoch 131 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5143529411764706\n",
      "Epoch 132 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5087058823529412\n",
      "Epoch 133 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 134 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 135 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5007058823529412\n",
      "Epoch 136 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 137 Loss 1.00 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5115294117647059\n",
      "Epoch 138 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5087058823529412\n",
      "Epoch 139 Loss 1.00 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5115294117647059\n",
      "Epoch 140 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5110588235294118\n",
      "Epoch 141 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5035294117647059\n",
      "Epoch 142 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.4988235294117647\n",
      "Epoch 143 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 144 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5087058823529412\n",
      "Epoch 145 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 146 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 147 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 148 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.49929411764705883\n",
      "Epoch 149 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 150 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 151 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 152 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 153 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5058823529411764\n",
      "Epoch 154 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.49976470588235294\n",
      "Epoch 155 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 156 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5091764705882353\n",
      "Epoch 157 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5030588235294118\n",
      "Epoch 158 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 159 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5016470588235294\n",
      "Epoch 160 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5025882352941177\n",
      "Epoch 161 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5058823529411764\n",
      "Epoch 162 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5143529411764706\n",
      "Epoch 163 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5105882352941177\n",
      "Epoch 164 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 165 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 166 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5030588235294118\n",
      "Epoch 167 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5087058823529412\n",
      "Epoch 168 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 169 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5016470588235294\n",
      "Epoch 170 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5096470588235295\n",
      "Epoch 171 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5063529411764706\n",
      "Epoch 172 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5115294117647059\n",
      "Epoch 173 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 174 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.4983529411764706\n",
      "Epoch 175 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.504\n",
      "Epoch 176 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5091764705882353\n",
      "Epoch 177 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.508235294117647\n",
      "Epoch 178 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5077647058823529\n",
      "Epoch 179 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5058823529411764\n",
      "Epoch 180 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.4983529411764706\n",
      "Epoch 181 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.4988235294117647\n",
      "Epoch 182 Loss 1.00 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.512\n",
      "Epoch 183 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5077647058823529\n",
      "Epoch 184 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.512\n",
      "Epoch 185 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 186 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5021176470588236\n",
      "Epoch 187 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 188 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5091764705882353\n",
      "Epoch 189 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 190 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 191 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5068235294117647\n",
      "Epoch 192 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4978823529411765\n",
      "Epoch 193 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5063529411764706\n",
      "Epoch 194 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 195 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 196 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5091764705882353\n",
      "Epoch 197 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5002352941176471\n",
      "Epoch 198 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.4983529411764706\n",
      "Epoch 199 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5068235294117647\n",
      "Epoch 200 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.504\n",
      "Epoch 201 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 202 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5077647058823529\n",
      "Epoch 203 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 204 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49741176470588233\n",
      "Epoch 205 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.508235294117647\n",
      "Epoch 206 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5143529411764706\n",
      "Epoch 207 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.512\n",
      "Epoch 208 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5110588235294118\n",
      "Epoch 209 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5011764705882353\n",
      "Epoch 210 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5021176470588236\n",
      "Epoch 211 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5110588235294118\n",
      "Epoch 212 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5110588235294118\n",
      "Epoch 213 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.512\n",
      "Epoch 214 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 215 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.4988235294117647\n",
      "Epoch 216 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 217 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5105882352941177\n",
      "Epoch 218 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5063529411764706\n",
      "Epoch 219 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 220 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.504\n",
      "Epoch 221 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.49976470588235294\n",
      "Epoch 222 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5021176470588236\n",
      "Epoch 223 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5124705882352941\n",
      "Epoch 224 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 225 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5101176470588236\n",
      "Epoch 226 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5030588235294118\n",
      "Epoch 227 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49741176470588233\n",
      "Epoch 228 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 229 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5115294117647059\n",
      "Epoch 230 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 231 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 232 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5105882352941177\n",
      "Epoch 233 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5011764705882353\n",
      "Epoch 234 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 235 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5077647058823529\n",
      "Epoch 236 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5072941176470588\n",
      "Epoch 237 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 238 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 239 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.49976470588235294\n",
      "Epoch 240 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5072941176470588\n",
      "Epoch 241 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 242 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 243 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 244 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 245 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 246 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5021176470588236\n",
      "Epoch 247 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5025882352941177\n",
      "Epoch 248 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 249 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.512\n",
      "Epoch 250 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 251 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 252 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5096470588235295\n",
      "Epoch 253 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5072941176470588\n",
      "Epoch 254 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 255 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5091764705882353\n",
      "Epoch 256 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5115294117647059\n",
      "Epoch 257 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5077647058823529\n",
      "Epoch 258 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5025882352941177\n",
      "Epoch 259 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5134117647058823\n",
      "Epoch 260 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5096470588235295\n",
      "Epoch 261 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 262 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 263 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5049411764705882\n",
      "Epoch 264 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 265 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5011764705882353\n",
      "Epoch 266 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.4978823529411765\n",
      "Epoch 267 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5077647058823529\n",
      "Epoch 268 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5044705882352941\n",
      "Epoch 269 Loss 1.00 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5110588235294118\n",
      "Epoch 270 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.512\n",
      "Epoch 271 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 272 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5011764705882353\n",
      "Epoch 273 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 274 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5058823529411764\n",
      "Epoch 275 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 276 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 277 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 278 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.496\n",
      "Epoch 279 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5002352941176471\n",
      "Epoch 280 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5129411764705882\n",
      "Epoch 281 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.508235294117647\n",
      "Epoch 282 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 283 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 284 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5011764705882353\n",
      "Epoch 285 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 286 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.504\n",
      "Epoch 287 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 288 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 289 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5021176470588236\n",
      "Epoch 290 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5007058823529412\n",
      "Epoch 291 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.504\n",
      "Epoch 292 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 293 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5105882352941177\n",
      "Epoch 294 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5054117647058823\n",
      "Epoch 295 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5016470588235294\n",
      "Epoch 296 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5025882352941177\n",
      "Epoch 297 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 298 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5091764705882353\n",
      "Epoch 299 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5044705882352941\n",
      "Epoch 300 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5035294117647059\n",
      "Epoch 301 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 302 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 303 Loss 1.00 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.508235294117647\n",
      "Epoch 304 Loss 1.00 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5091764705882353\n",
      "Epoch 305 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5077647058823529\n",
      "Epoch 306 Loss 1.00 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 307 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 308 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5049411764705882\n",
      "Epoch 309 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5101176470588236\n",
      "Epoch 310 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5105882352941177\n",
      "Epoch 311 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5115294117647059\n",
      "Epoch 312 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 313 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5011764705882353\n",
      "Epoch 314 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5011764705882353\n",
      "Epoch 315 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5096470588235295\n",
      "Epoch 316 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 317 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5058823529411764\n",
      "Epoch 318 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5011764705882353\n",
      "Epoch 319 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5016470588235294\n",
      "Epoch 320 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.49976470588235294\n",
      "Epoch 321 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 322 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5148235294117647\n",
      "Epoch 323 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5063529411764706\n",
      "Epoch 324 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.4978823529411765\n",
      "Epoch 325 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 326 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.49929411764705883\n",
      "Epoch 327 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5124705882352941\n",
      "Epoch 328 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5110588235294118\n",
      "Epoch 329 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.508235294117647\n",
      "Epoch 330 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5025882352941177\n",
      "Epoch 331 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5063529411764706\n",
      "Epoch 332 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5002352941176471\n",
      "Epoch 333 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.512\n",
      "Epoch 334 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5138823529411765\n",
      "Epoch 335 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.512\n",
      "Epoch 336 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5035294117647059\n",
      "Epoch 337 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.49929411764705883\n",
      "Epoch 338 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5044705882352941\n",
      "Epoch 339 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5105882352941177\n",
      "Epoch 340 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5105882352941177\n",
      "Epoch 341 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5063529411764706\n",
      "Epoch 342 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.4983529411764706\n",
      "Epoch 343 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5007058823529412\n",
      "Epoch 344 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5096470588235295\n",
      "Epoch 345 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 346 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 347 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 348 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.49929411764705883\n",
      "Epoch 349 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5016470588235294\n",
      "Epoch 350 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5063529411764706\n",
      "Epoch 351 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5129411764705882\n",
      "Epoch 352 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.512\n",
      "Epoch 353 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5091764705882353\n",
      "Epoch 354 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 355 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5011764705882353\n",
      "Epoch 356 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5030588235294118\n",
      "Epoch 357 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.512\n",
      "Epoch 358 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5101176470588236\n",
      "Epoch 359 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5110588235294118\n",
      "Epoch 360 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 361 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5021176470588236\n",
      "Epoch 362 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5021176470588236\n",
      "Epoch 363 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5134117647058823\n",
      "Epoch 364 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5124705882352941\n",
      "Epoch 365 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5068235294117647\n",
      "Epoch 366 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5011764705882353\n",
      "Epoch 367 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5011764705882353\n",
      "Epoch 368 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.504\n",
      "Epoch 369 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 370 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5110588235294118\n",
      "Epoch 371 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5044705882352941\n",
      "Epoch 372 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5002352941176471\n",
      "Epoch 373 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5030588235294118\n",
      "Epoch 374 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5021176470588236\n",
      "Epoch 375 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5101176470588236\n",
      "Epoch 376 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5101176470588236\n",
      "Epoch 377 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5030588235294118\n",
      "Epoch 378 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 379 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5072941176470588\n",
      "Epoch 380 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 381 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5087058823529412\n",
      "Epoch 382 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5030588235294118\n",
      "Epoch 383 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 384 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 385 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 386 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 387 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 388 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5072941176470588\n",
      "Epoch 389 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5110588235294118\n",
      "Epoch 390 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.4983529411764706\n",
      "Epoch 391 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 392 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5129411764705882\n",
      "Epoch 393 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 394 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 395 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5077647058823529\n",
      "Epoch 396 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 397 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 398 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5025882352941177\n",
      "Epoch 399 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5110588235294118\n",
      "Epoch 400 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5096470588235295\n",
      "Epoch 401 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5025882352941177\n",
      "Epoch 402 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 403 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 404 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5049411764705882\n",
      "Epoch 405 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5058823529411764\n",
      "Epoch 406 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 407 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 408 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5096470588235295\n",
      "Epoch 409 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 410 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 411 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5016470588235294\n",
      "Epoch 412 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5096470588235295\n",
      "Epoch 413 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.508235294117647\n",
      "Epoch 414 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5035294117647059\n",
      "Epoch 415 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 416 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 417 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5002352941176471\n",
      "Epoch 418 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 419 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5124705882352941\n",
      "Epoch 420 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 421 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5054117647058823\n",
      "Epoch 422 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 423 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5007058823529412\n",
      "Epoch 424 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 425 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5110588235294118\n",
      "Epoch 426 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5091764705882353\n",
      "Epoch 427 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 428 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5058823529411764\n",
      "Epoch 429 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 430 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5035294117647059\n",
      "Epoch 431 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5016470588235294\n",
      "Epoch 432 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 433 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 434 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49976470588235294\n",
      "Epoch 435 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 436 Loss 0.99 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.508235294117647\n",
      "Epoch 437 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5124705882352941\n",
      "Epoch 438 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 439 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5044705882352941\n",
      "Epoch 440 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.49976470588235294\n",
      "Epoch 441 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.508235294117647\n",
      "Epoch 442 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5011764705882353\n",
      "Epoch 443 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5110588235294118\n",
      "Epoch 444 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 445 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5030588235294118\n",
      "Epoch 446 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5030588235294118\n",
      "Epoch 447 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5101176470588236\n",
      "Epoch 448 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5087058823529412\n",
      "Epoch 449 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.508235294117647\n",
      "Epoch 450 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 451 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 452 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5068235294117647\n",
      "Epoch 453 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5044705882352941\n",
      "Epoch 454 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5049411764705882\n",
      "Epoch 455 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 456 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 457 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5101176470588236\n",
      "Epoch 458 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 459 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5058823529411764\n",
      "Epoch 460 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4964705882352941\n",
      "Epoch 461 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5077647058823529\n",
      "Epoch 462 Loss 1.00 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5124705882352941\n",
      "Epoch 463 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5091764705882353\n",
      "Epoch 464 Loss 1.00 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5134117647058823\n",
      "Epoch 465 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.508235294117647\n",
      "Epoch 466 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5044705882352941\n",
      "Epoch 467 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 468 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 469 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5105882352941177\n",
      "Epoch 470 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49929411764705883\n",
      "Epoch 471 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 472 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5049411764705882\n",
      "Epoch 473 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5002352941176471\n",
      "Epoch 474 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 475 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.508235294117647\n",
      "Epoch 476 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5091764705882353\n",
      "Epoch 477 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5025882352941177\n",
      "Epoch 478 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5025882352941177\n",
      "Epoch 479 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5016470588235294\n",
      "Epoch 480 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 481 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 482 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5030588235294118\n",
      "Epoch 483 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 484 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 485 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 486 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 487 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 488 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5021176470588236\n",
      "Epoch 489 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 490 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 491 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 492 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5087058823529412\n",
      "Epoch 493 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5025882352941177\n",
      "Epoch 494 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5049411764705882\n",
      "Epoch 495 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5072941176470588\n",
      "Epoch 496 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5124705882352941\n",
      "Epoch 497 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5124705882352941\n",
      "Epoch 498 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 499 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5072941176470588\n",
      "Epoch 500 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5087058823529412\n",
      "Epoch 501 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.49929411764705883\n",
      "Epoch 502 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5068235294117647\n",
      "Epoch 503 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5129411764705882\n",
      "Epoch 504 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 505 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 506 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5063529411764706\n",
      "Epoch 507 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5011764705882353\n",
      "Epoch 508 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5054117647058823\n",
      "Epoch 509 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5105882352941177\n",
      "Epoch 510 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 511 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 512 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 513 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.49976470588235294\n",
      "Epoch 514 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5101176470588236\n",
      "Epoch 515 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5124705882352941\n",
      "Epoch 516 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5044705882352941\n",
      "Epoch 517 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 518 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 519 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5035294117647059\n",
      "Epoch 520 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.508235294117647\n",
      "Epoch 521 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 522 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5054117647058823\n",
      "Epoch 523 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 524 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5016470588235294\n",
      "Epoch 525 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5021176470588236\n",
      "Epoch 526 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 527 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.512\n",
      "Epoch 528 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 529 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 530 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5030588235294118\n",
      "Epoch 531 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 532 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 533 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5044705882352941\n",
      "Epoch 534 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 535 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5007058823529412\n",
      "Epoch 536 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 537 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5124705882352941\n",
      "Epoch 538 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5124705882352941\n",
      "Epoch 539 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 540 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.49929411764705883\n",
      "Epoch 541 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5030588235294118\n",
      "Epoch 542 Loss 1.00 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5138823529411765\n",
      "Epoch 543 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 544 Loss 1.00 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5134117647058823\n",
      "Epoch 545 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5096470588235295\n",
      "Epoch 546 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5044705882352941\n",
      "Epoch 547 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5030588235294118\n",
      "Epoch 548 Loss 0.99 | Train Accuracy 0.523120367102012 | Val Accuracy 0.5054117647058823\n",
      "Epoch 549 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5110588235294118\n",
      "Epoch 550 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5021176470588236\n",
      "Epoch 551 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 552 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5030588235294118\n",
      "Epoch 553 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5011764705882353\n",
      "Epoch 554 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5091764705882353\n",
      "Epoch 555 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5101176470588236\n",
      "Epoch 556 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5063529411764706\n",
      "Epoch 557 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 558 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5035294117647059\n",
      "Epoch 559 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.49976470588235294\n",
      "Epoch 560 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5063529411764706\n",
      "Epoch 561 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 562 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 563 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5030588235294118\n",
      "Epoch 564 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5007058823529412\n",
      "Epoch 565 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5030588235294118\n",
      "Epoch 566 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 567 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 568 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 569 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 570 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5030588235294118\n",
      "Epoch 571 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5096470588235295\n",
      "Epoch 572 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5101176470588236\n",
      "Epoch 573 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 574 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5091764705882353\n",
      "Epoch 575 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 576 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 577 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5110588235294118\n",
      "Epoch 578 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5077647058823529\n",
      "Epoch 579 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5063529411764706\n",
      "Epoch 580 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5016470588235294\n",
      "Epoch 581 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5030588235294118\n",
      "Epoch 582 Loss 1.00 | Train Accuracy 0.5142957995058243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 583 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5124705882352941\n",
      "Epoch 584 Loss 1.00 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5124705882352941\n",
      "Epoch 585 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.512\n",
      "Epoch 586 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49929411764705883\n",
      "Epoch 587 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5068235294117647\n",
      "Epoch 588 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5096470588235295\n",
      "Epoch 589 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5077647058823529\n",
      "Epoch 590 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 591 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 592 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 593 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5011764705882353\n",
      "Epoch 594 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 595 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5091764705882353\n",
      "Epoch 596 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5110588235294118\n",
      "Epoch 597 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 598 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5011764705882353\n",
      "Epoch 599 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5016470588235294\n",
      "Epoch 600 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 601 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 602 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 603 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 604 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5068235294117647\n",
      "Epoch 605 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5058823529411764\n",
      "Epoch 606 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5049411764705882\n",
      "Epoch 607 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 608 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 609 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 610 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5143529411764706\n",
      "Epoch 611 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5138823529411765\n",
      "Epoch 612 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 613 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5016470588235294\n",
      "Epoch 614 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5105882352941177\n",
      "Epoch 615 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5105882352941177\n",
      "Epoch 616 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5021176470588236\n",
      "Epoch 617 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 618 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5054117647058823\n",
      "Epoch 619 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5105882352941177\n",
      "Epoch 620 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 621 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5011764705882353\n",
      "Epoch 622 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 623 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5068235294117647\n",
      "Epoch 624 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 625 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 626 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.49976470588235294\n",
      "Epoch 627 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 628 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5124705882352941\n",
      "Epoch 629 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 630 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 631 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 632 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5016470588235294\n",
      "Epoch 633 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.504\n",
      "Epoch 634 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5044705882352941\n",
      "Epoch 635 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5101176470588236\n",
      "Epoch 636 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 637 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 638 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 639 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 640 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 641 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5058823529411764\n",
      "Epoch 642 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5002352941176471\n",
      "Epoch 643 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5044705882352941\n",
      "Epoch 644 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5096470588235295\n",
      "Epoch 645 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5096470588235295\n",
      "Epoch 646 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 647 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5011764705882353\n",
      "Epoch 648 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5025882352941177\n",
      "Epoch 649 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5138823529411765\n",
      "Epoch 650 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 651 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5115294117647059\n",
      "Epoch 652 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.508235294117647\n",
      "Epoch 653 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.496\n",
      "Epoch 654 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 655 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5138823529411765\n",
      "Epoch 656 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5087058823529412\n",
      "Epoch 657 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5138823529411765\n",
      "Epoch 658 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 659 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5049411764705882\n",
      "Epoch 660 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.4983529411764706\n",
      "Epoch 661 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 662 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5105882352941177\n",
      "Epoch 663 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 664 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 665 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5025882352941177\n",
      "Epoch 666 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5002352941176471\n",
      "Epoch 667 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 668 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 669 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5077647058823529\n",
      "Epoch 670 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5030588235294118\n",
      "Epoch 671 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 672 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5002352941176471\n",
      "Epoch 673 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5049411764705882\n",
      "Epoch 674 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 675 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 676 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5021176470588236\n",
      "Epoch 677 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5035294117647059\n",
      "Epoch 678 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 679 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 680 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 681 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 682 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 683 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5054117647058823\n",
      "Epoch 684 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5087058823529412\n",
      "Epoch 685 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.512\n",
      "Epoch 686 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 687 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5007058823529412\n",
      "Epoch 688 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 689 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.512\n",
      "Epoch 690 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5101176470588236\n",
      "Epoch 691 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5110588235294118\n",
      "Epoch 692 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 693 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.49741176470588233\n",
      "Epoch 694 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5063529411764706\n",
      "Epoch 695 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5143529411764706\n",
      "Epoch 696 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 697 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5138823529411765\n",
      "Epoch 698 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 699 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5044705882352941\n",
      "Epoch 700 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.4988235294117647\n",
      "Epoch 701 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 702 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5096470588235295\n",
      "Epoch 703 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5058823529411764\n",
      "Epoch 704 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5105882352941177\n",
      "Epoch 705 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 706 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.49976470588235294\n",
      "Epoch 707 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5011764705882353\n",
      "Epoch 708 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 709 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 710 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 711 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 712 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5011764705882353\n",
      "Epoch 713 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.49929411764705883\n",
      "Epoch 714 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 715 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 716 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 717 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 718 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5007058823529412\n",
      "Epoch 719 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5016470588235294\n",
      "Epoch 720 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5091764705882353\n",
      "Epoch 721 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5096470588235295\n",
      "Epoch 722 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 723 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 724 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5044705882352941\n",
      "Epoch 725 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 726 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 727 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5044705882352941\n",
      "Epoch 728 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 729 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5054117647058823\n",
      "Epoch 730 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5011764705882353\n",
      "Epoch 731 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5025882352941177\n",
      "Epoch 732 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.512\n",
      "Epoch 733 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 734 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5124705882352941\n",
      "Epoch 735 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5096470588235295\n",
      "Epoch 736 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.4964705882352941\n",
      "Epoch 737 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 738 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5115294117647059\n",
      "Epoch 739 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 740 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5101176470588236\n",
      "Epoch 741 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 742 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5025882352941177\n",
      "Epoch 743 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 744 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 745 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 746 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 747 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5044705882352941\n",
      "Epoch 748 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.49976470588235294\n",
      "Epoch 749 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5011764705882353\n",
      "Epoch 750 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5068235294117647\n",
      "Epoch 751 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5110588235294118\n",
      "Epoch 752 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 753 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5030588235294118\n",
      "Epoch 754 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.508235294117647\n",
      "Epoch 755 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.508235294117647\n",
      "Epoch 756 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5049411764705882\n",
      "Epoch 757 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 758 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5035294117647059\n",
      "Epoch 759 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 760 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5124705882352941\n",
      "Epoch 761 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5105882352941177\n",
      "Epoch 762 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 763 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5007058823529412\n",
      "Epoch 764 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 765 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.4969411764705882\n",
      "Epoch 766 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5101176470588236\n",
      "Epoch 767 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5138823529411765\n",
      "Epoch 768 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 769 Loss 1.00 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 770 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 771 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5054117647058823\n",
      "Epoch 772 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.512\n",
      "Epoch 773 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5110588235294118\n",
      "Epoch 774 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5110588235294118\n",
      "Epoch 775 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5035294117647059\n",
      "Epoch 776 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 777 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.504\n",
      "Epoch 778 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5115294117647059\n",
      "Epoch 779 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5096470588235295\n",
      "Epoch 780 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5058823529411764\n",
      "Epoch 781 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.4983529411764706\n",
      "Epoch 782 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.4978823529411765\n",
      "Epoch 783 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5035294117647059\n",
      "Epoch 784 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 785 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.508235294117647\n",
      "Epoch 786 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 787 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5011764705882353\n",
      "Epoch 788 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5044705882352941\n",
      "Epoch 789 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5025882352941177\n",
      "Epoch 790 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5124705882352941\n",
      "Epoch 791 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5105882352941177\n",
      "Epoch 792 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5068235294117647\n",
      "Epoch 793 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 794 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 795 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5025882352941177\n",
      "Epoch 796 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.512\n",
      "Epoch 797 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5115294117647059\n",
      "Epoch 798 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5063529411764706\n",
      "Epoch 799 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5049411764705882\n",
      "Epoch 800 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 801 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5002352941176471\n",
      "Epoch 802 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5096470588235295\n",
      "Epoch 803 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5101176470588236\n",
      "Epoch 804 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 805 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 806 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5044705882352941\n",
      "Epoch 807 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 808 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 809 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5105882352941177\n",
      "Epoch 810 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 811 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 812 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5035294117647059\n",
      "Epoch 813 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 814 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5072941176470588\n",
      "Epoch 815 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5021176470588236\n",
      "Epoch 816 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 817 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 818 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5016470588235294\n",
      "Epoch 819 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 820 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5077647058823529\n",
      "Epoch 821 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5134117647058823\n",
      "Epoch 822 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5101176470588236\n",
      "Epoch 823 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5077647058823529\n",
      "Epoch 824 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.4978823529411765\n",
      "Epoch 825 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 826 Loss 0.99 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5134117647058823\n",
      "Epoch 827 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 828 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.512\n",
      "Epoch 829 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 830 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.49929411764705883\n",
      "Epoch 831 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.504\n",
      "Epoch 832 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5087058823529412\n",
      "Epoch 833 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 834 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 835 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 836 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5007058823529412\n",
      "Epoch 837 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 838 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5025882352941177\n",
      "Epoch 839 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 840 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 841 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 842 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.49976470588235294\n",
      "Epoch 843 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 844 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5049411764705882\n",
      "Epoch 845 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5101176470588236\n",
      "Epoch 846 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 847 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5063529411764706\n",
      "Epoch 848 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 849 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 850 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 851 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 852 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 853 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 854 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5068235294117647\n",
      "Epoch 855 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 856 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5105882352941177\n",
      "Epoch 857 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5011764705882353\n",
      "Epoch 858 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5016470588235294\n",
      "Epoch 859 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5096470588235295\n",
      "Epoch 860 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5143529411764706\n",
      "Epoch 861 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 862 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5072941176470588\n",
      "Epoch 863 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 864 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5016470588235294\n",
      "Epoch 865 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5058823529411764\n",
      "Epoch 866 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5115294117647059\n",
      "Epoch 867 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 868 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.508235294117647\n",
      "Epoch 869 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.4983529411764706\n",
      "Epoch 870 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.4978823529411765\n",
      "Epoch 871 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5101176470588236\n",
      "Epoch 872 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5138823529411765\n",
      "Epoch 873 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5105882352941177\n",
      "Epoch 874 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 875 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.49741176470588233\n",
      "Epoch 876 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.504\n",
      "Epoch 877 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5110588235294118\n",
      "Epoch 878 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 879 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 880 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5044705882352941\n",
      "Epoch 881 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5016470588235294\n",
      "Epoch 882 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 883 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 884 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5096470588235295\n",
      "Epoch 885 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 886 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 887 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5011764705882353\n",
      "Epoch 888 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5030588235294118\n",
      "Epoch 889 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 890 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 891 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 892 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5025882352941177\n",
      "Epoch 893 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5021176470588236\n",
      "Epoch 894 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5096470588235295\n",
      "Epoch 895 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5115294117647059\n",
      "Epoch 896 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 897 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 898 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 899 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5049411764705882\n",
      "Epoch 900 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 901 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 902 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 903 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 904 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5007058823529412\n",
      "Epoch 905 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5011764705882353\n",
      "Epoch 906 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5124705882352941\n",
      "Epoch 907 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5087058823529412\n",
      "Epoch 908 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5096470588235295\n",
      "Epoch 909 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5101176470588236\n",
      "Epoch 910 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 911 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5068235294117647\n",
      "Epoch 912 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5091764705882353\n",
      "Epoch 913 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5115294117647059\n",
      "Epoch 914 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5096470588235295\n",
      "Epoch 915 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 916 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5049411764705882\n",
      "Epoch 917 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5096470588235295\n",
      "Epoch 918 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5087058823529412\n",
      "Epoch 919 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5063529411764706\n",
      "Epoch 920 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5058823529411764\n",
      "Epoch 921 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 922 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5002352941176471\n",
      "Epoch 923 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 924 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5096470588235295\n",
      "Epoch 925 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 926 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5035294117647059\n",
      "Epoch 927 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5054117647058823\n",
      "Epoch 928 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.504\n",
      "Epoch 929 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5072941176470588\n",
      "Epoch 930 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 931 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 932 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5087058823529412\n",
      "Epoch 933 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.49976470588235294\n",
      "Epoch 934 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5129411764705882\n",
      "Epoch 935 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5110588235294118\n",
      "Epoch 936 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5011764705882353\n",
      "Epoch 937 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5049411764705882\n",
      "Epoch 938 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5091764705882353\n",
      "Epoch 939 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 940 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5044705882352941\n",
      "Epoch 941 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5002352941176471\n",
      "Epoch 942 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 943 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.508235294117647\n",
      "Epoch 944 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5007058823529412\n",
      "Epoch 945 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 946 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5049411764705882\n",
      "Epoch 947 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5105882352941177\n",
      "Epoch 948 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 949 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5007058823529412\n",
      "Epoch 950 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 951 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 952 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 953 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5087058823529412\n",
      "Epoch 954 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 955 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 956 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5096470588235295\n",
      "Epoch 957 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5054117647058823\n",
      "Epoch 958 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 959 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4969411764705882\n",
      "Epoch 960 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 961 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5072941176470588\n",
      "Epoch 962 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 963 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5124705882352941\n",
      "Epoch 964 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5035294117647059\n",
      "Epoch 965 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5002352941176471\n",
      "Epoch 966 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5077647058823529\n",
      "Epoch 967 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5091764705882353\n",
      "Epoch 968 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5091764705882353\n",
      "Epoch 969 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5068235294117647\n",
      "Epoch 970 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 971 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5044705882352941\n",
      "Epoch 972 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5002352941176471\n",
      "Epoch 973 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 974 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5110588235294118\n",
      "Epoch 975 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 976 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5068235294117647\n",
      "Epoch 977 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 978 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5007058823529412\n",
      "Epoch 979 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 980 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5124705882352941\n",
      "Epoch 981 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5035294117647059\n",
      "Epoch 982 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 983 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.504\n",
      "Epoch 984 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.49976470588235294\n",
      "Epoch 985 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5068235294117647\n",
      "Epoch 986 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5110588235294118\n",
      "Epoch 987 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 988 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 989 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 990 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.49929411764705883\n",
      "Epoch 991 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.512\n",
      "Epoch 992 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5110588235294118\n",
      "Epoch 993 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 994 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5063529411764706\n",
      "Epoch 995 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 996 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5007058823529412\n",
      "Epoch 997 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 998 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5096470588235295\n",
      "Epoch 999 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1000 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1001 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1002 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1003 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1004 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.508235294117647\n",
      "Epoch 1005 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 1006 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1007 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1008 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1009 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1010 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1011 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1012 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1013 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1014 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1015 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1016 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1017 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1018 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1019 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1020 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5002352941176471\n",
      "Epoch 1021 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5143529411764706\n",
      "Epoch 1022 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1023 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5143529411764706\n",
      "Epoch 1024 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1025 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 1026 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1027 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1028 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.512\n",
      "Epoch 1029 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1030 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1031 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1032 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1033 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1034 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1035 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1036 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1037 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1038 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1039 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1040 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1041 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1042 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1043 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1044 Loss 0.99 | Train Accuracy 0.5144134604071067 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1045 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1046 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1047 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1048 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.4983529411764706\n",
      "Epoch 1049 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1050 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5129411764705882\n",
      "Epoch 1051 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1052 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1053 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1054 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1055 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1056 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.512\n",
      "Epoch 1057 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 1058 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.512\n",
      "Epoch 1059 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1060 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1061 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1062 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1063 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 1064 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1065 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1066 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1067 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 1068 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1069 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1070 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.504\n",
      "Epoch 1071 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.504\n",
      "Epoch 1072 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1073 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1074 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1075 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1076 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1077 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1078 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1079 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.512\n",
      "Epoch 1080 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1081 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1082 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1083 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5143529411764706\n",
      "Epoch 1084 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1085 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1086 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1087 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1088 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1089 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1090 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1091 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1092 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1093 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1094 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1095 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1096 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1097 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1098 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1099 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1100 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1101 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1102 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1103 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1104 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1105 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1106 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1107 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1108 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1109 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1110 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1111 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1112 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1113 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1114 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 1115 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1116 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.512\n",
      "Epoch 1117 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1118 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1119 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.4983529411764706\n",
      "Epoch 1120 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1121 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1122 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1123 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1124 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1125 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.4988235294117647\n",
      "Epoch 1126 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1127 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.508235294117647\n",
      "Epoch 1128 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1129 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1130 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1131 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1132 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1133 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1134 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1135 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.508235294117647\n",
      "Epoch 1136 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1137 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1138 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1139 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1140 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1141 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1142 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1143 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1144 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1145 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1146 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1147 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1148 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1149 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1150 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5143529411764706\n",
      "Epoch 1151 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5152941176470588\n",
      "Epoch 1152 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.512\n",
      "Epoch 1153 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1154 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1155 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1156 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1157 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1158 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1159 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1160 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.504\n",
      "Epoch 1161 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1162 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1163 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1164 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1165 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.4983529411764706\n",
      "Epoch 1166 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1167 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1168 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 1169 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1170 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1171 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1172 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1173 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1174 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.508235294117647\n",
      "Epoch 1175 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1176 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1177 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1178 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1179 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1180 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1181 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1182 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.508235294117647\n",
      "Epoch 1183 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1184 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1185 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1186 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1187 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 1188 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.4964705882352941\n",
      "Epoch 1189 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1190 Loss 1.00 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1191 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1192 Loss 1.00 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5138823529411765\n",
      "Epoch 1193 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1194 Loss 1.00 | Train Accuracy 0.5142957995058243 | Val Accuracy 0.504\n",
      "Epoch 1195 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1196 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1197 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1198 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1199 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1200 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1201 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1202 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1203 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1204 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1205 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 1206 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1207 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1208 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1209 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 1210 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1211 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1212 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1213 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1214 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1215 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1216 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1217 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1218 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1219 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 1220 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1221 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1222 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1223 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1224 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1225 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1226 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1227 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1228 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1229 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1230 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1231 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1232 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.508235294117647\n",
      "Epoch 1233 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5002352941176471\n",
      "Epoch 1234 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.508235294117647\n",
      "Epoch 1235 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1236 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1237 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1238 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1239 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.4988235294117647\n",
      "Epoch 1240 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1241 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1242 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1243 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1244 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1245 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1246 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1247 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1248 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 1249 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1250 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1251 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1252 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1253 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1254 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1255 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1256 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1257 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1258 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1259 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 1260 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1261 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1262 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1263 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1264 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.512\n",
      "Epoch 1265 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1266 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1267 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1268 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1269 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1270 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1271 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1272 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1273 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1274 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1275 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1276 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1277 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1278 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1279 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1280 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1281 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1282 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1283 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1284 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1285 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1286 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1287 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1288 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1289 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1290 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1291 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1292 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1293 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1294 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1295 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 1296 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1297 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1298 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1299 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1300 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1301 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1302 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1303 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1304 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1305 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1306 Loss 1.00 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5152941176470588\n",
      "Epoch 1307 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.512\n",
      "Epoch 1308 Loss 1.00 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1309 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1310 Loss 1.00 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1311 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1312 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1313 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1314 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1315 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1316 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1317 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1318 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1319 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1320 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1321 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.4983529411764706\n",
      "Epoch 1322 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 1323 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1324 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1325 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1326 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1327 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1328 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.508235294117647\n",
      "Epoch 1329 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1330 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1331 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.4964705882352941\n",
      "Epoch 1332 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 1333 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1334 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1335 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1336 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.504\n",
      "Epoch 1337 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1338 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1339 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5002352941176471\n",
      "Epoch 1340 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1341 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1342 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1343 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.512\n",
      "Epoch 1344 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1345 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1346 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1347 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1348 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1349 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1350 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1351 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1352 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1353 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1354 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1355 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.512\n",
      "Epoch 1356 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1357 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1358 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1359 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1360 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1361 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1362 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1363 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1364 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1365 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1366 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1367 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1368 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1369 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1370 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1371 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1372 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.508235294117647\n",
      "Epoch 1373 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1374 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1375 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1376 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.4964705882352941\n",
      "Epoch 1377 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1378 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1379 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1380 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1381 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1382 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1383 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1384 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1385 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1386 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1387 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1388 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4988235294117647\n",
      "Epoch 1389 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.508235294117647\n",
      "Epoch 1390 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.508235294117647\n",
      "Epoch 1391 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.504\n",
      "Epoch 1392 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1393 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1394 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1395 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1396 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1397 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1398 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1399 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1400 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1401 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 1402 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1403 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1404 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 1405 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1406 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5002352941176471\n",
      "Epoch 1407 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1408 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1409 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1410 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 1411 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1412 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1413 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1414 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1415 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1416 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1417 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1418 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1419 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1420 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1421 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1422 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1423 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1424 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1425 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1426 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1427 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1428 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1429 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1430 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1431 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1432 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1433 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.512\n",
      "Epoch 1434 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1435 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1436 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1437 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1438 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1439 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1440 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1441 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1442 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1443 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1444 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1445 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1446 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1447 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1448 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1449 Loss 0.99 | Train Accuracy 0.5144134604071067 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1450 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5129411764705882\n",
      "Epoch 1451 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1452 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1453 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4983529411764706\n",
      "Epoch 1454 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1455 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.512\n",
      "Epoch 1456 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1457 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.512\n",
      "Epoch 1458 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1459 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1460 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1461 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1462 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1463 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1464 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1465 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5002352941176471\n",
      "Epoch 1466 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 1467 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.512\n",
      "Epoch 1468 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1469 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1470 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1471 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1472 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.508235294117647\n",
      "Epoch 1473 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1474 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1475 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1476 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1477 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1478 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1479 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 1480 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1481 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.504\n",
      "Epoch 1482 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1483 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.512\n",
      "Epoch 1484 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1485 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1486 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.508235294117647\n",
      "Epoch 1487 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1488 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1489 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1490 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1491 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1492 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1493 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1494 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1495 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1496 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1497 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1498 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1499 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1500 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1501 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1502 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1503 Loss 0.99 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1504 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1505 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1506 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1507 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1508 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.504\n",
      "Epoch 1509 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5002352941176471\n",
      "Epoch 1510 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1511 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.508235294117647\n",
      "Epoch 1512 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1513 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1514 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1515 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1516 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1517 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1518 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1519 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1520 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1521 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 1522 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1523 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1524 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 1525 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1526 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1527 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.508235294117647\n",
      "Epoch 1528 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5143529411764706\n",
      "Epoch 1529 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1530 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1531 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1532 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1533 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1534 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1535 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1536 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1537 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1538 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1539 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1540 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1541 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1542 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1543 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5002352941176471\n",
      "Epoch 1544 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1545 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1546 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 1547 Loss 0.99 | Train Accuracy 0.523120367102012 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1548 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1549 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1550 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1551 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1552 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1553 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1554 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1555 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1556 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1557 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1558 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1559 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1560 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1561 Loss 1.00 | Train Accuracy 0.5141781386045418 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1562 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5143529411764706\n",
      "Epoch 1563 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1564 Loss 1.00 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1565 Loss 1.00 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1566 Loss 1.00 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1567 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1568 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1569 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1570 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1571 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1572 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1573 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1574 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1575 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1576 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1577 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5002352941176471\n",
      "Epoch 1578 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1579 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1580 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1581 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1582 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1583 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1584 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1585 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1586 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1587 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1588 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1589 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1590 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.508235294117647\n",
      "Epoch 1591 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.508235294117647\n",
      "Epoch 1592 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1593 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1594 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1595 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1596 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1597 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1598 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1599 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1600 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1601 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5002352941176471\n",
      "Epoch 1602 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1603 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1604 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1605 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1606 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1607 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1608 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1609 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1610 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1611 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1612 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1613 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1614 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1615 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5143529411764706\n",
      "Epoch 1616 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1617 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1618 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1619 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1620 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1621 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1622 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1623 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1624 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1625 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1626 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1627 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1628 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1629 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1630 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.504\n",
      "Epoch 1631 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1632 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 1633 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1634 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1635 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1636 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1637 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1638 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1639 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1640 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1641 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1642 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1643 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1644 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1645 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1646 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1647 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1648 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 1649 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1650 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1651 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.508235294117647\n",
      "Epoch 1652 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1653 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1654 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1655 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1656 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1657 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1658 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.504\n",
      "Epoch 1659 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1660 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1661 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1662 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 1663 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1664 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1665 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1666 Loss 0.99 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1667 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5138823529411765\n",
      "Epoch 1668 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.512\n",
      "Epoch 1669 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1670 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.4983529411764706\n",
      "Epoch 1671 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1672 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1673 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1674 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1675 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1676 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1677 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1678 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1679 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1680 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1681 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1682 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1683 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 1684 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 1685 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1686 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1687 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1688 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1689 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1690 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1691 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1692 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1693 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1694 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1695 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1696 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1697 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1698 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1699 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1700 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5148235294117647\n",
      "Epoch 1701 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1702 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.512\n",
      "Epoch 1703 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1704 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1705 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1706 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.512\n",
      "Epoch 1707 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1708 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1709 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1710 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1711 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.512\n",
      "Epoch 1712 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1713 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1714 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1715 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.4988235294117647\n",
      "Epoch 1716 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1717 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1718 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1719 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1720 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1721 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1722 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1723 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1724 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1725 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1726 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1727 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1728 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1729 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.508235294117647\n",
      "Epoch 1730 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 1731 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1732 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1733 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1734 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1735 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1736 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1737 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1738 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1739 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1740 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1741 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1742 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1743 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1744 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.504\n",
      "Epoch 1745 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1746 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1747 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1748 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1749 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1750 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1751 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1752 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1753 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1754 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.4988235294117647\n",
      "Epoch 1755 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1756 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1757 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1758 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1759 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1760 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1761 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.49976470588235294\n",
      "Epoch 1762 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1763 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1764 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1765 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1766 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1767 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1768 Loss 0.99 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1769 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1770 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1771 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1772 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.4988235294117647\n",
      "Epoch 1773 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1774 Loss 0.99 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1775 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1776 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1777 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1778 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1779 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1780 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.508235294117647\n",
      "Epoch 1781 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1782 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1783 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1784 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.49741176470588233\n",
      "Epoch 1785 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1786 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1787 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1788 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1789 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1790 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1791 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 1792 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1793 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1794 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1795 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1796 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1797 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1798 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1799 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1800 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1801 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1802 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1803 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.512\n",
      "Epoch 1804 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1805 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1806 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1807 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5143529411764706\n",
      "Epoch 1808 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.512\n",
      "Epoch 1809 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1810 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1811 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1812 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1813 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1814 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1815 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1816 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1817 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5138823529411765\n",
      "Epoch 1818 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1819 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.504\n",
      "Epoch 1820 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1821 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1822 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1823 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1824 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1825 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1826 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1827 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.504\n",
      "Epoch 1828 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1829 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 1830 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1831 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1832 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1833 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1834 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1835 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1836 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1837 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1838 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1839 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1840 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1841 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5007058823529412\n",
      "Epoch 1842 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1843 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5101176470588236\n",
      "Epoch 1844 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1845 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1846 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1847 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1848 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1849 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1850 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1851 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1852 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1853 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1854 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1855 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1856 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1857 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1858 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1859 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1860 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1861 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1862 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1863 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1864 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1865 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1866 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1867 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.504\n",
      "Epoch 1868 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1869 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1870 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1871 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1872 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1873 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1874 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.4969411764705882\n",
      "Epoch 1875 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1876 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.512\n",
      "Epoch 1877 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1878 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1879 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1880 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1881 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1882 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1883 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1884 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1885 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1886 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1887 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1888 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1889 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 1890 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1891 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1892 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1893 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1894 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1895 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 1896 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1897 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1898 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 1899 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1900 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1901 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1902 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1903 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1904 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5167058823529411\n",
      "Epoch 1905 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5129411764705882\n",
      "Epoch 1906 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1907 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.4978823529411765\n",
      "Epoch 1908 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1909 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1910 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1911 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1912 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1913 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.4969411764705882\n",
      "Epoch 1914 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1915 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1916 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1917 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1918 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1919 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1920 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1921 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 1922 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.508235294117647\n",
      "Epoch 1923 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1924 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1925 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5021176470588236\n",
      "Epoch 1926 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1927 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1928 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1929 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1930 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1931 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1932 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5077647058823529\n",
      "Epoch 1933 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1934 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1935 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1936 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1937 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1938 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1939 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.508235294117647\n",
      "Epoch 1940 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5143529411764706\n",
      "Epoch 1941 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1942 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1943 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1944 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.496\n",
      "Epoch 1945 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1946 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1947 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.504\n",
      "Epoch 1948 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 1949 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 1950 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.4983529411764706\n",
      "Epoch 1951 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5134117647058823\n",
      "Epoch 1952 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5138823529411765\n",
      "Epoch 1953 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5035294117647059\n",
      "Epoch 1954 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1955 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1956 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.4988235294117647\n",
      "Epoch 1957 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1958 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1959 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1960 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1961 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1962 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1963 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1964 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1965 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5025882352941177\n",
      "Epoch 1966 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 1967 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1968 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5011764705882353\n",
      "Epoch 1969 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1970 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1971 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1972 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1973 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1974 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5105882352941177\n",
      "Epoch 1975 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5115294117647059\n",
      "Epoch 1976 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1977 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 1978 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5049411764705882\n",
      "Epoch 1979 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1980 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5087058823529412\n",
      "Epoch 1981 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5016470588235294\n",
      "Epoch 1982 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.508235294117647\n",
      "Epoch 1983 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5091764705882353\n",
      "Epoch 1984 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.49929411764705883\n",
      "Epoch 1985 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5044705882352941\n",
      "Epoch 1986 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1987 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1988 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5138823529411765\n",
      "Epoch 1989 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1990 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.49741176470588233\n",
      "Epoch 1991 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5068235294117647\n",
      "Epoch 1992 Loss 0.99 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.5124705882352941\n",
      "Epoch 1993 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1994 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5096470588235295\n",
      "Epoch 1995 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 1996 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.4983529411764706\n",
      "Epoch 1997 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 1998 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5110588235294118\n",
      "Epoch 1999 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2000 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2001 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2002 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2003 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2004 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2005 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2006 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2007 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2008 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2009 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2010 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2011 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2012 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2013 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2014 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2015 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2016 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.512\n",
      "Epoch 2017 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.512\n",
      "Epoch 2018 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.496\n",
      "Epoch 2019 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2020 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2021 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2022 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5134117647058823\n",
      "Epoch 2023 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2024 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.4912941176470588\n",
      "Epoch 2025 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2026 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.512\n",
      "Epoch 2027 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2028 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2029 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2030 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.496\n",
      "Epoch 2031 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2032 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2033 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2034 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2035 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2036 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.4955294117647059\n",
      "Epoch 2037 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2038 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2039 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2040 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2041 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2042 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2043 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2044 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2045 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2046 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2047 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2048 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2049 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2050 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2051 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2052 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2053 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2054 Loss 1.00 | Train Accuracy 0.5144134604071067 | Val Accuracy 0.5148235294117647\n",
      "Epoch 2055 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2056 Loss 1.00 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5134117647058823\n",
      "Epoch 2057 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2058 Loss 1.00 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.504\n",
      "Epoch 2059 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2060 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2061 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2062 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2063 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2064 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2065 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2066 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2067 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.508235294117647\n",
      "Epoch 2068 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2069 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2070 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.504\n",
      "Epoch 2071 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2072 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2073 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 2074 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2075 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2076 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2077 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2078 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2079 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2080 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2081 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2082 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2083 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2084 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2085 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2086 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2087 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 2088 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2089 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2090 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2091 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2092 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2093 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2094 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2095 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2096 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2097 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2098 Loss 0.99 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2099 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2100 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.512\n",
      "Epoch 2101 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2102 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.504\n",
      "Epoch 2103 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2104 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2105 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2106 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2107 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2108 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2109 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2110 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2111 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2112 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2113 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2114 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2115 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2116 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2117 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2118 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2119 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2120 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2121 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2122 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2123 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.504\n",
      "Epoch 2124 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2125 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2126 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2127 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2128 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2129 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2130 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2131 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2132 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 2133 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2134 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2135 Loss 1.00 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2136 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2137 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2138 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2139 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2140 Loss 1.00 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2141 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2142 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2143 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.508235294117647\n",
      "Epoch 2144 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2145 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2146 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2147 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2148 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2149 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2150 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2151 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2152 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2153 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2154 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2155 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2156 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2157 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2158 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2159 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2160 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2161 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2162 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2163 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2164 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2165 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2166 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 2167 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2168 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2169 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2170 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5148235294117647\n",
      "Epoch 2171 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2172 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.508235294117647\n",
      "Epoch 2173 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2174 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 2175 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2176 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2177 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 2178 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2179 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2180 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2181 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2182 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2183 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.4988235294117647\n",
      "Epoch 2184 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2185 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2186 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2187 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2188 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2189 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2190 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2191 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2192 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2193 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 2194 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.49929411764705883\n",
      "Epoch 2195 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2196 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2197 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5143529411764706\n",
      "Epoch 2198 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.512\n",
      "Epoch 2199 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.508235294117647\n",
      "Epoch 2200 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.4978823529411765\n",
      "Epoch 2201 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2202 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2203 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2204 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2205 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2206 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2207 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2208 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2209 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2210 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2211 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2212 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2213 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2214 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2215 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2216 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2217 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2218 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2219 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2220 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2221 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 2222 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2223 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2224 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2225 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2226 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2227 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.504\n",
      "Epoch 2228 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2229 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2230 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2231 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2232 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2233 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2234 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2235 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2236 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2237 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2238 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2239 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2240 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2241 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2242 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2243 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2244 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2245 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2246 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2247 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2248 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2249 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2250 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2251 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2252 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2253 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2254 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2255 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2256 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2257 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2258 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2259 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2260 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2261 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2262 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2263 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2264 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2265 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2266 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 2267 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2268 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2269 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2270 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2271 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2272 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2273 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2274 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.49929411764705883\n",
      "Epoch 2275 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2276 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5134117647058823\n",
      "Epoch 2277 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2278 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2279 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2280 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2281 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2282 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2283 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2284 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2285 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2286 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2287 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2288 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2289 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2290 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2291 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2292 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2293 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2294 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2295 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2296 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2297 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2298 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2299 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2300 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2301 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2302 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2303 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2304 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2305 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2306 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2307 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2308 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2309 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.496\n",
      "Epoch 2310 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2311 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2312 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2313 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2314 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2315 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.4988235294117647\n",
      "Epoch 2316 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2317 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2318 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2319 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2320 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2321 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2322 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 2323 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2324 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2325 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2326 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2327 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2328 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2329 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2330 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2331 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 2332 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2333 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.504\n",
      "Epoch 2334 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2335 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5143529411764706\n",
      "Epoch 2336 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2337 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2338 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2339 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2340 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2341 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2342 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2343 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2344 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2345 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2346 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2347 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2348 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2349 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2350 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2351 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2352 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2353 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2354 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2355 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2356 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2357 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2358 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2359 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2360 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2361 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2362 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2363 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2364 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2365 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2366 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2367 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2368 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2369 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2370 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 2371 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2372 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2373 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2374 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.504\n",
      "Epoch 2375 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2376 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2377 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2378 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2379 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2380 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2381 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.4964705882352941\n",
      "Epoch 2382 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2383 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5138823529411765\n",
      "Epoch 2384 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2385 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2386 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2387 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.49929411764705883\n",
      "Epoch 2388 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2389 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2390 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2391 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2392 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2393 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2394 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2395 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2396 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2397 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2398 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2399 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2400 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2401 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2402 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2403 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 2404 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2405 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2406 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2407 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5134117647058823\n",
      "Epoch 2408 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2409 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2410 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2411 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2412 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2413 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2414 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2415 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2416 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2417 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2418 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2419 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2420 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2421 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2422 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2423 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2424 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2425 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2426 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2427 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2428 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2429 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2430 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2431 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.504\n",
      "Epoch 2432 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2433 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2434 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2435 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2436 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2437 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2438 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 2439 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2440 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2441 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2442 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2443 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2444 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.504\n",
      "Epoch 2445 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2446 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2447 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2448 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2449 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2450 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 2451 Loss 0.99 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2452 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2453 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2454 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2455 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2456 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2457 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2458 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2459 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 2460 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2461 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2462 Loss 0.99 | Train Accuracy 0.5230027062007295 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2463 Loss 0.99 | Train Accuracy 0.5239439934109895 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2464 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2465 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2466 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2467 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2468 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2469 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.504\n",
      "Epoch 2470 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2471 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2472 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2473 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2474 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2475 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2476 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.512\n",
      "Epoch 2477 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2478 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2479 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2480 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2481 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2482 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2483 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2484 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2485 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.49929411764705883\n",
      "Epoch 2486 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2487 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 2488 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2489 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2490 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2491 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2492 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2493 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2494 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2495 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2496 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2497 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2498 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2499 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2500 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2501 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2502 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2503 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 2504 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5134117647058823\n",
      "Epoch 2505 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2506 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2507 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2508 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.4978823529411765\n",
      "Epoch 2509 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2510 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2511 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2512 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2513 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2514 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.49929411764705883\n",
      "Epoch 2515 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2516 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2517 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2518 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2519 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2520 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2521 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2522 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2523 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 2524 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 2525 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2526 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2527 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2528 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2529 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2530 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2531 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2532 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.508235294117647\n",
      "Epoch 2533 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2534 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2535 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2536 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2537 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2538 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2539 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2540 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2541 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 2542 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2543 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2544 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.4988235294117647\n",
      "Epoch 2545 Loss 1.00 | Train Accuracy 0.5138251559006942 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2546 Loss 1.00 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5152941176470588\n",
      "Epoch 2547 Loss 1.00 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2548 Loss 1.00 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2549 Loss 1.00 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.512\n",
      "Epoch 2550 Loss 1.00 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2551 Loss 1.00 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2552 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 2553 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2554 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2555 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2556 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2557 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2558 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2559 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2560 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2561 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2562 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.49741176470588233\n",
      "Epoch 2563 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2564 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2565 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2566 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2567 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2568 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2569 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 2570 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2571 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2572 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2573 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2574 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2575 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2576 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2577 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2578 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2579 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2580 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2581 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2582 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2583 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2584 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2585 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2586 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2587 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2588 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.504\n",
      "Epoch 2589 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2590 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2591 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 2592 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2593 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2594 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.512\n",
      "Epoch 2595 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2596 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2597 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2598 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2599 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2600 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5138823529411765\n",
      "Epoch 2601 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2602 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2603 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.4978823529411765\n",
      "Epoch 2604 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2605 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2606 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2607 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2608 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2609 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4988235294117647\n",
      "Epoch 2610 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2611 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2612 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2613 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2614 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 2615 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2616 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2617 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2618 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2619 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2620 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 2621 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2622 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2623 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2624 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2625 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2626 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 2627 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2628 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2629 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2630 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2631 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2632 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 2633 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2634 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2635 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2636 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2637 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.4964705882352941\n",
      "Epoch 2638 Loss 1.00 | Train Accuracy 0.509824685257089 | Val Accuracy 0.5152941176470588\n",
      "Epoch 2639 Loss 1.00 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2640 Loss 1.00 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2641 Loss 1.00 | Train Accuracy 0.5115895987763266 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2642 Loss 1.00 | Train Accuracy 0.5135898340981292 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2643 Loss 1.00 | Train Accuracy 0.5133545122955642 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2644 Loss 1.00 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5134117647058823\n",
      "Epoch 2645 Loss 1.00 | Train Accuracy 0.5142957995058243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2646 Loss 1.00 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2647 Loss 1.00 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2648 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.504\n",
      "Epoch 2649 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2650 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2651 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2652 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2653 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2654 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2655 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2656 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2657 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2658 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2659 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2660 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2661 Loss 0.99 | Train Accuracy 0.523120367102012 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2662 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2663 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2664 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2665 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.4983529411764706\n",
      "Epoch 2666 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2667 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2668 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2669 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2670 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2671 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 2672 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2673 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 2674 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2675 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2676 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2677 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 2678 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2679 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2680 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 2681 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2682 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2683 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2684 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2685 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2686 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2687 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2688 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 2689 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2690 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2691 Loss 0.99 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5143529411764706\n",
      "Epoch 2692 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2693 Loss 1.00 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2694 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2695 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2696 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2697 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2698 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2699 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2700 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2701 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2702 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2703 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2704 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 2705 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 2706 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2707 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2708 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2709 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2710 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2711 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.504\n",
      "Epoch 2712 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2713 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2714 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2715 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2716 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2717 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2718 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2719 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2720 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2721 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2722 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2723 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.4978823529411765\n",
      "Epoch 2724 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2725 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2726 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.512\n",
      "Epoch 2727 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2728 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2729 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2730 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2731 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5138823529411765\n",
      "Epoch 2732 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.508235294117647\n",
      "Epoch 2733 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2734 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2735 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2736 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2737 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2738 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2739 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2740 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2741 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2742 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2743 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2744 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2745 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 2746 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2747 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2748 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2749 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2750 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2751 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2752 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2753 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2754 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5148235294117647\n",
      "Epoch 2755 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2756 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5096470588235295\n",
      "Epoch 2757 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2758 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2759 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2760 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2761 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2762 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2763 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2764 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.504\n",
      "Epoch 2765 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2766 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 2767 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2768 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2769 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2770 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2771 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2772 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2773 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2774 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2775 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.4964705882352941\n",
      "Epoch 2776 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2777 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5134117647058823\n",
      "Epoch 2778 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2779 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2780 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2781 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2782 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2783 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.512\n",
      "Epoch 2784 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2785 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 2786 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2787 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2788 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2789 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2790 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2791 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2792 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2793 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2794 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 2795 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2796 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2797 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2798 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2799 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2800 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2801 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2802 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2803 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2804 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2805 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2806 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5134117647058823\n",
      "Epoch 2807 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2808 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2809 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2810 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.512\n",
      "Epoch 2811 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2812 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2813 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2814 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 2815 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2816 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2817 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2818 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2819 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2820 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2821 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.4988235294117647\n",
      "Epoch 2822 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2823 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2824 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.508235294117647\n",
      "Epoch 2825 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2826 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2827 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2828 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2829 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2830 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2831 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2832 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.504\n",
      "Epoch 2833 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2834 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2835 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2836 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.508235294117647\n",
      "Epoch 2837 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.49929411764705883\n",
      "Epoch 2838 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2839 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2840 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2841 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2842 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2843 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2844 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 2845 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2846 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2847 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2848 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2849 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2850 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2851 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2852 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2853 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2854 Loss 0.99 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2855 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5148235294117647\n",
      "Epoch 2856 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.512\n",
      "Epoch 2857 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2858 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2859 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2860 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.512\n",
      "Epoch 2861 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2862 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2863 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.508235294117647\n",
      "Epoch 2864 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2865 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2866 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2867 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 2868 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2869 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2870 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2871 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2872 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2873 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2874 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2875 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2876 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2877 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2878 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 2879 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2880 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2881 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2882 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2883 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2884 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2885 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2886 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 2887 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 2888 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2889 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2890 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2891 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2892 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.508235294117647\n",
      "Epoch 2893 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2894 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2895 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2896 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2897 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2898 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2899 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4964705882352941\n",
      "Epoch 2900 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2901 Loss 1.00 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5143529411764706\n",
      "Epoch 2902 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 2903 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5124705882352941\n",
      "Epoch 2904 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 2905 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.4988235294117647\n",
      "Epoch 2906 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2907 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2908 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2909 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2910 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2911 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2912 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2913 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2914 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2915 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2916 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5002352941176471\n",
      "Epoch 2917 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2918 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2919 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2920 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2921 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.508235294117647\n",
      "Epoch 2922 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2923 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 2924 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2925 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 2926 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2927 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2928 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2929 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2930 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2931 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2932 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5129411764705882\n",
      "Epoch 2933 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2934 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.508235294117647\n",
      "Epoch 2935 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2936 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2937 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2938 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2939 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2940 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2941 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2942 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2943 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.508235294117647\n",
      "Epoch 2944 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2945 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2946 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2947 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2948 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2949 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 2950 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2951 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2952 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5025882352941177\n",
      "Epoch 2953 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2954 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2955 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 2956 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2957 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 2958 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2959 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2960 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 2961 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2962 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2963 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5007058823529412\n",
      "Epoch 2964 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2965 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5138823529411765\n",
      "Epoch 2966 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2967 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 2968 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2969 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5030588235294118\n",
      "Epoch 2970 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2971 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2972 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2973 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 2974 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2975 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2976 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 2977 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5101176470588236\n",
      "Epoch 2978 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2979 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.504\n",
      "Epoch 2980 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5011764705882353\n",
      "Epoch 2981 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5063529411764706\n",
      "Epoch 2982 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2983 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 2984 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2985 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 2986 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5021176470588236\n",
      "Epoch 2987 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 2988 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2989 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5105882352941177\n",
      "Epoch 2990 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2991 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5016470588235294\n",
      "Epoch 2992 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.49976470588235294\n",
      "Epoch 2993 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 2994 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5110588235294118\n",
      "Epoch 2995 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 2996 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5115294117647059\n",
      "Epoch 2997 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 2998 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5035294117647059\n",
      "Epoch 2999 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.512\n",
      "Epoch 3000 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3001 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3002 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 3003 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3004 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3005 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3006 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3007 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.508235294117647\n",
      "Epoch 3008 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3009 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3010 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3011 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3012 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3013 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3014 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3015 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3016 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3017 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3018 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3019 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3020 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3021 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3022 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3023 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3024 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.512\n",
      "Epoch 3025 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3026 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3027 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3028 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3029 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3030 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3031 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3032 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3033 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3034 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.49976470588235294\n",
      "Epoch 3035 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3036 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3037 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3038 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 3039 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3040 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3041 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3042 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3043 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3044 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 3045 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 3046 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3047 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3048 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3049 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3050 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3051 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3052 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3053 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3054 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3055 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 3056 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3057 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3058 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3059 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3060 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5176470588235295\n",
      "Epoch 3061 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3062 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3063 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3064 Loss 1.00 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3065 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3066 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.504\n",
      "Epoch 3067 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3068 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3069 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3070 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3071 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3072 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3073 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3074 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3075 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3076 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3077 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.504\n",
      "Epoch 3078 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3079 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.504\n",
      "Epoch 3080 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3081 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3082 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3083 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3084 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3085 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3086 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3087 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.508235294117647\n",
      "Epoch 3088 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3089 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5148235294117647\n",
      "Epoch 3090 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3091 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3092 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.4983529411764706\n",
      "Epoch 3093 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3094 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3095 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5148235294117647\n",
      "Epoch 3096 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3097 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3098 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3099 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3100 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3101 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3102 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3103 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 3104 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.4983529411764706\n",
      "Epoch 3105 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3106 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3107 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3108 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3109 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3110 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3111 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3112 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3113 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3114 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3115 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3116 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3117 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3118 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3119 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3120 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3121 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3122 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3123 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3124 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3125 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3126 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3127 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.49976470588235294\n",
      "Epoch 3128 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.49976470588235294\n",
      "Epoch 3129 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3130 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3131 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3132 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 3133 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.4964705882352941\n",
      "Epoch 3134 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3135 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3136 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3137 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3138 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3139 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3140 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3141 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3142 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3143 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3144 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3145 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3146 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3147 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3148 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3149 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3150 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3151 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3152 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3153 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3154 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3155 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3156 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3157 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3158 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3159 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3160 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.512\n",
      "Epoch 3161 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3162 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3163 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 3164 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3165 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3166 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3167 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3168 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3169 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3170 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3171 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3172 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3173 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3174 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3175 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3176 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3177 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3178 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3179 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3180 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3181 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3182 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3183 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3184 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3185 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3186 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3187 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.504\n",
      "Epoch 3188 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3189 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3190 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3191 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3192 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3193 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3194 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3195 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5148235294117647\n",
      "Epoch 3196 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3197 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3198 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3199 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3200 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3201 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3202 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.508235294117647\n",
      "Epoch 3203 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3204 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3205 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3206 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3207 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3208 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3209 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3210 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3211 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.504\n",
      "Epoch 3212 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3213 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3214 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3215 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3216 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3217 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3218 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3219 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3220 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3221 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3222 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3223 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3224 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3225 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3226 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3227 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3228 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3229 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 3230 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3231 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3232 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3233 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3234 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3235 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3236 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3237 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3238 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3239 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3240 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.4978823529411765\n",
      "Epoch 3241 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3242 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3243 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3244 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3245 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.504\n",
      "Epoch 3246 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3247 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3248 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.508235294117647\n",
      "Epoch 3249 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3250 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3251 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3252 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3253 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3254 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3255 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3256 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3257 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3258 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3259 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3260 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3261 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3262 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3263 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3264 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3265 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3266 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.512\n",
      "Epoch 3267 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3268 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3269 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3270 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5148235294117647\n",
      "Epoch 3271 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5176470588235295\n",
      "Epoch 3272 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5143529411764706\n",
      "Epoch 3273 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3274 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3275 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3276 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3277 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3278 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3279 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3280 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3281 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3282 Loss 0.99 | Train Accuracy 0.5234733498058595 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3283 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3284 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.508235294117647\n",
      "Epoch 3285 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3286 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3287 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.504\n",
      "Epoch 3288 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.508235294117647\n",
      "Epoch 3289 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3290 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3291 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3292 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3293 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.504\n",
      "Epoch 3294 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3295 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.508235294117647\n",
      "Epoch 3296 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3297 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3298 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3299 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3300 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5148235294117647\n",
      "Epoch 3301 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3302 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3303 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3304 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3305 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.512\n",
      "Epoch 3306 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5152941176470588\n",
      "Epoch 3307 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3308 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3309 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3310 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3311 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3312 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3313 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3314 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3315 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3316 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3317 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3318 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3319 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 3320 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3321 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.49976470588235294\n",
      "Epoch 3322 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3323 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3324 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3325 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3326 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3327 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.49976470588235294\n",
      "Epoch 3328 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3329 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3330 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3331 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 3332 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3333 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3334 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3335 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3336 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 3337 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3338 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3339 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.512\n",
      "Epoch 3340 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3341 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3342 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3343 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3344 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3345 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3346 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3347 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3348 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3349 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3350 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3351 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3352 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3353 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3354 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3355 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3356 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3357 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3358 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3359 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 3360 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3361 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.4983529411764706\n",
      "Epoch 3362 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3363 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3364 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3365 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.512\n",
      "Epoch 3366 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.504\n",
      "Epoch 3367 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3368 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3369 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3370 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3371 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3372 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3373 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3374 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3375 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3376 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3377 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.4983529411764706\n",
      "Epoch 3378 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3379 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3380 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3381 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3382 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3383 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3384 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3385 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3386 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 3387 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3388 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3389 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3390 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3391 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3392 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3393 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3394 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3395 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3396 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3397 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3398 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3399 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3400 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3401 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3402 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3403 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3404 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3405 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3406 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3407 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3408 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3409 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3410 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3411 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3412 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3413 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3414 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3415 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3416 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.504\n",
      "Epoch 3417 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3418 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.512\n",
      "Epoch 3419 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3420 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3421 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3422 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3423 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5143529411764706\n",
      "Epoch 3424 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3425 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3426 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 3427 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3428 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3429 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3430 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3431 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3432 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3433 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3434 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3435 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 3436 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3437 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3438 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3439 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.496\n",
      "Epoch 3440 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3441 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3442 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3443 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3444 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3445 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.496\n",
      "Epoch 3446 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3447 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3448 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3449 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3450 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3451 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.4955294117647059\n",
      "Epoch 3452 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3453 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3454 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3455 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3456 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.49976470588235294\n",
      "Epoch 3457 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3458 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3459 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3460 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3461 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3462 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3463 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3464 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.512\n",
      "Epoch 3465 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5152941176470588\n",
      "Epoch 3466 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3467 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.504\n",
      "Epoch 3468 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3469 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3470 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3471 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3472 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3473 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3474 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3475 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3476 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3477 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 3478 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3479 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.49741176470588233\n",
      "Epoch 3480 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3481 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3482 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3483 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3484 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3485 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3486 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3487 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3488 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3489 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3490 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3491 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3492 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 3493 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3494 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3495 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3496 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3497 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3498 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3499 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3500 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3501 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3502 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 3503 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3504 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.504\n",
      "Epoch 3505 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.508235294117647\n",
      "Epoch 3506 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3507 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3508 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3509 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3510 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3511 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3512 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3513 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3514 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3515 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3516 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3517 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3518 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3519 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 3520 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3521 Loss 0.99 | Train Accuracy 0.5232380280032946 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3522 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3523 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3524 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3525 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3526 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3527 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3528 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3529 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.512\n",
      "Epoch 3530 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3531 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3532 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3533 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.49976470588235294\n",
      "Epoch 3534 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3535 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.512\n",
      "Epoch 3536 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3537 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3538 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 3539 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.4978823529411765\n",
      "Epoch 3540 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3541 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3542 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3543 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3544 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3545 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3546 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.504\n",
      "Epoch 3547 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 3548 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3549 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3550 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3551 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3552 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3553 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 3554 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 3555 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3556 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3557 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3558 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3559 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3560 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3561 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3562 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3563 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3564 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3565 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3566 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3567 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3568 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.4978823529411765\n",
      "Epoch 3569 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3570 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3571 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3572 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3573 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3574 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3575 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3576 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3577 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3578 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3579 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3580 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3581 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3582 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.508235294117647\n",
      "Epoch 3583 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 3584 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3585 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3586 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3587 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3588 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3589 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3590 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3591 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3592 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3593 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 3594 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.504\n",
      "Epoch 3595 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3596 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3597 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3598 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3599 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3600 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3601 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3602 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3603 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3604 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3605 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3606 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3607 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3608 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3609 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 3610 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3611 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3612 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3613 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3614 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3615 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3616 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3617 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3618 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3619 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3620 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3621 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3622 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3623 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3624 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3625 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3626 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3627 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3628 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3629 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3630 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3631 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3632 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3633 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3634 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3635 Loss 0.99 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3636 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3637 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3638 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3639 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3640 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3641 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.508235294117647\n",
      "Epoch 3642 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3643 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 3644 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3645 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.504\n",
      "Epoch 3646 Loss 0.99 | Train Accuracy 0.523355688904577 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3647 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3648 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 3649 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 3650 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3651 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3652 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3653 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.4898823529411765\n",
      "Epoch 3654 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3655 Loss 1.00 | Train Accuracy 0.5114719378750441 | Val Accuracy 0.5167058823529411\n",
      "Epoch 3656 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3657 Loss 1.00 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3658 Loss 1.00 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3659 Loss 1.00 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3660 Loss 1.00 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3661 Loss 1.00 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3662 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 3663 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3664 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3665 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3666 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3667 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3668 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3669 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.504\n",
      "Epoch 3670 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3671 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3672 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3673 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3674 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49976470588235294\n",
      "Epoch 3675 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3676 Loss 0.99 | Train Accuracy 0.523355688904577 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3677 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3678 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3679 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3680 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3681 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3682 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3683 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3684 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3685 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3686 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3687 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3688 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3689 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3690 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3691 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3692 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3693 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.508235294117647\n",
      "Epoch 3694 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3695 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3696 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3697 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3698 Loss 1.00 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.508235294117647\n",
      "Epoch 3699 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5148235294117647\n",
      "Epoch 3700 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3701 Loss 1.00 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3702 Loss 1.00 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3703 Loss 1.00 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3704 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3705 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3706 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3707 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3708 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 3709 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3710 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3711 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3712 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3713 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3714 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.504\n",
      "Epoch 3715 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3716 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3717 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3718 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3719 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3720 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3721 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3722 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3723 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3724 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3725 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3726 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3727 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 3728 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3729 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3730 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3731 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3732 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3733 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3734 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3735 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 3736 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3737 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 3738 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3739 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3740 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3741 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3742 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3743 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3744 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3745 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3746 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3747 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3748 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5134117647058823\n",
      "Epoch 3749 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3750 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3751 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3752 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3753 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3754 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3755 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3756 Loss 0.99 | Train Accuracy 0.5230027062007295 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3757 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3758 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3759 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 3760 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3761 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3762 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3763 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3764 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3765 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3766 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3767 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3768 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3769 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3770 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3771 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3772 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3773 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.508235294117647\n",
      "Epoch 3774 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3775 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3776 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3777 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 3778 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3779 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3780 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3781 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3782 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3783 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3784 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5115294117647059\n",
      "Epoch 3785 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3786 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3787 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3788 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.4983529411764706\n",
      "Epoch 3789 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3790 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3791 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3792 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 3793 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3794 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.4978823529411765\n",
      "Epoch 3795 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3796 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3797 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3798 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3799 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3800 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3801 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3802 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3803 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3804 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3805 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3806 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3807 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3808 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3809 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3810 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.504\n",
      "Epoch 3811 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.504\n",
      "Epoch 3812 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3813 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3814 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.504\n",
      "Epoch 3815 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3816 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3817 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3818 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3819 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3820 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3821 Loss 1.00 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3822 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3823 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3824 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.504\n",
      "Epoch 3825 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.508235294117647\n",
      "Epoch 3826 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3827 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3828 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3829 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3830 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3831 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 3832 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3833 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.508235294117647\n",
      "Epoch 3834 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3835 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3836 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3837 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3838 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.508235294117647\n",
      "Epoch 3839 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3840 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.508235294117647\n",
      "Epoch 3841 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.504\n",
      "Epoch 3842 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3843 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3844 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3845 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3846 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3847 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3848 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3849 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3850 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5138823529411765\n",
      "Epoch 3851 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3852 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3853 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3854 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3855 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3856 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3857 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3858 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3859 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.4983529411764706\n",
      "Epoch 3860 Loss 0.99 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3861 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.512\n",
      "Epoch 3862 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3863 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3864 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3865 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3866 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3867 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3868 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3869 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3870 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3871 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3872 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3873 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3874 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3875 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3876 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.49929411764705883\n",
      "Epoch 3877 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3878 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 3879 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3880 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3881 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3882 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3883 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3884 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3885 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 3886 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3887 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3888 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3889 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 3890 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3891 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3892 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3893 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3894 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3895 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 3896 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3897 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3898 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3899 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 3900 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5011764705882353\n",
      "Epoch 3901 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3902 Loss 1.00 | Train Accuracy 0.5135898340981292 | Val Accuracy 0.5152941176470588\n",
      "Epoch 3903 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3904 Loss 1.00 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5143529411764706\n",
      "Epoch 3905 Loss 1.00 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3906 Loss 1.00 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3907 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.4988235294117647\n",
      "Epoch 3908 Loss 1.00 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3909 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3910 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3911 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3912 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3913 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3914 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.4983529411764706\n",
      "Epoch 3915 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3916 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3917 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3918 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3919 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3920 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3921 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3922 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3923 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3924 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3925 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3926 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3927 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3928 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3929 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3930 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3931 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3932 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3933 Loss 0.99 | Train Accuracy 0.5230027062007295 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3934 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3935 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3936 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3937 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3938 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3939 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3940 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3941 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3942 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3943 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3944 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3945 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.508235294117647\n",
      "Epoch 3946 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5068235294117647\n",
      "Epoch 3947 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 3948 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3949 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3950 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3951 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3952 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3953 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3954 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3955 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.4950588235294118\n",
      "Epoch 3956 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 3957 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5124705882352941\n",
      "Epoch 3958 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3959 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3960 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3961 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5002352941176471\n",
      "Epoch 3962 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3963 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3964 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3965 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3966 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5007058823529412\n",
      "Epoch 3967 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3968 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3969 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.512\n",
      "Epoch 3970 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3971 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3972 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5030588235294118\n",
      "Epoch 3973 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3974 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 3975 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 3976 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3977 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3978 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5044705882352941\n",
      "Epoch 3979 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5025882352941177\n",
      "Epoch 3980 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 3981 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3982 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 3983 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5105882352941177\n",
      "Epoch 3984 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3985 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5021176470588236\n",
      "Epoch 3986 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 3987 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5110588235294118\n",
      "Epoch 3988 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.508235294117647\n",
      "Epoch 3989 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 3990 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 3991 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.4983529411764706\n",
      "Epoch 3992 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5087058823529412\n",
      "Epoch 3993 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5129411764705882\n",
      "Epoch 3994 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "Epoch 3995 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5063529411764706\n",
      "Epoch 3996 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 3997 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5016470588235294\n",
      "Epoch 3998 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5101176470588236\n",
      "Epoch 3999 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.512\n",
      "Epoch 4000 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4001 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4002 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4003 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4004 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4005 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4006 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4007 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4008 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4009 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4010 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4011 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4012 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4013 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4014 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 4015 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4016 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4017 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4018 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4019 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4020 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4021 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4022 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4023 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4024 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4025 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4026 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4027 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4028 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4029 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4030 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4031 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4032 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4033 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4034 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4035 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4036 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4037 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4038 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4039 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4040 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4041 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4042 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4043 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4044 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 4045 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4046 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4047 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4048 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4049 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4050 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4051 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4052 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4053 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4054 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 4055 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4056 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4057 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4058 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5138823529411765\n",
      "Epoch 4059 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4060 Loss 0.99 | Train Accuracy 0.523120367102012 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4061 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4062 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4063 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4064 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4065 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4066 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4067 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4068 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4069 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 4070 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4071 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4072 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4073 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4074 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5134117647058823\n",
      "Epoch 4075 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4076 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4077 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4078 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.49411764705882355\n",
      "Epoch 4079 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 4080 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4081 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4082 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4083 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4084 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4085 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 4086 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4087 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4088 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4089 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4090 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.4983529411764706\n",
      "Epoch 4091 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4092 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4093 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4094 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4095 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4096 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4097 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4098 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4099 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4100 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4101 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4102 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4103 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4104 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4105 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4106 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4107 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.4983529411764706\n",
      "Epoch 4108 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4109 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5143529411764706\n",
      "Epoch 4110 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4111 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4112 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 4113 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.504\n",
      "Epoch 4114 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4115 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4116 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4117 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4118 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4119 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4120 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4121 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4122 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4123 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.49929411764705883\n",
      "Epoch 4124 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4125 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4126 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4127 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4128 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4129 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4130 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4131 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4132 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4133 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4134 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4135 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4136 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4137 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4138 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4139 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.504\n",
      "Epoch 4140 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4141 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4142 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4143 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4144 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4145 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4146 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.4964705882352941\n",
      "Epoch 4147 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4148 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5148235294117647\n",
      "Epoch 4149 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4150 Loss 1.00 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5143529411764706\n",
      "Epoch 4151 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4152 Loss 1.00 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4153 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4154 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4155 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4156 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4157 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4158 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4159 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4988235294117647\n",
      "Epoch 4160 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4161 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4162 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4163 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4164 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4165 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.49929411764705883\n",
      "Epoch 4166 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4167 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4168 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4169 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4170 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.504\n",
      "Epoch 4171 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4172 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4173 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.512\n",
      "Epoch 4174 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4175 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4176 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4177 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.504\n",
      "Epoch 4178 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4179 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4180 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4181 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4182 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4183 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.508235294117647\n",
      "Epoch 4184 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4185 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4186 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4187 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4188 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4189 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.508235294117647\n",
      "Epoch 4190 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4191 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4192 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4193 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4194 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4195 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4196 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4197 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5138823529411765\n",
      "Epoch 4198 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4199 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4200 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4201 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.49929411764705883\n",
      "Epoch 4202 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4203 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4204 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4205 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4206 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4207 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4208 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4209 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4210 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4211 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4212 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.504\n",
      "Epoch 4213 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4214 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4215 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4216 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4217 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4218 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4219 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4220 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4221 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4222 Loss 0.99 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4223 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4224 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4225 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 4226 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.504\n",
      "Epoch 4227 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4228 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4229 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4230 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4231 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4232 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4233 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4234 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4235 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4236 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 4237 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4238 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5138823529411765\n",
      "Epoch 4239 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 4240 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4241 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4242 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4243 Loss 0.99 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4244 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4245 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4246 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4247 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4248 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4249 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4250 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4251 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4252 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.508235294117647\n",
      "Epoch 4253 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.504\n",
      "Epoch 4254 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4255 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4256 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.512\n",
      "Epoch 4257 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4258 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4259 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4260 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4261 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4262 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4263 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4264 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4265 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4266 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4267 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4268 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4269 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4270 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4271 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4272 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4273 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4274 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4275 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4276 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4277 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4278 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4279 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4280 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4281 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4282 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4283 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4284 Loss 0.99 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4285 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4286 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4287 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4288 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 4289 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4290 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4291 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5143529411764706\n",
      "Epoch 4292 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4293 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4294 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4295 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4296 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.512\n",
      "Epoch 4297 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.512\n",
      "Epoch 4298 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4299 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4300 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4301 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4302 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4303 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4304 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4305 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4306 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4307 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4308 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4309 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4310 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4311 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4312 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4313 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4314 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4315 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4316 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4317 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4318 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.504\n",
      "Epoch 4319 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4320 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4321 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4322 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4323 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4324 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.504\n",
      "Epoch 4325 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4326 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4327 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4328 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4329 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4330 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5134117647058823\n",
      "Epoch 4331 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4332 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4333 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4334 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4335 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4336 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.512\n",
      "Epoch 4337 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4338 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4339 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4340 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4341 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4342 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4343 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4344 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4345 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4346 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4347 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4348 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4349 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4350 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4351 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4352 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4353 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4354 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4355 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4356 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4357 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 4358 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4359 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.504\n",
      "Epoch 4360 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4361 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4362 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4363 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4364 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4365 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4366 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4367 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4368 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4369 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4370 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4371 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4372 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 4373 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 4374 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4375 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4376 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4377 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4378 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4379 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4380 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4381 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4382 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4383 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4384 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4385 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4386 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4387 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4388 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.512\n",
      "Epoch 4389 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4390 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4391 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4392 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4393 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4394 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4395 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4396 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4397 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4398 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4399 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4400 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4401 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4402 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.4978823529411765\n",
      "Epoch 4403 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4404 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4405 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4406 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4407 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4408 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4409 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4410 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4411 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4412 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4413 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4414 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.49741176470588233\n",
      "Epoch 4415 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4416 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4417 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4418 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4419 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.504\n",
      "Epoch 4420 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4421 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4422 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4423 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 4424 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4425 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4426 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4427 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4428 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4429 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4430 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4431 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4432 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4433 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4434 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5134117647058823\n",
      "Epoch 4435 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4436 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4437 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.4964705882352941\n",
      "Epoch 4438 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4439 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5138823529411765\n",
      "Epoch 4440 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4441 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4442 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4443 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4444 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.508235294117647\n",
      "Epoch 4445 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4446 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4447 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4448 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4449 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4450 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4451 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4452 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4453 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4454 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4455 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4456 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4457 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4458 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.508235294117647\n",
      "Epoch 4459 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4460 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 4461 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4462 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.504\n",
      "Epoch 4463 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.512\n",
      "Epoch 4464 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4465 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4466 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4467 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4468 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4469 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4470 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4471 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.508235294117647\n",
      "Epoch 4472 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.4969411764705882\n",
      "Epoch 4473 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4474 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.508235294117647\n",
      "Epoch 4475 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4476 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4477 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 4478 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.504\n",
      "Epoch 4479 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.4988235294117647\n",
      "Epoch 4480 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4481 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4482 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.504\n",
      "Epoch 4483 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4484 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4485 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4486 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4487 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4488 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4489 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4490 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4491 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4492 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4493 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4494 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4495 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4496 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4497 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4498 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4499 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4500 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4501 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4502 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4503 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4504 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4505 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4506 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4507 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4508 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.512\n",
      "Epoch 4509 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4510 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4511 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4512 Loss 0.99 | Train Accuracy 0.5144134604071067 | Val Accuracy 0.512\n",
      "Epoch 4513 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4514 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4515 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.508235294117647\n",
      "Epoch 4516 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.4950588235294118\n",
      "Epoch 4517 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4518 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5138823529411765\n",
      "Epoch 4519 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4520 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5134117647058823\n",
      "Epoch 4521 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4522 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4523 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.4964705882352941\n",
      "Epoch 4524 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4525 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.512\n",
      "Epoch 4526 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4527 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 4528 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4529 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4530 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.4988235294117647\n",
      "Epoch 4531 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4532 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4533 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4534 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4535 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4536 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.49929411764705883\n",
      "Epoch 4537 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4538 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4539 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 4540 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4541 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4542 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4543 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4544 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.512\n",
      "Epoch 4545 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4546 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4547 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 4548 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4549 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4550 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4551 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4552 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4553 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4554 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4555 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5143529411764706\n",
      "Epoch 4556 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4557 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4558 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4559 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4560 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4561 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4562 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4563 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4564 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4565 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4566 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4567 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4568 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5143529411764706\n",
      "Epoch 4569 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4570 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4571 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4572 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.508235294117647\n",
      "Epoch 4573 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4574 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4575 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4576 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4577 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4578 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4579 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4580 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4581 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4582 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4583 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.4950588235294118\n",
      "Epoch 4584 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4585 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4586 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 4587 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4588 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.508235294117647\n",
      "Epoch 4589 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4590 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4591 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5143529411764706\n",
      "Epoch 4592 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.508235294117647\n",
      "Epoch 4593 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4594 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 4595 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4596 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4597 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4598 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4599 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4600 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 4601 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4602 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4603 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4604 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4605 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.504\n",
      "Epoch 4606 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.504\n",
      "Epoch 4607 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4608 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4609 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4610 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4611 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4612 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4613 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4614 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4615 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 4616 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4617 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4618 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.508235294117647\n",
      "Epoch 4619 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4620 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4621 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4622 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4623 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5157647058823529\n",
      "Epoch 4624 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4625 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4626 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4627 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4628 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 4629 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4630 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4631 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4632 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4633 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4634 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4635 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4636 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4637 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4638 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4639 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4640 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 4641 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.512\n",
      "Epoch 4642 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4643 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4644 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4645 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4646 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4647 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4648 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4649 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4650 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4651 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4652 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4653 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4654 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4655 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.49929411764705883\n",
      "Epoch 4656 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4657 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4658 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.512\n",
      "Epoch 4659 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4660 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4661 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4662 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.4983529411764706\n",
      "Epoch 4663 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4664 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4665 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4666 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4667 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4668 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.4978823529411765\n",
      "Epoch 4669 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4670 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4671 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4672 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4673 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4674 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4675 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4676 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4677 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4678 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4679 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 4680 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4681 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4682 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4683 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4684 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4685 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4686 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4687 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4688 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4689 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4690 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 4691 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.49741176470588233\n",
      "Epoch 4692 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4693 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5134117647058823\n",
      "Epoch 4694 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4695 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4696 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4697 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.4983529411764706\n",
      "Epoch 4698 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4699 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4700 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4701 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4702 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4703 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4704 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4705 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4706 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4707 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4708 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4709 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.49741176470588233\n",
      "Epoch 4710 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4711 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4712 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4713 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4714 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4715 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.4969411764705882\n",
      "Epoch 4716 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 4717 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4718 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4719 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4720 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4721 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4722 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4723 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4724 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4725 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4726 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4727 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4728 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4729 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5134117647058823\n",
      "Epoch 4730 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4731 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.508235294117647\n",
      "Epoch 4732 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4733 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4734 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4735 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4736 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4737 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4738 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4739 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4740 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4741 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5138823529411765\n",
      "Epoch 4742 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4743 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.508235294117647\n",
      "Epoch 4744 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4745 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.49929411764705883\n",
      "Epoch 4746 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4747 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4748 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4749 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4750 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4751 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4752 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4753 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5143529411764706\n",
      "Epoch 4754 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4755 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4756 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4757 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4758 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4759 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4760 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4761 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4762 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 4763 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4764 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4765 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4766 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4767 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4768 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4769 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4770 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4771 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4772 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.508235294117647\n",
      "Epoch 4773 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4774 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4775 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4776 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4777 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.512\n",
      "Epoch 4778 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4779 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4780 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4781 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4782 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4783 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4784 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4785 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4786 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4787 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4788 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4789 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4790 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4791 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4792 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4793 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4794 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4795 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5134117647058823\n",
      "Epoch 4796 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4797 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4798 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4799 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4800 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4801 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4802 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4803 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4804 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4805 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4806 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4807 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4808 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4809 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 4810 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4811 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4812 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4813 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4814 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4815 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4816 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4817 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 4818 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5143529411764706\n",
      "Epoch 4819 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4820 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4821 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4822 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.4988235294117647\n",
      "Epoch 4823 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 4824 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4825 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4826 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4827 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4828 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4829 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4830 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4831 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4832 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4833 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4834 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.4978823529411765\n",
      "Epoch 4835 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4836 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4837 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4838 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4839 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4840 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4841 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4842 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.512\n",
      "Epoch 4843 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4844 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4845 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.4988235294117647\n",
      "Epoch 4846 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4847 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5124705882352941\n",
      "Epoch 4848 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4849 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4850 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4851 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.4969411764705882\n",
      "Epoch 4852 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4853 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4854 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4855 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4856 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4857 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.49929411764705883\n",
      "Epoch 4858 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.504\n",
      "Epoch 4859 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4860 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4861 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4862 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4863 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4864 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4865 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4866 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4867 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 4868 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.504\n",
      "Epoch 4869 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4870 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4871 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4872 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4873 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4874 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4875 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4876 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4877 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4878 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4879 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.4988235294117647\n",
      "Epoch 4880 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.49929411764705883\n",
      "Epoch 4881 Loss 1.00 | Train Accuracy 0.5128838686904341 | Val Accuracy 0.5167058823529411\n",
      "Epoch 4882 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4883 Loss 1.00 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.516235294117647\n",
      "Epoch 4884 Loss 1.00 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4885 Loss 1.00 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4886 Loss 1.00 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4887 Loss 1.00 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4888 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4889 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5134117647058823\n",
      "Epoch 4890 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4891 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4892 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4893 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5016470588235294\n",
      "Epoch 4894 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4895 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4896 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4897 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.49929411764705883\n",
      "Epoch 4898 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4899 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.4983529411764706\n",
      "Epoch 4900 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4901 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4902 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4903 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4904 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5021176470588236\n",
      "Epoch 4905 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4906 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 4907 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4908 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4909 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4910 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 4911 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4912 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4913 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4914 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4915 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4916 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4917 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.504\n",
      "Epoch 4918 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5129411764705882\n",
      "Epoch 4919 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5134117647058823\n",
      "Epoch 4920 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4921 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4922 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4923 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4924 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4925 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.512\n",
      "Epoch 4926 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4927 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4928 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.508235294117647\n",
      "Epoch 4929 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 4930 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4931 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4932 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4933 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4934 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4935 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4936 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4937 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4938 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4939 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.508235294117647\n",
      "Epoch 4940 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4941 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5007058823529412\n",
      "Epoch 4942 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4943 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4944 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5110588235294118\n",
      "Epoch 4945 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4946 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4947 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4948 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5105882352941177\n",
      "Epoch 4949 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4950 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4951 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4952 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4953 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5011764705882353\n",
      "Epoch 4954 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4955 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.512\n",
      "Epoch 4956 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4957 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4958 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4959 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4960 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 4961 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4962 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 4963 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 4964 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4965 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 4966 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4967 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4968 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 4969 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4970 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4971 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4972 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4973 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4974 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4975 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4976 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4977 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4978 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4979 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4980 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 4981 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5025882352941177\n",
      "Epoch 4982 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.4983529411764706\n",
      "Epoch 4983 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5058823529411764\n",
      "Epoch 4984 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5115294117647059\n",
      "Epoch 4985 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 4986 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5087058823529412\n",
      "Epoch 4987 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4988 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5002352941176471\n",
      "Epoch 4989 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5091764705882353\n",
      "Epoch 4990 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5096470588235295\n",
      "Epoch 4991 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5077647058823529\n",
      "Epoch 4992 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 4993 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 4994 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.49976470588235294\n",
      "Epoch 4995 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4996 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 4997 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 4998 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 4999 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5000 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5001 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5002 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5003 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5004 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5005 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5006 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5007 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5008 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5009 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5010 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5011 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5012 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.49976470588235294\n",
      "Epoch 5013 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5014 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5015 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 5016 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5017 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5018 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5019 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5020 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5021 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5022 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5023 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5024 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.504\n",
      "Epoch 5025 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5026 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5027 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5028 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5029 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 5030 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5031 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5032 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5033 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5034 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5035 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5036 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.504\n",
      "Epoch 5037 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5038 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5039 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5040 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5041 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5042 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5043 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.508235294117647\n",
      "Epoch 5044 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5045 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5046 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.49741176470588233\n",
      "Epoch 5047 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5048 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5049 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.512\n",
      "Epoch 5050 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5051 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.504\n",
      "Epoch 5052 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5053 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5054 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5055 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5056 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5057 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5058 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5059 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5060 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5061 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5062 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5063 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.4978823529411765\n",
      "Epoch 5064 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5065 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5066 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5067 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5068 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5069 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.49741176470588233\n",
      "Epoch 5070 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.508235294117647\n",
      "Epoch 5071 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5148235294117647\n",
      "Epoch 5072 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5073 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5074 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5075 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5076 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5077 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5078 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5079 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5080 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5081 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5082 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5083 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5084 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5085 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5086 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5087 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5088 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5089 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5090 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5091 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5092 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5093 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5094 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5095 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5096 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.508235294117647\n",
      "Epoch 5097 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5098 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5099 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5100 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5101 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5102 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5103 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5104 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5105 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5106 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5107 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5108 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 5109 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5110 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5111 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5112 Loss 1.00 | Train Accuracy 0.5140604777032592 | Val Accuracy 0.5152941176470588\n",
      "Epoch 5113 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5114 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5152941176470588\n",
      "Epoch 5115 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5116 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.49976470588235294\n",
      "Epoch 5117 Loss 1.00 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5118 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5119 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5120 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5121 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5122 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5123 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5124 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5125 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5126 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5127 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5128 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5129 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5130 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5131 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5132 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5133 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5134 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.508235294117647\n",
      "Epoch 5135 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5136 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5137 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5138 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.504\n",
      "Epoch 5139 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5140 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5141 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5142 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5143 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5144 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5145 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5146 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5147 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5148 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5149 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5150 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 5151 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5152 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5153 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5154 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5155 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5156 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5157 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5158 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5159 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5160 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5161 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5162 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5163 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5164 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5165 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 5166 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.504\n",
      "Epoch 5167 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5168 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5169 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5170 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5171 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.504\n",
      "Epoch 5172 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5173 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 5174 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5175 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5176 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5177 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5178 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5179 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.49458823529411766\n",
      "Epoch 5180 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5181 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5182 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5183 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5184 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5185 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.4969411764705882\n",
      "Epoch 5186 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5187 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5188 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5189 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5190 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5191 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5192 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5193 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5194 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5195 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5196 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5197 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 5198 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5199 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5200 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5201 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5202 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 5203 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5204 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5205 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5206 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5207 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5208 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5209 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5210 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5211 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.496\n",
      "Epoch 5212 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5213 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5214 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 5215 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5216 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5217 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.4978823529411765\n",
      "Epoch 5218 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5219 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5220 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5221 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5222 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5223 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5224 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5225 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5226 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5227 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5228 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5229 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5230 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5231 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5232 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5233 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5234 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5235 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5236 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5237 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5238 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5239 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.4908235294117647\n",
      "Epoch 5240 Loss 0.99 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5241 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5242 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5243 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5244 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5245 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.496\n",
      "Epoch 5246 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5247 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.512\n",
      "Epoch 5248 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5249 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5250 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5251 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5252 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5253 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5254 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 5255 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5256 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5257 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5258 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5259 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5260 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 5261 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5262 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5263 Loss 0.99 | Train Accuracy 0.5230027062007295 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5264 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5265 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5266 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5267 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5268 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5269 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5270 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5271 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5272 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5273 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5274 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5275 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5276 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5277 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5278 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5279 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5280 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5281 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.512\n",
      "Epoch 5282 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5283 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5284 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5285 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5286 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5287 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5288 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 5289 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.504\n",
      "Epoch 5290 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.4988235294117647\n",
      "Epoch 5291 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5292 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.512\n",
      "Epoch 5293 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5294 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5295 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5296 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.4969411764705882\n",
      "Epoch 5297 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5298 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5299 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5300 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5301 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5302 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5303 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5304 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5143529411764706\n",
      "Epoch 5305 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5306 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5307 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5308 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5309 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5310 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5311 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5312 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5313 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5314 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5315 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 5316 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5317 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5318 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 5319 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5320 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5321 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5322 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5323 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5324 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5325 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5326 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5327 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5328 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5329 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5330 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5331 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.4988235294117647\n",
      "Epoch 5332 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5333 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5334 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5335 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5336 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5337 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5338 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5339 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5340 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5341 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5342 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5343 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.49976470588235294\n",
      "Epoch 5344 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5345 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5346 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5347 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5348 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5349 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5350 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5351 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5352 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5353 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5354 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.504\n",
      "Epoch 5355 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5356 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5357 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5358 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5359 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5360 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5361 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5362 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5363 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5364 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5365 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5366 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5367 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5368 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5369 Loss 0.99 | Train Accuracy 0.5232380280032946 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5370 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5371 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5372 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5373 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5374 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5375 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5376 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5377 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5378 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.4978823529411765\n",
      "Epoch 5379 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5380 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5143529411764706\n",
      "Epoch 5381 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5382 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5383 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5384 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5385 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5386 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.512\n",
      "Epoch 5387 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5388 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5389 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5390 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5391 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5392 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5393 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5394 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5395 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.49976470588235294\n",
      "Epoch 5396 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.49976470588235294\n",
      "Epoch 5397 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5398 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5399 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5400 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 5401 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5402 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5403 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5404 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5405 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5406 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5407 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.504\n",
      "Epoch 5408 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5409 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5410 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 5411 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5412 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5413 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5414 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5415 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5148235294117647\n",
      "Epoch 5416 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5417 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5418 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.508235294117647\n",
      "Epoch 5419 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5420 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5421 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5422 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5423 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5424 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5425 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5426 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5427 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5428 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.508235294117647\n",
      "Epoch 5429 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5430 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5431 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.49976470588235294\n",
      "Epoch 5432 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5433 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5434 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5435 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5436 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5437 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.4988235294117647\n",
      "Epoch 5438 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5439 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5440 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5441 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5442 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5443 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5444 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5445 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.512\n",
      "Epoch 5446 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5447 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5448 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5449 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.504\n",
      "Epoch 5450 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5451 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5452 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5453 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5454 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5455 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5456 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5457 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5458 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5459 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5460 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5461 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5462 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5463 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5464 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5465 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5466 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5467 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 5468 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5469 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 5470 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5471 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5472 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5473 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5474 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5475 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5476 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5477 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5478 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5479 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5480 Loss 1.00 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.5152941176470588\n",
      "Epoch 5481 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5482 Loss 1.00 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5483 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5484 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5485 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.4988235294117647\n",
      "Epoch 5486 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5487 Loss 0.99 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5488 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5489 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5490 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5491 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5492 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5493 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5494 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5495 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5496 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.504\n",
      "Epoch 5497 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5498 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5499 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5500 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5501 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5502 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5503 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5504 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5505 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5506 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5507 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5508 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5509 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5510 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5511 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5512 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5513 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5514 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5515 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5516 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5517 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5518 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5519 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 5520 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5521 Loss 0.99 | Train Accuracy 0.523591010707142 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5522 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5523 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5524 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5525 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5526 Loss 1.00 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.512\n",
      "Epoch 5527 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5528 Loss 1.00 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5529 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5530 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5531 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5532 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 5533 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5534 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5535 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5536 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5537 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 5538 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 5539 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5540 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5541 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5542 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5543 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5544 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5545 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5546 Loss 0.99 | Train Accuracy 0.5232380280032946 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5547 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5548 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 5549 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5550 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5551 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5552 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5553 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5554 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5555 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5143529411764706\n",
      "Epoch 5556 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5557 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5558 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5559 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5560 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5561 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5562 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5563 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 5564 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5565 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5566 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5567 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5568 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 5569 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5570 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5571 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5572 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5573 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5138823529411765\n",
      "Epoch 5574 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5575 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5576 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5577 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5578 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.512\n",
      "Epoch 5579 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5580 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5581 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5582 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5583 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5584 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5585 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5586 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5587 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5588 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5589 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5590 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5591 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 5592 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5593 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.4988235294117647\n",
      "Epoch 5594 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5595 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5596 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5597 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5598 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5599 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5600 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5601 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5602 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5603 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 5604 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5605 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5606 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5607 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5608 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5609 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5610 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 5611 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.49976470588235294\n",
      "Epoch 5612 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5613 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5614 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5615 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5616 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5617 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5618 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 5619 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5620 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5621 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5622 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5623 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5624 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5625 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5626 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 5627 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.508235294117647\n",
      "Epoch 5628 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.4988235294117647\n",
      "Epoch 5629 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5630 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5138823529411765\n",
      "Epoch 5631 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5632 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5633 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5634 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.4969411764705882\n",
      "Epoch 5635 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5636 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.512\n",
      "Epoch 5637 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5638 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.512\n",
      "Epoch 5639 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5640 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5641 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5642 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5643 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5644 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5645 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5646 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5647 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5648 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 5649 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5650 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5651 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5652 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.504\n",
      "Epoch 5653 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5654 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5655 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5656 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5657 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5658 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5659 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.49976470588235294\n",
      "Epoch 5660 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5661 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.512\n",
      "Epoch 5662 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5663 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5664 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5665 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.49741176470588233\n",
      "Epoch 5666 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5667 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5668 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5669 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5670 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 5671 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5672 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5673 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5674 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5675 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5676 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5677 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5678 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5679 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5680 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5681 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5682 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5683 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5684 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5685 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5686 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5687 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5688 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5689 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5690 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5691 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5692 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5693 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5694 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5695 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5696 Loss 0.99 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5697 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5698 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5699 Loss 1.00 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5700 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5701 Loss 1.00 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5702 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5703 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5704 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5705 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5706 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5707 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5708 Loss 0.99 | Train Accuracy 0.523355688904577 | Val Accuracy 0.512\n",
      "Epoch 5709 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5710 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5711 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5712 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5713 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5714 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 5715 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5716 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5717 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5718 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5719 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5720 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5721 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5722 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5723 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5724 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 5725 Loss 0.99 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5726 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5727 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5728 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.504\n",
      "Epoch 5729 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5730 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5731 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5732 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5733 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 5734 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5735 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5736 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5737 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5738 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5739 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.508235294117647\n",
      "Epoch 5740 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5741 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5742 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.4988235294117647\n",
      "Epoch 5743 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5744 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5745 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5746 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 5747 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5748 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5749 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5750 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5138823529411765\n",
      "Epoch 5751 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5752 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5753 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5754 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5755 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5756 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5757 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5758 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5759 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5760 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5761 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.508235294117647\n",
      "Epoch 5762 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5763 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5764 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5765 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5766 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5767 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5768 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5769 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5770 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.504\n",
      "Epoch 5771 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5772 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5773 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5774 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.512\n",
      "Epoch 5775 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5776 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5777 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5778 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5779 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5780 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5781 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5782 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5783 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5784 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.49741176470588233\n",
      "Epoch 5785 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5786 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5138823529411765\n",
      "Epoch 5787 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5788 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5789 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5790 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5791 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 5792 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5793 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5794 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5795 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5796 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5797 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5798 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5799 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5800 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5801 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5802 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5803 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5804 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5805 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5806 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5807 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5808 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5809 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5810 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5811 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5812 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5813 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5814 Loss 1.00 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5148235294117647\n",
      "Epoch 5815 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5816 Loss 1.00 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5143529411764706\n",
      "Epoch 5817 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5818 Loss 1.00 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5819 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5820 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5821 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5822 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5823 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5824 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5825 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5826 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.512\n",
      "Epoch 5827 Loss 0.99 | Train Accuracy 0.523120367102012 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5828 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5829 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5830 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5831 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5832 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5833 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5834 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5835 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5836 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.504\n",
      "Epoch 5837 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5838 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5839 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5840 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5841 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5842 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5843 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.508235294117647\n",
      "Epoch 5844 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.508235294117647\n",
      "Epoch 5845 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 5846 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5847 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5848 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5849 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5850 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5851 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5852 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5853 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5854 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5138823529411765\n",
      "Epoch 5855 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5856 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5857 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5858 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5859 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5860 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5861 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5862 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5863 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5864 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5865 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5866 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5867 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.508235294117647\n",
      "Epoch 5868 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5869 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 5870 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5871 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5872 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5873 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5874 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5875 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5876 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5877 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5878 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5879 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5880 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.4978823529411765\n",
      "Epoch 5881 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5882 Loss 1.00 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5143529411764706\n",
      "Epoch 5883 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5884 Loss 1.00 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5885 Loss 1.00 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.512\n",
      "Epoch 5886 Loss 1.00 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5887 Loss 1.00 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5888 Loss 1.00 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5889 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5890 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5891 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5892 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5893 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5894 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5895 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5896 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5897 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5898 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5899 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5900 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5901 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.4983529411764706\n",
      "Epoch 5902 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5903 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 5904 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5905 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5906 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5907 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5908 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5909 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5910 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5911 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 5912 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5913 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5914 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 5915 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.512\n",
      "Epoch 5916 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5917 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5918 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5919 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5920 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 5921 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5110588235294118\n",
      "Epoch 5922 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5923 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 5924 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5925 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5926 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5134117647058823\n",
      "Epoch 5927 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5928 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5929 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5930 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5931 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5932 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5933 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5934 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5007058823529412\n",
      "Epoch 5935 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5936 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5937 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5938 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5939 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5044705882352941\n",
      "Epoch 5940 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5941 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5942 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5943 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5944 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5945 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.504\n",
      "Epoch 5946 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5947 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5948 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 5949 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.504\n",
      "Epoch 5950 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5951 Loss 1.00 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5152941176470588\n",
      "Epoch 5952 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.512\n",
      "Epoch 5953 Loss 1.00 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5129411764705882\n",
      "Epoch 5954 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5955 Loss 1.00 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5956 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5957 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5958 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5959 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 5960 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 5961 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5962 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 5963 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5964 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5965 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 5966 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5967 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.49929411764705883\n",
      "Epoch 5968 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5969 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 5970 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5016470588235294\n",
      "Epoch 5971 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5972 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5973 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5974 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5975 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5976 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 5977 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 5978 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 5979 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5980 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.504\n",
      "Epoch 5981 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5982 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5115294117647059\n",
      "Epoch 5983 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5984 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5985 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5011764705882353\n",
      "Epoch 5986 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.512\n",
      "Epoch 5987 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5124705882352941\n",
      "Epoch 5988 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 5989 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5990 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5991 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5030588235294118\n",
      "Epoch 5992 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5058823529411764\n",
      "Epoch 5993 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5994 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 5995 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 5996 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5002352941176471\n",
      "Epoch 5997 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.512\n",
      "Epoch 5998 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5105882352941177\n",
      "Epoch 5999 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6000 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6001 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6002 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6003 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6004 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6005 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6006 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6007 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6008 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6009 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 6010 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.512\n",
      "Epoch 6011 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6012 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 6013 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6014 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.4988235294117647\n",
      "Epoch 6015 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6016 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6017 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6018 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6019 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6020 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6021 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6022 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6023 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6024 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6025 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6026 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6027 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6028 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6029 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6030 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6031 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6032 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6033 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6034 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.504\n",
      "Epoch 6035 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6036 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6037 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6038 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.508235294117647\n",
      "Epoch 6039 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6040 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6041 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6042 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6043 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6044 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6045 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.496\n",
      "Epoch 6046 Loss 1.00 | Train Accuracy 0.5122955641840217 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6047 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5148235294117647\n",
      "Epoch 6048 Loss 1.00 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5157647058823529\n",
      "Epoch 6049 Loss 1.00 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6050 Loss 1.00 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6051 Loss 1.00 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6052 Loss 1.00 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6053 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6054 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.508235294117647\n",
      "Epoch 6055 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6056 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6057 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6058 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.49976470588235294\n",
      "Epoch 6059 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6060 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6061 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6062 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.504\n",
      "Epoch 6063 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6064 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6065 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.4988235294117647\n",
      "Epoch 6066 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.49976470588235294\n",
      "Epoch 6067 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6068 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6069 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6070 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6071 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6072 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6073 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6074 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6075 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6076 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.508235294117647\n",
      "Epoch 6077 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6078 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6079 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6080 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6081 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6082 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6083 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6084 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6085 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5148235294117647\n",
      "Epoch 6086 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6087 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6088 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6089 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6090 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6091 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.512\n",
      "Epoch 6092 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6093 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6094 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6095 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6096 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.512\n",
      "Epoch 6097 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.512\n",
      "Epoch 6098 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.508235294117647\n",
      "Epoch 6099 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6100 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6101 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6102 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6103 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6104 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6105 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6106 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6107 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6108 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 6109 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6110 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6111 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6112 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6113 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 6114 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6115 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6116 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6117 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6118 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6119 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6120 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6121 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 6122 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6123 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6124 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.508235294117647\n",
      "Epoch 6125 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6126 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6127 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 6128 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.4983529411764706\n",
      "Epoch 6129 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6130 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6131 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6132 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6133 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6134 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.49976470588235294\n",
      "Epoch 6135 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6136 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6137 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6138 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6139 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6140 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6141 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6142 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6143 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6144 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6145 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6146 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6147 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6148 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 6149 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 6150 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.504\n",
      "Epoch 6151 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6152 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6153 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6154 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6155 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6156 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6157 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6158 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6159 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6160 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6161 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5143529411764706\n",
      "Epoch 6162 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6163 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 6164 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6165 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.49741176470588233\n",
      "Epoch 6166 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6167 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5143529411764706\n",
      "Epoch 6168 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6169 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6170 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6171 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6172 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6173 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.512\n",
      "Epoch 6174 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6175 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 6176 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6177 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6178 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6179 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6180 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6181 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6182 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 6183 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6184 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6185 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6186 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6187 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 6188 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 6189 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6190 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6191 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6192 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6193 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6194 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.49458823529411766\n",
      "Epoch 6195 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6196 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6197 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6198 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6199 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6200 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.4978823529411765\n",
      "Epoch 6201 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6202 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6203 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6204 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6205 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6206 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6207 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6208 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6209 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6210 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6211 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6212 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6213 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6214 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6215 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6216 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6217 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6218 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6219 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6220 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5143529411764706\n",
      "Epoch 6221 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6222 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.512\n",
      "Epoch 6223 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6224 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6225 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6226 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 6227 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.512\n",
      "Epoch 6228 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6229 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6230 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6231 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6232 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6233 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6234 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6235 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6236 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6237 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6238 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6239 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6240 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6241 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.504\n",
      "Epoch 6242 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6243 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6244 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6245 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6246 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6247 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6248 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 6249 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6250 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6251 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6252 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6253 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5138823529411765\n",
      "Epoch 6254 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6255 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6256 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6257 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6258 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6259 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6260 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.508235294117647\n",
      "Epoch 6261 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6262 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6263 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6264 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6265 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6266 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6267 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6268 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6269 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6270 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6271 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6272 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6273 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6274 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6275 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6276 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6277 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6278 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6279 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6280 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6281 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6282 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.508235294117647\n",
      "Epoch 6283 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6284 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6285 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 6286 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6287 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6288 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6289 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6290 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6291 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6292 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6293 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6294 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6295 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5143529411764706\n",
      "Epoch 6296 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6297 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6298 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6299 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6300 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6301 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6302 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 6303 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6304 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6305 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6306 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5143529411764706\n",
      "Epoch 6307 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6308 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6309 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6310 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.4955294117647059\n",
      "Epoch 6311 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6312 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6313 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6314 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6315 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6316 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6317 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6318 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.512\n",
      "Epoch 6319 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6320 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6321 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6322 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6323 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6324 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6325 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6326 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6327 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6328 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6329 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6330 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6331 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6332 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6333 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6334 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6335 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6336 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6337 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6338 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6339 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6340 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6341 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.512\n",
      "Epoch 6342 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.512\n",
      "Epoch 6343 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6344 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6345 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6346 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6347 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6348 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6349 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.508235294117647\n",
      "Epoch 6350 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.4969411764705882\n",
      "Epoch 6351 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6352 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.512\n",
      "Epoch 6353 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6354 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6355 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6356 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6357 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6358 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6359 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6360 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6361 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6362 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6363 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6364 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6365 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6366 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6367 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6368 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6369 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6370 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.504\n",
      "Epoch 6371 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6372 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6373 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 6374 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6375 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6376 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.512\n",
      "Epoch 6377 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6378 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6379 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.4988235294117647\n",
      "Epoch 6380 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6381 Loss 0.99 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6382 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5138823529411765\n",
      "Epoch 6383 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6384 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6385 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.4983529411764706\n",
      "Epoch 6386 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6387 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6388 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.512\n",
      "Epoch 6389 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6390 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6391 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.4988235294117647\n",
      "Epoch 6392 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6393 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6394 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6395 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 6396 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6397 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6398 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6399 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6400 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6401 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6402 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6403 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6404 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6405 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6406 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6407 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6408 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6409 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6410 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6411 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6412 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6413 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6414 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6415 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6416 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6417 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6418 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6419 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6420 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6421 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6422 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6423 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5138823529411765\n",
      "Epoch 6424 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6425 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6426 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6427 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6428 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6429 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 6430 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 6431 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6432 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6433 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6434 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6435 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6436 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.508235294117647\n",
      "Epoch 6437 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.4964705882352941\n",
      "Epoch 6438 Loss 1.00 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6439 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6440 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.504\n",
      "Epoch 6441 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6442 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6443 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.504\n",
      "Epoch 6444 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6445 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6446 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 6447 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.504\n",
      "Epoch 6448 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6449 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.4983529411764706\n",
      "Epoch 6450 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6451 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6452 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6453 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6454 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6455 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6456 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6457 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6458 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6459 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6460 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6461 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 6462 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5134117647058823\n",
      "Epoch 6463 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6464 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6465 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6466 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.4964705882352941\n",
      "Epoch 6467 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6468 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6469 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6470 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6471 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 6472 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6473 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6474 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6475 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5134117647058823\n",
      "Epoch 6476 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6477 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6478 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6479 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6480 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6481 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6482 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6483 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6484 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6485 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6486 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6487 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6488 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6489 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6490 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 6491 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6492 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6493 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6494 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6495 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6496 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6497 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6498 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6499 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6500 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 6501 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6502 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.504\n",
      "Epoch 6503 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6504 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5143529411764706\n",
      "Epoch 6505 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6506 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6507 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.4988235294117647\n",
      "Epoch 6508 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 6509 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6510 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6511 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6512 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6513 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6514 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6515 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6516 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6517 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6518 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6519 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6520 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6521 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6522 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6523 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6524 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6525 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6526 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6527 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6528 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6529 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6530 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6531 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6532 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6533 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5134117647058823\n",
      "Epoch 6534 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6535 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.508235294117647\n",
      "Epoch 6536 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6537 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6538 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6539 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.512\n",
      "Epoch 6540 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6541 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6542 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6543 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6544 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6545 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.508235294117647\n",
      "Epoch 6546 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6547 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6548 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6549 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6550 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6551 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6552 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6553 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6554 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6555 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6556 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6557 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6558 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6559 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 6560 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6561 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6562 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6563 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6564 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6565 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6566 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6567 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6568 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6569 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6570 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6571 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.504\n",
      "Epoch 6572 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6573 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6574 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5138823529411765\n",
      "Epoch 6575 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6576 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6577 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6578 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6579 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6580 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6581 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6582 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6583 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6584 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6585 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.512\n",
      "Epoch 6586 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6587 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6588 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 6589 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6590 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6591 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6592 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6593 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6594 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6595 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6596 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6597 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6598 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6599 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6600 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6601 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6602 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6603 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6604 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6605 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6606 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6607 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6608 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6609 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6610 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6611 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6612 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.4950588235294118\n",
      "Epoch 6613 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6614 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5138823529411765\n",
      "Epoch 6615 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6616 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.512\n",
      "Epoch 6617 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6618 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.504\n",
      "Epoch 6619 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6620 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6621 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6622 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6623 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6624 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6625 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6626 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6627 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6628 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6629 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6630 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6631 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6632 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6633 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6634 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.508235294117647\n",
      "Epoch 6635 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6636 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6637 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6638 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6639 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6640 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.512\n",
      "Epoch 6641 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6642 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6643 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6644 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6645 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6646 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6647 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6648 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6649 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6650 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6651 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5134117647058823\n",
      "Epoch 6652 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6653 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6654 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6655 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.4983529411764706\n",
      "Epoch 6656 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 6657 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6658 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6659 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6660 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6661 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6662 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6663 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6664 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6665 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6666 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6667 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6668 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6669 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6670 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6671 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6672 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6673 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6674 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6675 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6676 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6677 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6678 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6679 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6680 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5134117647058823\n",
      "Epoch 6681 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6682 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.4988235294117647\n",
      "Epoch 6683 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.508235294117647\n",
      "Epoch 6684 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6685 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6686 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6687 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6688 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6689 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6690 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6691 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6692 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6693 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6694 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6695 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6696 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6697 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6698 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6699 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6700 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6701 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6702 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6703 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6704 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6705 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.512\n",
      "Epoch 6706 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6707 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6708 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 6709 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6710 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6711 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6712 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6713 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6714 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6715 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 6716 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6717 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6718 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6719 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6720 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6721 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.508235294117647\n",
      "Epoch 6722 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6723 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6724 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6725 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6726 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6727 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.504\n",
      "Epoch 6728 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6729 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6730 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6731 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6732 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6733 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6734 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6735 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6736 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6737 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6738 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6739 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6740 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6741 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6742 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6743 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6744 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.508235294117647\n",
      "Epoch 6745 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6746 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6747 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6748 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6749 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.504\n",
      "Epoch 6750 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5134117647058823\n",
      "Epoch 6751 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6752 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6753 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6754 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.504\n",
      "Epoch 6755 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6756 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6757 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6758 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 6759 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.508235294117647\n",
      "Epoch 6760 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6761 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6762 Loss 0.99 | Train Accuracy 0.5230027062007295 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6763 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6764 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6765 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6766 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6767 Loss 0.99 | Train Accuracy 0.523826332509707 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6768 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6769 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6770 Loss 0.99 | Train Accuracy 0.523355688904577 | Val Accuracy 0.4969411764705882\n",
      "Epoch 6771 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 6772 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6773 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6774 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6775 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6776 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6777 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6778 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.508235294117647\n",
      "Epoch 6779 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6780 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6781 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.49411764705882355\n",
      "Epoch 6782 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6783 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6784 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6785 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6786 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6787 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.4964705882352941\n",
      "Epoch 6788 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6789 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.512\n",
      "Epoch 6790 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6791 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.508235294117647\n",
      "Epoch 6792 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6793 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.4969411764705882\n",
      "Epoch 6794 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6795 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5134117647058823\n",
      "Epoch 6796 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6797 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6798 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6799 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6800 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6801 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6802 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6803 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6804 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6805 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6806 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6807 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6808 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6809 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6810 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6811 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6812 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6813 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6814 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6815 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6816 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6817 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6818 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6819 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6820 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6821 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6822 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6823 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6824 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6825 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.512\n",
      "Epoch 6826 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 6827 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6828 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6829 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.4988235294117647\n",
      "Epoch 6830 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6831 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6832 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6833 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6834 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6835 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6836 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 6837 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6838 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6839 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6840 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5011764705882353\n",
      "Epoch 6841 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6842 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6843 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6844 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6845 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6846 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6847 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6848 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6849 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6850 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6851 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6852 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.504\n",
      "Epoch 6853 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.512\n",
      "Epoch 6854 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.512\n",
      "Epoch 6855 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6856 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6857 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6858 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6859 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6860 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6861 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6862 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6863 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6864 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6865 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 6866 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6867 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6868 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6869 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6870 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6871 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6872 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6873 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6874 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6875 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6876 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6877 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6878 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.512\n",
      "Epoch 6879 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 6880 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6881 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6882 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.49929411764705883\n",
      "Epoch 6883 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6884 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6885 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6886 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6887 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6888 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6889 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6890 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6891 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6892 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6893 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6894 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5002352941176471\n",
      "Epoch 6895 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6896 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5115294117647059\n",
      "Epoch 6897 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6898 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6899 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6900 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6901 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6902 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6903 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6904 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 6905 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6906 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6907 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5101176470588236\n",
      "Epoch 6908 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5105882352941177\n",
      "Epoch 6909 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.508235294117647\n",
      "Epoch 6910 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6911 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6912 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6913 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6914 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6915 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6916 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6917 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6918 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6919 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6920 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 6921 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6922 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6923 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6924 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6925 Loss 1.00 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5157647058823529\n",
      "Epoch 6926 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6927 Loss 1.00 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5152941176470588\n",
      "Epoch 6928 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6929 Loss 1.00 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6930 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6931 Loss 1.00 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6932 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6933 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5124705882352941\n",
      "Epoch 6934 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6935 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6936 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 6937 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6938 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6939 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6940 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6941 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6942 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5007058823529412\n",
      "Epoch 6943 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5016470588235294\n",
      "Epoch 6944 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 6945 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6946 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 6947 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6948 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6949 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6950 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6951 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6952 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6953 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6954 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6955 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6956 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6957 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5077647058823529\n",
      "Epoch 6958 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6959 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6960 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 6961 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6962 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6963 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6964 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5110588235294118\n",
      "Epoch 6965 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.504\n",
      "Epoch 6966 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 6967 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6968 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6969 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6970 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5129411764705882\n",
      "Epoch 6971 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6972 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6973 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.508235294117647\n",
      "Epoch 6974 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5096470588235295\n",
      "Epoch 6975 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6976 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6977 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6978 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5025882352941177\n",
      "Epoch 6979 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6980 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6981 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6982 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 6983 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5035294117647059\n",
      "Epoch 6984 Loss 0.99 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5021176470588236\n",
      "Epoch 6985 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6986 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6987 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6988 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6989 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5072941176470588\n",
      "Epoch 6990 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 6991 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 6992 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5049411764705882\n",
      "Epoch 6993 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 6994 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 6995 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 6996 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.512\n",
      "Epoch 6997 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 6998 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 6999 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7000 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7001 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7002 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7003 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7004 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7005 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7006 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7007 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7008 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7009 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7010 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.49929411764705883\n",
      "Epoch 7011 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7012 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7013 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 7014 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7015 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7016 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4969411764705882\n",
      "Epoch 7017 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7018 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7019 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7020 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7021 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7022 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.4988235294117647\n",
      "Epoch 7023 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7024 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.512\n",
      "Epoch 7025 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7026 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7027 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7028 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7029 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7030 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7031 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7032 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7033 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7034 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7035 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7036 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7037 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7038 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7039 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7040 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7041 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7042 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 7043 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 7044 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7045 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7046 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7047 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7048 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7049 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7050 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7051 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7052 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7053 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7054 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7055 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7056 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7057 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 7058 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.508235294117647\n",
      "Epoch 7059 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 7060 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7061 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7062 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7063 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7064 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.512\n",
      "Epoch 7065 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5148235294117647\n",
      "Epoch 7066 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7067 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7068 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7069 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7070 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7071 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7072 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7073 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7074 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7075 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5167058823529411\n",
      "Epoch 7076 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7077 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 7078 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.504\n",
      "Epoch 7079 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.4969411764705882\n",
      "Epoch 7080 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7081 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7082 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7083 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 7084 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7085 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.49929411764705883\n",
      "Epoch 7086 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7087 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7088 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7089 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7090 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7091 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7092 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7093 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7094 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 7095 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7096 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7097 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7098 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 7099 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7100 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7101 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7102 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7103 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7104 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7105 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7106 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7107 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7108 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7109 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7110 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.508235294117647\n",
      "Epoch 7111 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7112 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 7113 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7114 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7115 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7116 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5157647058823529\n",
      "Epoch 7117 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7118 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7119 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7120 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7121 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7122 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7123 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7124 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7125 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7126 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7127 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7128 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 7129 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7130 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7131 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7132 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7133 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7134 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7135 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7136 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.504\n",
      "Epoch 7137 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7138 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7139 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7140 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7141 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7142 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7143 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7144 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7145 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.508235294117647\n",
      "Epoch 7146 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 7147 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7148 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7149 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7150 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7151 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5143529411764706\n",
      "Epoch 7152 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.512\n",
      "Epoch 7153 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7154 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.4978823529411765\n",
      "Epoch 7155 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7156 Loss 0.99 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7157 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7158 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5134117647058823\n",
      "Epoch 7159 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 7160 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.4983529411764706\n",
      "Epoch 7161 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7162 Loss 0.99 | Train Accuracy 0.5230027062007295 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7163 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7164 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7165 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7166 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7167 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7168 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7169 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7170 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7171 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 7172 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7173 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7174 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7175 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7176 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 7177 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7178 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7179 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7180 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7181 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7182 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7183 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7184 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7185 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7186 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7187 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7188 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7189 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7190 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7191 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.4988235294117647\n",
      "Epoch 7192 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7193 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5134117647058823\n",
      "Epoch 7194 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7195 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7196 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7197 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7198 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7199 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.508235294117647\n",
      "Epoch 7200 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7201 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7202 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7203 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7204 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7205 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7206 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7207 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7208 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7209 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7210 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7211 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7212 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7213 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7214 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7215 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7216 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5134117647058823\n",
      "Epoch 7217 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 7218 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7219 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7220 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7221 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7222 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7223 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.508235294117647\n",
      "Epoch 7224 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 7225 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.504\n",
      "Epoch 7226 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.4983529411764706\n",
      "Epoch 7227 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7228 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5143529411764706\n",
      "Epoch 7229 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7230 Loss 1.00 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7231 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7232 Loss 1.00 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7233 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7234 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7235 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7236 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 7237 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7238 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7239 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7240 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7241 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7242 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7243 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7244 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7245 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7246 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7247 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7248 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7249 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 7250 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7251 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 7252 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7253 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7254 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7255 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7256 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7257 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7258 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7259 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7260 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7261 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7262 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7263 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 7264 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7265 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7266 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7267 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7268 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7269 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7270 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7271 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7272 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7273 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7274 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.504\n",
      "Epoch 7275 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.504\n",
      "Epoch 7276 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7277 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7278 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7279 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7280 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7281 Loss 0.99 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5157647058823529\n",
      "Epoch 7282 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.508235294117647\n",
      "Epoch 7283 Loss 1.00 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7284 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7285 Loss 1.00 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7286 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7287 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7288 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7289 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7290 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7291 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7292 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7293 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7294 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7295 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7296 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7297 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7298 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7299 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 7300 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 7301 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7302 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7303 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7304 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7305 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 7306 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7307 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7308 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7309 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7310 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7311 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7312 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7313 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7314 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7315 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7316 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.49741176470588233\n",
      "Epoch 7317 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7318 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7319 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 7320 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7321 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.508235294117647\n",
      "Epoch 7322 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7323 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7324 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7325 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7326 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7327 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7328 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7329 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7330 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7331 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7332 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7333 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7334 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7335 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7336 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7337 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7338 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.504\n",
      "Epoch 7339 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7340 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7341 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7342 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7343 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7344 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7345 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7346 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7347 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7348 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7349 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 7350 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7351 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7352 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7353 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7354 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5138823529411765\n",
      "Epoch 7355 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7356 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 7357 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7358 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7359 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.504\n",
      "Epoch 7360 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7361 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7362 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7363 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7364 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7365 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7366 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7367 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7368 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7369 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7370 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 7371 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7372 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.508235294117647\n",
      "Epoch 7373 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7374 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7375 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7376 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7377 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.508235294117647\n",
      "Epoch 7378 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7379 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7380 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7381 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7382 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5138823529411765\n",
      "Epoch 7383 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7384 Loss 1.00 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7385 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7386 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7387 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7388 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7389 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7390 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7391 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7392 Loss 0.99 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7393 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7394 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7395 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7396 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7397 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7398 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7399 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7400 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7401 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7402 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7403 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7404 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7405 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7406 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7407 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7408 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7409 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.504\n",
      "Epoch 7410 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7411 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7412 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 7413 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7414 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7415 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7416 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7417 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 7418 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7419 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7420 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7421 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7422 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7423 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7424 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.49929411764705883\n",
      "Epoch 7425 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7426 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7427 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7428 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7429 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7430 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7431 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7432 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7433 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49741176470588233\n",
      "Epoch 7434 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7435 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7436 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 7437 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 7438 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7439 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7440 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7441 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7442 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7443 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7444 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7445 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7446 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7447 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7448 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7449 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7450 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7451 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7452 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7453 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7454 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7455 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7456 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7457 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7458 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7459 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7460 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7461 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7462 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7463 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7464 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.512\n",
      "Epoch 7465 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7466 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7467 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7468 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4964705882352941\n",
      "Epoch 7469 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7470 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7471 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7472 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7473 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7474 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7475 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.4983529411764706\n",
      "Epoch 7476 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7477 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7478 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7479 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7480 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7481 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7482 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7483 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7484 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7485 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7486 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7487 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7488 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7489 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7490 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7491 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7492 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7493 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7494 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7495 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7496 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7497 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7498 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7499 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.504\n",
      "Epoch 7500 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7501 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5148235294117647\n",
      "Epoch 7502 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7503 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7504 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7505 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.512\n",
      "Epoch 7506 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7507 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7508 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7509 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7510 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7511 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7512 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7513 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7514 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7515 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7516 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4978823529411765\n",
      "Epoch 7517 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 7518 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7519 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7520 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7521 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7522 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7523 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7524 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5148235294117647\n",
      "Epoch 7525 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7526 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 7527 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7528 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7529 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7530 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7531 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7532 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.504\n",
      "Epoch 7533 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7534 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7535 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7536 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7537 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7538 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7539 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7540 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7541 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7542 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.508235294117647\n",
      "Epoch 7543 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7544 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7545 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7546 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7547 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5134117647058823\n",
      "Epoch 7548 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7549 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7550 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7551 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.49929411764705883\n",
      "Epoch 7552 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7553 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7554 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7555 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.504\n",
      "Epoch 7556 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7557 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7558 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7559 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7560 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7561 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7562 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 7563 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7564 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7565 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7566 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7567 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7568 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7569 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7570 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7571 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7572 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7573 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7574 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7575 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7576 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7577 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5134117647058823\n",
      "Epoch 7578 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7579 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7580 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7581 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7582 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7583 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 7584 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7585 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7586 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7587 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7588 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7589 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7590 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7591 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7592 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7593 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5138823529411765\n",
      "Epoch 7594 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7595 Loss 1.00 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7596 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7597 Loss 1.00 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7598 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7599 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7600 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7601 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 7602 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7603 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7604 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7605 Loss 0.99 | Train Accuracy 0.5232380280032946 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7606 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7607 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7608 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7609 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7610 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7611 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 7612 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7613 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7614 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7615 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7616 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 7617 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7618 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7619 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7620 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7621 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7622 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7623 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7624 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7625 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7626 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7627 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7628 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.508235294117647\n",
      "Epoch 7629 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7630 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7631 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7632 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7633 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7634 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7635 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7636 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7637 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7638 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7639 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7640 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7641 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7642 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7643 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7644 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.512\n",
      "Epoch 7645 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7646 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7647 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7648 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7649 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7650 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7651 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7652 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7653 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7654 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7655 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7656 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7657 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7658 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7659 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7660 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7661 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.4978823529411765\n",
      "Epoch 7662 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 7663 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7664 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7665 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 7666 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7667 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.4978823529411765\n",
      "Epoch 7668 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7669 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5157647058823529\n",
      "Epoch 7670 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7671 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7672 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7673 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7674 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7675 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7676 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7677 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7678 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7679 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7680 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7681 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7682 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7683 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7684 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7685 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7686 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7687 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7688 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7689 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7690 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 7691 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7692 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.508235294117647\n",
      "Epoch 7693 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5134117647058823\n",
      "Epoch 7694 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7695 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7696 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7697 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7698 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7699 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7700 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7701 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7702 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7703 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49929411764705883\n",
      "Epoch 7704 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5152941176470588\n",
      "Epoch 7705 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7706 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5138823529411765\n",
      "Epoch 7707 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7708 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7709 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7710 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7711 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7712 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7713 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7714 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7715 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7716 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7717 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7718 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7719 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7720 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7721 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7722 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7723 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7724 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7725 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7726 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7727 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7728 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7729 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7730 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7731 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7732 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7733 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7734 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7735 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7736 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7737 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7738 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.4978823529411765\n",
      "Epoch 7739 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7740 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7741 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7742 Loss 1.00 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7743 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7744 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7745 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7746 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.508235294117647\n",
      "Epoch 7747 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.512\n",
      "Epoch 7748 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7749 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7750 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.504\n",
      "Epoch 7751 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7752 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7753 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7754 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7755 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7756 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7757 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7758 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7759 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.508235294117647\n",
      "Epoch 7760 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7761 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7762 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7763 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7764 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7765 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7766 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7767 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7768 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7769 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7770 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7771 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7772 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7773 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7774 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.504\n",
      "Epoch 7775 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7776 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.504\n",
      "Epoch 7777 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.508235294117647\n",
      "Epoch 7778 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7779 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7780 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.504\n",
      "Epoch 7781 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7782 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7783 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.49411764705882355\n",
      "Epoch 7784 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7785 Loss 0.99 | Train Accuracy 0.5142957995058243 | Val Accuracy 0.5138823529411765\n",
      "Epoch 7786 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7787 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7788 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7789 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.49458823529411766\n",
      "Epoch 7790 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7791 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7792 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7793 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7794 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7795 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7796 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.4988235294117647\n",
      "Epoch 7797 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7798 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7799 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7800 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7801 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7802 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.4969411764705882\n",
      "Epoch 7803 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7804 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7805 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7806 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7807 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7808 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.4983529411764706\n",
      "Epoch 7809 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7810 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7811 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 7812 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7813 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7814 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7815 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7816 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5138823529411765\n",
      "Epoch 7817 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7818 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7819 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7820 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7821 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.512\n",
      "Epoch 7822 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7823 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 7824 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7825 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7826 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7827 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5148235294117647\n",
      "Epoch 7828 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5134117647058823\n",
      "Epoch 7829 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7830 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 7831 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.504\n",
      "Epoch 7832 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.508235294117647\n",
      "Epoch 7833 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7834 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7835 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7836 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7837 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.49929411764705883\n",
      "Epoch 7838 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7839 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5138823529411765\n",
      "Epoch 7840 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7841 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7842 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.4978823529411765\n",
      "Epoch 7843 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7844 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5134117647058823\n",
      "Epoch 7845 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7846 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7847 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7848 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7849 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7850 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7851 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7852 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7853 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7854 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7855 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7856 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7857 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7858 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7859 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7860 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7861 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7862 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7863 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7864 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7865 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7866 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7867 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7868 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7869 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.508235294117647\n",
      "Epoch 7870 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7871 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7872 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7873 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7874 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5148235294117647\n",
      "Epoch 7875 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7876 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7877 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7878 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 7879 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 7880 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.512\n",
      "Epoch 7881 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 7882 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7883 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7884 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7885 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.512\n",
      "Epoch 7886 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.508235294117647\n",
      "Epoch 7887 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7888 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7889 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.504\n",
      "Epoch 7890 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7891 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7892 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7893 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7894 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7895 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7896 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5138823529411765\n",
      "Epoch 7897 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7898 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.508235294117647\n",
      "Epoch 7899 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7900 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7901 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7902 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.512\n",
      "Epoch 7903 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7904 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7905 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7906 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7907 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7908 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7909 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7910 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7911 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7912 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7913 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7914 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7915 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7916 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 7917 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7918 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7919 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7920 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7921 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.504\n",
      "Epoch 7922 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7923 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7924 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7925 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7926 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7927 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7928 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7929 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7930 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7931 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7932 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5124705882352941\n",
      "Epoch 7933 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7934 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7935 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 7936 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7937 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.512\n",
      "Epoch 7938 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5148235294117647\n",
      "Epoch 7939 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.508235294117647\n",
      "Epoch 7940 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7941 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.504\n",
      "Epoch 7942 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7943 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7944 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.512\n",
      "Epoch 7945 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.508235294117647\n",
      "Epoch 7946 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7947 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7948 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5011764705882353\n",
      "Epoch 7949 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7950 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7951 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7952 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7953 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7954 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7955 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.508235294117647\n",
      "Epoch 7956 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.512\n",
      "Epoch 7957 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7958 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7959 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 7960 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5002352941176471\n",
      "Epoch 7961 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7962 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5134117647058823\n",
      "Epoch 7963 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7964 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7965 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5025882352941177\n",
      "Epoch 7966 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7967 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5110588235294118\n",
      "Epoch 7968 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7969 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 7970 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7971 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7972 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5007058823529412\n",
      "Epoch 7973 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7974 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7975 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 7976 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7977 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 7978 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5016470588235294\n",
      "Epoch 7979 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 7980 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5115294117647059\n",
      "Epoch 7981 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7982 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5105882352941177\n",
      "Epoch 7983 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5044705882352941\n",
      "Epoch 7984 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5021176470588236\n",
      "Epoch 7985 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7986 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5101176470588236\n",
      "Epoch 7987 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7988 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7989 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5049411764705882\n",
      "Epoch 7990 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4964705882352941\n",
      "Epoch 7991 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5091764705882353\n",
      "Epoch 7992 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5129411764705882\n",
      "Epoch 7993 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 7994 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 7995 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 7996 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.49976470588235294\n",
      "Epoch 7997 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 7998 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5068235294117647\n",
      "Epoch 7999 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8000 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8001 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8002 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8003 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8004 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8005 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8006 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8007 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8008 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8009 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8010 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8011 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8012 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8013 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8014 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8015 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8016 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8017 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8018 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8019 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8020 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8021 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8022 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8023 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8024 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8025 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8026 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8027 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8028 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8029 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8030 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8031 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8032 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.512\n",
      "Epoch 8033 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8034 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8035 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 8036 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8037 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8038 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8039 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8040 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8041 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8042 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8043 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8044 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.508235294117647\n",
      "Epoch 8045 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8046 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8047 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.504\n",
      "Epoch 8048 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8049 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 8050 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8051 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8052 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8053 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8054 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8055 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8056 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.512\n",
      "Epoch 8057 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8058 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8059 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8060 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8061 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 8062 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.512\n",
      "Epoch 8063 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8064 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8065 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8066 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.4983529411764706\n",
      "Epoch 8067 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8068 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5157647058823529\n",
      "Epoch 8069 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8070 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8071 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8072 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8073 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 8074 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8075 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8076 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8077 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.504\n",
      "Epoch 8078 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 8079 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8080 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8081 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8082 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8083 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8084 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.504\n",
      "Epoch 8085 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8086 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8087 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8088 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8089 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8090 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8091 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8092 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8093 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8094 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8095 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8096 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8097 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8098 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8099 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8100 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8101 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8102 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.49929411764705883\n",
      "Epoch 8103 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8104 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8105 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8106 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8107 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4983529411764706\n",
      "Epoch 8108 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8109 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8110 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8111 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8112 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.508235294117647\n",
      "Epoch 8113 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8114 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8115 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8116 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8117 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8118 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8119 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.49929411764705883\n",
      "Epoch 8120 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8121 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8122 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8123 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8124 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8125 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8126 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8127 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8128 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8129 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8130 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8131 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8132 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8133 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8134 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8135 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8136 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8137 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.512\n",
      "Epoch 8138 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8139 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8140 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8141 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.504\n",
      "Epoch 8142 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8143 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8144 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8145 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8146 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8147 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8148 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8149 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8150 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8151 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.504\n",
      "Epoch 8152 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8153 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8154 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8155 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 8156 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8157 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8158 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8159 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8160 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8161 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8162 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5134117647058823\n",
      "Epoch 8163 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8164 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8165 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8166 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8167 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8168 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.4988235294117647\n",
      "Epoch 8169 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8170 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8171 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8172 Loss 0.99 | Train Accuracy 0.523120367102012 | Val Accuracy 0.504\n",
      "Epoch 8173 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.49741176470588233\n",
      "Epoch 8174 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8175 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8176 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8177 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 8178 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8179 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.504\n",
      "Epoch 8180 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 8181 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8182 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8183 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8184 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8185 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8186 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8187 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8188 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8189 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8190 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8191 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8192 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8193 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8194 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 8195 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8196 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8197 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8198 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8199 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8200 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8201 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8202 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8203 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8204 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8205 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8206 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8207 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8208 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8209 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8210 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8211 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8212 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8213 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8214 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8215 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8216 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8217 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8218 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8219 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8220 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.512\n",
      "Epoch 8221 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8222 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8223 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8224 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8225 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8226 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8227 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8228 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8229 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8230 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8231 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.508235294117647\n",
      "Epoch 8232 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8233 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8234 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8235 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8236 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8237 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8238 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8239 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8240 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8241 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8242 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8243 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8244 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8245 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 8246 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8247 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49929411764705883\n",
      "Epoch 8248 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8249 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8250 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8251 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 8252 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8253 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8254 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8255 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8256 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8257 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8258 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8259 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8260 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8261 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8262 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8263 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8264 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.49741176470588233\n",
      "Epoch 8265 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8266 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8267 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8268 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.512\n",
      "Epoch 8269 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 8270 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.49741176470588233\n",
      "Epoch 8271 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8272 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8273 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8274 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8275 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8276 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8277 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8278 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8279 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8280 Loss 0.99 | Train Accuracy 0.5234733498058595 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8281 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8282 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8283 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8284 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8285 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8286 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8287 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8288 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8289 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8290 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.512\n",
      "Epoch 8291 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8292 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8293 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8294 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.512\n",
      "Epoch 8295 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8296 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8297 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8298 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8299 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8300 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8301 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5134117647058823\n",
      "Epoch 8302 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8303 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8304 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8305 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.508235294117647\n",
      "Epoch 8306 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8307 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8308 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8309 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8310 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8311 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8312 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8313 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8314 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8315 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8316 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8317 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8318 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8319 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8320 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8321 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8322 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8323 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8324 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8325 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8326 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5134117647058823\n",
      "Epoch 8327 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.512\n",
      "Epoch 8328 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8329 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8330 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8331 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8332 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.508235294117647\n",
      "Epoch 8333 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8334 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8335 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8336 Loss 0.99 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8337 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.512\n",
      "Epoch 8338 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.512\n",
      "Epoch 8339 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.508235294117647\n",
      "Epoch 8340 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.49741176470588233\n",
      "Epoch 8341 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8342 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8343 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8344 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8345 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8346 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8347 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8348 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8349 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8350 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8351 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 8352 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8353 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 8354 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8355 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8356 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8357 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8358 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8359 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8360 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8361 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8362 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8363 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8364 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8365 Loss 0.99 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8366 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.512\n",
      "Epoch 8367 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8368 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8369 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8370 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.504\n",
      "Epoch 8371 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.504\n",
      "Epoch 8372 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8373 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.508235294117647\n",
      "Epoch 8374 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8375 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8376 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.504\n",
      "Epoch 8377 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 8378 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.508235294117647\n",
      "Epoch 8379 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8380 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8381 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8382 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8383 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5138823529411765\n",
      "Epoch 8384 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8385 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8386 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 8387 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8388 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8389 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8390 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8391 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8392 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8393 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8394 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8395 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8396 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8397 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8398 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8399 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8400 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8401 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8402 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8403 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8404 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8405 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8406 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8407 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8408 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8409 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8410 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.49929411764705883\n",
      "Epoch 8411 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8412 Loss 0.99 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8413 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8414 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8415 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8416 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8417 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8418 Loss 0.99 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8419 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8420 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8421 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8422 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.49741176470588233\n",
      "Epoch 8423 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8424 Loss 0.99 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8425 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8426 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8427 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8428 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8429 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8430 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8431 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 8432 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 8433 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.504\n",
      "Epoch 8434 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8435 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8436 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8437 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 8438 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8439 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8440 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8441 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8442 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8443 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8444 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8445 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8446 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8447 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8448 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8449 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8450 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8451 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.504\n",
      "Epoch 8452 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8453 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.508235294117647\n",
      "Epoch 8454 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8455 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8456 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8457 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8458 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.504\n",
      "Epoch 8459 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8460 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8461 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8462 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8463 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8464 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8465 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8466 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8467 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8468 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8469 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8470 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5143529411764706\n",
      "Epoch 8471 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8472 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8473 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8474 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8475 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8476 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.504\n",
      "Epoch 8477 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8478 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8479 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8480 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8481 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8482 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.508235294117647\n",
      "Epoch 8483 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8484 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8485 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8486 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8487 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8488 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8489 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8490 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8491 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8492 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8493 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8494 Loss 0.99 | Train Accuracy 0.5230027062007295 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8495 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8496 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 8497 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8498 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8499 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8500 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8501 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8502 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8503 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.4988235294117647\n",
      "Epoch 8504 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8505 Loss 0.99 | Train Accuracy 0.523355688904577 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8506 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8507 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8508 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8509 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8510 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8511 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8512 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8513 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8514 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8515 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8516 Loss 0.99 | Train Accuracy 0.523120367102012 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8517 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8518 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8519 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.4955294117647059\n",
      "Epoch 8520 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8521 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.508235294117647\n",
      "Epoch 8522 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8523 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8524 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.49317647058823527\n",
      "Epoch 8525 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8526 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.516235294117647\n",
      "Epoch 8527 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8528 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8529 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8530 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.4978823529411765\n",
      "Epoch 8531 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8532 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8533 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8534 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8535 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8536 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.4955294117647059\n",
      "Epoch 8537 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8538 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8539 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 8540 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8541 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8542 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.4969411764705882\n",
      "Epoch 8543 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8544 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8545 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8546 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 8547 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8548 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8549 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8550 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8551 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8552 Loss 0.99 | Train Accuracy 0.5232380280032946 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8553 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 8554 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8555 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8556 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8557 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8558 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8559 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8560 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8561 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8562 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.508235294117647\n",
      "Epoch 8563 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8564 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8565 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.4978823529411765\n",
      "Epoch 8566 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.504\n",
      "Epoch 8567 Loss 1.00 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.516235294117647\n",
      "Epoch 8568 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.512\n",
      "Epoch 8569 Loss 1.00 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5171764705882353\n",
      "Epoch 8570 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8571 Loss 1.00 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8572 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.4983529411764706\n",
      "Epoch 8573 Loss 1.00 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8574 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8575 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8576 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.504\n",
      "Epoch 8577 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8578 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8579 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.4988235294117647\n",
      "Epoch 8580 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8581 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8582 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8583 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8584 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8585 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8586 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8587 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8588 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8589 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8590 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8591 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8592 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 8593 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8594 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8595 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8596 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8597 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8598 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8599 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8600 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8601 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8602 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8603 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8604 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8605 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8606 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.504\n",
      "Epoch 8607 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.504\n",
      "Epoch 8608 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8609 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5138823529411765\n",
      "Epoch 8610 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.512\n",
      "Epoch 8611 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8612 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.49929411764705883\n",
      "Epoch 8613 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8614 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8615 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8616 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8617 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8618 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.4983529411764706\n",
      "Epoch 8619 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8620 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8621 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8622 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8623 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8624 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.4983529411764706\n",
      "Epoch 8625 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8626 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8627 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8628 Loss 0.99 | Train Accuracy 0.523120367102012 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8629 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8630 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8631 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8632 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8633 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8634 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8635 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8636 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8637 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8638 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8639 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8640 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8641 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8642 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8643 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8644 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8645 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8646 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8647 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8648 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8649 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8650 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8651 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8652 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8653 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.508235294117647\n",
      "Epoch 8654 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8655 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.504\n",
      "Epoch 8656 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8657 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8658 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8659 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8660 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8661 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8662 Loss 0.99 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8663 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5134117647058823\n",
      "Epoch 8664 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8665 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8666 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.49929411764705883\n",
      "Epoch 8667 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8668 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8669 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8670 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8671 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8672 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.4988235294117647\n",
      "Epoch 8673 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8674 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8675 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8676 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8677 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8678 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.49929411764705883\n",
      "Epoch 8679 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8680 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8681 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8682 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8683 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8684 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8685 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8686 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8687 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8688 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.508235294117647\n",
      "Epoch 8689 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8690 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8691 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8692 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8693 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8694 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8695 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8696 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8697 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8698 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8699 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8700 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.504\n",
      "Epoch 8701 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8702 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8703 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5138823529411765\n",
      "Epoch 8704 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8705 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8706 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.4988235294117647\n",
      "Epoch 8707 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8708 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8709 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8710 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5110588235294118\n",
      "Epoch 8711 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8712 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8713 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8714 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8715 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8716 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8717 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8718 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8719 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8720 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 8721 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8722 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8723 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8724 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8725 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.504\n",
      "Epoch 8726 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8727 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8728 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8729 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8730 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8731 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8732 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.512\n",
      "Epoch 8733 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8734 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8735 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.49929411764705883\n",
      "Epoch 8736 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8737 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8738 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.512\n",
      "Epoch 8739 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8740 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8741 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8742 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8743 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.504\n",
      "Epoch 8744 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 8745 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.508235294117647\n",
      "Epoch 8746 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8747 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.504\n",
      "Epoch 8748 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 8749 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8750 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.508235294117647\n",
      "Epoch 8751 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8752 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8753 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8754 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.508235294117647\n",
      "Epoch 8755 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8756 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8757 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8758 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8759 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8760 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8761 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8762 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5143529411764706\n",
      "Epoch 8763 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8764 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8765 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8766 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8767 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8768 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5134117647058823\n",
      "Epoch 8769 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8770 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8771 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8772 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8773 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8774 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8775 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8776 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 8777 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8778 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8779 Loss 0.99 | Train Accuracy 0.5225320625955995 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8780 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 8781 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8782 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.508235294117647\n",
      "Epoch 8783 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8784 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8785 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8786 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8787 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8788 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8789 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8790 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.504\n",
      "Epoch 8791 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8792 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8793 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8794 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8795 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.4983529411764706\n",
      "Epoch 8796 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 8797 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.512\n",
      "Epoch 8798 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8799 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8800 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8801 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8802 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8803 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8804 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8805 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8806 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.504\n",
      "Epoch 8807 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8808 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8809 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5143529411764706\n",
      "Epoch 8810 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8811 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8812 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8813 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8814 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8815 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.508235294117647\n",
      "Epoch 8816 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8817 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 8818 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8819 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8820 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8821 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8822 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8823 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8824 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8825 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8826 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8827 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8828 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8829 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8830 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.504\n",
      "Epoch 8831 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8832 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5143529411764706\n",
      "Epoch 8833 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8834 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8835 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8836 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8837 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8838 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8839 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8840 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8841 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8842 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5143529411764706\n",
      "Epoch 8843 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8844 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8845 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8846 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8847 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8848 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8849 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 8850 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8851 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8852 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8853 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8854 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8855 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8856 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8857 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8858 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8859 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8860 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8861 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8862 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 8863 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8864 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8865 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8866 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8867 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8868 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8869 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8870 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8871 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8872 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8873 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 8874 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8875 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8876 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8877 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8878 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5096470588235295\n",
      "Epoch 8879 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8880 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8881 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5134117647058823\n",
      "Epoch 8882 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8883 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8884 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8885 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8886 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8887 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8888 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8889 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8890 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8891 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.508235294117647\n",
      "Epoch 8892 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8893 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.512\n",
      "Epoch 8894 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.508235294117647\n",
      "Epoch 8895 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.4983529411764706\n",
      "Epoch 8896 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8897 Loss 0.99 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8898 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8899 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.508235294117647\n",
      "Epoch 8900 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8901 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8902 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.49929411764705883\n",
      "Epoch 8903 Loss 0.99 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.512\n",
      "Epoch 8904 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8905 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8906 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8907 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8908 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8909 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 8910 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8911 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8912 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8913 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8914 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8915 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8916 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8917 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8918 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 8919 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8920 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8921 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 8922 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8923 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8924 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8925 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8926 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8927 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8928 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8929 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8930 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8931 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8932 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8933 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8934 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8935 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8936 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8937 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8938 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8939 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8940 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5134117647058823\n",
      "Epoch 8941 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 8942 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8943 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.496\n",
      "Epoch 8944 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8945 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8946 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8947 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8948 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8949 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8950 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8951 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5105882352941177\n",
      "Epoch 8952 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8953 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5068235294117647\n",
      "Epoch 8954 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8955 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.49976470588235294\n",
      "Epoch 8956 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5016470588235294\n",
      "Epoch 8957 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5129411764705882\n",
      "Epoch 8958 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8959 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.508235294117647\n",
      "Epoch 8960 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8961 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8962 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8963 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5030588235294118\n",
      "Epoch 8964 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8965 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.504\n",
      "Epoch 8966 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 8967 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.504\n",
      "Epoch 8968 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8969 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5124705882352941\n",
      "Epoch 8970 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8971 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8972 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5002352941176471\n",
      "Epoch 8973 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5011764705882353\n",
      "Epoch 8974 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5044705882352941\n",
      "Epoch 8975 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.512\n",
      "Epoch 8976 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8977 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8978 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5007058823529412\n",
      "Epoch 8979 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8980 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5063529411764706\n",
      "Epoch 8981 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5087058823529412\n",
      "Epoch 8982 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8983 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8984 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8985 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8986 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 8987 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8988 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 8989 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5025882352941177\n",
      "Epoch 8990 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8991 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5077647058823529\n",
      "Epoch 8992 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5115294117647059\n",
      "Epoch 8993 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8994 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5035294117647059\n",
      "Epoch 8995 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5049411764705882\n",
      "Epoch 8996 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.504\n",
      "Epoch 8997 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 8998 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5091764705882353\n",
      "Epoch 8999 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9000 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9001 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9002 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9003 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9004 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9005 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9006 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9007 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.504\n",
      "Epoch 9008 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9009 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5157647058823529\n",
      "Epoch 9010 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9011 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 9012 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.4988235294117647\n",
      "Epoch 9013 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9014 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9015 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9016 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9017 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9018 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.4978823529411765\n",
      "Epoch 9019 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9020 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9021 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9022 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9023 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9024 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9025 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9026 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9027 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9028 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9029 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.504\n",
      "Epoch 9030 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9031 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9032 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9033 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9034 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9035 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9036 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9037 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9038 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9039 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9040 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 9041 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.504\n",
      "Epoch 9042 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9043 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9044 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.512\n",
      "Epoch 9045 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9046 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9047 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9048 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9049 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9050 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9051 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9052 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9053 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9054 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9055 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9056 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.512\n",
      "Epoch 9057 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9058 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9059 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9060 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9061 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9062 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9063 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9064 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9065 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9066 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9067 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9068 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9069 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9070 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 9071 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9072 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.4983529411764706\n",
      "Epoch 9073 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9074 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9075 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9076 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9077 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9078 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9079 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9080 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9081 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9082 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9083 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9084 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9085 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9086 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9087 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9088 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9089 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9090 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9091 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5148235294117647\n",
      "Epoch 9092 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9093 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.512\n",
      "Epoch 9094 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9095 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.4978823529411765\n",
      "Epoch 9096 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9097 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9098 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9099 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9100 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9101 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9102 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9103 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9104 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.508235294117647\n",
      "Epoch 9105 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9106 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9107 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9108 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.504\n",
      "Epoch 9109 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9110 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.508235294117647\n",
      "Epoch 9111 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 9112 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9113 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9114 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9115 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9116 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9117 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9118 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.4964705882352941\n",
      "Epoch 9119 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9120 Loss 0.99 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9121 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9122 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9123 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9124 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9125 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.508235294117647\n",
      "Epoch 9126 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9127 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 9128 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9129 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9130 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9131 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9132 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9133 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9134 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9135 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9136 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9137 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9138 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9139 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9140 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9141 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9142 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9143 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9144 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9145 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 9146 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9147 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9148 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9149 Loss 1.00 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9150 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9151 Loss 1.00 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5143529411764706\n",
      "Epoch 9152 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9153 Loss 1.00 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9154 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9155 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9156 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9157 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9158 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9159 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9160 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9161 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9162 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9163 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9164 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9165 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9166 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9167 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9168 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9169 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9170 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9171 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9172 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9173 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9174 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9175 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.504\n",
      "Epoch 9176 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9177 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9178 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9179 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9180 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9181 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9182 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9183 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9184 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.504\n",
      "Epoch 9185 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.512\n",
      "Epoch 9186 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.512\n",
      "Epoch 9187 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9188 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9189 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9190 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9191 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9192 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.512\n",
      "Epoch 9193 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9194 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9195 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9196 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9197 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9198 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9199 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9200 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9201 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.504\n",
      "Epoch 9202 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9203 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9204 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9205 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9206 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9207 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9208 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9209 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5148235294117647\n",
      "Epoch 9210 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9211 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.508235294117647\n",
      "Epoch 9212 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.4978823529411765\n",
      "Epoch 9213 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9214 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9215 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9216 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5138823529411765\n",
      "Epoch 9217 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9218 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9219 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9220 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9221 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9222 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9223 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9224 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9225 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9226 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9227 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.508235294117647\n",
      "Epoch 9228 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9229 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9230 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9231 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9232 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9233 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9234 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9235 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9236 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9237 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9238 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9239 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9240 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9241 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 9242 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9243 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9244 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9245 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.512\n",
      "Epoch 9246 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9247 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9248 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9249 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9250 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.508235294117647\n",
      "Epoch 9251 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9252 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9253 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9254 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9255 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9256 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 9257 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9258 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9259 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9260 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9261 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9262 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9263 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9264 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9265 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9266 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.504\n",
      "Epoch 9267 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9268 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9269 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9270 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9271 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9272 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9273 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9274 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9275 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9276 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9277 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9278 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.4978823529411765\n",
      "Epoch 9279 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9280 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9281 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9282 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9283 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9284 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9285 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9286 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9287 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9288 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9289 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9290 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.4983529411764706\n",
      "Epoch 9291 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9292 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9293 Loss 0.99 | Train Accuracy 0.5222967407930345 | Val Accuracy 0.508235294117647\n",
      "Epoch 9294 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9295 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9296 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9297 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9298 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9299 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9300 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9301 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.4983529411764706\n",
      "Epoch 9302 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9303 Loss 0.99 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5143529411764706\n",
      "Epoch 9304 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9305 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5138823529411765\n",
      "Epoch 9306 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9307 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.4983529411764706\n",
      "Epoch 9308 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 9309 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9310 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9311 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9312 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9313 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9314 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9315 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9316 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9317 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9318 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9319 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9320 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9321 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9322 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9323 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9324 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9325 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9326 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9327 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9328 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9329 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9330 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9331 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9332 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.508235294117647\n",
      "Epoch 9333 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9334 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9335 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9336 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9337 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9338 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9339 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9340 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9341 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9342 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.504\n",
      "Epoch 9343 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.504\n",
      "Epoch 9344 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9345 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9346 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9347 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9348 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9349 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.504\n",
      "Epoch 9350 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4988235294117647\n",
      "Epoch 9351 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9352 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9353 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9354 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9355 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9356 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9357 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9358 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9359 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.508235294117647\n",
      "Epoch 9360 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9361 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9362 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4978823529411765\n",
      "Epoch 9363 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9364 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.512\n",
      "Epoch 9365 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9366 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9367 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9368 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9369 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9370 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9371 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9372 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9373 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9374 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9375 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9376 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.512\n",
      "Epoch 9377 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9378 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9379 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9380 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.4988235294117647\n",
      "Epoch 9381 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9382 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9383 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9384 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9385 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9386 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9387 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9388 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9389 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9390 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9391 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9392 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9393 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9394 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9395 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9396 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9397 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9398 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.4978823529411765\n",
      "Epoch 9399 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9400 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9401 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9402 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9403 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9404 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9405 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9406 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9407 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9408 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9409 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9410 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9411 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9412 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9413 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9414 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9415 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.504\n",
      "Epoch 9416 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9417 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9418 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9419 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9420 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9421 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9422 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9423 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9424 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9425 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9426 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9427 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9428 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9429 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9430 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9431 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9432 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9433 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9434 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9435 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9436 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5143529411764706\n",
      "Epoch 9437 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9438 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9439 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9440 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9441 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9442 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9443 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "Epoch 9444 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9445 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9446 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9447 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9448 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9449 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9450 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9451 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9452 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.504\n",
      "Epoch 9453 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9454 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9455 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9456 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9457 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9458 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9459 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9460 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9461 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9462 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9463 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5138823529411765\n",
      "Epoch 9464 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9465 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9466 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9467 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9468 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9469 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9470 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9471 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9472 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9473 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9474 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9475 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9476 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9477 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9478 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9479 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9480 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9481 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9482 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9483 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9484 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9485 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9486 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.504\n",
      "Epoch 9487 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.508235294117647\n",
      "Epoch 9488 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9489 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.512\n",
      "Epoch 9490 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9491 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9492 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9493 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9494 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9495 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9496 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9497 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9498 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9499 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9500 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9501 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9502 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9503 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9504 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9505 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9506 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9507 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.508235294117647\n",
      "Epoch 9508 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9509 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9510 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.508235294117647\n",
      "Epoch 9511 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9512 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.504\n",
      "Epoch 9513 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9514 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.504\n",
      "Epoch 9515 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9516 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9517 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9518 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9519 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9520 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9521 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9522 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9523 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9524 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9525 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9526 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9527 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.49741176470588233\n",
      "Epoch 9528 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.512\n",
      "Epoch 9529 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9530 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9531 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9532 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9533 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9534 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9535 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9536 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9537 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9538 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9539 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9540 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.508235294117647\n",
      "Epoch 9541 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9542 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9543 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9544 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9545 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9546 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9547 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9548 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9549 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9550 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9551 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9552 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9553 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9554 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9555 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9556 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.4983529411764706\n",
      "Epoch 9557 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9558 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5148235294117647\n",
      "Epoch 9559 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9560 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9561 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9562 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9563 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9564 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9565 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9566 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 9567 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9568 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9569 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9570 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9571 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9572 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9573 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9574 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9575 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9576 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9577 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9578 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9579 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9580 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9581 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9582 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9583 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9584 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9585 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9586 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.504\n",
      "Epoch 9587 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.4988235294117647\n",
      "Epoch 9588 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9589 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9590 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9591 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.508235294117647\n",
      "Epoch 9592 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9593 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9594 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9595 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.512\n",
      "Epoch 9596 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9597 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9598 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9599 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9600 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9601 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9602 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9603 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9604 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9605 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9606 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9607 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9608 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9609 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9610 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9611 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9612 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9613 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9614 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 9615 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9616 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9617 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9618 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9619 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9620 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9621 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9622 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.4988235294117647\n",
      "Epoch 9623 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9624 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9625 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9626 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.508235294117647\n",
      "Epoch 9627 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.508235294117647\n",
      "Epoch 9628 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9629 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9630 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9631 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9632 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9633 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9634 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9635 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9636 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9637 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9638 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9639 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.504\n",
      "Epoch 9640 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9641 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9642 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9643 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9644 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9645 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9646 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9647 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9648 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9649 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9650 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 9651 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9652 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9653 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9654 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5157647058823529\n",
      "Epoch 9655 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9656 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9657 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9658 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.4978823529411765\n",
      "Epoch 9659 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9660 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9661 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9662 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9663 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 9664 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9665 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9666 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9667 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9668 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9669 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 9670 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9671 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9672 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9673 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9674 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9675 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9676 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9677 Loss 0.99 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9678 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9679 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9680 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.508235294117647\n",
      "Epoch 9681 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9682 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9683 Loss 0.99 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9684 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9685 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9686 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9687 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9688 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9689 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9690 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9691 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9692 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9693 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9694 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.504\n",
      "Epoch 9695 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9696 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9697 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9698 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9699 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9700 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9701 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.504\n",
      "Epoch 9702 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.512\n",
      "Epoch 9703 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.508235294117647\n",
      "Epoch 9704 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9705 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.504\n",
      "Epoch 9706 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9707 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.504\n",
      "Epoch 9708 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5143529411764706\n",
      "Epoch 9709 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9710 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9711 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.508235294117647\n",
      "Epoch 9712 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9713 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9714 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9715 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9716 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.508235294117647\n",
      "Epoch 9717 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9718 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9719 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.508235294117647\n",
      "Epoch 9720 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9721 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9722 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9723 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9724 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9725 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9726 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9727 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9728 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9729 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9730 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9731 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9732 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9733 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9734 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.508235294117647\n",
      "Epoch 9735 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9736 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9737 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9738 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9739 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9740 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.508235294117647\n",
      "Epoch 9741 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9742 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9743 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.504\n",
      "Epoch 9744 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9745 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.512\n",
      "Epoch 9746 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.508235294117647\n",
      "Epoch 9747 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9748 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9749 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9750 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9751 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9752 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9753 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9754 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.4983529411764706\n",
      "Epoch 9755 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9756 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9757 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9758 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9759 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 9760 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9761 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9762 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9763 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9764 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9765 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9766 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9767 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9768 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9769 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9770 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9771 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9772 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9773 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9774 Loss 0.99 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9775 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9776 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9777 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9778 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9779 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5167058823529411\n",
      "Epoch 9780 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9781 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.512\n",
      "Epoch 9782 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9783 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.4988235294117647\n",
      "Epoch 9784 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9785 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9786 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9787 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9788 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9789 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9790 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.508235294117647\n",
      "Epoch 9791 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9792 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9793 Loss 0.99 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9794 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9795 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9796 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9797 Loss 0.99 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.508235294117647\n",
      "Epoch 9798 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9799 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9800 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.4969411764705882\n",
      "Epoch 9801 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9802 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9803 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 9804 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9805 Loss 0.99 | Train Accuracy 0.5193552182609719 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9806 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9807 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9808 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9809 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9810 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9811 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9812 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9813 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.508235294117647\n",
      "Epoch 9814 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9815 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9816 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9817 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9818 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9819 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9820 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9821 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.49741176470588233\n",
      "Epoch 9822 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9823 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9824 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9825 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.508235294117647\n",
      "Epoch 9826 Loss 0.99 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.49176470588235294\n",
      "Epoch 9827 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9828 Loss 0.99 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9829 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9830 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9831 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9832 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9833 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9834 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.504\n",
      "Epoch 9835 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9836 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9837 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.496\n",
      "Epoch 9838 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.508235294117647\n",
      "Epoch 9839 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5134117647058823\n",
      "Epoch 9840 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9841 Loss 0.99 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9842 Loss 0.99 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9843 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9844 Loss 0.99 | Train Accuracy 0.522414401694317 | Val Accuracy 0.512\n",
      "Epoch 9845 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 9846 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9847 Loss 0.99 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "Epoch 9848 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.49929411764705883\n",
      "Epoch 9849 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9850 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9851 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.504\n",
      "Epoch 9852 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9853 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.4964705882352941\n",
      "Epoch 9854 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9855 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9856 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9857 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9858 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9859 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9860 Loss 0.99 | Train Accuracy 0.522649723496882 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9861 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9862 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9863 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.4969411764705882\n",
      "Epoch 9864 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9865 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9866 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9867 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9868 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.4955294117647059\n",
      "Epoch 9869 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9870 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9871 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9872 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9873 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9874 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9875 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9876 Loss 0.99 | Train Accuracy 0.5230027062007295 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9877 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9878 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9879 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9880 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9881 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9882 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9883 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9884 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9885 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9886 Loss 0.99 | Train Accuracy 0.5232380280032946 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9887 Loss 0.99 | Train Accuracy 0.5221790798917519 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9888 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9889 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.508235294117647\n",
      "Epoch 9890 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9891 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.4983529411764706\n",
      "Epoch 9892 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9893 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9894 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9895 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9896 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9897 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.496\n",
      "Epoch 9898 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9899 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9900 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9901 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9902 Loss 0.99 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9903 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.4988235294117647\n",
      "Epoch 9904 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9905 Loss 0.99 | Train Accuracy 0.5220614189904694 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9906 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5091764705882353\n",
      "Epoch 9907 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9908 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9909 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 9910 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9911 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9912 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9913 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9914 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9915 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9916 Loss 0.99 | Train Accuracy 0.5213554535827745 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9917 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9918 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.512\n",
      "Epoch 9919 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9920 Loss 0.99 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9921 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9922 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9923 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.512\n",
      "Epoch 9924 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9925 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9926 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9927 Loss 0.99 | Train Accuracy 0.5185315919519944 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9928 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.512\n",
      "Epoch 9929 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9930 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9931 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.504\n",
      "Epoch 9932 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.512\n",
      "Epoch 9933 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.512\n",
      "Epoch 9934 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9935 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9936 Loss 0.99 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9937 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5030588235294118\n",
      "Epoch 9938 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9939 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9940 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9941 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9942 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9943 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5011764705882353\n",
      "Epoch 9944 Loss 0.99 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9945 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5101176470588236\n",
      "Epoch 9946 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9947 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5058823529411764\n",
      "Epoch 9948 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.4964705882352941\n",
      "Epoch 9949 Loss 0.99 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.504\n",
      "Epoch 9950 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9951 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9952 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.508235294117647\n",
      "Epoch 9953 Loss 0.99 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9954 Loss 0.99 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9955 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9956 Loss 0.99 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5087058823529412\n",
      "Epoch 9957 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9958 Loss 0.99 | Train Accuracy 0.5208848099776444 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9959 Loss 0.99 | Train Accuracy 0.5198258618661019 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9960 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5007058823529412\n",
      "Epoch 9961 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9962 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5124705882352941\n",
      "Epoch 9963 Loss 0.99 | Train Accuracy 0.5204141663725144 | Val Accuracy 0.5115294117647059\n",
      "Epoch 9964 Loss 0.99 | Train Accuracy 0.521237792681492 | Val Accuracy 0.5063529411764706\n",
      "Epoch 9965 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.504\n",
      "Epoch 9966 Loss 0.99 | Train Accuracy 0.5205318272737969 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9967 Loss 0.99 | Train Accuracy 0.521708436286622 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9968 Loss 0.99 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9969 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.508235294117647\n",
      "Epoch 9970 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9971 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9972 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9973 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.508235294117647\n",
      "Epoch 9974 Loss 0.99 | Train Accuracy 0.5211201317802094 | Val Accuracy 0.5129411764705882\n",
      "Epoch 9975 Loss 0.99 | Train Accuracy 0.5187669137545594 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9976 Loss 0.99 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9977 Loss 0.99 | Train Accuracy 0.521473114484057 | Val Accuracy 0.5021176470588236\n",
      "Epoch 9978 Loss 0.99 | Train Accuracy 0.5215907753853395 | Val Accuracy 0.5054117647058823\n",
      "Epoch 9979 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5035294117647059\n",
      "Epoch 9980 Loss 0.99 | Train Accuracy 0.5190022355571243 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9981 Loss 0.99 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9982 Loss 0.99 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5025882352941177\n",
      "Epoch 9983 Loss 0.99 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.49976470588235294\n",
      "Epoch 9984 Loss 0.99 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9985 Loss 0.99 | Train Accuracy 0.5206494881750794 | Val Accuracy 0.5105882352941177\n",
      "Epoch 9986 Loss 0.99 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5068235294117647\n",
      "Epoch 9987 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5077647058823529\n",
      "Epoch 9988 Loss 0.99 | Train Accuracy 0.5210024708789269 | Val Accuracy 0.5002352941176471\n",
      "Epoch 9989 Loss 0.99 | Train Accuracy 0.5219437580891869 | Val Accuracy 0.5016470588235294\n",
      "Epoch 9990 Loss 0.99 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5049411764705882\n",
      "Epoch 9991 Loss 0.99 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5143529411764706\n",
      "Epoch 9992 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9993 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5072941176470588\n",
      "Epoch 9994 Loss 0.99 | Train Accuracy 0.522885045299447 | Val Accuracy 0.4983529411764706\n",
      "Epoch 9995 Loss 0.99 | Train Accuracy 0.520296505471232 | Val Accuracy 0.4988235294117647\n",
      "Epoch 9996 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5044705882352941\n",
      "Epoch 9997 Loss 0.99 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5110588235294118\n",
      "Epoch 9998 Loss 0.99 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5096470588235295\n",
      "Epoch 9999 Loss 0.99 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5072941176470588\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "N_EPOCHS = 10000 # + 100\n",
    "net.train()\n",
    "criterion = nn.CrossEntropyLoss() # loss\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.005, weight_decay=5e-2)\n",
    "\n",
    "train_accuracies = [1.0]\n",
    "val_accuracies = [1.0]\n",
    "val_check = 1\n",
    "best_state, best_val = None, 0.0\n",
    "best_min_state, best_min_val = None, 0.0\n",
    "for epoch in range(N_EPOCHS):  # loop over the dataset multiple times\n",
    "    # Iterate over batches and perform SGD step.\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net(x_train)\n",
    "    loss = criterion(y_pred, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_acc, val_acc = accuracy_score(torch.argmax(y_pred, axis=1), torch.argmax(Y_train, axis=1)), val_accuracies[-1]\n",
    "    if(epoch % val_check == 0):\n",
    "        hat_y_val = net(x_valid)\n",
    "        #val_loss = criterion(hat_y_val, y_val)\n",
    "        val_acc = accuracy_score(torch.argmax(hat_y_val, axis=1), torch.argmax(Y_valid, axis=1))\n",
    "        if(val_acc > best_val):\n",
    "            best_val = val_acc\n",
    "            best_state = copy.deepcopy(net.state_dict())\n",
    "\n",
    "        if(min(val_acc, train_acc) > best_min_val):\n",
    "            best_min_val = min(val_acc, train_acc)\n",
    "            best_min_state = copy.deepcopy(net.state_dict())\n",
    "\n",
    "    val_accuracies.append(val_acc)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(f\"Epoch {epoch} Loss {loss.detach().cpu().numpy():.2f} | Train Accuracy {train_acc} | Val Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_min_state, \"MCT_P_params_best_min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       HOME_TEAM_GAME_WON_season_sum  \\\n",
      "ID                                     \n",
      "9107                             5.0   \n",
      "8231                             2.0   \n",
      "5367                            10.0   \n",
      "3264                             4.0   \n",
      "9590                             1.0   \n",
      "...                              ...   \n",
      "11964                            2.0   \n",
      "5191                             5.0   \n",
      "5390                             4.0   \n",
      "860                              1.0   \n",
      "7270                             0.0   \n",
      "\n",
      "       HOME_TEAM_BALL_POSSESSION_season_average  \\\n",
      "ID                                                \n",
      "9107                                        4.0   \n",
      "8231                                        0.0   \n",
      "5367                                        6.0   \n",
      "3264                                        5.0   \n",
      "9590                                        1.0   \n",
      "...                                         ...   \n",
      "11964                                       2.0   \n",
      "5191                                        1.0   \n",
      "5390                                        3.0   \n",
      "860                                         3.0   \n",
      "7270                                        0.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_ON_TARGET_5_last_match_average  \\\n",
      "ID                                                      \n",
      "9107                                              3.0   \n",
      "8231                                              0.0   \n",
      "5367                                              6.0   \n",
      "3264                                              4.0   \n",
      "9590                                              2.0   \n",
      "...                                               ...   \n",
      "11964                                             4.0   \n",
      "5191                                              2.0   \n",
      "5390                                              2.0   \n",
      "860                                               7.0   \n",
      "7270                                              0.0   \n",
      "\n",
      "       AWAY_TEAM_SHOTS_ON_TARGET_season_average  \\\n",
      "ID                                                \n",
      "9107                                        2.0   \n",
      "8231                                        3.0   \n",
      "5367                                        3.0   \n",
      "3264                                        0.0   \n",
      "9590                                        9.0   \n",
      "...                                         ...   \n",
      "11964                                       5.0   \n",
      "5191                                        7.0   \n",
      "5390                                        4.0   \n",
      "860                                         1.0   \n",
      "7270                                        6.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_LOST_season_average  AWAY_TEAM_CORNERS_season_average  \\\n",
      "ID                                                                            \n",
      "9107                                  1.0                               4.0   \n",
      "8231                                  4.0                               3.0   \n",
      "5367                                  4.0                               4.0   \n",
      "3264                                  3.0                               2.0   \n",
      "9590                                  0.0                               8.0   \n",
      "...                                   ...                               ...   \n",
      "11964                                 4.0                               4.0   \n",
      "5191                                  4.0                               4.0   \n",
      "5390                                  4.0                               4.0   \n",
      "860                                   6.0                               3.0   \n",
      "7270                                  3.0                               9.0   \n",
      "\n",
      "       HOME_TEAM_PASSES_season_average  AWAY_TEAM_ATTACKS_season_average  \\\n",
      "ID                                                                         \n",
      "9107                               3.0                               4.0   \n",
      "8231                               3.0                               2.0   \n",
      "5367                               6.0                               1.0   \n",
      "3264                               4.0                               0.0   \n",
      "9590                               1.0                               6.0   \n",
      "...                                ...                               ...   \n",
      "11964                              0.0                               7.0   \n",
      "5191                               2.0                               4.0   \n",
      "5390                               3.0                               3.0   \n",
      "860                                NaN                               4.0   \n",
      "7270                               0.0                               2.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_ON_TARGET_season_average  \\\n",
      "ID                                                \n",
      "9107                                        1.0   \n",
      "8231                                        0.0   \n",
      "5367                                        6.0   \n",
      "3264                                        4.0   \n",
      "9590                                        1.0   \n",
      "...                                         ...   \n",
      "11964                                       4.0   \n",
      "5191                                        3.0   \n",
      "5390                                        3.0   \n",
      "860                                        10.0   \n",
      "7270                                        0.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_LOST_season_sum  ...  \\\n",
      "ID                                     ...   \n",
      "9107                              1.0  ...   \n",
      "8231                              4.0  ...   \n",
      "5367                              6.0  ...   \n",
      "3264                              4.0  ...   \n",
      "9590                              0.0  ...   \n",
      "...                               ...  ...   \n",
      "11964                             5.0  ...   \n",
      "5191                              4.0  ...   \n",
      "5390                              4.0  ...   \n",
      "860                               6.0  ...   \n",
      "7270                              3.0  ...   \n",
      "\n",
      "       HOME_TEAM_PENALTIES_5_last_match_sum  HOME_TEAM_BALL_SAFE_season_sum  \\\n",
      "ID                                                                            \n",
      "9107                                    0.0                             2.0   \n",
      "8231                                    0.0                             8.0   \n",
      "5367                                    2.0                             0.0   \n",
      "3264                                    5.0                            10.0   \n",
      "9590                                    3.0                             3.0   \n",
      "...                                     ...                             ...   \n",
      "11964                                   0.0                             8.0   \n",
      "5191                                    0.0                             8.0   \n",
      "5390                                    5.0                             9.0   \n",
      "860                                     0.0                             7.0   \n",
      "7270                                    2.0                             4.0   \n",
      "\n",
      "       AWAY_TEAM_REDCARDS_season_std  \\\n",
      "ID                                     \n",
      "9107                             4.0   \n",
      "8231                             4.0   \n",
      "5367                             0.0   \n",
      "3264                             6.0   \n",
      "9590                             9.0   \n",
      "...                              ...   \n",
      "11964                            4.0   \n",
      "5191                             7.0   \n",
      "5390                             9.0   \n",
      "860                              2.0   \n",
      "7270                             4.0   \n",
      "\n",
      "       HOME_TEAM_PENALTIES_5_last_match_average  \\\n",
      "ID                                                \n",
      "9107                                        0.0   \n",
      "8231                                        0.0   \n",
      "5367                                        2.0   \n",
      "3264                                        5.0   \n",
      "9590                                        3.0   \n",
      "...                                         ...   \n",
      "11964                                       0.0   \n",
      "5191                                        0.0   \n",
      "5390                                        5.0   \n",
      "860                                         0.0   \n",
      "7270                                        2.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_WON_5_last_match_sum  \\\n",
      "ID                                           \n",
      "9107                                   6.0   \n",
      "8231                                   6.0   \n",
      "5367                                   7.0   \n",
      "3264                                   4.0   \n",
      "9590                                   6.0   \n",
      "...                                    ...   \n",
      "11964                                  5.0   \n",
      "5191                                   6.0   \n",
      "5390                                   8.0   \n",
      "860                                    6.0   \n",
      "7270                                  10.0   \n",
      "\n",
      "       AWAY_TEAM_PENALTIES_5_last_match_std  \\\n",
      "ID                                            \n",
      "9107                                    0.0   \n",
      "8231                                    0.0   \n",
      "5367                                    6.0   \n",
      "3264                                    0.0   \n",
      "9590                                    5.0   \n",
      "...                                     ...   \n",
      "11964                                  10.0   \n",
      "5191                                    8.0   \n",
      "5390                                    0.0   \n",
      "860                                     5.0   \n",
      "7270                                    0.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_DRAW_season_average  \\\n",
      "ID                                          \n",
      "9107                                  8.0   \n",
      "8231                                  4.0   \n",
      "5367                                  0.0   \n",
      "3264                                  9.0   \n",
      "9590                                  5.0   \n",
      "...                                   ...   \n",
      "11964                                 0.0   \n",
      "5191                                  4.0   \n",
      "5390                                  1.0   \n",
      "860                                   7.0   \n",
      "7270                                  3.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_DRAW_5_last_match_sum  \\\n",
      "ID                                            \n",
      "9107                                    5.0   \n",
      "8231                                    2.0   \n",
      "5367                                    0.0   \n",
      "3264                                   10.0   \n",
      "9590                                    3.0   \n",
      "...                                     ...   \n",
      "11964                                   0.0   \n",
      "5191                                    0.0   \n",
      "5390                                    3.0   \n",
      "860                                     5.0   \n",
      "7270                                    3.0   \n",
      "\n",
      "       HOME_TEAM_YELLOWCARDS_season_average  AWAY_TEAM_FOULS_5_last_match_std  \n",
      "ID                                                                             \n",
      "9107                                    5.0                               2.0  \n",
      "8231                                    4.0                               1.0  \n",
      "5367                                    4.0                               8.0  \n",
      "3264                                    4.0                               3.0  \n",
      "9590                                    3.0                               4.0  \n",
      "...                                     ...                               ...  \n",
      "11964                                   5.0                               2.0  \n",
      "5191                                    0.0                               9.0  \n",
      "5390                                    6.0                               2.0  \n",
      "860                                     5.0                               NaN  \n",
      "7270                                    8.0                               8.0  \n",
      "\n",
      "[9842 rows x 204 columns]\n",
      "       HOME_TEAM_GAME_WON_season_sum  \\\n",
      "ID                                     \n",
      "8961                            10.0   \n",
      "724                              5.0   \n",
      "9165                             1.0   \n",
      "12165                            3.0   \n",
      "8771                            10.0   \n",
      "...                              ...   \n",
      "8288                             2.0   \n",
      "3378                             3.0   \n",
      "4007                             0.0   \n",
      "9037                             2.0   \n",
      "549                              1.0   \n",
      "\n",
      "       HOME_TEAM_BALL_POSSESSION_season_average  \\\n",
      "ID                                                \n",
      "8961                                        6.0   \n",
      "724                                         6.0   \n",
      "9165                                        3.0   \n",
      "12165                                       3.0   \n",
      "8771                                        5.0   \n",
      "...                                         ...   \n",
      "8288                                        1.0   \n",
      "3378                                        2.0   \n",
      "4007                                        0.0   \n",
      "9037                                        0.0   \n",
      "549                                         2.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_ON_TARGET_5_last_match_average  \\\n",
      "ID                                                      \n",
      "8961                                             10.0   \n",
      "724                                               7.0   \n",
      "9165                                              1.0   \n",
      "12165                                             6.0   \n",
      "8771                                             10.0   \n",
      "...                                               ...   \n",
      "8288                                              2.0   \n",
      "3378                                              0.0   \n",
      "4007                                              0.0   \n",
      "9037                                              2.0   \n",
      "549                                               3.0   \n",
      "\n",
      "       AWAY_TEAM_SHOTS_ON_TARGET_season_average  \\\n",
      "ID                                                \n",
      "8961                                        4.0   \n",
      "724                                         7.0   \n",
      "9165                                        9.0   \n",
      "12165                                       6.0   \n",
      "8771                                        3.0   \n",
      "...                                         ...   \n",
      "8288                                        3.0   \n",
      "3378                                        2.0   \n",
      "4007                                        3.0   \n",
      "9037                                        1.0   \n",
      "549                                         5.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_LOST_season_average  AWAY_TEAM_CORNERS_season_average  \\\n",
      "ID                                                                            \n",
      "8961                                  4.0                               6.0   \n",
      "724                                   2.0                               3.0   \n",
      "9165                                  0.0                               3.0   \n",
      "12165                                 4.0                               1.0   \n",
      "8771                                  3.0                               7.0   \n",
      "...                                   ...                               ...   \n",
      "8288                                  4.0                               5.0   \n",
      "3378                                  7.0                               2.0   \n",
      "4007                                  3.0                               7.0   \n",
      "9037                                  9.0                               4.0   \n",
      "549                                   2.0                               3.0   \n",
      "\n",
      "       HOME_TEAM_PASSES_season_average  AWAY_TEAM_ATTACKS_season_average  \\\n",
      "ID                                                                         \n",
      "8961                               7.0                               6.0   \n",
      "724                                5.0                               5.0   \n",
      "9165                               3.0                               3.0   \n",
      "12165                              3.0                               3.0   \n",
      "8771                               5.0                               4.0   \n",
      "...                                ...                               ...   \n",
      "8288                               0.0                               3.0   \n",
      "3378                               2.0                               0.0   \n",
      "4007                               0.0                               6.0   \n",
      "9037                               0.0                               4.0   \n",
      "549                                1.0                               4.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_ON_TARGET_season_average  \\\n",
      "ID                                                \n",
      "8961                                       10.0   \n",
      "724                                         5.0   \n",
      "9165                                        2.0   \n",
      "12165                                       2.0   \n",
      "8771                                        5.0   \n",
      "...                                         ...   \n",
      "8288                                        1.0   \n",
      "3378                                        1.0   \n",
      "4007                                        0.0   \n",
      "9037                                        3.0   \n",
      "549                                         2.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_LOST_season_sum  ...  \\\n",
      "ID                                     ...   \n",
      "8961                              4.0  ...   \n",
      "724                               2.0  ...   \n",
      "9165                              0.0  ...   \n",
      "12165                             5.0  ...   \n",
      "8771                              4.0  ...   \n",
      "...                               ...  ...   \n",
      "8288                              4.0  ...   \n",
      "3378                              7.0  ...   \n",
      "4007                              3.0  ...   \n",
      "9037                             10.0  ...   \n",
      "549                               2.0  ...   \n",
      "\n",
      "       HOME_TEAM_PENALTIES_5_last_match_sum  HOME_TEAM_BALL_SAFE_season_sum  \\\n",
      "ID                                                                            \n",
      "8961                                   10.0                             7.0   \n",
      "724                                     0.0                             5.0   \n",
      "9165                                    0.0                             2.0   \n",
      "12165                                   0.0                             8.0   \n",
      "8771                                    0.0                             5.0   \n",
      "...                                     ...                             ...   \n",
      "8288                                    0.0                             7.0   \n",
      "3378                                    0.0                             3.0   \n",
      "4007                                    0.0                             3.0   \n",
      "9037                                    0.0                             6.0   \n",
      "549                                     3.0                             3.0   \n",
      "\n",
      "       AWAY_TEAM_REDCARDS_season_std  \\\n",
      "ID                                     \n",
      "8961                             0.0   \n",
      "724                              0.0   \n",
      "9165                             5.0   \n",
      "12165                            6.0   \n",
      "8771                             3.0   \n",
      "...                              ...   \n",
      "8288                            10.0   \n",
      "3378                             6.0   \n",
      "4007                             2.0   \n",
      "9037                             4.0   \n",
      "549                              2.0   \n",
      "\n",
      "       HOME_TEAM_PENALTIES_5_last_match_average  \\\n",
      "ID                                                \n",
      "8961                                       10.0   \n",
      "724                                         0.0   \n",
      "9165                                        0.0   \n",
      "12165                                       0.0   \n",
      "8771                                        0.0   \n",
      "...                                         ...   \n",
      "8288                                        0.0   \n",
      "3378                                        0.0   \n",
      "4007                                        0.0   \n",
      "9037                                        0.0   \n",
      "549                                         3.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_WON_5_last_match_sum  \\\n",
      "ID                                           \n",
      "8961                                   5.0   \n",
      "724                                    7.0   \n",
      "9165                                   6.0   \n",
      "12165                                  7.0   \n",
      "8771                                  10.0   \n",
      "...                                    ...   \n",
      "8288                                   4.0   \n",
      "3378                                   0.0   \n",
      "4007                                   7.0   \n",
      "9037                                   0.0   \n",
      "549                                   10.0   \n",
      "\n",
      "       AWAY_TEAM_PENALTIES_5_last_match_std  \\\n",
      "ID                                            \n",
      "8961                                    5.0   \n",
      "724                                     6.0   \n",
      "9165                                    5.0   \n",
      "12165                                   6.0   \n",
      "8771                                   10.0   \n",
      "...                                     ...   \n",
      "8288                                    9.0   \n",
      "3378                                    8.0   \n",
      "4007                                   10.0   \n",
      "9037                                    5.0   \n",
      "549                                     5.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_DRAW_season_average  \\\n",
      "ID                                          \n",
      "8961                                  2.0   \n",
      "724                                   8.0   \n",
      "9165                                  3.0   \n",
      "12165                                 6.0   \n",
      "8771                                  5.0   \n",
      "...                                   ...   \n",
      "8288                                  1.0   \n",
      "3378                                  1.0   \n",
      "4007                                  4.0   \n",
      "9037                                  4.0   \n",
      "549                                   3.0   \n",
      "\n",
      "       AWAY_TEAM_GAME_DRAW_5_last_match_sum  \\\n",
      "ID                                            \n",
      "8961                                    6.0   \n",
      "724                                     6.0   \n",
      "9165                                    5.0   \n",
      "12165                                   3.0   \n",
      "8771                                    0.0   \n",
      "...                                     ...   \n",
      "8288                                    0.0   \n",
      "3378                                    0.0   \n",
      "4007                                    3.0   \n",
      "9037                                    7.0   \n",
      "549                                     2.0   \n",
      "\n",
      "       HOME_TEAM_YELLOWCARDS_season_average  AWAY_TEAM_FOULS_5_last_match_std  \n",
      "ID                                                                             \n",
      "8961                                    0.0                               7.0  \n",
      "724                                     0.0                               8.0  \n",
      "9165                                    9.0                               9.0  \n",
      "12165                                   3.0                               5.0  \n",
      "8771                                    7.0                               7.0  \n",
      "...                                     ...                               ...  \n",
      "8288                                    2.0                               4.0  \n",
      "3378                                    4.0                               0.0  \n",
      "4007                                   10.0                               1.0  \n",
      "9037                                    3.0                               3.0  \n",
      "549                                     6.0                               7.0  \n",
      "\n",
      "[2461 rows x 204 columns]\n"
     ]
    }
   ],
   "source": [
    "select_fts = open(\"team_fs.txt\", \"r\").readlines()\n",
    "select_fts = [ft[:-1] for ft in select_fts]\n",
    "X_train = X_train[select_fts]\n",
    "X_valid = X_valid[select_fts]\n",
    "print(X_train)\n",
    "print(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0980339\ttest: 1.0980462\tbest: 1.0980462 (0)\ttotal: 15.5ms\tremaining: 2m 35s\n",
      "1:\tlearn: 1.0974461\ttest: 1.0974877\tbest: 1.0974877 (1)\ttotal: 25.9ms\tremaining: 2m 9s\n",
      "2:\tlearn: 1.0968395\ttest: 1.0969383\tbest: 1.0969383 (2)\ttotal: 37ms\tremaining: 2m 3s\n",
      "3:\tlearn: 1.0962418\ttest: 1.0963918\tbest: 1.0963918 (3)\ttotal: 46.6ms\tremaining: 1m 56s\n",
      "4:\tlearn: 1.0956599\ttest: 1.0958316\tbest: 1.0958316 (4)\ttotal: 55.8ms\tremaining: 1m 51s\n",
      "5:\tlearn: 1.0950924\ttest: 1.0952977\tbest: 1.0952977 (5)\ttotal: 65.2ms\tremaining: 1m 48s\n",
      "6:\tlearn: 1.0945138\ttest: 1.0947618\tbest: 1.0947618 (6)\ttotal: 76.1ms\tremaining: 1m 48s\n",
      "7:\tlearn: 1.0939664\ttest: 1.0942338\tbest: 1.0942338 (7)\ttotal: 87.4ms\tremaining: 1m 49s\n",
      "8:\tlearn: 1.0934304\ttest: 1.0937084\tbest: 1.0937084 (8)\ttotal: 96.7ms\tremaining: 1m 47s\n",
      "9:\tlearn: 1.0929360\ttest: 1.0932496\tbest: 1.0932496 (9)\ttotal: 109ms\tremaining: 1m 49s\n",
      "10:\tlearn: 1.0923804\ttest: 1.0927504\tbest: 1.0927504 (10)\ttotal: 119ms\tremaining: 1m 48s\n",
      "11:\tlearn: 1.0918586\ttest: 1.0922421\tbest: 1.0922421 (11)\ttotal: 130ms\tremaining: 1m 48s\n",
      "12:\tlearn: 1.0913679\ttest: 1.0917517\tbest: 1.0917517 (12)\ttotal: 141ms\tremaining: 1m 48s\n",
      "13:\tlearn: 1.0908319\ttest: 1.0912458\tbest: 1.0912458 (13)\ttotal: 150ms\tremaining: 1m 46s\n",
      "14:\tlearn: 1.0903138\ttest: 1.0907579\tbest: 1.0907579 (14)\ttotal: 160ms\tremaining: 1m 46s\n",
      "15:\tlearn: 1.0898127\ttest: 1.0902626\tbest: 1.0902626 (15)\ttotal: 171ms\tremaining: 1m 46s\n",
      "16:\tlearn: 1.0892741\ttest: 1.0897582\tbest: 1.0897582 (16)\ttotal: 180ms\tremaining: 1m 45s\n",
      "17:\tlearn: 1.0887514\ttest: 1.0892803\tbest: 1.0892803 (17)\ttotal: 190ms\tremaining: 1m 45s\n",
      "18:\tlearn: 1.0882870\ttest: 1.0888346\tbest: 1.0888346 (18)\ttotal: 199ms\tremaining: 1m 44s\n",
      "19:\tlearn: 1.0878248\ttest: 1.0884160\tbest: 1.0884160 (19)\ttotal: 209ms\tremaining: 1m 44s\n",
      "20:\tlearn: 1.0872954\ttest: 1.0879295\tbest: 1.0879295 (20)\ttotal: 220ms\tremaining: 1m 44s\n",
      "21:\tlearn: 1.0868013\ttest: 1.0874081\tbest: 1.0874081 (21)\ttotal: 230ms\tremaining: 1m 44s\n",
      "22:\tlearn: 1.0863091\ttest: 1.0869347\tbest: 1.0869347 (22)\ttotal: 240ms\tremaining: 1m 44s\n",
      "23:\tlearn: 1.0858252\ttest: 1.0864236\tbest: 1.0864236 (23)\ttotal: 251ms\tremaining: 1m 44s\n",
      "24:\tlearn: 1.0853396\ttest: 1.0859485\tbest: 1.0859485 (24)\ttotal: 262ms\tremaining: 1m 44s\n",
      "25:\tlearn: 1.0848248\ttest: 1.0854551\tbest: 1.0854551 (25)\ttotal: 272ms\tremaining: 1m 44s\n",
      "26:\tlearn: 1.0842842\ttest: 1.0849691\tbest: 1.0849691 (26)\ttotal: 282ms\tremaining: 1m 44s\n",
      "27:\tlearn: 1.0837865\ttest: 1.0845066\tbest: 1.0845066 (27)\ttotal: 292ms\tremaining: 1m 43s\n",
      "28:\tlearn: 1.0832400\ttest: 1.0840216\tbest: 1.0840216 (28)\ttotal: 303ms\tremaining: 1m 44s\n",
      "29:\tlearn: 1.0827959\ttest: 1.0835900\tbest: 1.0835900 (29)\ttotal: 312ms\tremaining: 1m 43s\n",
      "30:\tlearn: 1.0823318\ttest: 1.0831508\tbest: 1.0831508 (30)\ttotal: 322ms\tremaining: 1m 43s\n",
      "31:\tlearn: 1.0818624\ttest: 1.0826938\tbest: 1.0826938 (31)\ttotal: 331ms\tremaining: 1m 43s\n",
      "32:\tlearn: 1.0814341\ttest: 1.0822849\tbest: 1.0822849 (32)\ttotal: 341ms\tremaining: 1m 43s\n",
      "33:\tlearn: 1.0809974\ttest: 1.0818774\tbest: 1.0818774 (33)\ttotal: 350ms\tremaining: 1m 42s\n",
      "34:\tlearn: 1.0805119\ttest: 1.0814278\tbest: 1.0814278 (34)\ttotal: 359ms\tremaining: 1m 42s\n",
      "35:\tlearn: 1.0800148\ttest: 1.0809453\tbest: 1.0809453 (35)\ttotal: 369ms\tremaining: 1m 42s\n",
      "36:\tlearn: 1.0795872\ttest: 1.0805621\tbest: 1.0805621 (36)\ttotal: 378ms\tremaining: 1m 41s\n",
      "37:\tlearn: 1.0791608\ttest: 1.0801740\tbest: 1.0801740 (37)\ttotal: 387ms\tremaining: 1m 41s\n",
      "38:\tlearn: 1.0787633\ttest: 1.0797983\tbest: 1.0797983 (38)\ttotal: 398ms\tremaining: 1m 41s\n",
      "39:\tlearn: 1.0783157\ttest: 1.0793820\tbest: 1.0793820 (39)\ttotal: 408ms\tremaining: 1m 41s\n",
      "40:\tlearn: 1.0778982\ttest: 1.0789622\tbest: 1.0789622 (40)\ttotal: 418ms\tremaining: 1m 41s\n",
      "41:\tlearn: 1.0775369\ttest: 1.0786148\tbest: 1.0786148 (41)\ttotal: 427ms\tremaining: 1m 41s\n",
      "42:\tlearn: 1.0771338\ttest: 1.0782528\tbest: 1.0782528 (42)\ttotal: 436ms\tremaining: 1m 40s\n",
      "43:\tlearn: 1.0767348\ttest: 1.0778635\tbest: 1.0778635 (43)\ttotal: 446ms\tremaining: 1m 41s\n",
      "44:\tlearn: 1.0763059\ttest: 1.0774487\tbest: 1.0774487 (44)\ttotal: 455ms\tremaining: 1m 40s\n",
      "45:\tlearn: 1.0758786\ttest: 1.0770065\tbest: 1.0770065 (45)\ttotal: 467ms\tremaining: 1m 41s\n",
      "46:\tlearn: 1.0754340\ttest: 1.0765978\tbest: 1.0765978 (46)\ttotal: 476ms\tremaining: 1m 40s\n",
      "47:\tlearn: 1.0750293\ttest: 1.0762096\tbest: 1.0762096 (47)\ttotal: 486ms\tremaining: 1m 40s\n",
      "48:\tlearn: 1.0746185\ttest: 1.0758383\tbest: 1.0758383 (48)\ttotal: 496ms\tremaining: 1m 40s\n",
      "49:\tlearn: 1.0742053\ttest: 1.0754490\tbest: 1.0754490 (49)\ttotal: 505ms\tremaining: 1m 40s\n",
      "50:\tlearn: 1.0737837\ttest: 1.0750661\tbest: 1.0750661 (50)\ttotal: 514ms\tremaining: 1m 40s\n",
      "51:\tlearn: 1.0733733\ttest: 1.0746954\tbest: 1.0746954 (51)\ttotal: 523ms\tremaining: 1m 40s\n",
      "52:\tlearn: 1.0729408\ttest: 1.0743154\tbest: 1.0743154 (52)\ttotal: 532ms\tremaining: 1m 39s\n",
      "53:\tlearn: 1.0725642\ttest: 1.0739472\tbest: 1.0739472 (53)\ttotal: 541ms\tremaining: 1m 39s\n",
      "54:\tlearn: 1.0721814\ttest: 1.0735992\tbest: 1.0735992 (54)\ttotal: 552ms\tremaining: 1m 39s\n",
      "55:\tlearn: 1.0718084\ttest: 1.0732597\tbest: 1.0732597 (55)\ttotal: 564ms\tremaining: 1m 40s\n",
      "56:\tlearn: 1.0714568\ttest: 1.0729354\tbest: 1.0729354 (56)\ttotal: 578ms\tremaining: 1m 40s\n",
      "57:\tlearn: 1.0710610\ttest: 1.0725767\tbest: 1.0725767 (57)\ttotal: 591ms\tremaining: 1m 41s\n",
      "58:\tlearn: 1.0706790\ttest: 1.0722114\tbest: 1.0722114 (58)\ttotal: 606ms\tremaining: 1m 42s\n",
      "59:\tlearn: 1.0703387\ttest: 1.0718709\tbest: 1.0718709 (59)\ttotal: 626ms\tremaining: 1m 43s\n",
      "60:\tlearn: 1.0700071\ttest: 1.0715338\tbest: 1.0715338 (60)\ttotal: 637ms\tremaining: 1m 43s\n",
      "61:\tlearn: 1.0697018\ttest: 1.0712282\tbest: 1.0712282 (61)\ttotal: 648ms\tremaining: 1m 43s\n",
      "62:\tlearn: 1.0693804\ttest: 1.0709266\tbest: 1.0709266 (62)\ttotal: 657ms\tremaining: 1m 43s\n",
      "63:\tlearn: 1.0690317\ttest: 1.0705993\tbest: 1.0705993 (63)\ttotal: 668ms\tremaining: 1m 43s\n",
      "64:\tlearn: 1.0686901\ttest: 1.0702933\tbest: 1.0702933 (64)\ttotal: 681ms\tremaining: 1m 44s\n",
      "65:\tlearn: 1.0683244\ttest: 1.0699602\tbest: 1.0699602 (65)\ttotal: 693ms\tremaining: 1m 44s\n",
      "66:\tlearn: 1.0679492\ttest: 1.0696274\tbest: 1.0696274 (66)\ttotal: 702ms\tremaining: 1m 44s\n",
      "67:\tlearn: 1.0676133\ttest: 1.0692991\tbest: 1.0692991 (67)\ttotal: 713ms\tremaining: 1m 44s\n",
      "68:\tlearn: 1.0672265\ttest: 1.0689586\tbest: 1.0689586 (68)\ttotal: 722ms\tremaining: 1m 43s\n",
      "69:\tlearn: 1.0668735\ttest: 1.0686037\tbest: 1.0686037 (69)\ttotal: 731ms\tremaining: 1m 43s\n",
      "70:\tlearn: 1.0665409\ttest: 1.0682875\tbest: 1.0682875 (70)\ttotal: 741ms\tremaining: 1m 43s\n",
      "71:\tlearn: 1.0662069\ttest: 1.0679569\tbest: 1.0679569 (71)\ttotal: 750ms\tremaining: 1m 43s\n",
      "72:\tlearn: 1.0658573\ttest: 1.0676124\tbest: 1.0676124 (72)\ttotal: 761ms\tremaining: 1m 43s\n",
      "73:\tlearn: 1.0655144\ttest: 1.0673079\tbest: 1.0673079 (73)\ttotal: 769ms\tremaining: 1m 43s\n",
      "74:\tlearn: 1.0651531\ttest: 1.0669622\tbest: 1.0669622 (74)\ttotal: 779ms\tremaining: 1m 43s\n",
      "75:\tlearn: 1.0648258\ttest: 1.0666508\tbest: 1.0666508 (75)\ttotal: 788ms\tremaining: 1m 42s\n",
      "76:\tlearn: 1.0644895\ttest: 1.0663254\tbest: 1.0663254 (76)\ttotal: 796ms\tremaining: 1m 42s\n",
      "77:\tlearn: 1.0641125\ttest: 1.0659891\tbest: 1.0659891 (77)\ttotal: 806ms\tremaining: 1m 42s\n",
      "78:\tlearn: 1.0638115\ttest: 1.0657074\tbest: 1.0657074 (78)\ttotal: 815ms\tremaining: 1m 42s\n",
      "79:\tlearn: 1.0634660\ttest: 1.0653779\tbest: 1.0653779 (79)\ttotal: 825ms\tremaining: 1m 42s\n",
      "80:\tlearn: 1.0631453\ttest: 1.0651178\tbest: 1.0651178 (80)\ttotal: 835ms\tremaining: 1m 42s\n",
      "81:\tlearn: 1.0628356\ttest: 1.0648277\tbest: 1.0648277 (81)\ttotal: 844ms\tremaining: 1m 42s\n",
      "82:\tlearn: 1.0625339\ttest: 1.0645111\tbest: 1.0645111 (82)\ttotal: 854ms\tremaining: 1m 42s\n",
      "83:\tlearn: 1.0622045\ttest: 1.0641893\tbest: 1.0641893 (83)\ttotal: 864ms\tremaining: 1m 41s\n",
      "84:\tlearn: 1.0618709\ttest: 1.0638687\tbest: 1.0638687 (84)\ttotal: 875ms\tremaining: 1m 42s\n",
      "85:\tlearn: 1.0616022\ttest: 1.0636096\tbest: 1.0636096 (85)\ttotal: 885ms\tremaining: 1m 41s\n",
      "86:\tlearn: 1.0612992\ttest: 1.0633176\tbest: 1.0633176 (86)\ttotal: 895ms\tremaining: 1m 41s\n",
      "87:\tlearn: 1.0609739\ttest: 1.0630505\tbest: 1.0630505 (87)\ttotal: 905ms\tremaining: 1m 41s\n",
      "88:\tlearn: 1.0606981\ttest: 1.0628070\tbest: 1.0628070 (88)\ttotal: 915ms\tremaining: 1m 41s\n",
      "89:\tlearn: 1.0603997\ttest: 1.0625346\tbest: 1.0625346 (89)\ttotal: 925ms\tremaining: 1m 41s\n",
      "90:\tlearn: 1.0601104\ttest: 1.0622695\tbest: 1.0622695 (90)\ttotal: 935ms\tremaining: 1m 41s\n",
      "91:\tlearn: 1.0598623\ttest: 1.0620394\tbest: 1.0620394 (91)\ttotal: 945ms\tremaining: 1m 41s\n",
      "92:\tlearn: 1.0595455\ttest: 1.0617572\tbest: 1.0617572 (92)\ttotal: 954ms\tremaining: 1m 41s\n",
      "93:\tlearn: 1.0592552\ttest: 1.0615072\tbest: 1.0615072 (93)\ttotal: 963ms\tremaining: 1m 41s\n",
      "94:\tlearn: 1.0589435\ttest: 1.0612233\tbest: 1.0612233 (94)\ttotal: 973ms\tremaining: 1m 41s\n",
      "95:\tlearn: 1.0586458\ttest: 1.0609658\tbest: 1.0609658 (95)\ttotal: 983ms\tremaining: 1m 41s\n",
      "96:\tlearn: 1.0583288\ttest: 1.0607070\tbest: 1.0607070 (96)\ttotal: 993ms\tremaining: 1m 41s\n",
      "97:\tlearn: 1.0580433\ttest: 1.0604604\tbest: 1.0604604 (97)\ttotal: 1s\tremaining: 1m 41s\n",
      "98:\tlearn: 1.0577524\ttest: 1.0601869\tbest: 1.0601869 (98)\ttotal: 1.01s\tremaining: 1m 41s\n",
      "99:\tlearn: 1.0574719\ttest: 1.0599377\tbest: 1.0599377 (99)\ttotal: 1.02s\tremaining: 1m 41s\n",
      "100:\tlearn: 1.0572013\ttest: 1.0597016\tbest: 1.0597016 (100)\ttotal: 1.03s\tremaining: 1m 41s\n",
      "101:\tlearn: 1.0569081\ttest: 1.0594696\tbest: 1.0594696 (101)\ttotal: 1.04s\tremaining: 1m 40s\n",
      "102:\tlearn: 1.0566355\ttest: 1.0592035\tbest: 1.0592035 (102)\ttotal: 1.05s\tremaining: 1m 41s\n",
      "103:\tlearn: 1.0563874\ttest: 1.0589746\tbest: 1.0589746 (103)\ttotal: 1.06s\tremaining: 1m 41s\n",
      "104:\tlearn: 1.0561107\ttest: 1.0587226\tbest: 1.0587226 (104)\ttotal: 1.07s\tremaining: 1m 41s\n",
      "105:\tlearn: 1.0558367\ttest: 1.0584584\tbest: 1.0584584 (105)\ttotal: 1.08s\tremaining: 1m 40s\n",
      "106:\tlearn: 1.0556182\ttest: 1.0582580\tbest: 1.0582580 (106)\ttotal: 1.09s\tremaining: 1m 40s\n",
      "107:\tlearn: 1.0553507\ttest: 1.0580253\tbest: 1.0580253 (107)\ttotal: 1.1s\tremaining: 1m 41s\n",
      "108:\tlearn: 1.0551141\ttest: 1.0577933\tbest: 1.0577933 (108)\ttotal: 1.12s\tremaining: 1m 41s\n",
      "109:\tlearn: 1.0548558\ttest: 1.0575518\tbest: 1.0575518 (109)\ttotal: 1.13s\tremaining: 1m 41s\n",
      "110:\tlearn: 1.0545955\ttest: 1.0573081\tbest: 1.0573081 (110)\ttotal: 1.14s\tremaining: 1m 42s\n",
      "111:\tlearn: 1.0543280\ttest: 1.0570594\tbest: 1.0570594 (111)\ttotal: 1.16s\tremaining: 1m 42s\n",
      "112:\tlearn: 1.0540998\ttest: 1.0568335\tbest: 1.0568335 (112)\ttotal: 1.17s\tremaining: 1m 42s\n",
      "113:\tlearn: 1.0538567\ttest: 1.0566242\tbest: 1.0566242 (113)\ttotal: 1.18s\tremaining: 1m 42s\n",
      "114:\tlearn: 1.0535998\ttest: 1.0564254\tbest: 1.0564254 (114)\ttotal: 1.19s\tremaining: 1m 42s\n",
      "115:\tlearn: 1.0533761\ttest: 1.0562040\tbest: 1.0562040 (115)\ttotal: 1.2s\tremaining: 1m 42s\n",
      "116:\tlearn: 1.0531085\ttest: 1.0559716\tbest: 1.0559716 (116)\ttotal: 1.21s\tremaining: 1m 42s\n",
      "117:\tlearn: 1.0528699\ttest: 1.0557708\tbest: 1.0557708 (117)\ttotal: 1.22s\tremaining: 1m 42s\n",
      "118:\tlearn: 1.0526187\ttest: 1.0555349\tbest: 1.0555349 (118)\ttotal: 1.23s\tremaining: 1m 42s\n",
      "119:\tlearn: 1.0523892\ttest: 1.0553349\tbest: 1.0553349 (119)\ttotal: 1.24s\tremaining: 1m 41s\n",
      "120:\tlearn: 1.0521442\ttest: 1.0551282\tbest: 1.0551282 (120)\ttotal: 1.25s\tremaining: 1m 41s\n",
      "121:\tlearn: 1.0518906\ttest: 1.0549063\tbest: 1.0549063 (121)\ttotal: 1.25s\tremaining: 1m 41s\n",
      "122:\tlearn: 1.0516765\ttest: 1.0546845\tbest: 1.0546845 (122)\ttotal: 1.26s\tremaining: 1m 41s\n",
      "123:\tlearn: 1.0514376\ttest: 1.0544658\tbest: 1.0544658 (123)\ttotal: 1.27s\tremaining: 1m 41s\n",
      "124:\tlearn: 1.0512358\ttest: 1.0542927\tbest: 1.0542927 (124)\ttotal: 1.28s\tremaining: 1m 41s\n",
      "125:\tlearn: 1.0509987\ttest: 1.0540819\tbest: 1.0540819 (125)\ttotal: 1.29s\tremaining: 1m 41s\n",
      "126:\tlearn: 1.0507785\ttest: 1.0539347\tbest: 1.0539347 (126)\ttotal: 1.3s\tremaining: 1m 41s\n",
      "127:\tlearn: 1.0505531\ttest: 1.0537316\tbest: 1.0537316 (127)\ttotal: 1.31s\tremaining: 1m 41s\n",
      "128:\tlearn: 1.0503432\ttest: 1.0535468\tbest: 1.0535468 (128)\ttotal: 1.32s\tremaining: 1m 41s\n",
      "129:\tlearn: 1.0500986\ttest: 1.0533328\tbest: 1.0533328 (129)\ttotal: 1.33s\tremaining: 1m 40s\n",
      "130:\tlearn: 1.0498420\ttest: 1.0531231\tbest: 1.0531231 (130)\ttotal: 1.34s\tremaining: 1m 40s\n",
      "131:\tlearn: 1.0496429\ttest: 1.0529256\tbest: 1.0529256 (131)\ttotal: 1.35s\tremaining: 1m 40s\n",
      "132:\tlearn: 1.0494192\ttest: 1.0526968\tbest: 1.0526968 (132)\ttotal: 1.36s\tremaining: 1m 40s\n",
      "133:\tlearn: 1.0492156\ttest: 1.0525133\tbest: 1.0525133 (133)\ttotal: 1.37s\tremaining: 1m 40s\n",
      "134:\tlearn: 1.0489857\ttest: 1.0523029\tbest: 1.0523029 (134)\ttotal: 1.38s\tremaining: 1m 40s\n",
      "135:\tlearn: 1.0487731\ttest: 1.0520975\tbest: 1.0520975 (135)\ttotal: 1.39s\tremaining: 1m 40s\n",
      "136:\tlearn: 1.0485611\ttest: 1.0518994\tbest: 1.0518994 (136)\ttotal: 1.4s\tremaining: 1m 40s\n",
      "137:\tlearn: 1.0483657\ttest: 1.0517275\tbest: 1.0517275 (137)\ttotal: 1.41s\tremaining: 1m 40s\n",
      "138:\tlearn: 1.0481542\ttest: 1.0515544\tbest: 1.0515544 (138)\ttotal: 1.42s\tremaining: 1m 40s\n",
      "139:\tlearn: 1.0479615\ttest: 1.0513719\tbest: 1.0513719 (139)\ttotal: 1.43s\tremaining: 1m 40s\n",
      "140:\tlearn: 1.0477546\ttest: 1.0511643\tbest: 1.0511643 (140)\ttotal: 1.44s\tremaining: 1m 40s\n",
      "141:\tlearn: 1.0475389\ttest: 1.0509745\tbest: 1.0509745 (141)\ttotal: 1.45s\tremaining: 1m 40s\n",
      "142:\tlearn: 1.0473253\ttest: 1.0508143\tbest: 1.0508143 (142)\ttotal: 1.46s\tremaining: 1m 40s\n",
      "143:\tlearn: 1.0471327\ttest: 1.0506508\tbest: 1.0506508 (143)\ttotal: 1.47s\tremaining: 1m 40s\n",
      "144:\tlearn: 1.0469245\ttest: 1.0504541\tbest: 1.0504541 (144)\ttotal: 1.48s\tremaining: 1m 40s\n",
      "145:\tlearn: 1.0467190\ttest: 1.0502682\tbest: 1.0502682 (145)\ttotal: 1.49s\tremaining: 1m 40s\n",
      "146:\tlearn: 1.0465632\ttest: 1.0501256\tbest: 1.0501256 (146)\ttotal: 1.5s\tremaining: 1m 40s\n",
      "147:\tlearn: 1.0463546\ttest: 1.0499151\tbest: 1.0499151 (147)\ttotal: 1.51s\tremaining: 1m 40s\n",
      "148:\tlearn: 1.0461206\ttest: 1.0497123\tbest: 1.0497123 (148)\ttotal: 1.52s\tremaining: 1m 40s\n",
      "149:\tlearn: 1.0459389\ttest: 1.0495653\tbest: 1.0495653 (149)\ttotal: 1.53s\tremaining: 1m 40s\n",
      "150:\tlearn: 1.0457787\ttest: 1.0494233\tbest: 1.0494233 (150)\ttotal: 1.54s\tremaining: 1m 40s\n",
      "151:\tlearn: 1.0455565\ttest: 1.0492375\tbest: 1.0492375 (151)\ttotal: 1.55s\tremaining: 1m 40s\n",
      "152:\tlearn: 1.0453496\ttest: 1.0490596\tbest: 1.0490596 (152)\ttotal: 1.56s\tremaining: 1m 40s\n",
      "153:\tlearn: 1.0451657\ttest: 1.0489098\tbest: 1.0489098 (153)\ttotal: 1.57s\tremaining: 1m 40s\n",
      "154:\tlearn: 1.0449796\ttest: 1.0487336\tbest: 1.0487336 (154)\ttotal: 1.58s\tremaining: 1m 40s\n",
      "155:\tlearn: 1.0447866\ttest: 1.0485639\tbest: 1.0485639 (155)\ttotal: 1.59s\tremaining: 1m 40s\n",
      "156:\tlearn: 1.0445863\ttest: 1.0483967\tbest: 1.0483967 (156)\ttotal: 1.6s\tremaining: 1m 40s\n",
      "157:\tlearn: 1.0444075\ttest: 1.0482389\tbest: 1.0482389 (157)\ttotal: 1.61s\tremaining: 1m 40s\n",
      "158:\tlearn: 1.0442386\ttest: 1.0480822\tbest: 1.0480822 (158)\ttotal: 1.62s\tremaining: 1m 40s\n",
      "159:\tlearn: 1.0440662\ttest: 1.0479582\tbest: 1.0479582 (159)\ttotal: 1.63s\tremaining: 1m 40s\n",
      "160:\tlearn: 1.0438585\ttest: 1.0477834\tbest: 1.0477834 (160)\ttotal: 1.64s\tremaining: 1m 40s\n",
      "161:\tlearn: 1.0436614\ttest: 1.0476167\tbest: 1.0476167 (161)\ttotal: 1.65s\tremaining: 1m 40s\n",
      "162:\tlearn: 1.0434671\ttest: 1.0474444\tbest: 1.0474444 (162)\ttotal: 1.66s\tremaining: 1m 39s\n",
      "163:\tlearn: 1.0432918\ttest: 1.0472653\tbest: 1.0472653 (163)\ttotal: 1.66s\tremaining: 1m 39s\n",
      "164:\tlearn: 1.0431065\ttest: 1.0470792\tbest: 1.0470792 (164)\ttotal: 1.67s\tremaining: 1m 39s\n",
      "165:\tlearn: 1.0428914\ttest: 1.0468809\tbest: 1.0468809 (165)\ttotal: 1.68s\tremaining: 1m 39s\n",
      "166:\tlearn: 1.0426885\ttest: 1.0467194\tbest: 1.0467194 (166)\ttotal: 1.69s\tremaining: 1m 39s\n",
      "167:\tlearn: 1.0425404\ttest: 1.0465696\tbest: 1.0465696 (167)\ttotal: 1.7s\tremaining: 1m 39s\n",
      "168:\tlearn: 1.0423860\ttest: 1.0464047\tbest: 1.0464047 (168)\ttotal: 1.71s\tremaining: 1m 39s\n",
      "169:\tlearn: 1.0422036\ttest: 1.0462507\tbest: 1.0462507 (169)\ttotal: 1.72s\tremaining: 1m 39s\n",
      "170:\tlearn: 1.0420132\ttest: 1.0460820\tbest: 1.0460820 (170)\ttotal: 1.73s\tremaining: 1m 39s\n",
      "171:\tlearn: 1.0418301\ttest: 1.0459205\tbest: 1.0459205 (171)\ttotal: 1.74s\tremaining: 1m 39s\n",
      "172:\tlearn: 1.0416502\ttest: 1.0457446\tbest: 1.0457446 (172)\ttotal: 1.75s\tremaining: 1m 39s\n",
      "173:\tlearn: 1.0414855\ttest: 1.0456148\tbest: 1.0456148 (173)\ttotal: 1.76s\tremaining: 1m 39s\n",
      "174:\tlearn: 1.0413160\ttest: 1.0454536\tbest: 1.0454536 (174)\ttotal: 1.77s\tremaining: 1m 39s\n",
      "175:\tlearn: 1.0411564\ttest: 1.0453446\tbest: 1.0453446 (175)\ttotal: 1.78s\tremaining: 1m 39s\n",
      "176:\tlearn: 1.0409762\ttest: 1.0451876\tbest: 1.0451876 (176)\ttotal: 1.79s\tremaining: 1m 39s\n",
      "177:\tlearn: 1.0408207\ttest: 1.0450564\tbest: 1.0450564 (177)\ttotal: 1.8s\tremaining: 1m 39s\n",
      "178:\tlearn: 1.0406846\ttest: 1.0449091\tbest: 1.0449091 (178)\ttotal: 1.81s\tremaining: 1m 39s\n",
      "179:\tlearn: 1.0405075\ttest: 1.0447556\tbest: 1.0447556 (179)\ttotal: 1.82s\tremaining: 1m 39s\n",
      "180:\tlearn: 1.0403319\ttest: 1.0446154\tbest: 1.0446154 (180)\ttotal: 1.83s\tremaining: 1m 39s\n",
      "181:\tlearn: 1.0401761\ttest: 1.0444733\tbest: 1.0444733 (181)\ttotal: 1.84s\tremaining: 1m 39s\n",
      "182:\tlearn: 1.0400163\ttest: 1.0443392\tbest: 1.0443392 (182)\ttotal: 1.85s\tremaining: 1m 39s\n",
      "183:\tlearn: 1.0398545\ttest: 1.0442168\tbest: 1.0442168 (183)\ttotal: 1.86s\tremaining: 1m 39s\n",
      "184:\tlearn: 1.0396797\ttest: 1.0440691\tbest: 1.0440691 (184)\ttotal: 1.87s\tremaining: 1m 39s\n",
      "185:\tlearn: 1.0395504\ttest: 1.0439564\tbest: 1.0439564 (185)\ttotal: 1.88s\tremaining: 1m 39s\n",
      "186:\tlearn: 1.0393786\ttest: 1.0438046\tbest: 1.0438046 (186)\ttotal: 1.89s\tremaining: 1m 39s\n",
      "187:\tlearn: 1.0392270\ttest: 1.0436847\tbest: 1.0436847 (187)\ttotal: 1.9s\tremaining: 1m 39s\n",
      "188:\tlearn: 1.0390464\ttest: 1.0435435\tbest: 1.0435435 (188)\ttotal: 1.91s\tremaining: 1m 39s\n",
      "189:\tlearn: 1.0388872\ttest: 1.0433914\tbest: 1.0433914 (189)\ttotal: 1.92s\tremaining: 1m 39s\n",
      "190:\tlearn: 1.0387430\ttest: 1.0432768\tbest: 1.0432768 (190)\ttotal: 1.93s\tremaining: 1m 39s\n",
      "191:\tlearn: 1.0385945\ttest: 1.0431484\tbest: 1.0431484 (191)\ttotal: 1.94s\tremaining: 1m 39s\n",
      "192:\tlearn: 1.0384225\ttest: 1.0429952\tbest: 1.0429952 (192)\ttotal: 1.95s\tremaining: 1m 39s\n",
      "193:\tlearn: 1.0382707\ttest: 1.0428653\tbest: 1.0428653 (193)\ttotal: 1.96s\tremaining: 1m 39s\n",
      "194:\tlearn: 1.0381338\ttest: 1.0427314\tbest: 1.0427314 (194)\ttotal: 1.97s\tremaining: 1m 39s\n",
      "195:\tlearn: 1.0379825\ttest: 1.0425937\tbest: 1.0425937 (195)\ttotal: 1.98s\tremaining: 1m 39s\n",
      "196:\tlearn: 1.0378391\ttest: 1.0424919\tbest: 1.0424919 (196)\ttotal: 1.99s\tremaining: 1m 39s\n",
      "197:\tlearn: 1.0377041\ttest: 1.0423794\tbest: 1.0423794 (197)\ttotal: 2s\tremaining: 1m 39s\n",
      "198:\tlearn: 1.0375415\ttest: 1.0422569\tbest: 1.0422569 (198)\ttotal: 2.01s\tremaining: 1m 38s\n",
      "199:\tlearn: 1.0373640\ttest: 1.0421103\tbest: 1.0421103 (199)\ttotal: 2.02s\tremaining: 1m 38s\n",
      "200:\tlearn: 1.0371817\ttest: 1.0419399\tbest: 1.0419399 (200)\ttotal: 2.03s\tremaining: 1m 39s\n",
      "201:\tlearn: 1.0370201\ttest: 1.0417938\tbest: 1.0417938 (201)\ttotal: 2.04s\tremaining: 1m 39s\n",
      "202:\tlearn: 1.0368770\ttest: 1.0416889\tbest: 1.0416889 (202)\ttotal: 2.05s\tremaining: 1m 39s\n",
      "203:\tlearn: 1.0367263\ttest: 1.0415555\tbest: 1.0415555 (203)\ttotal: 2.06s\tremaining: 1m 39s\n",
      "204:\tlearn: 1.0365880\ttest: 1.0414554\tbest: 1.0414554 (204)\ttotal: 2.08s\tremaining: 1m 39s\n",
      "205:\tlearn: 1.0364189\ttest: 1.0413093\tbest: 1.0413093 (205)\ttotal: 2.09s\tremaining: 1m 39s\n",
      "206:\tlearn: 1.0362812\ttest: 1.0411871\tbest: 1.0411871 (206)\ttotal: 2.1s\tremaining: 1m 39s\n",
      "207:\tlearn: 1.0361489\ttest: 1.0410966\tbest: 1.0410966 (207)\ttotal: 2.11s\tremaining: 1m 39s\n",
      "208:\tlearn: 1.0360096\ttest: 1.0409696\tbest: 1.0409696 (208)\ttotal: 2.12s\tremaining: 1m 39s\n",
      "209:\tlearn: 1.0358932\ttest: 1.0408656\tbest: 1.0408656 (209)\ttotal: 2.13s\tremaining: 1m 39s\n",
      "210:\tlearn: 1.0357406\ttest: 1.0407450\tbest: 1.0407450 (210)\ttotal: 2.14s\tremaining: 1m 39s\n",
      "211:\tlearn: 1.0356168\ttest: 1.0406291\tbest: 1.0406291 (211)\ttotal: 2.15s\tremaining: 1m 39s\n",
      "212:\tlearn: 1.0354850\ttest: 1.0405121\tbest: 1.0405121 (212)\ttotal: 2.16s\tremaining: 1m 39s\n",
      "213:\tlearn: 1.0353609\ttest: 1.0404061\tbest: 1.0404061 (213)\ttotal: 2.17s\tremaining: 1m 39s\n",
      "214:\tlearn: 1.0352305\ttest: 1.0402862\tbest: 1.0402862 (214)\ttotal: 2.18s\tremaining: 1m 39s\n",
      "215:\tlearn: 1.0350753\ttest: 1.0401551\tbest: 1.0401551 (215)\ttotal: 2.19s\tremaining: 1m 39s\n",
      "216:\tlearn: 1.0349332\ttest: 1.0400480\tbest: 1.0400480 (216)\ttotal: 2.2s\tremaining: 1m 39s\n",
      "217:\tlearn: 1.0348061\ttest: 1.0399449\tbest: 1.0399449 (217)\ttotal: 2.2s\tremaining: 1m 38s\n",
      "218:\tlearn: 1.0346738\ttest: 1.0398344\tbest: 1.0398344 (218)\ttotal: 2.21s\tremaining: 1m 38s\n",
      "219:\tlearn: 1.0345633\ttest: 1.0397337\tbest: 1.0397337 (219)\ttotal: 2.22s\tremaining: 1m 38s\n",
      "220:\tlearn: 1.0344297\ttest: 1.0396156\tbest: 1.0396156 (220)\ttotal: 2.23s\tremaining: 1m 38s\n",
      "221:\tlearn: 1.0342945\ttest: 1.0394836\tbest: 1.0394836 (221)\ttotal: 2.24s\tremaining: 1m 38s\n",
      "222:\tlearn: 1.0341732\ttest: 1.0393734\tbest: 1.0393734 (222)\ttotal: 2.25s\tremaining: 1m 38s\n",
      "223:\tlearn: 1.0340350\ttest: 1.0392520\tbest: 1.0392520 (223)\ttotal: 2.26s\tremaining: 1m 38s\n",
      "224:\tlearn: 1.0339067\ttest: 1.0391359\tbest: 1.0391359 (224)\ttotal: 2.27s\tremaining: 1m 38s\n",
      "225:\tlearn: 1.0337775\ttest: 1.0390207\tbest: 1.0390207 (225)\ttotal: 2.28s\tremaining: 1m 38s\n",
      "226:\tlearn: 1.0336516\ttest: 1.0389089\tbest: 1.0389089 (226)\ttotal: 2.28s\tremaining: 1m 38s\n",
      "227:\tlearn: 1.0335222\ttest: 1.0388042\tbest: 1.0388042 (227)\ttotal: 2.29s\tremaining: 1m 38s\n",
      "228:\tlearn: 1.0333832\ttest: 1.0386900\tbest: 1.0386900 (228)\ttotal: 2.3s\tremaining: 1m 38s\n",
      "229:\tlearn: 1.0332407\ttest: 1.0385519\tbest: 1.0385519 (229)\ttotal: 2.31s\tremaining: 1m 38s\n",
      "230:\tlearn: 1.0331131\ttest: 1.0384423\tbest: 1.0384423 (230)\ttotal: 2.32s\tremaining: 1m 38s\n",
      "231:\tlearn: 1.0329945\ttest: 1.0383415\tbest: 1.0383415 (231)\ttotal: 2.33s\tremaining: 1m 38s\n",
      "232:\tlearn: 1.0328830\ttest: 1.0382504\tbest: 1.0382504 (232)\ttotal: 2.34s\tremaining: 1m 38s\n",
      "233:\tlearn: 1.0327848\ttest: 1.0381778\tbest: 1.0381778 (233)\ttotal: 2.35s\tremaining: 1m 38s\n",
      "234:\tlearn: 1.0326478\ttest: 1.0380813\tbest: 1.0380813 (234)\ttotal: 2.36s\tremaining: 1m 38s\n",
      "235:\tlearn: 1.0325446\ttest: 1.0379891\tbest: 1.0379891 (235)\ttotal: 2.37s\tremaining: 1m 38s\n",
      "236:\tlearn: 1.0324270\ttest: 1.0378814\tbest: 1.0378814 (236)\ttotal: 2.38s\tremaining: 1m 38s\n",
      "237:\tlearn: 1.0323016\ttest: 1.0377861\tbest: 1.0377861 (237)\ttotal: 2.39s\tremaining: 1m 38s\n",
      "238:\tlearn: 1.0321832\ttest: 1.0377071\tbest: 1.0377071 (238)\ttotal: 2.4s\tremaining: 1m 38s\n",
      "239:\tlearn: 1.0320614\ttest: 1.0376059\tbest: 1.0376059 (239)\ttotal: 2.41s\tremaining: 1m 38s\n",
      "240:\tlearn: 1.0319585\ttest: 1.0375372\tbest: 1.0375372 (240)\ttotal: 2.42s\tremaining: 1m 38s\n",
      "241:\tlearn: 1.0318704\ttest: 1.0374638\tbest: 1.0374638 (241)\ttotal: 2.43s\tremaining: 1m 38s\n",
      "242:\tlearn: 1.0317468\ttest: 1.0373644\tbest: 1.0373644 (242)\ttotal: 2.44s\tremaining: 1m 37s\n",
      "243:\tlearn: 1.0316360\ttest: 1.0372675\tbest: 1.0372675 (243)\ttotal: 2.45s\tremaining: 1m 37s\n",
      "244:\tlearn: 1.0315119\ttest: 1.0371732\tbest: 1.0371732 (244)\ttotal: 2.46s\tremaining: 1m 37s\n",
      "245:\tlearn: 1.0313979\ttest: 1.0370911\tbest: 1.0370911 (245)\ttotal: 2.47s\tremaining: 1m 38s\n",
      "246:\tlearn: 1.0312708\ttest: 1.0369989\tbest: 1.0369989 (246)\ttotal: 2.48s\tremaining: 1m 37s\n",
      "247:\tlearn: 1.0311569\ttest: 1.0369052\tbest: 1.0369052 (247)\ttotal: 2.49s\tremaining: 1m 37s\n",
      "248:\tlearn: 1.0310553\ttest: 1.0368094\tbest: 1.0368094 (248)\ttotal: 2.5s\tremaining: 1m 37s\n",
      "249:\tlearn: 1.0309543\ttest: 1.0367341\tbest: 1.0367341 (249)\ttotal: 2.51s\tremaining: 1m 37s\n",
      "250:\tlearn: 1.0308342\ttest: 1.0366424\tbest: 1.0366424 (250)\ttotal: 2.52s\tremaining: 1m 37s\n",
      "251:\tlearn: 1.0307108\ttest: 1.0365383\tbest: 1.0365383 (251)\ttotal: 2.53s\tremaining: 1m 37s\n",
      "252:\tlearn: 1.0305875\ttest: 1.0364432\tbest: 1.0364432 (252)\ttotal: 2.54s\tremaining: 1m 37s\n",
      "253:\tlearn: 1.0304824\ttest: 1.0363412\tbest: 1.0363412 (253)\ttotal: 2.54s\tremaining: 1m 37s\n",
      "254:\tlearn: 1.0303640\ttest: 1.0362384\tbest: 1.0362384 (254)\ttotal: 2.56s\tremaining: 1m 37s\n",
      "255:\tlearn: 1.0302447\ttest: 1.0361439\tbest: 1.0361439 (255)\ttotal: 2.57s\tremaining: 1m 37s\n",
      "256:\tlearn: 1.0301254\ttest: 1.0360412\tbest: 1.0360412 (256)\ttotal: 2.58s\tremaining: 1m 37s\n",
      "257:\tlearn: 1.0300312\ttest: 1.0359659\tbest: 1.0359659 (257)\ttotal: 2.58s\tremaining: 1m 37s\n",
      "258:\tlearn: 1.0299102\ttest: 1.0358666\tbest: 1.0358666 (258)\ttotal: 2.6s\tremaining: 1m 37s\n",
      "259:\tlearn: 1.0297926\ttest: 1.0357725\tbest: 1.0357725 (259)\ttotal: 2.6s\tremaining: 1m 37s\n",
      "260:\tlearn: 1.0296759\ttest: 1.0356837\tbest: 1.0356837 (260)\ttotal: 2.62s\tremaining: 1m 37s\n",
      "261:\tlearn: 1.0295765\ttest: 1.0355868\tbest: 1.0355868 (261)\ttotal: 2.63s\tremaining: 1m 37s\n",
      "262:\tlearn: 1.0294668\ttest: 1.0355001\tbest: 1.0355001 (262)\ttotal: 2.63s\tremaining: 1m 37s\n",
      "263:\tlearn: 1.0293643\ttest: 1.0354244\tbest: 1.0354244 (263)\ttotal: 2.64s\tremaining: 1m 37s\n",
      "264:\tlearn: 1.0292716\ttest: 1.0353643\tbest: 1.0353643 (264)\ttotal: 2.65s\tremaining: 1m 37s\n",
      "265:\tlearn: 1.0291641\ttest: 1.0352898\tbest: 1.0352898 (265)\ttotal: 2.66s\tremaining: 1m 37s\n",
      "266:\tlearn: 1.0290647\ttest: 1.0351847\tbest: 1.0351847 (266)\ttotal: 2.67s\tremaining: 1m 37s\n",
      "267:\tlearn: 1.0289688\ttest: 1.0351048\tbest: 1.0351048 (267)\ttotal: 2.68s\tremaining: 1m 37s\n",
      "268:\tlearn: 1.0288480\ttest: 1.0350260\tbest: 1.0350260 (268)\ttotal: 2.69s\tremaining: 1m 37s\n",
      "269:\tlearn: 1.0287461\ttest: 1.0349466\tbest: 1.0349466 (269)\ttotal: 2.7s\tremaining: 1m 37s\n",
      "270:\tlearn: 1.0286141\ttest: 1.0348513\tbest: 1.0348513 (270)\ttotal: 2.71s\tremaining: 1m 37s\n",
      "271:\tlearn: 1.0285123\ttest: 1.0347817\tbest: 1.0347817 (271)\ttotal: 2.72s\tremaining: 1m 37s\n",
      "272:\tlearn: 1.0284183\ttest: 1.0346948\tbest: 1.0346948 (272)\ttotal: 2.73s\tremaining: 1m 37s\n",
      "273:\tlearn: 1.0283283\ttest: 1.0346181\tbest: 1.0346181 (273)\ttotal: 2.74s\tremaining: 1m 37s\n",
      "274:\tlearn: 1.0282447\ttest: 1.0345608\tbest: 1.0345608 (274)\ttotal: 2.75s\tremaining: 1m 37s\n",
      "275:\tlearn: 1.0281475\ttest: 1.0344947\tbest: 1.0344947 (275)\ttotal: 2.76s\tremaining: 1m 37s\n",
      "276:\tlearn: 1.0280457\ttest: 1.0344103\tbest: 1.0344103 (276)\ttotal: 2.77s\tremaining: 1m 37s\n",
      "277:\tlearn: 1.0279345\ttest: 1.0343156\tbest: 1.0343156 (277)\ttotal: 2.78s\tremaining: 1m 37s\n",
      "278:\tlearn: 1.0278664\ttest: 1.0342454\tbest: 1.0342454 (278)\ttotal: 2.79s\tremaining: 1m 37s\n",
      "279:\tlearn: 1.0277948\ttest: 1.0341880\tbest: 1.0341880 (279)\ttotal: 2.8s\tremaining: 1m 37s\n",
      "280:\tlearn: 1.0277067\ttest: 1.0341212\tbest: 1.0341212 (280)\ttotal: 2.81s\tremaining: 1m 37s\n",
      "281:\tlearn: 1.0275954\ttest: 1.0340384\tbest: 1.0340384 (281)\ttotal: 2.82s\tremaining: 1m 37s\n",
      "282:\tlearn: 1.0275051\ttest: 1.0339476\tbest: 1.0339476 (282)\ttotal: 2.83s\tremaining: 1m 37s\n",
      "283:\tlearn: 1.0274148\ttest: 1.0338604\tbest: 1.0338604 (283)\ttotal: 2.83s\tremaining: 1m 36s\n",
      "284:\tlearn: 1.0273259\ttest: 1.0337750\tbest: 1.0337750 (284)\ttotal: 2.84s\tremaining: 1m 36s\n",
      "285:\tlearn: 1.0272574\ttest: 1.0337165\tbest: 1.0337165 (285)\ttotal: 2.85s\tremaining: 1m 36s\n",
      "286:\tlearn: 1.0271628\ttest: 1.0336467\tbest: 1.0336467 (286)\ttotal: 2.86s\tremaining: 1m 36s\n",
      "287:\tlearn: 1.0270538\ttest: 1.0335595\tbest: 1.0335595 (287)\ttotal: 2.87s\tremaining: 1m 36s\n",
      "288:\tlearn: 1.0269322\ttest: 1.0334786\tbest: 1.0334786 (288)\ttotal: 2.88s\tremaining: 1m 36s\n",
      "289:\tlearn: 1.0268421\ttest: 1.0334124\tbest: 1.0334124 (289)\ttotal: 2.89s\tremaining: 1m 36s\n",
      "290:\tlearn: 1.0267590\ttest: 1.0333337\tbest: 1.0333337 (290)\ttotal: 2.9s\tremaining: 1m 36s\n",
      "291:\tlearn: 1.0266651\ttest: 1.0332715\tbest: 1.0332715 (291)\ttotal: 2.91s\tremaining: 1m 36s\n",
      "292:\tlearn: 1.0265831\ttest: 1.0331980\tbest: 1.0331980 (292)\ttotal: 2.92s\tremaining: 1m 36s\n",
      "293:\tlearn: 1.0264911\ttest: 1.0331201\tbest: 1.0331201 (293)\ttotal: 2.93s\tremaining: 1m 36s\n",
      "294:\tlearn: 1.0263949\ttest: 1.0330448\tbest: 1.0330448 (294)\ttotal: 2.94s\tremaining: 1m 36s\n",
      "295:\tlearn: 1.0262983\ttest: 1.0329762\tbest: 1.0329762 (295)\ttotal: 2.95s\tremaining: 1m 36s\n",
      "296:\tlearn: 1.0261992\ttest: 1.0328924\tbest: 1.0328924 (296)\ttotal: 2.96s\tremaining: 1m 36s\n",
      "297:\tlearn: 1.0260985\ttest: 1.0328304\tbest: 1.0328304 (297)\ttotal: 2.97s\tremaining: 1m 36s\n",
      "298:\tlearn: 1.0260297\ttest: 1.0327681\tbest: 1.0327681 (298)\ttotal: 2.98s\tremaining: 1m 36s\n",
      "299:\tlearn: 1.0259270\ttest: 1.0326864\tbest: 1.0326864 (299)\ttotal: 2.99s\tremaining: 1m 36s\n",
      "300:\tlearn: 1.0258355\ttest: 1.0326152\tbest: 1.0326152 (300)\ttotal: 3s\tremaining: 1m 36s\n",
      "301:\tlearn: 1.0257507\ttest: 1.0325438\tbest: 1.0325438 (301)\ttotal: 3s\tremaining: 1m 36s\n",
      "302:\tlearn: 1.0256494\ttest: 1.0324676\tbest: 1.0324676 (302)\ttotal: 3.02s\tremaining: 1m 36s\n",
      "303:\tlearn: 1.0255273\ttest: 1.0323710\tbest: 1.0323710 (303)\ttotal: 3.02s\tremaining: 1m 36s\n",
      "304:\tlearn: 1.0254471\ttest: 1.0323162\tbest: 1.0323162 (304)\ttotal: 3.04s\tremaining: 1m 36s\n",
      "305:\tlearn: 1.0253465\ttest: 1.0322402\tbest: 1.0322402 (305)\ttotal: 3.04s\tremaining: 1m 36s\n",
      "306:\tlearn: 1.0252777\ttest: 1.0321738\tbest: 1.0321738 (306)\ttotal: 3.05s\tremaining: 1m 36s\n",
      "307:\tlearn: 1.0251985\ttest: 1.0321162\tbest: 1.0321162 (307)\ttotal: 3.06s\tremaining: 1m 36s\n",
      "308:\tlearn: 1.0251041\ttest: 1.0320546\tbest: 1.0320546 (308)\ttotal: 3.08s\tremaining: 1m 36s\n",
      "309:\tlearn: 1.0250275\ttest: 1.0319980\tbest: 1.0319980 (309)\ttotal: 3.09s\tremaining: 1m 36s\n",
      "310:\tlearn: 1.0249366\ttest: 1.0319481\tbest: 1.0319481 (310)\ttotal: 3.1s\tremaining: 1m 36s\n",
      "311:\tlearn: 1.0248368\ttest: 1.0318763\tbest: 1.0318763 (311)\ttotal: 3.1s\tremaining: 1m 36s\n",
      "312:\tlearn: 1.0247528\ttest: 1.0318221\tbest: 1.0318221 (312)\ttotal: 3.11s\tremaining: 1m 36s\n",
      "313:\tlearn: 1.0246576\ttest: 1.0317648\tbest: 1.0317648 (313)\ttotal: 3.12s\tremaining: 1m 36s\n",
      "314:\tlearn: 1.0245788\ttest: 1.0316985\tbest: 1.0316985 (314)\ttotal: 3.13s\tremaining: 1m 36s\n",
      "315:\tlearn: 1.0244936\ttest: 1.0316209\tbest: 1.0316209 (315)\ttotal: 3.14s\tremaining: 1m 36s\n",
      "316:\tlearn: 1.0244142\ttest: 1.0315769\tbest: 1.0315769 (316)\ttotal: 3.15s\tremaining: 1m 36s\n",
      "317:\tlearn: 1.0243313\ttest: 1.0315215\tbest: 1.0315215 (317)\ttotal: 3.16s\tremaining: 1m 36s\n",
      "318:\tlearn: 1.0242405\ttest: 1.0314619\tbest: 1.0314619 (318)\ttotal: 3.17s\tremaining: 1m 36s\n",
      "319:\tlearn: 1.0241546\ttest: 1.0313781\tbest: 1.0313781 (319)\ttotal: 3.19s\tremaining: 1m 36s\n",
      "320:\tlearn: 1.0240790\ttest: 1.0313155\tbest: 1.0313155 (320)\ttotal: 3.19s\tremaining: 1m 36s\n",
      "321:\tlearn: 1.0239924\ttest: 1.0312786\tbest: 1.0312786 (321)\ttotal: 3.23s\tremaining: 1m 36s\n",
      "322:\tlearn: 1.0239041\ttest: 1.0312080\tbest: 1.0312080 (322)\ttotal: 3.24s\tremaining: 1m 37s\n",
      "323:\tlearn: 1.0238143\ttest: 1.0311446\tbest: 1.0311446 (323)\ttotal: 3.25s\tremaining: 1m 37s\n",
      "324:\tlearn: 1.0237441\ttest: 1.0310966\tbest: 1.0310966 (324)\ttotal: 3.26s\tremaining: 1m 37s\n",
      "325:\tlearn: 1.0236611\ttest: 1.0310452\tbest: 1.0310452 (325)\ttotal: 3.27s\tremaining: 1m 37s\n",
      "326:\tlearn: 1.0235728\ttest: 1.0309783\tbest: 1.0309783 (326)\ttotal: 3.28s\tremaining: 1m 37s\n",
      "327:\tlearn: 1.0235128\ttest: 1.0309299\tbest: 1.0309299 (327)\ttotal: 3.29s\tremaining: 1m 37s\n",
      "328:\tlearn: 1.0234291\ttest: 1.0308818\tbest: 1.0308818 (328)\ttotal: 3.3s\tremaining: 1m 36s\n",
      "329:\tlearn: 1.0233412\ttest: 1.0308366\tbest: 1.0308366 (329)\ttotal: 3.31s\tremaining: 1m 36s\n",
      "330:\tlearn: 1.0232614\ttest: 1.0307626\tbest: 1.0307626 (330)\ttotal: 3.32s\tremaining: 1m 36s\n",
      "331:\tlearn: 1.0231851\ttest: 1.0306998\tbest: 1.0306998 (331)\ttotal: 3.33s\tremaining: 1m 36s\n",
      "332:\tlearn: 1.0231157\ttest: 1.0306533\tbest: 1.0306533 (332)\ttotal: 3.34s\tremaining: 1m 36s\n",
      "333:\tlearn: 1.0230274\ttest: 1.0305910\tbest: 1.0305910 (333)\ttotal: 3.35s\tremaining: 1m 36s\n",
      "334:\tlearn: 1.0229504\ttest: 1.0305296\tbest: 1.0305296 (334)\ttotal: 3.35s\tremaining: 1m 36s\n",
      "335:\tlearn: 1.0228802\ttest: 1.0304700\tbest: 1.0304700 (335)\ttotal: 3.36s\tremaining: 1m 36s\n",
      "336:\tlearn: 1.0228124\ttest: 1.0304230\tbest: 1.0304230 (336)\ttotal: 3.37s\tremaining: 1m 36s\n",
      "337:\tlearn: 1.0227370\ttest: 1.0303667\tbest: 1.0303667 (337)\ttotal: 3.38s\tremaining: 1m 36s\n",
      "338:\tlearn: 1.0226621\ttest: 1.0303165\tbest: 1.0303165 (338)\ttotal: 3.39s\tremaining: 1m 36s\n",
      "339:\tlearn: 1.0225889\ttest: 1.0302763\tbest: 1.0302763 (339)\ttotal: 3.4s\tremaining: 1m 36s\n",
      "340:\tlearn: 1.0225214\ttest: 1.0302193\tbest: 1.0302193 (340)\ttotal: 3.41s\tremaining: 1m 36s\n",
      "341:\tlearn: 1.0224347\ttest: 1.0301672\tbest: 1.0301672 (341)\ttotal: 3.42s\tremaining: 1m 36s\n",
      "342:\tlearn: 1.0223599\ttest: 1.0301195\tbest: 1.0301195 (342)\ttotal: 3.44s\tremaining: 1m 36s\n",
      "343:\tlearn: 1.0222916\ttest: 1.0300723\tbest: 1.0300723 (343)\ttotal: 3.44s\tremaining: 1m 36s\n",
      "344:\tlearn: 1.0222215\ttest: 1.0300240\tbest: 1.0300240 (344)\ttotal: 3.46s\tremaining: 1m 36s\n",
      "345:\tlearn: 1.0221417\ttest: 1.0299537\tbest: 1.0299537 (345)\ttotal: 3.46s\tremaining: 1m 36s\n",
      "346:\tlearn: 1.0220694\ttest: 1.0299002\tbest: 1.0299002 (346)\ttotal: 3.47s\tremaining: 1m 36s\n",
      "347:\tlearn: 1.0219881\ttest: 1.0298598\tbest: 1.0298598 (347)\ttotal: 3.48s\tremaining: 1m 36s\n",
      "348:\tlearn: 1.0219186\ttest: 1.0297879\tbest: 1.0297879 (348)\ttotal: 3.49s\tremaining: 1m 36s\n",
      "349:\tlearn: 1.0218424\ttest: 1.0297274\tbest: 1.0297274 (349)\ttotal: 3.5s\tremaining: 1m 36s\n",
      "350:\tlearn: 1.0217629\ttest: 1.0296682\tbest: 1.0296682 (350)\ttotal: 3.51s\tremaining: 1m 36s\n",
      "351:\tlearn: 1.0216900\ttest: 1.0296055\tbest: 1.0296055 (351)\ttotal: 3.52s\tremaining: 1m 36s\n",
      "352:\tlearn: 1.0216079\ttest: 1.0295512\tbest: 1.0295512 (352)\ttotal: 3.53s\tremaining: 1m 36s\n",
      "353:\tlearn: 1.0215481\ttest: 1.0295180\tbest: 1.0295180 (353)\ttotal: 3.54s\tremaining: 1m 36s\n",
      "354:\tlearn: 1.0214533\ttest: 1.0294709\tbest: 1.0294709 (354)\ttotal: 3.55s\tremaining: 1m 36s\n",
      "355:\tlearn: 1.0213725\ttest: 1.0294152\tbest: 1.0294152 (355)\ttotal: 3.56s\tremaining: 1m 36s\n",
      "356:\tlearn: 1.0212980\ttest: 1.0293540\tbest: 1.0293540 (356)\ttotal: 3.57s\tremaining: 1m 36s\n",
      "357:\tlearn: 1.0212163\ttest: 1.0292953\tbest: 1.0292953 (357)\ttotal: 3.58s\tremaining: 1m 36s\n",
      "358:\tlearn: 1.0211489\ttest: 1.0292430\tbest: 1.0292430 (358)\ttotal: 3.59s\tremaining: 1m 36s\n",
      "359:\tlearn: 1.0210803\ttest: 1.0291969\tbest: 1.0291969 (359)\ttotal: 3.6s\tremaining: 1m 36s\n",
      "360:\tlearn: 1.0210192\ttest: 1.0291491\tbest: 1.0291491 (360)\ttotal: 3.6s\tremaining: 1m 36s\n",
      "361:\tlearn: 1.0209397\ttest: 1.0290941\tbest: 1.0290941 (361)\ttotal: 3.62s\tremaining: 1m 36s\n",
      "362:\tlearn: 1.0208537\ttest: 1.0290487\tbest: 1.0290487 (362)\ttotal: 3.63s\tremaining: 1m 36s\n",
      "363:\tlearn: 1.0207793\ttest: 1.0289808\tbest: 1.0289808 (363)\ttotal: 3.64s\tremaining: 1m 36s\n",
      "364:\tlearn: 1.0207174\ttest: 1.0289487\tbest: 1.0289487 (364)\ttotal: 3.65s\tremaining: 1m 36s\n",
      "365:\tlearn: 1.0206517\ttest: 1.0289081\tbest: 1.0289081 (365)\ttotal: 3.66s\tremaining: 1m 36s\n",
      "366:\tlearn: 1.0205748\ttest: 1.0288543\tbest: 1.0288543 (366)\ttotal: 3.67s\tremaining: 1m 36s\n",
      "367:\tlearn: 1.0205078\ttest: 1.0288094\tbest: 1.0288094 (367)\ttotal: 3.68s\tremaining: 1m 36s\n",
      "368:\tlearn: 1.0204306\ttest: 1.0287703\tbest: 1.0287703 (368)\ttotal: 3.69s\tremaining: 1m 36s\n",
      "369:\tlearn: 1.0203530\ttest: 1.0287220\tbest: 1.0287220 (369)\ttotal: 3.7s\tremaining: 1m 36s\n",
      "370:\tlearn: 1.0203097\ttest: 1.0286962\tbest: 1.0286962 (370)\ttotal: 3.7s\tremaining: 1m 36s\n",
      "371:\tlearn: 1.0202370\ttest: 1.0286357\tbest: 1.0286357 (371)\ttotal: 3.72s\tremaining: 1m 36s\n",
      "372:\tlearn: 1.0201844\ttest: 1.0285985\tbest: 1.0285985 (372)\ttotal: 3.73s\tremaining: 1m 36s\n",
      "373:\tlearn: 1.0200971\ttest: 1.0285388\tbest: 1.0285388 (373)\ttotal: 3.73s\tremaining: 1m 36s\n",
      "374:\tlearn: 1.0200310\ttest: 1.0284988\tbest: 1.0284988 (374)\ttotal: 3.75s\tremaining: 1m 36s\n",
      "375:\tlearn: 1.0199706\ttest: 1.0284700\tbest: 1.0284700 (375)\ttotal: 3.75s\tremaining: 1m 36s\n",
      "376:\tlearn: 1.0199144\ttest: 1.0284200\tbest: 1.0284200 (376)\ttotal: 3.76s\tremaining: 1m 36s\n",
      "377:\tlearn: 1.0198500\ttest: 1.0283714\tbest: 1.0283714 (377)\ttotal: 3.77s\tremaining: 1m 36s\n",
      "378:\tlearn: 1.0197896\ttest: 1.0283396\tbest: 1.0283396 (378)\ttotal: 3.78s\tremaining: 1m 35s\n",
      "379:\tlearn: 1.0197318\ttest: 1.0283013\tbest: 1.0283013 (379)\ttotal: 3.79s\tremaining: 1m 35s\n",
      "380:\tlearn: 1.0196668\ttest: 1.0282658\tbest: 1.0282658 (380)\ttotal: 3.8s\tremaining: 1m 35s\n",
      "381:\tlearn: 1.0196019\ttest: 1.0282247\tbest: 1.0282247 (381)\ttotal: 3.81s\tremaining: 1m 35s\n",
      "382:\tlearn: 1.0195369\ttest: 1.0281733\tbest: 1.0281733 (382)\ttotal: 3.82s\tremaining: 1m 35s\n",
      "383:\tlearn: 1.0194741\ttest: 1.0281250\tbest: 1.0281250 (383)\ttotal: 3.83s\tremaining: 1m 35s\n",
      "384:\tlearn: 1.0194076\ttest: 1.0280794\tbest: 1.0280794 (384)\ttotal: 3.84s\tremaining: 1m 35s\n",
      "385:\tlearn: 1.0193485\ttest: 1.0280662\tbest: 1.0280662 (385)\ttotal: 3.85s\tremaining: 1m 35s\n",
      "386:\tlearn: 1.0192796\ttest: 1.0280370\tbest: 1.0280370 (386)\ttotal: 3.86s\tremaining: 1m 35s\n",
      "387:\tlearn: 1.0192112\ttest: 1.0279918\tbest: 1.0279918 (387)\ttotal: 3.87s\tremaining: 1m 35s\n",
      "388:\tlearn: 1.0191529\ttest: 1.0279530\tbest: 1.0279530 (388)\ttotal: 3.88s\tremaining: 1m 35s\n",
      "389:\tlearn: 1.0190956\ttest: 1.0279303\tbest: 1.0279303 (389)\ttotal: 3.89s\tremaining: 1m 35s\n",
      "390:\tlearn: 1.0190172\ttest: 1.0278952\tbest: 1.0278952 (390)\ttotal: 3.9s\tremaining: 1m 35s\n",
      "391:\tlearn: 1.0189521\ttest: 1.0278587\tbest: 1.0278587 (391)\ttotal: 3.91s\tremaining: 1m 35s\n",
      "392:\tlearn: 1.0189032\ttest: 1.0278157\tbest: 1.0278157 (392)\ttotal: 3.92s\tremaining: 1m 35s\n",
      "393:\tlearn: 1.0188373\ttest: 1.0277870\tbest: 1.0277870 (393)\ttotal: 3.92s\tremaining: 1m 35s\n",
      "394:\tlearn: 1.0187756\ttest: 1.0277489\tbest: 1.0277489 (394)\ttotal: 3.93s\tremaining: 1m 35s\n",
      "395:\tlearn: 1.0187211\ttest: 1.0277095\tbest: 1.0277095 (395)\ttotal: 3.94s\tremaining: 1m 35s\n",
      "396:\tlearn: 1.0186616\ttest: 1.0276595\tbest: 1.0276595 (396)\ttotal: 3.95s\tremaining: 1m 35s\n",
      "397:\tlearn: 1.0185985\ttest: 1.0276151\tbest: 1.0276151 (397)\ttotal: 3.96s\tremaining: 1m 35s\n",
      "398:\tlearn: 1.0185360\ttest: 1.0275641\tbest: 1.0275641 (398)\ttotal: 3.97s\tremaining: 1m 35s\n",
      "399:\tlearn: 1.0184749\ttest: 1.0275385\tbest: 1.0275385 (399)\ttotal: 3.98s\tremaining: 1m 35s\n",
      "400:\tlearn: 1.0184149\ttest: 1.0274882\tbest: 1.0274882 (400)\ttotal: 3.99s\tremaining: 1m 35s\n",
      "401:\tlearn: 1.0183613\ttest: 1.0274576\tbest: 1.0274576 (401)\ttotal: 4s\tremaining: 1m 35s\n",
      "402:\tlearn: 1.0183119\ttest: 1.0274072\tbest: 1.0274072 (402)\ttotal: 4.01s\tremaining: 1m 35s\n",
      "403:\tlearn: 1.0182573\ttest: 1.0273607\tbest: 1.0273607 (403)\ttotal: 4.02s\tremaining: 1m 35s\n",
      "404:\tlearn: 1.0182006\ttest: 1.0273307\tbest: 1.0273307 (404)\ttotal: 4.03s\tremaining: 1m 35s\n",
      "405:\tlearn: 1.0181452\ttest: 1.0272953\tbest: 1.0272953 (405)\ttotal: 4.04s\tremaining: 1m 35s\n",
      "406:\tlearn: 1.0180884\ttest: 1.0272681\tbest: 1.0272681 (406)\ttotal: 4.05s\tremaining: 1m 35s\n",
      "407:\tlearn: 1.0180482\ttest: 1.0272474\tbest: 1.0272474 (407)\ttotal: 4.06s\tremaining: 1m 35s\n",
      "408:\tlearn: 1.0179857\ttest: 1.0272097\tbest: 1.0272097 (408)\ttotal: 4.07s\tremaining: 1m 35s\n",
      "409:\tlearn: 1.0179088\ttest: 1.0271726\tbest: 1.0271726 (409)\ttotal: 4.08s\tremaining: 1m 35s\n",
      "410:\tlearn: 1.0178519\ttest: 1.0271504\tbest: 1.0271504 (410)\ttotal: 4.09s\tremaining: 1m 35s\n",
      "411:\tlearn: 1.0177801\ttest: 1.0271054\tbest: 1.0271054 (411)\ttotal: 4.1s\tremaining: 1m 35s\n",
      "412:\tlearn: 1.0177193\ttest: 1.0270565\tbest: 1.0270565 (412)\ttotal: 4.11s\tremaining: 1m 35s\n",
      "413:\tlearn: 1.0176673\ttest: 1.0270388\tbest: 1.0270388 (413)\ttotal: 4.12s\tremaining: 1m 35s\n",
      "414:\tlearn: 1.0176131\ttest: 1.0270097\tbest: 1.0270097 (414)\ttotal: 4.13s\tremaining: 1m 35s\n",
      "415:\tlearn: 1.0175523\ttest: 1.0269649\tbest: 1.0269649 (415)\ttotal: 4.14s\tremaining: 1m 35s\n",
      "416:\tlearn: 1.0174938\ttest: 1.0269291\tbest: 1.0269291 (416)\ttotal: 4.16s\tremaining: 1m 35s\n",
      "417:\tlearn: 1.0174384\ttest: 1.0268700\tbest: 1.0268700 (417)\ttotal: 4.17s\tremaining: 1m 35s\n",
      "418:\tlearn: 1.0173832\ttest: 1.0268211\tbest: 1.0268211 (418)\ttotal: 4.17s\tremaining: 1m 35s\n",
      "419:\tlearn: 1.0173112\ttest: 1.0267922\tbest: 1.0267922 (419)\ttotal: 4.18s\tremaining: 1m 35s\n",
      "420:\tlearn: 1.0172563\ttest: 1.0267525\tbest: 1.0267525 (420)\ttotal: 4.19s\tremaining: 1m 35s\n",
      "421:\tlearn: 1.0172020\ttest: 1.0267196\tbest: 1.0267196 (421)\ttotal: 4.2s\tremaining: 1m 35s\n",
      "422:\tlearn: 1.0171411\ttest: 1.0266713\tbest: 1.0266713 (422)\ttotal: 4.21s\tremaining: 1m 35s\n",
      "423:\tlearn: 1.0170845\ttest: 1.0266290\tbest: 1.0266290 (423)\ttotal: 4.22s\tremaining: 1m 35s\n",
      "424:\tlearn: 1.0170351\ttest: 1.0265886\tbest: 1.0265886 (424)\ttotal: 4.23s\tremaining: 1m 35s\n",
      "425:\tlearn: 1.0169814\ttest: 1.0265348\tbest: 1.0265348 (425)\ttotal: 4.24s\tremaining: 1m 35s\n",
      "426:\tlearn: 1.0169256\ttest: 1.0265197\tbest: 1.0265197 (426)\ttotal: 4.25s\tremaining: 1m 35s\n",
      "427:\tlearn: 1.0168698\ttest: 1.0264766\tbest: 1.0264766 (427)\ttotal: 4.26s\tremaining: 1m 35s\n",
      "428:\tlearn: 1.0168163\ttest: 1.0264540\tbest: 1.0264540 (428)\ttotal: 4.28s\tremaining: 1m 35s\n",
      "429:\tlearn: 1.0167620\ttest: 1.0264223\tbest: 1.0264223 (429)\ttotal: 4.29s\tremaining: 1m 35s\n",
      "430:\tlearn: 1.0167162\ttest: 1.0263870\tbest: 1.0263870 (430)\ttotal: 4.29s\tremaining: 1m 35s\n",
      "431:\tlearn: 1.0166479\ttest: 1.0263386\tbest: 1.0263386 (431)\ttotal: 4.3s\tremaining: 1m 35s\n",
      "432:\tlearn: 1.0165924\ttest: 1.0263136\tbest: 1.0263136 (432)\ttotal: 4.31s\tremaining: 1m 35s\n",
      "433:\tlearn: 1.0165453\ttest: 1.0262884\tbest: 1.0262884 (433)\ttotal: 4.32s\tremaining: 1m 35s\n",
      "434:\tlearn: 1.0165020\ttest: 1.0262646\tbest: 1.0262646 (434)\ttotal: 4.33s\tremaining: 1m 35s\n",
      "435:\tlearn: 1.0164328\ttest: 1.0262163\tbest: 1.0262163 (435)\ttotal: 4.34s\tremaining: 1m 35s\n",
      "436:\tlearn: 1.0163885\ttest: 1.0261960\tbest: 1.0261960 (436)\ttotal: 4.35s\tremaining: 1m 35s\n",
      "437:\tlearn: 1.0163409\ttest: 1.0261569\tbest: 1.0261569 (437)\ttotal: 4.36s\tremaining: 1m 35s\n",
      "438:\tlearn: 1.0162992\ttest: 1.0261341\tbest: 1.0261341 (438)\ttotal: 4.37s\tremaining: 1m 35s\n",
      "439:\tlearn: 1.0162482\ttest: 1.0261009\tbest: 1.0261009 (439)\ttotal: 4.38s\tremaining: 1m 35s\n",
      "440:\tlearn: 1.0161951\ttest: 1.0260563\tbest: 1.0260563 (440)\ttotal: 4.39s\tremaining: 1m 35s\n",
      "441:\tlearn: 1.0161438\ttest: 1.0260352\tbest: 1.0260352 (441)\ttotal: 4.4s\tremaining: 1m 35s\n",
      "442:\tlearn: 1.0160926\ttest: 1.0259989\tbest: 1.0259989 (442)\ttotal: 4.41s\tremaining: 1m 35s\n",
      "443:\tlearn: 1.0160579\ttest: 1.0259736\tbest: 1.0259736 (443)\ttotal: 4.42s\tremaining: 1m 35s\n",
      "444:\tlearn: 1.0160171\ttest: 1.0259507\tbest: 1.0259507 (444)\ttotal: 4.42s\tremaining: 1m 35s\n",
      "445:\tlearn: 1.0159729\ttest: 1.0259313\tbest: 1.0259313 (445)\ttotal: 4.43s\tremaining: 1m 34s\n",
      "446:\tlearn: 1.0159355\ttest: 1.0259041\tbest: 1.0259041 (446)\ttotal: 4.44s\tremaining: 1m 34s\n",
      "447:\tlearn: 1.0158885\ttest: 1.0258839\tbest: 1.0258839 (447)\ttotal: 4.45s\tremaining: 1m 34s\n",
      "448:\tlearn: 1.0158444\ttest: 1.0258423\tbest: 1.0258423 (448)\ttotal: 4.46s\tremaining: 1m 34s\n",
      "449:\tlearn: 1.0157832\ttest: 1.0258092\tbest: 1.0258092 (449)\ttotal: 4.47s\tremaining: 1m 34s\n",
      "450:\tlearn: 1.0157335\ttest: 1.0257866\tbest: 1.0257866 (450)\ttotal: 4.49s\tremaining: 1m 34s\n",
      "451:\tlearn: 1.0156848\ttest: 1.0257659\tbest: 1.0257659 (451)\ttotal: 4.49s\tremaining: 1m 34s\n",
      "452:\tlearn: 1.0156392\ttest: 1.0257559\tbest: 1.0257559 (452)\ttotal: 4.5s\tremaining: 1m 34s\n",
      "453:\tlearn: 1.0155821\ttest: 1.0257394\tbest: 1.0257394 (453)\ttotal: 4.51s\tremaining: 1m 34s\n",
      "454:\tlearn: 1.0155165\ttest: 1.0256942\tbest: 1.0256942 (454)\ttotal: 4.52s\tremaining: 1m 34s\n",
      "455:\tlearn: 1.0154807\ttest: 1.0256681\tbest: 1.0256681 (455)\ttotal: 4.53s\tremaining: 1m 34s\n",
      "456:\tlearn: 1.0154314\ttest: 1.0256283\tbest: 1.0256283 (456)\ttotal: 4.54s\tremaining: 1m 34s\n",
      "457:\tlearn: 1.0153937\ttest: 1.0255989\tbest: 1.0255989 (457)\ttotal: 4.55s\tremaining: 1m 34s\n",
      "458:\tlearn: 1.0153431\ttest: 1.0255630\tbest: 1.0255630 (458)\ttotal: 4.56s\tremaining: 1m 34s\n",
      "459:\tlearn: 1.0152885\ttest: 1.0255252\tbest: 1.0255252 (459)\ttotal: 4.57s\tremaining: 1m 34s\n",
      "460:\tlearn: 1.0152513\ttest: 1.0255099\tbest: 1.0255099 (460)\ttotal: 4.58s\tremaining: 1m 34s\n",
      "461:\tlearn: 1.0152092\ttest: 1.0254779\tbest: 1.0254779 (461)\ttotal: 4.58s\tremaining: 1m 34s\n",
      "462:\tlearn: 1.0151590\ttest: 1.0254341\tbest: 1.0254341 (462)\ttotal: 4.59s\tremaining: 1m 34s\n",
      "463:\tlearn: 1.0151066\ttest: 1.0254107\tbest: 1.0254107 (463)\ttotal: 4.6s\tremaining: 1m 34s\n",
      "464:\tlearn: 1.0150496\ttest: 1.0253756\tbest: 1.0253756 (464)\ttotal: 4.61s\tremaining: 1m 34s\n",
      "465:\tlearn: 1.0150098\ttest: 1.0253565\tbest: 1.0253565 (465)\ttotal: 4.62s\tremaining: 1m 34s\n",
      "466:\tlearn: 1.0149615\ttest: 1.0253137\tbest: 1.0253137 (466)\ttotal: 4.63s\tremaining: 1m 34s\n",
      "467:\tlearn: 1.0149077\ttest: 1.0252782\tbest: 1.0252782 (467)\ttotal: 4.64s\tremaining: 1m 34s\n",
      "468:\tlearn: 1.0148679\ttest: 1.0252564\tbest: 1.0252564 (468)\ttotal: 4.65s\tremaining: 1m 34s\n",
      "469:\tlearn: 1.0148264\ttest: 1.0252343\tbest: 1.0252343 (469)\ttotal: 4.66s\tremaining: 1m 34s\n",
      "470:\tlearn: 1.0147623\ttest: 1.0252060\tbest: 1.0252060 (470)\ttotal: 4.67s\tremaining: 1m 34s\n",
      "471:\tlearn: 1.0147152\ttest: 1.0251923\tbest: 1.0251923 (471)\ttotal: 4.68s\tremaining: 1m 34s\n",
      "472:\tlearn: 1.0146586\ttest: 1.0251673\tbest: 1.0251673 (472)\ttotal: 4.69s\tremaining: 1m 34s\n",
      "473:\tlearn: 1.0145984\ttest: 1.0251387\tbest: 1.0251387 (473)\ttotal: 4.7s\tremaining: 1m 34s\n",
      "474:\tlearn: 1.0145474\ttest: 1.0251278\tbest: 1.0251278 (474)\ttotal: 4.71s\tremaining: 1m 34s\n",
      "475:\tlearn: 1.0145049\ttest: 1.0251025\tbest: 1.0251025 (475)\ttotal: 4.72s\tremaining: 1m 34s\n",
      "476:\tlearn: 1.0144584\ttest: 1.0250695\tbest: 1.0250695 (476)\ttotal: 4.73s\tremaining: 1m 34s\n",
      "477:\tlearn: 1.0144175\ttest: 1.0250447\tbest: 1.0250447 (477)\ttotal: 4.74s\tremaining: 1m 34s\n",
      "478:\tlearn: 1.0143670\ttest: 1.0250143\tbest: 1.0250143 (478)\ttotal: 4.75s\tremaining: 1m 34s\n",
      "479:\tlearn: 1.0143177\ttest: 1.0249825\tbest: 1.0249825 (479)\ttotal: 4.76s\tremaining: 1m 34s\n",
      "480:\tlearn: 1.0142612\ttest: 1.0249713\tbest: 1.0249713 (480)\ttotal: 4.77s\tremaining: 1m 34s\n",
      "481:\tlearn: 1.0142115\ttest: 1.0249212\tbest: 1.0249212 (481)\ttotal: 4.78s\tremaining: 1m 34s\n",
      "482:\tlearn: 1.0141752\ttest: 1.0249081\tbest: 1.0249081 (482)\ttotal: 4.79s\tremaining: 1m 34s\n",
      "483:\tlearn: 1.0141166\ttest: 1.0248791\tbest: 1.0248791 (483)\ttotal: 4.8s\tremaining: 1m 34s\n",
      "484:\tlearn: 1.0140721\ttest: 1.0248701\tbest: 1.0248701 (484)\ttotal: 4.8s\tremaining: 1m 34s\n",
      "485:\tlearn: 1.0140206\ttest: 1.0248540\tbest: 1.0248540 (485)\ttotal: 4.82s\tremaining: 1m 34s\n",
      "486:\tlearn: 1.0139751\ttest: 1.0248309\tbest: 1.0248309 (486)\ttotal: 4.83s\tremaining: 1m 34s\n",
      "487:\tlearn: 1.0139117\ttest: 1.0248038\tbest: 1.0248038 (487)\ttotal: 4.83s\tremaining: 1m 34s\n",
      "488:\tlearn: 1.0138753\ttest: 1.0247738\tbest: 1.0247738 (488)\ttotal: 4.84s\tremaining: 1m 34s\n",
      "489:\tlearn: 1.0138424\ttest: 1.0247476\tbest: 1.0247476 (489)\ttotal: 4.85s\tremaining: 1m 34s\n",
      "490:\tlearn: 1.0137925\ttest: 1.0247161\tbest: 1.0247161 (490)\ttotal: 4.86s\tremaining: 1m 34s\n",
      "491:\tlearn: 1.0137542\ttest: 1.0246901\tbest: 1.0246901 (491)\ttotal: 4.87s\tremaining: 1m 34s\n",
      "492:\tlearn: 1.0137116\ttest: 1.0246500\tbest: 1.0246500 (492)\ttotal: 4.88s\tremaining: 1m 34s\n",
      "493:\tlearn: 1.0136638\ttest: 1.0246191\tbest: 1.0246191 (493)\ttotal: 4.89s\tremaining: 1m 34s\n",
      "494:\tlearn: 1.0136088\ttest: 1.0245886\tbest: 1.0245886 (494)\ttotal: 4.9s\tremaining: 1m 34s\n",
      "495:\tlearn: 1.0135695\ttest: 1.0245799\tbest: 1.0245799 (495)\ttotal: 4.91s\tremaining: 1m 34s\n",
      "496:\tlearn: 1.0135351\ttest: 1.0245607\tbest: 1.0245607 (496)\ttotal: 4.92s\tremaining: 1m 34s\n",
      "497:\tlearn: 1.0134950\ttest: 1.0245406\tbest: 1.0245406 (497)\ttotal: 4.93s\tremaining: 1m 34s\n",
      "498:\tlearn: 1.0134518\ttest: 1.0245175\tbest: 1.0245175 (498)\ttotal: 4.94s\tremaining: 1m 34s\n",
      "499:\tlearn: 1.0134205\ttest: 1.0245029\tbest: 1.0245029 (499)\ttotal: 4.95s\tremaining: 1m 33s\n",
      "500:\tlearn: 1.0133753\ttest: 1.0244835\tbest: 1.0244835 (500)\ttotal: 4.96s\tremaining: 1m 34s\n",
      "501:\tlearn: 1.0133188\ttest: 1.0244509\tbest: 1.0244509 (501)\ttotal: 4.97s\tremaining: 1m 34s\n",
      "502:\tlearn: 1.0132876\ttest: 1.0244270\tbest: 1.0244270 (502)\ttotal: 4.98s\tremaining: 1m 34s\n",
      "503:\tlearn: 1.0132449\ttest: 1.0244035\tbest: 1.0244035 (503)\ttotal: 4.99s\tremaining: 1m 33s\n",
      "504:\tlearn: 1.0131918\ttest: 1.0243829\tbest: 1.0243829 (504)\ttotal: 5s\tremaining: 1m 33s\n",
      "505:\tlearn: 1.0131539\ttest: 1.0243556\tbest: 1.0243556 (505)\ttotal: 5.01s\tremaining: 1m 33s\n",
      "506:\tlearn: 1.0131071\ttest: 1.0243345\tbest: 1.0243345 (506)\ttotal: 5.02s\tremaining: 1m 33s\n",
      "507:\tlearn: 1.0130598\ttest: 1.0243001\tbest: 1.0243001 (507)\ttotal: 5.03s\tremaining: 1m 33s\n",
      "508:\tlearn: 1.0130138\ttest: 1.0242743\tbest: 1.0242743 (508)\ttotal: 5.04s\tremaining: 1m 33s\n",
      "509:\tlearn: 1.0129694\ttest: 1.0242508\tbest: 1.0242508 (509)\ttotal: 5.04s\tremaining: 1m 33s\n",
      "510:\tlearn: 1.0129287\ttest: 1.0242392\tbest: 1.0242392 (510)\ttotal: 5.05s\tremaining: 1m 33s\n",
      "511:\tlearn: 1.0128805\ttest: 1.0242144\tbest: 1.0242144 (511)\ttotal: 5.06s\tremaining: 1m 33s\n",
      "512:\tlearn: 1.0128345\ttest: 1.0241922\tbest: 1.0241922 (512)\ttotal: 5.07s\tremaining: 1m 33s\n",
      "513:\tlearn: 1.0127860\ttest: 1.0241670\tbest: 1.0241670 (513)\ttotal: 5.08s\tremaining: 1m 33s\n",
      "514:\tlearn: 1.0127479\ttest: 1.0241462\tbest: 1.0241462 (514)\ttotal: 5.09s\tremaining: 1m 33s\n",
      "515:\tlearn: 1.0127010\ttest: 1.0241155\tbest: 1.0241155 (515)\ttotal: 5.1s\tremaining: 1m 33s\n",
      "516:\tlearn: 1.0126506\ttest: 1.0240826\tbest: 1.0240826 (516)\ttotal: 5.11s\tremaining: 1m 33s\n",
      "517:\tlearn: 1.0126130\ttest: 1.0240654\tbest: 1.0240654 (517)\ttotal: 5.12s\tremaining: 1m 33s\n",
      "518:\tlearn: 1.0125640\ttest: 1.0240289\tbest: 1.0240289 (518)\ttotal: 5.13s\tremaining: 1m 33s\n",
      "519:\tlearn: 1.0125333\ttest: 1.0240155\tbest: 1.0240155 (519)\ttotal: 5.14s\tremaining: 1m 33s\n",
      "520:\tlearn: 1.0124812\ttest: 1.0239890\tbest: 1.0239890 (520)\ttotal: 5.15s\tremaining: 1m 33s\n",
      "521:\tlearn: 1.0124304\ttest: 1.0239636\tbest: 1.0239636 (521)\ttotal: 5.16s\tremaining: 1m 33s\n",
      "522:\tlearn: 1.0123994\ttest: 1.0239464\tbest: 1.0239464 (522)\ttotal: 5.16s\tremaining: 1m 33s\n",
      "523:\tlearn: 1.0123418\ttest: 1.0239260\tbest: 1.0239260 (523)\ttotal: 5.17s\tremaining: 1m 33s\n",
      "524:\tlearn: 1.0123059\ttest: 1.0239045\tbest: 1.0239045 (524)\ttotal: 5.18s\tremaining: 1m 33s\n",
      "525:\tlearn: 1.0122631\ttest: 1.0238852\tbest: 1.0238852 (525)\ttotal: 5.19s\tremaining: 1m 33s\n",
      "526:\tlearn: 1.0122162\ttest: 1.0238681\tbest: 1.0238681 (526)\ttotal: 5.2s\tremaining: 1m 33s\n",
      "527:\tlearn: 1.0121722\ttest: 1.0238361\tbest: 1.0238361 (527)\ttotal: 5.21s\tremaining: 1m 33s\n",
      "528:\tlearn: 1.0121370\ttest: 1.0238223\tbest: 1.0238223 (528)\ttotal: 5.22s\tremaining: 1m 33s\n",
      "529:\tlearn: 1.0120882\ttest: 1.0238000\tbest: 1.0238000 (529)\ttotal: 5.23s\tremaining: 1m 33s\n",
      "530:\tlearn: 1.0120439\ttest: 1.0237589\tbest: 1.0237589 (530)\ttotal: 5.24s\tremaining: 1m 33s\n",
      "531:\tlearn: 1.0120115\ttest: 1.0237408\tbest: 1.0237408 (531)\ttotal: 5.25s\tremaining: 1m 33s\n",
      "532:\tlearn: 1.0119783\ttest: 1.0237341\tbest: 1.0237341 (532)\ttotal: 5.26s\tremaining: 1m 33s\n",
      "533:\tlearn: 1.0119336\ttest: 1.0237044\tbest: 1.0237044 (533)\ttotal: 5.27s\tremaining: 1m 33s\n",
      "534:\tlearn: 1.0118902\ttest: 1.0236798\tbest: 1.0236798 (534)\ttotal: 5.28s\tremaining: 1m 33s\n",
      "535:\tlearn: 1.0118596\ttest: 1.0236597\tbest: 1.0236597 (535)\ttotal: 5.29s\tremaining: 1m 33s\n",
      "536:\tlearn: 1.0117977\ttest: 1.0236371\tbest: 1.0236371 (536)\ttotal: 5.31s\tremaining: 1m 33s\n",
      "537:\tlearn: 1.0117629\ttest: 1.0236276\tbest: 1.0236276 (537)\ttotal: 5.33s\tremaining: 1m 33s\n",
      "538:\tlearn: 1.0117331\ttest: 1.0236173\tbest: 1.0236173 (538)\ttotal: 5.33s\tremaining: 1m 33s\n",
      "539:\tlearn: 1.0116903\ttest: 1.0235920\tbest: 1.0235920 (539)\ttotal: 5.34s\tremaining: 1m 33s\n",
      "540:\tlearn: 1.0116560\ttest: 1.0235806\tbest: 1.0235806 (540)\ttotal: 5.35s\tremaining: 1m 33s\n",
      "541:\tlearn: 1.0116359\ttest: 1.0235637\tbest: 1.0235637 (541)\ttotal: 5.36s\tremaining: 1m 33s\n",
      "542:\tlearn: 1.0115929\ttest: 1.0235505\tbest: 1.0235505 (542)\ttotal: 5.37s\tremaining: 1m 33s\n",
      "543:\tlearn: 1.0115479\ttest: 1.0235263\tbest: 1.0235263 (543)\ttotal: 5.38s\tremaining: 1m 33s\n",
      "544:\tlearn: 1.0115067\ttest: 1.0235263\tbest: 1.0235263 (543)\ttotal: 5.39s\tremaining: 1m 33s\n",
      "545:\tlearn: 1.0114651\ttest: 1.0235061\tbest: 1.0235061 (545)\ttotal: 5.4s\tremaining: 1m 33s\n",
      "546:\tlearn: 1.0114192\ttest: 1.0234874\tbest: 1.0234874 (546)\ttotal: 5.41s\tremaining: 1m 33s\n",
      "547:\tlearn: 1.0113845\ttest: 1.0234606\tbest: 1.0234606 (547)\ttotal: 5.42s\tremaining: 1m 33s\n",
      "548:\tlearn: 1.0113400\ttest: 1.0234401\tbest: 1.0234401 (548)\ttotal: 5.43s\tremaining: 1m 33s\n",
      "549:\tlearn: 1.0113049\ttest: 1.0234188\tbest: 1.0234188 (549)\ttotal: 5.44s\tremaining: 1m 33s\n",
      "550:\tlearn: 1.0112608\ttest: 1.0233940\tbest: 1.0233940 (550)\ttotal: 5.45s\tremaining: 1m 33s\n",
      "551:\tlearn: 1.0112177\ttest: 1.0233692\tbest: 1.0233692 (551)\ttotal: 5.46s\tremaining: 1m 33s\n",
      "552:\tlearn: 1.0111745\ttest: 1.0233559\tbest: 1.0233559 (552)\ttotal: 5.47s\tremaining: 1m 33s\n",
      "553:\tlearn: 1.0111343\ttest: 1.0233257\tbest: 1.0233257 (553)\ttotal: 5.48s\tremaining: 1m 33s\n",
      "554:\tlearn: 1.0110915\ttest: 1.0233095\tbest: 1.0233095 (554)\ttotal: 5.49s\tremaining: 1m 33s\n",
      "555:\tlearn: 1.0110584\ttest: 1.0232936\tbest: 1.0232936 (555)\ttotal: 5.5s\tremaining: 1m 33s\n",
      "556:\tlearn: 1.0110148\ttest: 1.0232753\tbest: 1.0232753 (556)\ttotal: 5.51s\tremaining: 1m 33s\n",
      "557:\tlearn: 1.0109803\ttest: 1.0232676\tbest: 1.0232676 (557)\ttotal: 5.52s\tremaining: 1m 33s\n",
      "558:\tlearn: 1.0109447\ttest: 1.0232504\tbest: 1.0232504 (558)\ttotal: 5.53s\tremaining: 1m 33s\n",
      "559:\tlearn: 1.0109183\ttest: 1.0232256\tbest: 1.0232256 (559)\ttotal: 5.54s\tremaining: 1m 33s\n",
      "560:\tlearn: 1.0108718\ttest: 1.0232078\tbest: 1.0232078 (560)\ttotal: 5.55s\tremaining: 1m 33s\n",
      "561:\tlearn: 1.0108317\ttest: 1.0231747\tbest: 1.0231747 (561)\ttotal: 5.56s\tremaining: 1m 33s\n",
      "562:\tlearn: 1.0107900\ttest: 1.0231595\tbest: 1.0231595 (562)\ttotal: 5.57s\tremaining: 1m 33s\n",
      "563:\tlearn: 1.0107517\ttest: 1.0231293\tbest: 1.0231293 (563)\ttotal: 5.58s\tremaining: 1m 33s\n",
      "564:\tlearn: 1.0107140\ttest: 1.0231076\tbest: 1.0231076 (564)\ttotal: 5.58s\tremaining: 1m 33s\n",
      "565:\tlearn: 1.0106848\ttest: 1.0230923\tbest: 1.0230923 (565)\ttotal: 5.59s\tremaining: 1m 33s\n",
      "566:\tlearn: 1.0106501\ttest: 1.0230614\tbest: 1.0230614 (566)\ttotal: 5.6s\tremaining: 1m 33s\n",
      "567:\tlearn: 1.0106136\ttest: 1.0230487\tbest: 1.0230487 (567)\ttotal: 5.61s\tremaining: 1m 33s\n",
      "568:\tlearn: 1.0105701\ttest: 1.0230264\tbest: 1.0230264 (568)\ttotal: 5.62s\tremaining: 1m 33s\n",
      "569:\tlearn: 1.0105191\ttest: 1.0229970\tbest: 1.0229970 (569)\ttotal: 5.63s\tremaining: 1m 33s\n",
      "570:\tlearn: 1.0104680\ttest: 1.0229746\tbest: 1.0229746 (570)\ttotal: 5.64s\tremaining: 1m 33s\n",
      "571:\tlearn: 1.0104407\ttest: 1.0229682\tbest: 1.0229682 (571)\ttotal: 5.65s\tremaining: 1m 33s\n",
      "572:\tlearn: 1.0104068\ttest: 1.0229503\tbest: 1.0229503 (572)\ttotal: 5.66s\tremaining: 1m 33s\n",
      "573:\tlearn: 1.0103647\ttest: 1.0229333\tbest: 1.0229333 (573)\ttotal: 5.67s\tremaining: 1m 33s\n",
      "574:\tlearn: 1.0103313\ttest: 1.0229109\tbest: 1.0229109 (574)\ttotal: 5.68s\tremaining: 1m 33s\n",
      "575:\tlearn: 1.0102947\ttest: 1.0228983\tbest: 1.0228983 (575)\ttotal: 5.69s\tremaining: 1m 33s\n",
      "576:\tlearn: 1.0102602\ttest: 1.0228859\tbest: 1.0228859 (576)\ttotal: 5.7s\tremaining: 1m 33s\n",
      "577:\tlearn: 1.0102155\ttest: 1.0228668\tbest: 1.0228668 (577)\ttotal: 5.71s\tremaining: 1m 33s\n",
      "578:\tlearn: 1.0101888\ttest: 1.0228407\tbest: 1.0228407 (578)\ttotal: 5.72s\tremaining: 1m 33s\n",
      "579:\tlearn: 1.0101442\ttest: 1.0228081\tbest: 1.0228081 (579)\ttotal: 5.73s\tremaining: 1m 33s\n",
      "580:\tlearn: 1.0101075\ttest: 1.0227848\tbest: 1.0227848 (580)\ttotal: 5.74s\tremaining: 1m 33s\n",
      "581:\tlearn: 1.0100727\ttest: 1.0227620\tbest: 1.0227620 (581)\ttotal: 5.75s\tremaining: 1m 33s\n",
      "582:\tlearn: 1.0100244\ttest: 1.0227387\tbest: 1.0227387 (582)\ttotal: 5.76s\tremaining: 1m 33s\n",
      "583:\tlearn: 1.0099987\ttest: 1.0227226\tbest: 1.0227226 (583)\ttotal: 5.77s\tremaining: 1m 33s\n",
      "584:\tlearn: 1.0099603\ttest: 1.0227072\tbest: 1.0227072 (584)\ttotal: 5.78s\tremaining: 1m 33s\n",
      "585:\tlearn: 1.0099250\ttest: 1.0226941\tbest: 1.0226941 (585)\ttotal: 5.79s\tremaining: 1m 32s\n",
      "586:\tlearn: 1.0098878\ttest: 1.0226945\tbest: 1.0226941 (585)\ttotal: 5.8s\tremaining: 1m 32s\n",
      "587:\tlearn: 1.0098488\ttest: 1.0226809\tbest: 1.0226809 (587)\ttotal: 5.81s\tremaining: 1m 32s\n",
      "588:\tlearn: 1.0098172\ttest: 1.0226629\tbest: 1.0226629 (588)\ttotal: 5.82s\tremaining: 1m 32s\n",
      "589:\tlearn: 1.0097828\ttest: 1.0226445\tbest: 1.0226445 (589)\ttotal: 5.82s\tremaining: 1m 32s\n",
      "590:\tlearn: 1.0097448\ttest: 1.0226304\tbest: 1.0226304 (590)\ttotal: 5.83s\tremaining: 1m 32s\n",
      "591:\tlearn: 1.0097049\ttest: 1.0226121\tbest: 1.0226121 (591)\ttotal: 5.84s\tremaining: 1m 32s\n",
      "592:\tlearn: 1.0096662\ttest: 1.0226012\tbest: 1.0226012 (592)\ttotal: 5.85s\tremaining: 1m 32s\n",
      "593:\tlearn: 1.0096387\ttest: 1.0225905\tbest: 1.0225905 (593)\ttotal: 5.86s\tremaining: 1m 32s\n",
      "594:\tlearn: 1.0096047\ttest: 1.0225812\tbest: 1.0225812 (594)\ttotal: 5.87s\tremaining: 1m 32s\n",
      "595:\tlearn: 1.0095652\ttest: 1.0225643\tbest: 1.0225643 (595)\ttotal: 5.88s\tremaining: 1m 32s\n",
      "596:\tlearn: 1.0095272\ttest: 1.0225604\tbest: 1.0225604 (596)\ttotal: 5.89s\tremaining: 1m 32s\n",
      "597:\tlearn: 1.0094958\ttest: 1.0225377\tbest: 1.0225377 (597)\ttotal: 5.9s\tremaining: 1m 32s\n",
      "598:\tlearn: 1.0094484\ttest: 1.0225316\tbest: 1.0225316 (598)\ttotal: 5.91s\tremaining: 1m 32s\n",
      "599:\tlearn: 1.0094111\ttest: 1.0225302\tbest: 1.0225302 (599)\ttotal: 5.92s\tremaining: 1m 32s\n",
      "600:\tlearn: 1.0093791\ttest: 1.0225124\tbest: 1.0225124 (600)\ttotal: 5.93s\tremaining: 1m 32s\n",
      "601:\tlearn: 1.0093413\ttest: 1.0225119\tbest: 1.0225119 (601)\ttotal: 5.94s\tremaining: 1m 32s\n",
      "602:\tlearn: 1.0093093\ttest: 1.0225064\tbest: 1.0225064 (602)\ttotal: 5.95s\tremaining: 1m 32s\n",
      "603:\tlearn: 1.0092663\ttest: 1.0224948\tbest: 1.0224948 (603)\ttotal: 5.96s\tremaining: 1m 32s\n",
      "604:\tlearn: 1.0092319\ttest: 1.0224769\tbest: 1.0224769 (604)\ttotal: 5.97s\tremaining: 1m 32s\n",
      "605:\tlearn: 1.0091958\ttest: 1.0224567\tbest: 1.0224567 (605)\ttotal: 5.98s\tremaining: 1m 32s\n",
      "606:\tlearn: 1.0091580\ttest: 1.0224497\tbest: 1.0224497 (606)\ttotal: 5.99s\tremaining: 1m 32s\n",
      "607:\tlearn: 1.0091258\ttest: 1.0224289\tbest: 1.0224289 (607)\ttotal: 6s\tremaining: 1m 32s\n",
      "608:\tlearn: 1.0090866\ttest: 1.0224167\tbest: 1.0224167 (608)\ttotal: 6.01s\tremaining: 1m 32s\n",
      "609:\tlearn: 1.0090467\ttest: 1.0223945\tbest: 1.0223945 (609)\ttotal: 6.06s\tremaining: 1m 33s\n",
      "610:\tlearn: 1.0090188\ttest: 1.0223927\tbest: 1.0223927 (610)\ttotal: 6.07s\tremaining: 1m 33s\n",
      "611:\tlearn: 1.0089875\ttest: 1.0223823\tbest: 1.0223823 (611)\ttotal: 6.09s\tremaining: 1m 33s\n",
      "612:\tlearn: 1.0089531\ttest: 1.0223640\tbest: 1.0223640 (612)\ttotal: 6.11s\tremaining: 1m 33s\n",
      "613:\tlearn: 1.0089081\ttest: 1.0223410\tbest: 1.0223410 (613)\ttotal: 6.12s\tremaining: 1m 33s\n",
      "614:\tlearn: 1.0088718\ttest: 1.0223200\tbest: 1.0223200 (614)\ttotal: 6.13s\tremaining: 1m 33s\n",
      "615:\tlearn: 1.0088439\ttest: 1.0223041\tbest: 1.0223041 (615)\ttotal: 6.14s\tremaining: 1m 33s\n",
      "616:\tlearn: 1.0088130\ttest: 1.0222865\tbest: 1.0222865 (616)\ttotal: 6.15s\tremaining: 1m 33s\n",
      "617:\tlearn: 1.0087818\ttest: 1.0222770\tbest: 1.0222770 (617)\ttotal: 6.16s\tremaining: 1m 33s\n",
      "618:\tlearn: 1.0087468\ttest: 1.0222627\tbest: 1.0222627 (618)\ttotal: 6.17s\tremaining: 1m 33s\n",
      "619:\tlearn: 1.0087112\ttest: 1.0222520\tbest: 1.0222520 (619)\ttotal: 6.18s\tremaining: 1m 33s\n",
      "620:\tlearn: 1.0086816\ttest: 1.0222316\tbest: 1.0222316 (620)\ttotal: 6.19s\tremaining: 1m 33s\n",
      "621:\tlearn: 1.0086511\ttest: 1.0222103\tbest: 1.0222103 (621)\ttotal: 6.2s\tremaining: 1m 33s\n",
      "622:\tlearn: 1.0086118\ttest: 1.0221963\tbest: 1.0221963 (622)\ttotal: 6.21s\tremaining: 1m 33s\n",
      "623:\tlearn: 1.0085801\ttest: 1.0221800\tbest: 1.0221800 (623)\ttotal: 6.22s\tremaining: 1m 33s\n",
      "624:\tlearn: 1.0085431\ttest: 1.0221580\tbest: 1.0221580 (624)\ttotal: 6.23s\tremaining: 1m 33s\n",
      "625:\tlearn: 1.0085140\ttest: 1.0221440\tbest: 1.0221440 (625)\ttotal: 6.24s\tremaining: 1m 33s\n",
      "626:\tlearn: 1.0084921\ttest: 1.0221368\tbest: 1.0221368 (626)\ttotal: 6.25s\tremaining: 1m 33s\n",
      "627:\tlearn: 1.0084761\ttest: 1.0221324\tbest: 1.0221324 (627)\ttotal: 6.25s\tremaining: 1m 33s\n",
      "628:\tlearn: 1.0084410\ttest: 1.0221135\tbest: 1.0221135 (628)\ttotal: 6.26s\tremaining: 1m 33s\n",
      "629:\tlearn: 1.0084042\ttest: 1.0220938\tbest: 1.0220938 (629)\ttotal: 6.27s\tremaining: 1m 33s\n",
      "630:\tlearn: 1.0083784\ttest: 1.0220742\tbest: 1.0220742 (630)\ttotal: 6.28s\tremaining: 1m 33s\n",
      "631:\tlearn: 1.0083349\ttest: 1.0220677\tbest: 1.0220677 (631)\ttotal: 6.29s\tremaining: 1m 33s\n",
      "632:\tlearn: 1.0082926\ttest: 1.0220420\tbest: 1.0220420 (632)\ttotal: 6.3s\tremaining: 1m 33s\n",
      "633:\tlearn: 1.0082555\ttest: 1.0220425\tbest: 1.0220420 (632)\ttotal: 6.32s\tremaining: 1m 33s\n",
      "634:\tlearn: 1.0082166\ttest: 1.0220323\tbest: 1.0220323 (634)\ttotal: 6.33s\tremaining: 1m 33s\n",
      "635:\tlearn: 1.0081815\ttest: 1.0220141\tbest: 1.0220141 (635)\ttotal: 6.34s\tremaining: 1m 33s\n",
      "636:\tlearn: 1.0081435\ttest: 1.0219833\tbest: 1.0219833 (636)\ttotal: 6.35s\tremaining: 1m 33s\n",
      "637:\tlearn: 1.0081115\ttest: 1.0219718\tbest: 1.0219718 (637)\ttotal: 6.36s\tremaining: 1m 33s\n",
      "638:\tlearn: 1.0080775\ttest: 1.0219615\tbest: 1.0219615 (638)\ttotal: 6.37s\tremaining: 1m 33s\n",
      "639:\tlearn: 1.0080412\ttest: 1.0219580\tbest: 1.0219580 (639)\ttotal: 6.38s\tremaining: 1m 33s\n",
      "640:\tlearn: 1.0080105\ttest: 1.0219455\tbest: 1.0219455 (640)\ttotal: 6.39s\tremaining: 1m 33s\n",
      "641:\tlearn: 1.0079662\ttest: 1.0219287\tbest: 1.0219287 (641)\ttotal: 6.39s\tremaining: 1m 33s\n",
      "642:\tlearn: 1.0079352\ttest: 1.0219055\tbest: 1.0219055 (642)\ttotal: 6.4s\tremaining: 1m 33s\n",
      "643:\tlearn: 1.0079107\ttest: 1.0218976\tbest: 1.0218976 (643)\ttotal: 6.41s\tremaining: 1m 33s\n",
      "644:\tlearn: 1.0078785\ttest: 1.0218855\tbest: 1.0218855 (644)\ttotal: 6.42s\tremaining: 1m 33s\n",
      "645:\tlearn: 1.0078394\ttest: 1.0218722\tbest: 1.0218722 (645)\ttotal: 6.43s\tremaining: 1m 33s\n",
      "646:\tlearn: 1.0078056\ttest: 1.0218560\tbest: 1.0218560 (646)\ttotal: 6.44s\tremaining: 1m 33s\n",
      "647:\tlearn: 1.0077725\ttest: 1.0218336\tbest: 1.0218336 (647)\ttotal: 6.45s\tremaining: 1m 33s\n",
      "648:\tlearn: 1.0077377\ttest: 1.0218105\tbest: 1.0218105 (648)\ttotal: 6.46s\tremaining: 1m 33s\n",
      "649:\tlearn: 1.0077031\ttest: 1.0218109\tbest: 1.0218105 (648)\ttotal: 6.47s\tremaining: 1m 33s\n",
      "650:\tlearn: 1.0076699\ttest: 1.0217869\tbest: 1.0217869 (650)\ttotal: 6.48s\tremaining: 1m 33s\n",
      "651:\tlearn: 1.0076415\ttest: 1.0217645\tbest: 1.0217645 (651)\ttotal: 6.49s\tremaining: 1m 33s\n",
      "652:\tlearn: 1.0076126\ttest: 1.0217579\tbest: 1.0217579 (652)\ttotal: 6.5s\tremaining: 1m 33s\n",
      "653:\tlearn: 1.0075817\ttest: 1.0217472\tbest: 1.0217472 (653)\ttotal: 6.51s\tremaining: 1m 33s\n",
      "654:\tlearn: 1.0075496\ttest: 1.0217374\tbest: 1.0217374 (654)\ttotal: 6.52s\tremaining: 1m 33s\n",
      "655:\tlearn: 1.0075127\ttest: 1.0217345\tbest: 1.0217345 (655)\ttotal: 6.53s\tremaining: 1m 32s\n",
      "656:\tlearn: 1.0074715\ttest: 1.0217220\tbest: 1.0217220 (656)\ttotal: 6.54s\tremaining: 1m 32s\n",
      "657:\tlearn: 1.0074396\ttest: 1.0217169\tbest: 1.0217169 (657)\ttotal: 6.55s\tremaining: 1m 32s\n",
      "658:\tlearn: 1.0073941\ttest: 1.0217026\tbest: 1.0217026 (658)\ttotal: 6.56s\tremaining: 1m 33s\n",
      "659:\tlearn: 1.0073632\ttest: 1.0216957\tbest: 1.0216957 (659)\ttotal: 6.57s\tremaining: 1m 32s\n",
      "660:\tlearn: 1.0073249\ttest: 1.0216763\tbest: 1.0216763 (660)\ttotal: 6.58s\tremaining: 1m 32s\n",
      "661:\tlearn: 1.0072878\ttest: 1.0216581\tbest: 1.0216581 (661)\ttotal: 6.59s\tremaining: 1m 32s\n",
      "662:\tlearn: 1.0072482\ttest: 1.0216459\tbest: 1.0216459 (662)\ttotal: 6.6s\tremaining: 1m 32s\n",
      "663:\tlearn: 1.0072079\ttest: 1.0216385\tbest: 1.0216385 (663)\ttotal: 6.61s\tremaining: 1m 32s\n",
      "664:\tlearn: 1.0071727\ttest: 1.0216227\tbest: 1.0216227 (664)\ttotal: 6.62s\tremaining: 1m 32s\n",
      "665:\tlearn: 1.0071447\ttest: 1.0216244\tbest: 1.0216227 (664)\ttotal: 6.63s\tremaining: 1m 32s\n",
      "666:\tlearn: 1.0071163\ttest: 1.0216258\tbest: 1.0216227 (664)\ttotal: 6.64s\tremaining: 1m 32s\n",
      "667:\tlearn: 1.0070799\ttest: 1.0216185\tbest: 1.0216185 (667)\ttotal: 6.65s\tremaining: 1m 32s\n",
      "668:\tlearn: 1.0070459\ttest: 1.0216069\tbest: 1.0216069 (668)\ttotal: 6.66s\tremaining: 1m 32s\n",
      "669:\tlearn: 1.0070199\ttest: 1.0215882\tbest: 1.0215882 (669)\ttotal: 6.67s\tremaining: 1m 32s\n",
      "670:\tlearn: 1.0069928\ttest: 1.0215921\tbest: 1.0215882 (669)\ttotal: 6.68s\tremaining: 1m 32s\n",
      "671:\tlearn: 1.0069653\ttest: 1.0215775\tbest: 1.0215775 (671)\ttotal: 6.68s\tremaining: 1m 32s\n",
      "672:\tlearn: 1.0069403\ttest: 1.0215684\tbest: 1.0215684 (672)\ttotal: 6.7s\tremaining: 1m 32s\n",
      "673:\tlearn: 1.0069159\ttest: 1.0215468\tbest: 1.0215468 (673)\ttotal: 6.7s\tremaining: 1m 32s\n",
      "674:\tlearn: 1.0068829\ttest: 1.0215327\tbest: 1.0215327 (674)\ttotal: 6.71s\tremaining: 1m 32s\n",
      "675:\tlearn: 1.0068579\ttest: 1.0215102\tbest: 1.0215102 (675)\ttotal: 6.72s\tremaining: 1m 32s\n",
      "676:\tlearn: 1.0068191\ttest: 1.0214871\tbest: 1.0214871 (676)\ttotal: 6.74s\tremaining: 1m 32s\n",
      "677:\tlearn: 1.0068010\ttest: 1.0214753\tbest: 1.0214753 (677)\ttotal: 6.75s\tremaining: 1m 32s\n",
      "678:\tlearn: 1.0067716\ttest: 1.0214562\tbest: 1.0214562 (678)\ttotal: 6.75s\tremaining: 1m 32s\n",
      "679:\tlearn: 1.0067383\ttest: 1.0214336\tbest: 1.0214336 (679)\ttotal: 6.77s\tremaining: 1m 32s\n",
      "680:\tlearn: 1.0067052\ttest: 1.0214305\tbest: 1.0214305 (680)\ttotal: 6.78s\tremaining: 1m 32s\n",
      "681:\tlearn: 1.0066779\ttest: 1.0214031\tbest: 1.0214031 (681)\ttotal: 6.79s\tremaining: 1m 32s\n",
      "682:\tlearn: 1.0066495\ttest: 1.0213927\tbest: 1.0213927 (682)\ttotal: 6.8s\tremaining: 1m 32s\n",
      "683:\tlearn: 1.0066144\ttest: 1.0213860\tbest: 1.0213860 (683)\ttotal: 6.81s\tremaining: 1m 32s\n",
      "684:\tlearn: 1.0065775\ttest: 1.0213762\tbest: 1.0213762 (684)\ttotal: 6.82s\tremaining: 1m 32s\n",
      "685:\tlearn: 1.0065519\ttest: 1.0213699\tbest: 1.0213699 (685)\ttotal: 6.83s\tremaining: 1m 32s\n",
      "686:\tlearn: 1.0065134\ttest: 1.0213625\tbest: 1.0213625 (686)\ttotal: 6.84s\tremaining: 1m 32s\n",
      "687:\tlearn: 1.0064847\ttest: 1.0213559\tbest: 1.0213559 (687)\ttotal: 6.85s\tremaining: 1m 32s\n",
      "688:\tlearn: 1.0064534\ttest: 1.0213633\tbest: 1.0213559 (687)\ttotal: 6.86s\tremaining: 1m 32s\n",
      "689:\tlearn: 1.0064154\ttest: 1.0213439\tbest: 1.0213439 (689)\ttotal: 6.87s\tremaining: 1m 32s\n",
      "690:\tlearn: 1.0063839\ttest: 1.0213416\tbest: 1.0213416 (690)\ttotal: 6.88s\tremaining: 1m 32s\n",
      "691:\tlearn: 1.0063537\ttest: 1.0213363\tbest: 1.0213363 (691)\ttotal: 6.89s\tremaining: 1m 32s\n",
      "692:\tlearn: 1.0063260\ttest: 1.0213252\tbest: 1.0213252 (692)\ttotal: 6.9s\tremaining: 1m 32s\n",
      "693:\tlearn: 1.0063033\ttest: 1.0213179\tbest: 1.0213179 (693)\ttotal: 6.91s\tremaining: 1m 32s\n",
      "694:\tlearn: 1.0062748\ttest: 1.0212981\tbest: 1.0212981 (694)\ttotal: 6.92s\tremaining: 1m 32s\n",
      "695:\tlearn: 1.0062515\ttest: 1.0212993\tbest: 1.0212981 (694)\ttotal: 6.93s\tremaining: 1m 32s\n",
      "696:\tlearn: 1.0062336\ttest: 1.0212905\tbest: 1.0212905 (696)\ttotal: 6.94s\tremaining: 1m 32s\n",
      "697:\tlearn: 1.0062009\ttest: 1.0212695\tbest: 1.0212695 (697)\ttotal: 6.95s\tremaining: 1m 32s\n",
      "698:\tlearn: 1.0061715\ttest: 1.0212745\tbest: 1.0212695 (697)\ttotal: 6.96s\tremaining: 1m 32s\n",
      "699:\tlearn: 1.0061450\ttest: 1.0212621\tbest: 1.0212621 (699)\ttotal: 6.97s\tremaining: 1m 32s\n",
      "700:\tlearn: 1.0060983\ttest: 1.0212447\tbest: 1.0212447 (700)\ttotal: 6.98s\tremaining: 1m 32s\n",
      "701:\tlearn: 1.0060735\ttest: 1.0212403\tbest: 1.0212403 (701)\ttotal: 6.99s\tremaining: 1m 32s\n",
      "702:\tlearn: 1.0060345\ttest: 1.0212377\tbest: 1.0212377 (702)\ttotal: 7s\tremaining: 1m 32s\n",
      "703:\tlearn: 1.0060122\ttest: 1.0212300\tbest: 1.0212300 (703)\ttotal: 7.01s\tremaining: 1m 32s\n",
      "704:\tlearn: 1.0059766\ttest: 1.0212141\tbest: 1.0212141 (704)\ttotal: 7.02s\tremaining: 1m 32s\n",
      "705:\tlearn: 1.0059464\ttest: 1.0211937\tbest: 1.0211937 (705)\ttotal: 7.03s\tremaining: 1m 32s\n",
      "706:\tlearn: 1.0059178\ttest: 1.0211856\tbest: 1.0211856 (706)\ttotal: 7.04s\tremaining: 1m 32s\n",
      "707:\tlearn: 1.0058807\ttest: 1.0211731\tbest: 1.0211731 (707)\ttotal: 7.05s\tremaining: 1m 32s\n",
      "708:\tlearn: 1.0058501\ttest: 1.0211741\tbest: 1.0211731 (707)\ttotal: 7.06s\tremaining: 1m 32s\n",
      "709:\tlearn: 1.0058177\ttest: 1.0211560\tbest: 1.0211560 (709)\ttotal: 7.07s\tremaining: 1m 32s\n",
      "710:\tlearn: 1.0057933\ttest: 1.0211403\tbest: 1.0211403 (710)\ttotal: 7.08s\tremaining: 1m 32s\n",
      "711:\tlearn: 1.0057637\ttest: 1.0211404\tbest: 1.0211403 (710)\ttotal: 7.08s\tremaining: 1m 32s\n",
      "712:\tlearn: 1.0057269\ttest: 1.0211251\tbest: 1.0211251 (712)\ttotal: 7.09s\tremaining: 1m 32s\n",
      "713:\tlearn: 1.0057042\ttest: 1.0211205\tbest: 1.0211205 (713)\ttotal: 7.11s\tremaining: 1m 32s\n",
      "714:\tlearn: 1.0056739\ttest: 1.0211083\tbest: 1.0211083 (714)\ttotal: 7.11s\tremaining: 1m 32s\n",
      "715:\tlearn: 1.0056458\ttest: 1.0210977\tbest: 1.0210977 (715)\ttotal: 7.12s\tremaining: 1m 32s\n",
      "716:\tlearn: 1.0056186\ttest: 1.0210846\tbest: 1.0210846 (716)\ttotal: 7.13s\tremaining: 1m 32s\n",
      "717:\tlearn: 1.0055919\ttest: 1.0210761\tbest: 1.0210761 (717)\ttotal: 7.14s\tremaining: 1m 32s\n",
      "718:\tlearn: 1.0055680\ttest: 1.0210763\tbest: 1.0210761 (717)\ttotal: 7.15s\tremaining: 1m 32s\n",
      "719:\tlearn: 1.0055372\ttest: 1.0210709\tbest: 1.0210709 (719)\ttotal: 7.16s\tremaining: 1m 32s\n",
      "720:\tlearn: 1.0055117\ttest: 1.0210717\tbest: 1.0210709 (719)\ttotal: 7.17s\tremaining: 1m 32s\n",
      "721:\tlearn: 1.0054853\ttest: 1.0210634\tbest: 1.0210634 (721)\ttotal: 7.18s\tremaining: 1m 32s\n",
      "722:\tlearn: 1.0054511\ttest: 1.0210456\tbest: 1.0210456 (722)\ttotal: 7.19s\tremaining: 1m 32s\n",
      "723:\tlearn: 1.0054250\ttest: 1.0210406\tbest: 1.0210406 (723)\ttotal: 7.2s\tremaining: 1m 32s\n",
      "724:\tlearn: 1.0054005\ttest: 1.0210303\tbest: 1.0210303 (724)\ttotal: 7.21s\tremaining: 1m 32s\n",
      "725:\tlearn: 1.0053714\ttest: 1.0210204\tbest: 1.0210204 (725)\ttotal: 7.22s\tremaining: 1m 32s\n",
      "726:\tlearn: 1.0053391\ttest: 1.0210133\tbest: 1.0210133 (726)\ttotal: 7.23s\tremaining: 1m 32s\n",
      "727:\tlearn: 1.0053145\ttest: 1.0210142\tbest: 1.0210133 (726)\ttotal: 7.24s\tremaining: 1m 32s\n",
      "728:\tlearn: 1.0052836\ttest: 1.0210146\tbest: 1.0210133 (726)\ttotal: 7.25s\tremaining: 1m 32s\n",
      "729:\tlearn: 1.0052474\ttest: 1.0210045\tbest: 1.0210045 (729)\ttotal: 7.26s\tremaining: 1m 32s\n",
      "730:\tlearn: 1.0052167\ttest: 1.0209951\tbest: 1.0209951 (730)\ttotal: 7.27s\tremaining: 1m 32s\n",
      "731:\tlearn: 1.0051884\ttest: 1.0209843\tbest: 1.0209843 (731)\ttotal: 7.28s\tremaining: 1m 32s\n",
      "732:\tlearn: 1.0051562\ttest: 1.0209707\tbest: 1.0209707 (732)\ttotal: 7.29s\tremaining: 1m 32s\n",
      "733:\tlearn: 1.0051163\ttest: 1.0209548\tbest: 1.0209548 (733)\ttotal: 7.3s\tremaining: 1m 32s\n",
      "734:\tlearn: 1.0050800\ttest: 1.0209351\tbest: 1.0209351 (734)\ttotal: 7.31s\tremaining: 1m 32s\n",
      "735:\tlearn: 1.0050519\ttest: 1.0209266\tbest: 1.0209266 (735)\ttotal: 7.32s\tremaining: 1m 32s\n",
      "736:\tlearn: 1.0050220\ttest: 1.0209241\tbest: 1.0209241 (736)\ttotal: 7.32s\tremaining: 1m 32s\n",
      "737:\tlearn: 1.0049981\ttest: 1.0209122\tbest: 1.0209122 (737)\ttotal: 7.33s\tremaining: 1m 32s\n",
      "738:\tlearn: 1.0049766\ttest: 1.0209175\tbest: 1.0209122 (737)\ttotal: 7.34s\tremaining: 1m 31s\n",
      "739:\tlearn: 1.0049565\ttest: 1.0209117\tbest: 1.0209117 (739)\ttotal: 7.35s\tremaining: 1m 32s\n",
      "740:\tlearn: 1.0049309\ttest: 1.0209088\tbest: 1.0209088 (740)\ttotal: 7.36s\tremaining: 1m 31s\n",
      "741:\tlearn: 1.0048996\ttest: 1.0208983\tbest: 1.0208983 (741)\ttotal: 7.37s\tremaining: 1m 31s\n",
      "742:\tlearn: 1.0048708\ttest: 1.0208949\tbest: 1.0208949 (742)\ttotal: 7.38s\tremaining: 1m 31s\n",
      "743:\tlearn: 1.0048466\ttest: 1.0208875\tbest: 1.0208875 (743)\ttotal: 7.39s\tremaining: 1m 31s\n",
      "744:\tlearn: 1.0048149\ttest: 1.0208796\tbest: 1.0208796 (744)\ttotal: 7.4s\tremaining: 1m 31s\n",
      "745:\tlearn: 1.0047859\ttest: 1.0208835\tbest: 1.0208796 (744)\ttotal: 7.41s\tremaining: 1m 31s\n",
      "746:\tlearn: 1.0047507\ttest: 1.0208647\tbest: 1.0208647 (746)\ttotal: 7.42s\tremaining: 1m 31s\n",
      "747:\tlearn: 1.0047209\ttest: 1.0208552\tbest: 1.0208552 (747)\ttotal: 7.43s\tremaining: 1m 31s\n",
      "748:\tlearn: 1.0046935\ttest: 1.0208412\tbest: 1.0208412 (748)\ttotal: 7.44s\tremaining: 1m 31s\n",
      "749:\tlearn: 1.0046625\ttest: 1.0208382\tbest: 1.0208382 (749)\ttotal: 7.45s\tremaining: 1m 31s\n",
      "750:\tlearn: 1.0046256\ttest: 1.0208196\tbest: 1.0208196 (750)\ttotal: 7.46s\tremaining: 1m 31s\n",
      "751:\tlearn: 1.0045962\ttest: 1.0208041\tbest: 1.0208041 (751)\ttotal: 7.47s\tremaining: 1m 31s\n",
      "752:\tlearn: 1.0045699\ttest: 1.0207911\tbest: 1.0207911 (752)\ttotal: 7.48s\tremaining: 1m 31s\n",
      "753:\tlearn: 1.0045445\ttest: 1.0207878\tbest: 1.0207878 (753)\ttotal: 7.49s\tremaining: 1m 31s\n",
      "754:\tlearn: 1.0045225\ttest: 1.0207743\tbest: 1.0207743 (754)\ttotal: 7.5s\tremaining: 1m 31s\n",
      "755:\tlearn: 1.0044943\ttest: 1.0207692\tbest: 1.0207692 (755)\ttotal: 7.51s\tremaining: 1m 31s\n",
      "756:\tlearn: 1.0044710\ttest: 1.0207582\tbest: 1.0207582 (756)\ttotal: 7.51s\tremaining: 1m 31s\n",
      "757:\tlearn: 1.0044449\ttest: 1.0207511\tbest: 1.0207511 (757)\ttotal: 7.52s\tremaining: 1m 31s\n",
      "758:\tlearn: 1.0044139\ttest: 1.0207392\tbest: 1.0207392 (758)\ttotal: 7.53s\tremaining: 1m 31s\n",
      "759:\tlearn: 1.0043864\ttest: 1.0207321\tbest: 1.0207321 (759)\ttotal: 7.54s\tremaining: 1m 31s\n",
      "760:\tlearn: 1.0043586\ttest: 1.0207149\tbest: 1.0207149 (760)\ttotal: 7.55s\tremaining: 1m 31s\n",
      "761:\tlearn: 1.0043292\ttest: 1.0207056\tbest: 1.0207056 (761)\ttotal: 7.56s\tremaining: 1m 31s\n",
      "762:\tlearn: 1.0042976\ttest: 1.0207025\tbest: 1.0207025 (762)\ttotal: 7.57s\tremaining: 1m 31s\n",
      "763:\tlearn: 1.0042765\ttest: 1.0206982\tbest: 1.0206982 (763)\ttotal: 7.58s\tremaining: 1m 31s\n",
      "764:\tlearn: 1.0042489\ttest: 1.0206879\tbest: 1.0206879 (764)\ttotal: 7.59s\tremaining: 1m 31s\n",
      "765:\tlearn: 1.0042234\ttest: 1.0206790\tbest: 1.0206790 (765)\ttotal: 7.6s\tremaining: 1m 31s\n",
      "766:\tlearn: 1.0041949\ttest: 1.0206827\tbest: 1.0206790 (765)\ttotal: 7.61s\tremaining: 1m 31s\n",
      "767:\tlearn: 1.0041625\ttest: 1.0206688\tbest: 1.0206688 (767)\ttotal: 7.62s\tremaining: 1m 31s\n",
      "768:\tlearn: 1.0041293\ttest: 1.0206600\tbest: 1.0206600 (768)\ttotal: 7.63s\tremaining: 1m 31s\n",
      "769:\tlearn: 1.0041043\ttest: 1.0206573\tbest: 1.0206573 (769)\ttotal: 7.64s\tremaining: 1m 31s\n",
      "770:\tlearn: 1.0040801\ttest: 1.0206413\tbest: 1.0206413 (770)\ttotal: 7.65s\tremaining: 1m 31s\n",
      "771:\tlearn: 1.0040484\ttest: 1.0206277\tbest: 1.0206277 (771)\ttotal: 7.66s\tremaining: 1m 31s\n",
      "772:\tlearn: 1.0040183\ttest: 1.0206234\tbest: 1.0206234 (772)\ttotal: 7.67s\tremaining: 1m 31s\n",
      "773:\tlearn: 1.0039953\ttest: 1.0206242\tbest: 1.0206234 (772)\ttotal: 7.68s\tremaining: 1m 31s\n",
      "774:\tlearn: 1.0039688\ttest: 1.0206155\tbest: 1.0206155 (774)\ttotal: 7.69s\tremaining: 1m 31s\n",
      "775:\tlearn: 1.0039368\ttest: 1.0206038\tbest: 1.0206038 (775)\ttotal: 7.7s\tremaining: 1m 31s\n",
      "776:\tlearn: 1.0039128\ttest: 1.0206029\tbest: 1.0206029 (776)\ttotal: 7.71s\tremaining: 1m 31s\n",
      "777:\tlearn: 1.0038816\ttest: 1.0205829\tbest: 1.0205829 (777)\ttotal: 7.72s\tremaining: 1m 31s\n",
      "778:\tlearn: 1.0038508\ttest: 1.0205764\tbest: 1.0205764 (778)\ttotal: 7.73s\tremaining: 1m 31s\n",
      "779:\tlearn: 1.0038317\ttest: 1.0205659\tbest: 1.0205659 (779)\ttotal: 7.74s\tremaining: 1m 31s\n",
      "780:\tlearn: 1.0037961\ttest: 1.0205628\tbest: 1.0205628 (780)\ttotal: 7.75s\tremaining: 1m 31s\n",
      "781:\tlearn: 1.0037690\ttest: 1.0205583\tbest: 1.0205583 (781)\ttotal: 7.75s\tremaining: 1m 31s\n",
      "782:\tlearn: 1.0037347\ttest: 1.0205431\tbest: 1.0205431 (782)\ttotal: 7.76s\tremaining: 1m 31s\n",
      "783:\tlearn: 1.0037037\ttest: 1.0205465\tbest: 1.0205431 (782)\ttotal: 7.77s\tremaining: 1m 31s\n",
      "784:\tlearn: 1.0036797\ttest: 1.0205410\tbest: 1.0205410 (784)\ttotal: 7.78s\tremaining: 1m 31s\n",
      "785:\tlearn: 1.0036515\ttest: 1.0205366\tbest: 1.0205366 (785)\ttotal: 7.79s\tremaining: 1m 31s\n",
      "786:\tlearn: 1.0036192\ttest: 1.0205238\tbest: 1.0205238 (786)\ttotal: 7.8s\tremaining: 1m 31s\n",
      "787:\tlearn: 1.0035915\ttest: 1.0205214\tbest: 1.0205214 (787)\ttotal: 7.82s\tremaining: 1m 31s\n",
      "788:\tlearn: 1.0035703\ttest: 1.0205093\tbest: 1.0205093 (788)\ttotal: 7.82s\tremaining: 1m 31s\n",
      "789:\tlearn: 1.0035442\ttest: 1.0204972\tbest: 1.0204972 (789)\ttotal: 7.83s\tremaining: 1m 31s\n",
      "790:\tlearn: 1.0035050\ttest: 1.0204884\tbest: 1.0204884 (790)\ttotal: 7.84s\tremaining: 1m 31s\n",
      "791:\tlearn: 1.0034792\ttest: 1.0204868\tbest: 1.0204868 (791)\ttotal: 7.85s\tremaining: 1m 31s\n",
      "792:\tlearn: 1.0034552\ttest: 1.0204662\tbest: 1.0204662 (792)\ttotal: 7.86s\tremaining: 1m 31s\n",
      "793:\tlearn: 1.0034318\ttest: 1.0204661\tbest: 1.0204661 (793)\ttotal: 7.87s\tremaining: 1m 31s\n",
      "794:\tlearn: 1.0034069\ttest: 1.0204514\tbest: 1.0204514 (794)\ttotal: 7.88s\tremaining: 1m 31s\n",
      "795:\tlearn: 1.0033732\ttest: 1.0204509\tbest: 1.0204509 (795)\ttotal: 7.89s\tremaining: 1m 31s\n",
      "796:\tlearn: 1.0033424\ttest: 1.0204288\tbest: 1.0204288 (796)\ttotal: 7.9s\tremaining: 1m 31s\n",
      "797:\tlearn: 1.0033226\ttest: 1.0204200\tbest: 1.0204200 (797)\ttotal: 7.91s\tremaining: 1m 31s\n",
      "798:\tlearn: 1.0032992\ttest: 1.0204152\tbest: 1.0204152 (798)\ttotal: 7.92s\tremaining: 1m 31s\n",
      "799:\tlearn: 1.0032716\ttest: 1.0204019\tbest: 1.0204019 (799)\ttotal: 7.93s\tremaining: 1m 31s\n",
      "800:\tlearn: 1.0032399\ttest: 1.0203871\tbest: 1.0203871 (800)\ttotal: 7.94s\tremaining: 1m 31s\n",
      "801:\tlearn: 1.0032245\ttest: 1.0203808\tbest: 1.0203808 (801)\ttotal: 7.95s\tremaining: 1m 31s\n",
      "802:\tlearn: 1.0031976\ttest: 1.0203755\tbest: 1.0203755 (802)\ttotal: 7.96s\tremaining: 1m 31s\n",
      "803:\tlearn: 1.0031721\ttest: 1.0203635\tbest: 1.0203635 (803)\ttotal: 7.96s\tremaining: 1m 31s\n",
      "804:\tlearn: 1.0031520\ttest: 1.0203610\tbest: 1.0203610 (804)\ttotal: 7.97s\tremaining: 1m 31s\n",
      "805:\tlearn: 1.0031225\ttest: 1.0203535\tbest: 1.0203535 (805)\ttotal: 7.98s\tremaining: 1m 31s\n",
      "806:\tlearn: 1.0030964\ttest: 1.0203525\tbest: 1.0203525 (806)\ttotal: 7.99s\tremaining: 1m 31s\n",
      "807:\tlearn: 1.0030747\ttest: 1.0203601\tbest: 1.0203525 (806)\ttotal: 8.01s\tremaining: 1m 31s\n",
      "808:\tlearn: 1.0030598\ttest: 1.0203498\tbest: 1.0203498 (808)\ttotal: 8.02s\tremaining: 1m 31s\n",
      "809:\tlearn: 1.0030394\ttest: 1.0203521\tbest: 1.0203498 (808)\ttotal: 8.03s\tremaining: 1m 31s\n",
      "810:\tlearn: 1.0030035\ttest: 1.0203512\tbest: 1.0203498 (808)\ttotal: 8.04s\tremaining: 1m 31s\n",
      "811:\tlearn: 1.0029791\ttest: 1.0203464\tbest: 1.0203464 (811)\ttotal: 8.05s\tremaining: 1m 31s\n",
      "812:\tlearn: 1.0029454\ttest: 1.0203410\tbest: 1.0203410 (812)\ttotal: 8.06s\tremaining: 1m 31s\n",
      "813:\tlearn: 1.0029178\ttest: 1.0203340\tbest: 1.0203340 (813)\ttotal: 8.06s\tremaining: 1m 31s\n",
      "814:\tlearn: 1.0028914\ttest: 1.0203336\tbest: 1.0203336 (814)\ttotal: 8.08s\tremaining: 1m 31s\n",
      "815:\tlearn: 1.0028566\ttest: 1.0203275\tbest: 1.0203275 (815)\ttotal: 8.08s\tremaining: 1m 30s\n",
      "816:\tlearn: 1.0028365\ttest: 1.0203318\tbest: 1.0203275 (815)\ttotal: 8.09s\tremaining: 1m 30s\n",
      "817:\tlearn: 1.0028125\ttest: 1.0203282\tbest: 1.0203275 (815)\ttotal: 8.1s\tremaining: 1m 30s\n",
      "818:\tlearn: 1.0027886\ttest: 1.0203242\tbest: 1.0203242 (818)\ttotal: 8.11s\tremaining: 1m 30s\n",
      "819:\tlearn: 1.0027569\ttest: 1.0203167\tbest: 1.0203167 (819)\ttotal: 8.12s\tremaining: 1m 30s\n",
      "820:\tlearn: 1.0027355\ttest: 1.0203184\tbest: 1.0203167 (819)\ttotal: 8.13s\tremaining: 1m 30s\n",
      "821:\tlearn: 1.0027084\ttest: 1.0203063\tbest: 1.0203063 (821)\ttotal: 8.14s\tremaining: 1m 30s\n",
      "822:\tlearn: 1.0026974\ttest: 1.0202996\tbest: 1.0202996 (822)\ttotal: 8.15s\tremaining: 1m 30s\n",
      "823:\tlearn: 1.0026727\ttest: 1.0202955\tbest: 1.0202955 (823)\ttotal: 8.16s\tremaining: 1m 30s\n",
      "824:\tlearn: 1.0026493\ttest: 1.0202902\tbest: 1.0202902 (824)\ttotal: 8.17s\tremaining: 1m 30s\n",
      "825:\tlearn: 1.0026267\ttest: 1.0202810\tbest: 1.0202810 (825)\ttotal: 8.18s\tremaining: 1m 30s\n",
      "826:\tlearn: 1.0026021\ttest: 1.0202658\tbest: 1.0202658 (826)\ttotal: 8.19s\tremaining: 1m 30s\n",
      "827:\tlearn: 1.0025767\ttest: 1.0202675\tbest: 1.0202658 (826)\ttotal: 8.2s\tremaining: 1m 30s\n",
      "828:\tlearn: 1.0025554\ttest: 1.0202645\tbest: 1.0202645 (828)\ttotal: 8.21s\tremaining: 1m 30s\n",
      "829:\tlearn: 1.0025329\ttest: 1.0202605\tbest: 1.0202605 (829)\ttotal: 8.22s\tremaining: 1m 30s\n",
      "830:\tlearn: 1.0025075\ttest: 1.0202468\tbest: 1.0202468 (830)\ttotal: 8.23s\tremaining: 1m 30s\n",
      "831:\tlearn: 1.0024841\ttest: 1.0202385\tbest: 1.0202385 (831)\ttotal: 8.24s\tremaining: 1m 30s\n",
      "832:\tlearn: 1.0024648\ttest: 1.0202385\tbest: 1.0202385 (832)\ttotal: 8.26s\tremaining: 1m 30s\n",
      "833:\tlearn: 1.0024335\ttest: 1.0202283\tbest: 1.0202283 (833)\ttotal: 8.26s\tremaining: 1m 30s\n",
      "834:\tlearn: 1.0024048\ttest: 1.0202175\tbest: 1.0202175 (834)\ttotal: 8.27s\tremaining: 1m 30s\n",
      "835:\tlearn: 1.0023745\ttest: 1.0202071\tbest: 1.0202071 (835)\ttotal: 8.28s\tremaining: 1m 30s\n",
      "836:\tlearn: 1.0023419\ttest: 1.0201997\tbest: 1.0201997 (836)\ttotal: 8.29s\tremaining: 1m 30s\n",
      "837:\tlearn: 1.0023189\ttest: 1.0201954\tbest: 1.0201954 (837)\ttotal: 8.3s\tremaining: 1m 30s\n",
      "838:\tlearn: 1.0022975\ttest: 1.0201881\tbest: 1.0201881 (838)\ttotal: 8.32s\tremaining: 1m 30s\n",
      "839:\tlearn: 1.0022701\ttest: 1.0201864\tbest: 1.0201864 (839)\ttotal: 8.33s\tremaining: 1m 30s\n",
      "840:\tlearn: 1.0022338\ttest: 1.0201708\tbest: 1.0201708 (840)\ttotal: 8.34s\tremaining: 1m 30s\n",
      "841:\tlearn: 1.0022085\ttest: 1.0201692\tbest: 1.0201692 (841)\ttotal: 8.35s\tremaining: 1m 30s\n",
      "842:\tlearn: 1.0021800\ttest: 1.0201601\tbest: 1.0201601 (842)\ttotal: 8.36s\tremaining: 1m 30s\n",
      "843:\tlearn: 1.0021640\ttest: 1.0201614\tbest: 1.0201601 (842)\ttotal: 8.37s\tremaining: 1m 30s\n",
      "844:\tlearn: 1.0021407\ttest: 1.0201563\tbest: 1.0201563 (844)\ttotal: 8.38s\tremaining: 1m 30s\n",
      "845:\tlearn: 1.0021101\ttest: 1.0201623\tbest: 1.0201563 (844)\ttotal: 8.39s\tremaining: 1m 30s\n",
      "846:\tlearn: 1.0020924\ttest: 1.0201622\tbest: 1.0201563 (844)\ttotal: 8.4s\tremaining: 1m 30s\n",
      "847:\tlearn: 1.0020600\ttest: 1.0201586\tbest: 1.0201563 (844)\ttotal: 8.42s\tremaining: 1m 30s\n",
      "848:\tlearn: 1.0020350\ttest: 1.0201565\tbest: 1.0201563 (844)\ttotal: 8.43s\tremaining: 1m 30s\n",
      "849:\tlearn: 1.0020149\ttest: 1.0201631\tbest: 1.0201563 (844)\ttotal: 8.44s\tremaining: 1m 30s\n",
      "850:\tlearn: 1.0019821\ttest: 1.0201314\tbest: 1.0201314 (850)\ttotal: 8.45s\tremaining: 1m 30s\n",
      "851:\tlearn: 1.0019582\ttest: 1.0201232\tbest: 1.0201232 (851)\ttotal: 8.46s\tremaining: 1m 30s\n",
      "852:\tlearn: 1.0019373\ttest: 1.0201195\tbest: 1.0201195 (852)\ttotal: 8.46s\tremaining: 1m 30s\n",
      "853:\tlearn: 1.0019089\ttest: 1.0201199\tbest: 1.0201195 (852)\ttotal: 8.47s\tremaining: 1m 30s\n",
      "854:\tlearn: 1.0018818\ttest: 1.0201021\tbest: 1.0201021 (854)\ttotal: 8.48s\tremaining: 1m 30s\n",
      "855:\tlearn: 1.0018459\ttest: 1.0200952\tbest: 1.0200952 (855)\ttotal: 8.49s\tremaining: 1m 30s\n",
      "856:\tlearn: 1.0018207\ttest: 1.0200922\tbest: 1.0200922 (856)\ttotal: 8.5s\tremaining: 1m 30s\n",
      "857:\tlearn: 1.0017938\ttest: 1.0200947\tbest: 1.0200922 (856)\ttotal: 8.51s\tremaining: 1m 30s\n",
      "858:\tlearn: 1.0017732\ttest: 1.0200848\tbest: 1.0200848 (858)\ttotal: 8.52s\tremaining: 1m 30s\n",
      "859:\tlearn: 1.0017467\ttest: 1.0200669\tbest: 1.0200669 (859)\ttotal: 8.53s\tremaining: 1m 30s\n",
      "860:\tlearn: 1.0017249\ttest: 1.0200630\tbest: 1.0200630 (860)\ttotal: 8.54s\tremaining: 1m 30s\n",
      "861:\tlearn: 1.0017033\ttest: 1.0200553\tbest: 1.0200553 (861)\ttotal: 8.55s\tremaining: 1m 30s\n",
      "862:\tlearn: 1.0016825\ttest: 1.0200610\tbest: 1.0200553 (861)\ttotal: 8.55s\tremaining: 1m 30s\n",
      "863:\tlearn: 1.0016510\ttest: 1.0200572\tbest: 1.0200553 (861)\ttotal: 8.56s\tremaining: 1m 30s\n",
      "864:\tlearn: 1.0016286\ttest: 1.0200504\tbest: 1.0200504 (864)\ttotal: 8.58s\tremaining: 1m 30s\n",
      "865:\tlearn: 1.0016058\ttest: 1.0200475\tbest: 1.0200475 (865)\ttotal: 8.59s\tremaining: 1m 30s\n",
      "866:\tlearn: 1.0015808\ttest: 1.0200490\tbest: 1.0200475 (865)\ttotal: 8.59s\tremaining: 1m 30s\n",
      "867:\tlearn: 1.0015586\ttest: 1.0200424\tbest: 1.0200424 (867)\ttotal: 8.6s\tremaining: 1m 30s\n",
      "868:\tlearn: 1.0015277\ttest: 1.0200572\tbest: 1.0200424 (867)\ttotal: 8.61s\tremaining: 1m 30s\n",
      "869:\tlearn: 1.0014966\ttest: 1.0200424\tbest: 1.0200424 (869)\ttotal: 8.62s\tremaining: 1m 30s\n",
      "870:\tlearn: 1.0014666\ttest: 1.0200365\tbest: 1.0200365 (870)\ttotal: 8.63s\tremaining: 1m 30s\n",
      "871:\tlearn: 1.0014366\ttest: 1.0200129\tbest: 1.0200129 (871)\ttotal: 8.64s\tremaining: 1m 30s\n",
      "872:\tlearn: 1.0014125\ttest: 1.0200074\tbest: 1.0200074 (872)\ttotal: 8.65s\tremaining: 1m 30s\n",
      "873:\tlearn: 1.0013871\ttest: 1.0200098\tbest: 1.0200074 (872)\ttotal: 8.66s\tremaining: 1m 30s\n",
      "874:\tlearn: 1.0013674\ttest: 1.0200006\tbest: 1.0200006 (874)\ttotal: 8.68s\tremaining: 1m 30s\n",
      "875:\tlearn: 1.0013367\ttest: 1.0199869\tbest: 1.0199869 (875)\ttotal: 8.68s\tremaining: 1m 30s\n",
      "876:\tlearn: 1.0013104\ttest: 1.0199853\tbest: 1.0199853 (876)\ttotal: 8.69s\tremaining: 1m 30s\n",
      "877:\tlearn: 1.0012836\ttest: 1.0199661\tbest: 1.0199661 (877)\ttotal: 8.7s\tremaining: 1m 30s\n",
      "878:\tlearn: 1.0012377\ttest: 1.0199472\tbest: 1.0199472 (878)\ttotal: 8.71s\tremaining: 1m 30s\n",
      "879:\tlearn: 1.0012229\ttest: 1.0199479\tbest: 1.0199472 (878)\ttotal: 8.72s\tremaining: 1m 30s\n",
      "880:\tlearn: 1.0011945\ttest: 1.0199488\tbest: 1.0199472 (878)\ttotal: 8.73s\tremaining: 1m 30s\n",
      "881:\tlearn: 1.0011596\ttest: 1.0199478\tbest: 1.0199472 (878)\ttotal: 8.74s\tremaining: 1m 30s\n",
      "882:\tlearn: 1.0011339\ttest: 1.0199589\tbest: 1.0199472 (878)\ttotal: 8.76s\tremaining: 1m 30s\n",
      "883:\tlearn: 1.0011010\ttest: 1.0199514\tbest: 1.0199472 (878)\ttotal: 8.77s\tremaining: 1m 30s\n",
      "884:\tlearn: 1.0010812\ttest: 1.0199436\tbest: 1.0199436 (884)\ttotal: 8.77s\tremaining: 1m 30s\n",
      "885:\tlearn: 1.0010517\ttest: 1.0199273\tbest: 1.0199273 (885)\ttotal: 8.79s\tremaining: 1m 30s\n",
      "886:\tlearn: 1.0010213\ttest: 1.0199299\tbest: 1.0199273 (885)\ttotal: 8.79s\tremaining: 1m 30s\n",
      "887:\tlearn: 1.0009988\ttest: 1.0199240\tbest: 1.0199240 (887)\ttotal: 8.8s\tremaining: 1m 30s\n",
      "888:\tlearn: 1.0009791\ttest: 1.0199039\tbest: 1.0199039 (888)\ttotal: 8.81s\tremaining: 1m 30s\n",
      "889:\tlearn: 1.0009574\ttest: 1.0198945\tbest: 1.0198945 (889)\ttotal: 8.82s\tremaining: 1m 30s\n",
      "890:\tlearn: 1.0009406\ttest: 1.0198877\tbest: 1.0198877 (890)\ttotal: 8.83s\tremaining: 1m 30s\n",
      "891:\tlearn: 1.0009178\ttest: 1.0198762\tbest: 1.0198762 (891)\ttotal: 8.84s\tremaining: 1m 30s\n",
      "892:\tlearn: 1.0008928\ttest: 1.0198667\tbest: 1.0198667 (892)\ttotal: 8.85s\tremaining: 1m 30s\n",
      "893:\tlearn: 1.0008699\ttest: 1.0198653\tbest: 1.0198653 (893)\ttotal: 8.86s\tremaining: 1m 30s\n",
      "894:\tlearn: 1.0008549\ttest: 1.0198771\tbest: 1.0198653 (893)\ttotal: 8.87s\tremaining: 1m 30s\n",
      "895:\tlearn: 1.0008387\ttest: 1.0198726\tbest: 1.0198653 (893)\ttotal: 8.88s\tremaining: 1m 30s\n",
      "896:\tlearn: 1.0008168\ttest: 1.0198721\tbest: 1.0198653 (893)\ttotal: 8.89s\tremaining: 1m 30s\n",
      "897:\tlearn: 1.0007984\ttest: 1.0198693\tbest: 1.0198653 (893)\ttotal: 8.9s\tremaining: 1m 30s\n",
      "898:\tlearn: 1.0007742\ttest: 1.0198540\tbest: 1.0198540 (898)\ttotal: 8.91s\tremaining: 1m 30s\n",
      "899:\tlearn: 1.0007398\ttest: 1.0198376\tbest: 1.0198376 (899)\ttotal: 8.92s\tremaining: 1m 30s\n",
      "900:\tlearn: 1.0007254\ttest: 1.0198359\tbest: 1.0198359 (900)\ttotal: 8.93s\tremaining: 1m 30s\n",
      "901:\tlearn: 1.0007034\ttest: 1.0198235\tbest: 1.0198235 (901)\ttotal: 8.94s\tremaining: 1m 30s\n",
      "902:\tlearn: 1.0006780\ttest: 1.0198170\tbest: 1.0198170 (902)\ttotal: 8.95s\tremaining: 1m 30s\n",
      "903:\tlearn: 1.0006500\ttest: 1.0198075\tbest: 1.0198075 (903)\ttotal: 8.96s\tremaining: 1m 30s\n",
      "904:\tlearn: 1.0006297\ttest: 1.0198120\tbest: 1.0198075 (903)\ttotal: 8.97s\tremaining: 1m 30s\n",
      "905:\tlearn: 1.0006056\ttest: 1.0198070\tbest: 1.0198070 (905)\ttotal: 8.98s\tremaining: 1m 30s\n",
      "906:\tlearn: 1.0005819\ttest: 1.0198047\tbest: 1.0198047 (906)\ttotal: 8.99s\tremaining: 1m 30s\n",
      "907:\tlearn: 1.0005576\ttest: 1.0197892\tbest: 1.0197892 (907)\ttotal: 9s\tremaining: 1m 30s\n",
      "908:\tlearn: 1.0005382\ttest: 1.0197879\tbest: 1.0197879 (908)\ttotal: 9.01s\tremaining: 1m 30s\n",
      "909:\tlearn: 1.0005109\ttest: 1.0197835\tbest: 1.0197835 (909)\ttotal: 9.02s\tremaining: 1m 30s\n",
      "910:\tlearn: 1.0004845\ttest: 1.0197786\tbest: 1.0197786 (910)\ttotal: 9.03s\tremaining: 1m 30s\n",
      "911:\tlearn: 1.0004594\ttest: 1.0197744\tbest: 1.0197744 (911)\ttotal: 9.04s\tremaining: 1m 30s\n",
      "912:\tlearn: 1.0004310\ttest: 1.0197626\tbest: 1.0197626 (912)\ttotal: 9.05s\tremaining: 1m 30s\n",
      "913:\tlearn: 1.0004051\ttest: 1.0197584\tbest: 1.0197584 (913)\ttotal: 9.06s\tremaining: 1m 30s\n",
      "914:\tlearn: 1.0003825\ttest: 1.0197562\tbest: 1.0197562 (914)\ttotal: 9.07s\tremaining: 1m 30s\n",
      "915:\tlearn: 1.0003522\ttest: 1.0197522\tbest: 1.0197522 (915)\ttotal: 9.08s\tremaining: 1m 30s\n",
      "916:\tlearn: 1.0003206\ttest: 1.0197558\tbest: 1.0197522 (915)\ttotal: 9.09s\tremaining: 1m 30s\n",
      "917:\tlearn: 1.0002951\ttest: 1.0197271\tbest: 1.0197271 (917)\ttotal: 9.1s\tremaining: 1m 30s\n",
      "918:\tlearn: 1.0002749\ttest: 1.0197232\tbest: 1.0197232 (918)\ttotal: 9.11s\tremaining: 1m 30s\n",
      "919:\tlearn: 1.0002515\ttest: 1.0197189\tbest: 1.0197189 (919)\ttotal: 9.12s\tremaining: 1m 29s\n",
      "920:\tlearn: 1.0002302\ttest: 1.0197184\tbest: 1.0197184 (920)\ttotal: 9.13s\tremaining: 1m 29s\n",
      "921:\tlearn: 1.0002096\ttest: 1.0197244\tbest: 1.0197184 (920)\ttotal: 9.14s\tremaining: 1m 29s\n",
      "922:\tlearn: 1.0001964\ttest: 1.0197211\tbest: 1.0197184 (920)\ttotal: 9.14s\tremaining: 1m 29s\n",
      "923:\tlearn: 1.0001716\ttest: 1.0197118\tbest: 1.0197118 (923)\ttotal: 9.16s\tremaining: 1m 29s\n",
      "924:\tlearn: 1.0001427\ttest: 1.0196999\tbest: 1.0196999 (924)\ttotal: 9.17s\tremaining: 1m 29s\n",
      "925:\tlearn: 1.0001199\ttest: 1.0196901\tbest: 1.0196901 (925)\ttotal: 9.18s\tremaining: 1m 29s\n",
      "926:\tlearn: 1.0001035\ttest: 1.0196862\tbest: 1.0196862 (926)\ttotal: 9.18s\tremaining: 1m 29s\n",
      "927:\tlearn: 1.0000729\ttest: 1.0196746\tbest: 1.0196746 (927)\ttotal: 9.19s\tremaining: 1m 29s\n",
      "928:\tlearn: 1.0000508\ttest: 1.0196765\tbest: 1.0196746 (927)\ttotal: 9.2s\tremaining: 1m 29s\n",
      "929:\tlearn: 1.0000346\ttest: 1.0196759\tbest: 1.0196746 (927)\ttotal: 9.21s\tremaining: 1m 29s\n",
      "930:\tlearn: 1.0000110\ttest: 1.0196721\tbest: 1.0196721 (930)\ttotal: 9.23s\tremaining: 1m 29s\n",
      "931:\tlearn: 0.9999914\ttest: 1.0196634\tbest: 1.0196634 (931)\ttotal: 9.24s\tremaining: 1m 29s\n",
      "932:\tlearn: 0.9999609\ttest: 1.0196564\tbest: 1.0196564 (932)\ttotal: 9.25s\tremaining: 1m 29s\n",
      "933:\tlearn: 0.9999412\ttest: 1.0196516\tbest: 1.0196516 (933)\ttotal: 9.27s\tremaining: 1m 29s\n",
      "934:\tlearn: 0.9999276\ttest: 1.0196496\tbest: 1.0196496 (934)\ttotal: 9.27s\tremaining: 1m 29s\n",
      "935:\tlearn: 0.9998964\ttest: 1.0196562\tbest: 1.0196496 (934)\ttotal: 9.28s\tremaining: 1m 29s\n",
      "936:\tlearn: 0.9998610\ttest: 1.0196516\tbest: 1.0196496 (934)\ttotal: 9.29s\tremaining: 1m 29s\n",
      "937:\tlearn: 0.9998431\ttest: 1.0196366\tbest: 1.0196366 (937)\ttotal: 9.3s\tremaining: 1m 29s\n",
      "938:\tlearn: 0.9998278\ttest: 1.0196347\tbest: 1.0196347 (938)\ttotal: 9.31s\tremaining: 1m 29s\n",
      "939:\tlearn: 0.9998018\ttest: 1.0196342\tbest: 1.0196342 (939)\ttotal: 9.32s\tremaining: 1m 29s\n",
      "940:\tlearn: 0.9997824\ttest: 1.0196343\tbest: 1.0196342 (939)\ttotal: 9.33s\tremaining: 1m 29s\n",
      "941:\tlearn: 0.9997593\ttest: 1.0196162\tbest: 1.0196162 (941)\ttotal: 9.34s\tremaining: 1m 29s\n",
      "942:\tlearn: 0.9997340\ttest: 1.0196276\tbest: 1.0196162 (941)\ttotal: 9.35s\tremaining: 1m 29s\n",
      "943:\tlearn: 0.9997147\ttest: 1.0196304\tbest: 1.0196162 (941)\ttotal: 9.36s\tremaining: 1m 29s\n",
      "944:\tlearn: 0.9996865\ttest: 1.0196308\tbest: 1.0196162 (941)\ttotal: 9.37s\tremaining: 1m 29s\n",
      "945:\tlearn: 0.9996644\ttest: 1.0196289\tbest: 1.0196162 (941)\ttotal: 9.38s\tremaining: 1m 29s\n",
      "946:\tlearn: 0.9996400\ttest: 1.0196161\tbest: 1.0196161 (946)\ttotal: 9.39s\tremaining: 1m 29s\n",
      "947:\tlearn: 0.9996156\ttest: 1.0196022\tbest: 1.0196022 (947)\ttotal: 9.4s\tremaining: 1m 29s\n",
      "948:\tlearn: 0.9995992\ttest: 1.0196186\tbest: 1.0196022 (947)\ttotal: 9.41s\tremaining: 1m 29s\n",
      "949:\tlearn: 0.9995733\ttest: 1.0196062\tbest: 1.0196022 (947)\ttotal: 9.42s\tremaining: 1m 29s\n",
      "950:\tlearn: 0.9995540\ttest: 1.0196012\tbest: 1.0196012 (950)\ttotal: 9.43s\tremaining: 1m 29s\n",
      "951:\tlearn: 0.9995318\ttest: 1.0195980\tbest: 1.0195980 (951)\ttotal: 9.44s\tremaining: 1m 29s\n",
      "952:\tlearn: 0.9995084\ttest: 1.0195808\tbest: 1.0195808 (952)\ttotal: 9.45s\tremaining: 1m 29s\n",
      "953:\tlearn: 0.9994940\ttest: 1.0195740\tbest: 1.0195740 (953)\ttotal: 9.46s\tremaining: 1m 29s\n",
      "954:\tlearn: 0.9994704\ttest: 1.0195640\tbest: 1.0195640 (954)\ttotal: 9.47s\tremaining: 1m 29s\n",
      "955:\tlearn: 0.9994416\ttest: 1.0195488\tbest: 1.0195488 (955)\ttotal: 9.48s\tremaining: 1m 29s\n",
      "956:\tlearn: 0.9994167\ttest: 1.0195328\tbest: 1.0195328 (956)\ttotal: 9.49s\tremaining: 1m 29s\n",
      "957:\tlearn: 0.9993894\ttest: 1.0195107\tbest: 1.0195107 (957)\ttotal: 9.5s\tremaining: 1m 29s\n",
      "958:\tlearn: 0.9993634\ttest: 1.0195038\tbest: 1.0195038 (958)\ttotal: 9.51s\tremaining: 1m 29s\n",
      "959:\tlearn: 0.9993414\ttest: 1.0195026\tbest: 1.0195026 (959)\ttotal: 9.52s\tremaining: 1m 29s\n",
      "960:\tlearn: 0.9993168\ttest: 1.0194948\tbest: 1.0194948 (960)\ttotal: 9.53s\tremaining: 1m 29s\n",
      "961:\tlearn: 0.9992941\ttest: 1.0194900\tbest: 1.0194900 (961)\ttotal: 9.54s\tremaining: 1m 29s\n",
      "962:\tlearn: 0.9992670\ttest: 1.0194809\tbest: 1.0194809 (962)\ttotal: 9.55s\tremaining: 1m 29s\n",
      "963:\tlearn: 0.9992393\ttest: 1.0194768\tbest: 1.0194768 (963)\ttotal: 9.56s\tremaining: 1m 29s\n",
      "964:\tlearn: 0.9992148\ttest: 1.0194642\tbest: 1.0194642 (964)\ttotal: 9.57s\tremaining: 1m 29s\n",
      "965:\tlearn: 0.9991945\ttest: 1.0194610\tbest: 1.0194610 (965)\ttotal: 9.58s\tremaining: 1m 29s\n",
      "966:\tlearn: 0.9991697\ttest: 1.0194483\tbest: 1.0194483 (966)\ttotal: 9.59s\tremaining: 1m 29s\n",
      "967:\tlearn: 0.9991535\ttest: 1.0194450\tbest: 1.0194450 (967)\ttotal: 9.6s\tremaining: 1m 29s\n",
      "968:\tlearn: 0.9991355\ttest: 1.0194319\tbest: 1.0194319 (968)\ttotal: 9.61s\tremaining: 1m 29s\n",
      "969:\tlearn: 0.9991049\ttest: 1.0194306\tbest: 1.0194306 (969)\ttotal: 9.62s\tremaining: 1m 29s\n",
      "970:\tlearn: 0.9990754\ttest: 1.0194284\tbest: 1.0194284 (970)\ttotal: 9.63s\tremaining: 1m 29s\n",
      "971:\tlearn: 0.9990539\ttest: 1.0194173\tbest: 1.0194173 (971)\ttotal: 9.64s\tremaining: 1m 29s\n",
      "972:\tlearn: 0.9990291\ttest: 1.0194182\tbest: 1.0194173 (971)\ttotal: 9.65s\tremaining: 1m 29s\n",
      "973:\tlearn: 0.9990058\ttest: 1.0194104\tbest: 1.0194104 (973)\ttotal: 9.66s\tremaining: 1m 29s\n",
      "974:\tlearn: 0.9989887\ttest: 1.0194008\tbest: 1.0194008 (974)\ttotal: 9.67s\tremaining: 1m 29s\n",
      "975:\tlearn: 0.9989597\ttest: 1.0194023\tbest: 1.0194008 (974)\ttotal: 9.68s\tremaining: 1m 29s\n",
      "976:\tlearn: 0.9989361\ttest: 1.0193931\tbest: 1.0193931 (976)\ttotal: 9.69s\tremaining: 1m 29s\n",
      "977:\tlearn: 0.9989142\ttest: 1.0194000\tbest: 1.0193931 (976)\ttotal: 9.7s\tremaining: 1m 29s\n",
      "978:\tlearn: 0.9988933\ttest: 1.0193943\tbest: 1.0193931 (976)\ttotal: 9.71s\tremaining: 1m 29s\n",
      "979:\tlearn: 0.9988726\ttest: 1.0193883\tbest: 1.0193883 (979)\ttotal: 9.71s\tremaining: 1m 29s\n",
      "980:\tlearn: 0.9988461\ttest: 1.0193738\tbest: 1.0193738 (980)\ttotal: 9.72s\tremaining: 1m 29s\n",
      "981:\tlearn: 0.9988207\ttest: 1.0193674\tbest: 1.0193674 (981)\ttotal: 9.73s\tremaining: 1m 29s\n",
      "982:\tlearn: 0.9987997\ttest: 1.0193604\tbest: 1.0193604 (982)\ttotal: 9.74s\tremaining: 1m 29s\n",
      "983:\tlearn: 0.9987828\ttest: 1.0193560\tbest: 1.0193560 (983)\ttotal: 9.75s\tremaining: 1m 29s\n",
      "984:\tlearn: 0.9987629\ttest: 1.0193594\tbest: 1.0193560 (983)\ttotal: 9.76s\tremaining: 1m 29s\n",
      "985:\tlearn: 0.9987445\ttest: 1.0193577\tbest: 1.0193560 (983)\ttotal: 9.77s\tremaining: 1m 29s\n",
      "986:\tlearn: 0.9987144\ttest: 1.0193546\tbest: 1.0193546 (986)\ttotal: 9.78s\tremaining: 1m 29s\n",
      "987:\tlearn: 0.9987006\ttest: 1.0193514\tbest: 1.0193514 (987)\ttotal: 9.79s\tremaining: 1m 29s\n",
      "988:\tlearn: 0.9986739\ttest: 1.0193344\tbest: 1.0193344 (988)\ttotal: 9.8s\tremaining: 1m 29s\n",
      "989:\tlearn: 0.9986556\ttest: 1.0193254\tbest: 1.0193254 (989)\ttotal: 9.81s\tremaining: 1m 29s\n",
      "990:\tlearn: 0.9986276\ttest: 1.0193238\tbest: 1.0193238 (990)\ttotal: 9.82s\tremaining: 1m 29s\n",
      "991:\tlearn: 0.9986055\ttest: 1.0193256\tbest: 1.0193238 (990)\ttotal: 9.83s\tremaining: 1m 29s\n",
      "992:\tlearn: 0.9985803\ttest: 1.0193125\tbest: 1.0193125 (992)\ttotal: 9.84s\tremaining: 1m 29s\n",
      "993:\tlearn: 0.9985643\ttest: 1.0193119\tbest: 1.0193119 (993)\ttotal: 9.85s\tremaining: 1m 29s\n",
      "994:\tlearn: 0.9985389\ttest: 1.0193097\tbest: 1.0193097 (994)\ttotal: 9.86s\tremaining: 1m 29s\n",
      "995:\tlearn: 0.9985137\ttest: 1.0192960\tbest: 1.0192960 (995)\ttotal: 9.88s\tremaining: 1m 29s\n",
      "996:\tlearn: 0.9984910\ttest: 1.0192984\tbest: 1.0192960 (995)\ttotal: 9.89s\tremaining: 1m 29s\n",
      "997:\tlearn: 0.9984730\ttest: 1.0192922\tbest: 1.0192922 (997)\ttotal: 9.9s\tremaining: 1m 29s\n",
      "998:\tlearn: 0.9984539\ttest: 1.0192917\tbest: 1.0192917 (998)\ttotal: 9.9s\tremaining: 1m 29s\n",
      "999:\tlearn: 0.9984355\ttest: 1.0192897\tbest: 1.0192897 (999)\ttotal: 9.91s\tremaining: 1m 29s\n",
      "1000:\tlearn: 0.9984117\ttest: 1.0192817\tbest: 1.0192817 (1000)\ttotal: 9.93s\tremaining: 1m 29s\n",
      "1001:\tlearn: 0.9983873\ttest: 1.0192799\tbest: 1.0192799 (1001)\ttotal: 9.93s\tremaining: 1m 29s\n",
      "1002:\tlearn: 0.9983635\ttest: 1.0192872\tbest: 1.0192799 (1001)\ttotal: 9.94s\tremaining: 1m 29s\n",
      "1003:\tlearn: 0.9983405\ttest: 1.0192895\tbest: 1.0192799 (1001)\ttotal: 9.95s\tremaining: 1m 29s\n",
      "1004:\tlearn: 0.9983247\ttest: 1.0192828\tbest: 1.0192799 (1001)\ttotal: 9.96s\tremaining: 1m 29s\n",
      "1005:\tlearn: 0.9983090\ttest: 1.0192746\tbest: 1.0192746 (1005)\ttotal: 9.97s\tremaining: 1m 29s\n",
      "1006:\tlearn: 0.9982966\ttest: 1.0192727\tbest: 1.0192727 (1006)\ttotal: 9.98s\tremaining: 1m 29s\n",
      "1007:\tlearn: 0.9982728\ttest: 1.0192715\tbest: 1.0192715 (1007)\ttotal: 9.99s\tremaining: 1m 29s\n",
      "1008:\tlearn: 0.9982484\ttest: 1.0192683\tbest: 1.0192683 (1008)\ttotal: 10s\tremaining: 1m 29s\n",
      "1009:\tlearn: 0.9982343\ttest: 1.0192717\tbest: 1.0192683 (1008)\ttotal: 10s\tremaining: 1m 29s\n",
      "1010:\tlearn: 0.9982013\ttest: 1.0192677\tbest: 1.0192677 (1010)\ttotal: 10s\tremaining: 1m 29s\n",
      "1011:\tlearn: 0.9981830\ttest: 1.0192666\tbest: 1.0192666 (1011)\ttotal: 10s\tremaining: 1m 29s\n",
      "1012:\tlearn: 0.9981556\ttest: 1.0192662\tbest: 1.0192662 (1012)\ttotal: 10s\tremaining: 1m 29s\n",
      "1013:\tlearn: 0.9981276\ttest: 1.0192425\tbest: 1.0192425 (1013)\ttotal: 10s\tremaining: 1m 29s\n",
      "1014:\tlearn: 0.9980994\ttest: 1.0192378\tbest: 1.0192378 (1014)\ttotal: 10.1s\tremaining: 1m 29s\n",
      "1015:\tlearn: 0.9980796\ttest: 1.0192321\tbest: 1.0192321 (1015)\ttotal: 10.1s\tremaining: 1m 29s\n",
      "1016:\tlearn: 0.9980554\ttest: 1.0192161\tbest: 1.0192161 (1016)\ttotal: 10.1s\tremaining: 1m 29s\n",
      "1017:\tlearn: 0.9980335\ttest: 1.0192140\tbest: 1.0192140 (1017)\ttotal: 10.1s\tremaining: 1m 29s\n",
      "1018:\tlearn: 0.9980143\ttest: 1.0192221\tbest: 1.0192140 (1017)\ttotal: 10.1s\tremaining: 1m 29s\n",
      "1019:\tlearn: 0.9979949\ttest: 1.0192231\tbest: 1.0192140 (1017)\ttotal: 10.1s\tremaining: 1m 29s\n",
      "1020:\tlearn: 0.9979784\ttest: 1.0192192\tbest: 1.0192140 (1017)\ttotal: 10.1s\tremaining: 1m 29s\n",
      "1021:\tlearn: 0.9979508\ttest: 1.0192203\tbest: 1.0192140 (1017)\ttotal: 10.1s\tremaining: 1m 29s\n",
      "1022:\tlearn: 0.9979321\ttest: 1.0192189\tbest: 1.0192140 (1017)\ttotal: 10.1s\tremaining: 1m 28s\n",
      "1023:\tlearn: 0.9979112\ttest: 1.0192199\tbest: 1.0192140 (1017)\ttotal: 10.1s\tremaining: 1m 28s\n",
      "1024:\tlearn: 0.9978941\ttest: 1.0192114\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1025:\tlearn: 0.9978674\ttest: 1.0192244\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1026:\tlearn: 0.9978450\ttest: 1.0192214\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1027:\tlearn: 0.9978251\ttest: 1.0192352\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1028:\tlearn: 0.9978067\ttest: 1.0192281\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1029:\tlearn: 0.9977823\ttest: 1.0192281\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1030:\tlearn: 0.9977561\ttest: 1.0192421\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1031:\tlearn: 0.9977288\ttest: 1.0192398\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1032:\tlearn: 0.9977008\ttest: 1.0192372\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1033:\tlearn: 0.9976802\ttest: 1.0192279\tbest: 1.0192114 (1024)\ttotal: 10.2s\tremaining: 1m 28s\n",
      "1034:\tlearn: 0.9976566\ttest: 1.0192304\tbest: 1.0192114 (1024)\ttotal: 10.3s\tremaining: 1m 28s\n",
      "1035:\tlearn: 0.9976349\ttest: 1.0192393\tbest: 1.0192114 (1024)\ttotal: 10.3s\tremaining: 1m 28s\n",
      "1036:\tlearn: 0.9976104\ttest: 1.0192531\tbest: 1.0192114 (1024)\ttotal: 10.3s\tremaining: 1m 28s\n",
      "1037:\tlearn: 0.9975958\ttest: 1.0192558\tbest: 1.0192114 (1024)\ttotal: 10.3s\tremaining: 1m 28s\n",
      "1038:\tlearn: 0.9975757\ttest: 1.0192426\tbest: 1.0192114 (1024)\ttotal: 10.3s\tremaining: 1m 28s\n",
      "1039:\tlearn: 0.9975591\ttest: 1.0192429\tbest: 1.0192114 (1024)\ttotal: 10.3s\tremaining: 1m 28s\n",
      "1040:\tlearn: 0.9975369\ttest: 1.0192417\tbest: 1.0192114 (1024)\ttotal: 10.3s\tremaining: 1m 28s\n",
      "1041:\tlearn: 0.9975118\ttest: 1.0192455\tbest: 1.0192114 (1024)\ttotal: 10.3s\tremaining: 1m 28s\n",
      "1042:\tlearn: 0.9974934\ttest: 1.0192327\tbest: 1.0192114 (1024)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1043:\tlearn: 0.9974625\ttest: 1.0192133\tbest: 1.0192114 (1024)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1044:\tlearn: 0.9974386\ttest: 1.0192092\tbest: 1.0192092 (1044)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1045:\tlearn: 0.9974244\ttest: 1.0192107\tbest: 1.0192092 (1044)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1046:\tlearn: 0.9974025\ttest: 1.0192084\tbest: 1.0192084 (1046)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1047:\tlearn: 0.9973759\ttest: 1.0192183\tbest: 1.0192084 (1046)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1048:\tlearn: 0.9973484\ttest: 1.0192070\tbest: 1.0192070 (1048)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1049:\tlearn: 0.9973169\ttest: 1.0192070\tbest: 1.0192070 (1048)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1050:\tlearn: 0.9972972\ttest: 1.0191985\tbest: 1.0191985 (1050)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1051:\tlearn: 0.9972755\ttest: 1.0191890\tbest: 1.0191890 (1051)\ttotal: 10.4s\tremaining: 1m 28s\n",
      "1052:\tlearn: 0.9972605\ttest: 1.0191911\tbest: 1.0191890 (1051)\ttotal: 10.5s\tremaining: 1m 28s\n",
      "1053:\tlearn: 0.9972403\ttest: 1.0192026\tbest: 1.0191890 (1051)\ttotal: 10.5s\tremaining: 1m 28s\n",
      "1054:\tlearn: 0.9972211\ttest: 1.0192059\tbest: 1.0191890 (1051)\ttotal: 10.5s\tremaining: 1m 28s\n",
      "1055:\tlearn: 0.9971978\ttest: 1.0191986\tbest: 1.0191890 (1051)\ttotal: 10.5s\tremaining: 1m 28s\n",
      "1056:\tlearn: 0.9971848\ttest: 1.0192035\tbest: 1.0191890 (1051)\ttotal: 10.5s\tremaining: 1m 28s\n",
      "1057:\tlearn: 0.9971697\ttest: 1.0191983\tbest: 1.0191890 (1051)\ttotal: 10.5s\tremaining: 1m 28s\n",
      "1058:\tlearn: 0.9971547\ttest: 1.0191943\tbest: 1.0191890 (1051)\ttotal: 10.5s\tremaining: 1m 28s\n",
      "1059:\tlearn: 0.9971348\ttest: 1.0191839\tbest: 1.0191839 (1059)\ttotal: 10.5s\tremaining: 1m 28s\n",
      "1060:\tlearn: 0.9971180\ttest: 1.0191857\tbest: 1.0191839 (1059)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1061:\tlearn: 0.9970966\ttest: 1.0191899\tbest: 1.0191839 (1059)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1062:\tlearn: 0.9970716\ttest: 1.0191921\tbest: 1.0191839 (1059)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1063:\tlearn: 0.9970571\ttest: 1.0191890\tbest: 1.0191839 (1059)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1064:\tlearn: 0.9970401\ttest: 1.0191797\tbest: 1.0191797 (1064)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1065:\tlearn: 0.9970220\ttest: 1.0191669\tbest: 1.0191669 (1065)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1066:\tlearn: 0.9970011\ttest: 1.0191589\tbest: 1.0191589 (1066)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1067:\tlearn: 0.9969786\ttest: 1.0191522\tbest: 1.0191522 (1067)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1068:\tlearn: 0.9969595\ttest: 1.0191410\tbest: 1.0191410 (1068)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1069:\tlearn: 0.9969407\ttest: 1.0191462\tbest: 1.0191410 (1068)\ttotal: 10.6s\tremaining: 1m 28s\n",
      "1070:\tlearn: 0.9969288\ttest: 1.0191493\tbest: 1.0191410 (1068)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1071:\tlearn: 0.9969059\ttest: 1.0191595\tbest: 1.0191410 (1068)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1072:\tlearn: 0.9968858\ttest: 1.0191527\tbest: 1.0191410 (1068)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1073:\tlearn: 0.9968674\ttest: 1.0191580\tbest: 1.0191410 (1068)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1074:\tlearn: 0.9968487\ttest: 1.0191528\tbest: 1.0191410 (1068)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1075:\tlearn: 0.9968298\ttest: 1.0191456\tbest: 1.0191410 (1068)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1076:\tlearn: 0.9968053\ttest: 1.0191390\tbest: 1.0191390 (1076)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1077:\tlearn: 0.9967839\ttest: 1.0191353\tbest: 1.0191353 (1077)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1078:\tlearn: 0.9967711\ttest: 1.0191343\tbest: 1.0191343 (1078)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1079:\tlearn: 0.9967524\ttest: 1.0191343\tbest: 1.0191343 (1079)\ttotal: 10.7s\tremaining: 1m 28s\n",
      "1080:\tlearn: 0.9967321\ttest: 1.0191360\tbest: 1.0191343 (1079)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1081:\tlearn: 0.9967048\ttest: 1.0191393\tbest: 1.0191343 (1079)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1082:\tlearn: 0.9966785\ttest: 1.0191405\tbest: 1.0191343 (1079)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1083:\tlearn: 0.9966573\ttest: 1.0191466\tbest: 1.0191343 (1079)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1084:\tlearn: 0.9966363\ttest: 1.0191420\tbest: 1.0191343 (1079)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1085:\tlearn: 0.9966101\ttest: 1.0191353\tbest: 1.0191343 (1079)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1086:\tlearn: 0.9965882\ttest: 1.0191264\tbest: 1.0191264 (1086)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1087:\tlearn: 0.9965654\ttest: 1.0191269\tbest: 1.0191264 (1086)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1088:\tlearn: 0.9965424\ttest: 1.0191262\tbest: 1.0191262 (1088)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1089:\tlearn: 0.9965197\ttest: 1.0191229\tbest: 1.0191229 (1089)\ttotal: 10.8s\tremaining: 1m 28s\n",
      "1090:\tlearn: 0.9964933\ttest: 1.0191276\tbest: 1.0191229 (1089)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1091:\tlearn: 0.9964671\ttest: 1.0191148\tbest: 1.0191148 (1091)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1092:\tlearn: 0.9964425\ttest: 1.0191247\tbest: 1.0191148 (1091)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1093:\tlearn: 0.9964314\ttest: 1.0191284\tbest: 1.0191148 (1091)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1094:\tlearn: 0.9964078\ttest: 1.0191337\tbest: 1.0191148 (1091)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1095:\tlearn: 0.9963856\ttest: 1.0191166\tbest: 1.0191148 (1091)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1096:\tlearn: 0.9963772\ttest: 1.0191183\tbest: 1.0191148 (1091)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1097:\tlearn: 0.9963524\ttest: 1.0191140\tbest: 1.0191140 (1097)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1098:\tlearn: 0.9963298\ttest: 1.0191025\tbest: 1.0191025 (1098)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1099:\tlearn: 0.9963120\ttest: 1.0191022\tbest: 1.0191022 (1099)\ttotal: 10.9s\tremaining: 1m 28s\n",
      "1100:\tlearn: 0.9962863\ttest: 1.0191069\tbest: 1.0191022 (1099)\ttotal: 11s\tremaining: 1m 28s\n",
      "1101:\tlearn: 0.9962660\ttest: 1.0191012\tbest: 1.0191012 (1101)\ttotal: 11s\tremaining: 1m 28s\n",
      "1102:\tlearn: 0.9962389\ttest: 1.0191054\tbest: 1.0191012 (1101)\ttotal: 11s\tremaining: 1m 28s\n",
      "1103:\tlearn: 0.9962124\ttest: 1.0191093\tbest: 1.0191012 (1101)\ttotal: 11s\tremaining: 1m 28s\n",
      "1104:\tlearn: 0.9961852\ttest: 1.0191208\tbest: 1.0191012 (1101)\ttotal: 11s\tremaining: 1m 28s\n",
      "1105:\tlearn: 0.9961677\ttest: 1.0191166\tbest: 1.0191012 (1101)\ttotal: 11s\tremaining: 1m 28s\n",
      "1106:\tlearn: 0.9961473\ttest: 1.0191076\tbest: 1.0191012 (1101)\ttotal: 11s\tremaining: 1m 28s\n",
      "1107:\tlearn: 0.9961307\ttest: 1.0191006\tbest: 1.0191006 (1107)\ttotal: 11s\tremaining: 1m 28s\n",
      "1108:\tlearn: 0.9961112\ttest: 1.0190918\tbest: 1.0190918 (1108)\ttotal: 11s\tremaining: 1m 28s\n",
      "1109:\tlearn: 0.9960864\ttest: 1.0190826\tbest: 1.0190826 (1109)\ttotal: 11s\tremaining: 1m 28s\n",
      "1110:\tlearn: 0.9960611\ttest: 1.0190967\tbest: 1.0190826 (1109)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1111:\tlearn: 0.9960524\ttest: 1.0190921\tbest: 1.0190826 (1109)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1112:\tlearn: 0.9960345\ttest: 1.0190900\tbest: 1.0190826 (1109)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1113:\tlearn: 0.9960084\ttest: 1.0190898\tbest: 1.0190826 (1109)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1114:\tlearn: 0.9959820\ttest: 1.0190909\tbest: 1.0190826 (1109)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1115:\tlearn: 0.9959613\ttest: 1.0190826\tbest: 1.0190826 (1109)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1116:\tlearn: 0.9959363\ttest: 1.0190874\tbest: 1.0190826 (1109)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1117:\tlearn: 0.9959148\ttest: 1.0190837\tbest: 1.0190826 (1109)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1118:\tlearn: 0.9958902\ttest: 1.0190717\tbest: 1.0190717 (1118)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1119:\tlearn: 0.9958657\ttest: 1.0190786\tbest: 1.0190717 (1118)\ttotal: 11.1s\tremaining: 1m 28s\n",
      "1120:\tlearn: 0.9958442\ttest: 1.0190865\tbest: 1.0190717 (1118)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1121:\tlearn: 0.9958300\ttest: 1.0190865\tbest: 1.0190717 (1118)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1122:\tlearn: 0.9958036\ttest: 1.0190772\tbest: 1.0190717 (1118)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1123:\tlearn: 0.9957846\ttest: 1.0190767\tbest: 1.0190717 (1118)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1124:\tlearn: 0.9957652\ttest: 1.0190729\tbest: 1.0190717 (1118)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1125:\tlearn: 0.9957515\ttest: 1.0190683\tbest: 1.0190683 (1125)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1126:\tlearn: 0.9957260\ttest: 1.0190689\tbest: 1.0190683 (1125)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1127:\tlearn: 0.9957041\ttest: 1.0190671\tbest: 1.0190671 (1127)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1128:\tlearn: 0.9956840\ttest: 1.0190525\tbest: 1.0190525 (1128)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1129:\tlearn: 0.9956657\ttest: 1.0190533\tbest: 1.0190525 (1128)\ttotal: 11.2s\tremaining: 1m 28s\n",
      "1130:\tlearn: 0.9956410\ttest: 1.0190655\tbest: 1.0190525 (1128)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1131:\tlearn: 0.9956282\ttest: 1.0190646\tbest: 1.0190525 (1128)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1132:\tlearn: 0.9956081\ttest: 1.0190582\tbest: 1.0190525 (1128)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1133:\tlearn: 0.9955838\ttest: 1.0190595\tbest: 1.0190525 (1128)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1134:\tlearn: 0.9955591\ttest: 1.0190575\tbest: 1.0190525 (1128)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1135:\tlearn: 0.9955427\ttest: 1.0190555\tbest: 1.0190525 (1128)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1136:\tlearn: 0.9955262\ttest: 1.0190522\tbest: 1.0190522 (1136)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1137:\tlearn: 0.9955045\ttest: 1.0190445\tbest: 1.0190445 (1137)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1138:\tlearn: 0.9954815\ttest: 1.0190353\tbest: 1.0190353 (1138)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1139:\tlearn: 0.9954658\ttest: 1.0190343\tbest: 1.0190343 (1139)\ttotal: 11.3s\tremaining: 1m 28s\n",
      "1140:\tlearn: 0.9954441\ttest: 1.0190305\tbest: 1.0190305 (1140)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1141:\tlearn: 0.9954241\ttest: 1.0190197\tbest: 1.0190197 (1141)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1142:\tlearn: 0.9954089\ttest: 1.0190260\tbest: 1.0190197 (1141)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1143:\tlearn: 0.9953913\ttest: 1.0190285\tbest: 1.0190197 (1141)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1144:\tlearn: 0.9953736\ttest: 1.0190346\tbest: 1.0190197 (1141)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1145:\tlearn: 0.9953560\ttest: 1.0190323\tbest: 1.0190197 (1141)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1146:\tlearn: 0.9953436\ttest: 1.0190259\tbest: 1.0190197 (1141)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1147:\tlearn: 0.9953184\ttest: 1.0190310\tbest: 1.0190197 (1141)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1148:\tlearn: 0.9952948\ttest: 1.0190153\tbest: 1.0190153 (1148)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1149:\tlearn: 0.9952796\ttest: 1.0190056\tbest: 1.0190056 (1149)\ttotal: 11.4s\tremaining: 1m 28s\n",
      "1150:\tlearn: 0.9952604\ttest: 1.0190060\tbest: 1.0190056 (1149)\ttotal: 11.5s\tremaining: 1m 28s\n",
      "1151:\tlearn: 0.9952391\ttest: 1.0190094\tbest: 1.0190056 (1149)\ttotal: 11.5s\tremaining: 1m 28s\n",
      "1152:\tlearn: 0.9952196\ttest: 1.0190025\tbest: 1.0190025 (1152)\ttotal: 11.5s\tremaining: 1m 28s\n",
      "1153:\tlearn: 0.9951939\ttest: 1.0189984\tbest: 1.0189984 (1153)\ttotal: 11.5s\tremaining: 1m 28s\n",
      "1154:\tlearn: 0.9951720\ttest: 1.0189910\tbest: 1.0189910 (1154)\ttotal: 11.5s\tremaining: 1m 28s\n",
      "1155:\tlearn: 0.9951444\ttest: 1.0189982\tbest: 1.0189910 (1154)\ttotal: 11.5s\tremaining: 1m 27s\n",
      "1156:\tlearn: 0.9951175\ttest: 1.0190175\tbest: 1.0189910 (1154)\ttotal: 11.5s\tremaining: 1m 27s\n",
      "1157:\tlearn: 0.9950995\ttest: 1.0190165\tbest: 1.0189910 (1154)\ttotal: 11.5s\tremaining: 1m 27s\n",
      "1158:\tlearn: 0.9950817\ttest: 1.0190111\tbest: 1.0189910 (1154)\ttotal: 11.5s\tremaining: 1m 27s\n",
      "1159:\tlearn: 0.9950578\ttest: 1.0190050\tbest: 1.0189910 (1154)\ttotal: 11.5s\tremaining: 1m 27s\n",
      "1160:\tlearn: 0.9950430\ttest: 1.0189879\tbest: 1.0189879 (1160)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1161:\tlearn: 0.9950224\ttest: 1.0189833\tbest: 1.0189833 (1161)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1162:\tlearn: 0.9950052\ttest: 1.0189781\tbest: 1.0189781 (1162)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1163:\tlearn: 0.9949788\ttest: 1.0189805\tbest: 1.0189781 (1162)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1164:\tlearn: 0.9949587\ttest: 1.0189821\tbest: 1.0189781 (1162)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1165:\tlearn: 0.9949340\ttest: 1.0189820\tbest: 1.0189781 (1162)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1166:\tlearn: 0.9949167\ttest: 1.0189846\tbest: 1.0189781 (1162)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1167:\tlearn: 0.9948955\ttest: 1.0189934\tbest: 1.0189781 (1162)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1168:\tlearn: 0.9948699\ttest: 1.0189929\tbest: 1.0189781 (1162)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1169:\tlearn: 0.9948483\ttest: 1.0189863\tbest: 1.0189781 (1162)\ttotal: 11.6s\tremaining: 1m 27s\n",
      "1170:\tlearn: 0.9948265\ttest: 1.0189891\tbest: 1.0189781 (1162)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1171:\tlearn: 0.9948082\ttest: 1.0189894\tbest: 1.0189781 (1162)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1172:\tlearn: 0.9947933\ttest: 1.0189896\tbest: 1.0189781 (1162)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1173:\tlearn: 0.9947722\ttest: 1.0189941\tbest: 1.0189781 (1162)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1174:\tlearn: 0.9947518\ttest: 1.0189841\tbest: 1.0189781 (1162)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1175:\tlearn: 0.9947321\ttest: 1.0189720\tbest: 1.0189720 (1175)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1176:\tlearn: 0.9947075\ttest: 1.0189616\tbest: 1.0189616 (1176)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1177:\tlearn: 0.9946875\ttest: 1.0189523\tbest: 1.0189523 (1177)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1178:\tlearn: 0.9946679\ttest: 1.0189519\tbest: 1.0189519 (1178)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1179:\tlearn: 0.9946501\ttest: 1.0189546\tbest: 1.0189519 (1178)\ttotal: 11.7s\tremaining: 1m 27s\n",
      "1180:\tlearn: 0.9946325\ttest: 1.0189598\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1181:\tlearn: 0.9946108\ttest: 1.0189670\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1182:\tlearn: 0.9945922\ttest: 1.0189622\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1183:\tlearn: 0.9945768\ttest: 1.0189609\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1184:\tlearn: 0.9945557\ttest: 1.0189727\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1185:\tlearn: 0.9945390\ttest: 1.0189712\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1186:\tlearn: 0.9945263\ttest: 1.0189727\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1187:\tlearn: 0.9945057\ttest: 1.0189716\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1188:\tlearn: 0.9944880\ttest: 1.0189704\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1189:\tlearn: 0.9944761\ttest: 1.0189698\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1190:\tlearn: 0.9944590\ttest: 1.0189753\tbest: 1.0189519 (1178)\ttotal: 11.8s\tremaining: 1m 27s\n",
      "1191:\tlearn: 0.9944434\ttest: 1.0189774\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1192:\tlearn: 0.9944281\ttest: 1.0189846\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1193:\tlearn: 0.9944100\ttest: 1.0189764\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1194:\tlearn: 0.9943874\ttest: 1.0189835\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1195:\tlearn: 0.9943662\ttest: 1.0189855\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1196:\tlearn: 0.9943508\ttest: 1.0189913\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1197:\tlearn: 0.9943290\ttest: 1.0189983\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1198:\tlearn: 0.9943126\ttest: 1.0189980\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1199:\tlearn: 0.9942960\ttest: 1.0189981\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1200:\tlearn: 0.9942767\ttest: 1.0189920\tbest: 1.0189519 (1178)\ttotal: 11.9s\tremaining: 1m 27s\n",
      "1201:\tlearn: 0.9942593\ttest: 1.0189814\tbest: 1.0189519 (1178)\ttotal: 12s\tremaining: 1m 27s\n",
      "1202:\tlearn: 0.9942386\ttest: 1.0189780\tbest: 1.0189519 (1178)\ttotal: 12s\tremaining: 1m 27s\n",
      "1203:\tlearn: 0.9942210\ttest: 1.0189760\tbest: 1.0189519 (1178)\ttotal: 12s\tremaining: 1m 27s\n",
      "1204:\tlearn: 0.9941979\ttest: 1.0189692\tbest: 1.0189519 (1178)\ttotal: 12s\tremaining: 1m 27s\n",
      "1205:\tlearn: 0.9941775\ttest: 1.0189620\tbest: 1.0189519 (1178)\ttotal: 12s\tremaining: 1m 27s\n",
      "1206:\tlearn: 0.9941584\ttest: 1.0189578\tbest: 1.0189519 (1178)\ttotal: 12s\tremaining: 1m 27s\n",
      "1207:\tlearn: 0.9941408\ttest: 1.0189524\tbest: 1.0189519 (1178)\ttotal: 12s\tremaining: 1m 27s\n",
      "1208:\tlearn: 0.9941212\ttest: 1.0189392\tbest: 1.0189392 (1208)\ttotal: 12s\tremaining: 1m 27s\n",
      "1209:\tlearn: 0.9941085\ttest: 1.0189355\tbest: 1.0189355 (1209)\ttotal: 12s\tremaining: 1m 27s\n",
      "1210:\tlearn: 0.9940883\ttest: 1.0189430\tbest: 1.0189355 (1209)\ttotal: 12s\tremaining: 1m 27s\n",
      "1211:\tlearn: 0.9940632\ttest: 1.0189334\tbest: 1.0189334 (1211)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1212:\tlearn: 0.9940440\ttest: 1.0189301\tbest: 1.0189301 (1212)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1213:\tlearn: 0.9940288\ttest: 1.0189299\tbest: 1.0189299 (1213)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1214:\tlearn: 0.9940094\ttest: 1.0189199\tbest: 1.0189199 (1214)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1215:\tlearn: 0.9939909\ttest: 1.0189171\tbest: 1.0189171 (1215)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1216:\tlearn: 0.9939707\ttest: 1.0189143\tbest: 1.0189143 (1216)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1217:\tlearn: 0.9939534\ttest: 1.0189132\tbest: 1.0189132 (1217)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1218:\tlearn: 0.9939320\ttest: 1.0189036\tbest: 1.0189036 (1218)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1219:\tlearn: 0.9939161\ttest: 1.0189094\tbest: 1.0189036 (1218)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1220:\tlearn: 0.9938904\ttest: 1.0189210\tbest: 1.0189036 (1218)\ttotal: 12.1s\tremaining: 1m 27s\n",
      "1221:\tlearn: 0.9938747\ttest: 1.0189161\tbest: 1.0189036 (1218)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1222:\tlearn: 0.9938659\ttest: 1.0189029\tbest: 1.0189029 (1222)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1223:\tlearn: 0.9938416\ttest: 1.0188943\tbest: 1.0188943 (1223)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1224:\tlearn: 0.9938253\ttest: 1.0188893\tbest: 1.0188893 (1224)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1225:\tlearn: 0.9938082\ttest: 1.0188842\tbest: 1.0188842 (1225)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1226:\tlearn: 0.9937841\ttest: 1.0188885\tbest: 1.0188842 (1225)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1227:\tlearn: 0.9937639\ttest: 1.0188906\tbest: 1.0188842 (1225)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1228:\tlearn: 0.9937397\ttest: 1.0189020\tbest: 1.0188842 (1225)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1229:\tlearn: 0.9937215\ttest: 1.0189013\tbest: 1.0188842 (1225)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1230:\tlearn: 0.9937009\ttest: 1.0189041\tbest: 1.0188842 (1225)\ttotal: 12.2s\tremaining: 1m 27s\n",
      "1231:\tlearn: 0.9936851\ttest: 1.0188972\tbest: 1.0188842 (1225)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1232:\tlearn: 0.9936651\ttest: 1.0188940\tbest: 1.0188842 (1225)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1233:\tlearn: 0.9936516\ttest: 1.0188942\tbest: 1.0188842 (1225)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1234:\tlearn: 0.9936319\ttest: 1.0188839\tbest: 1.0188839 (1234)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1235:\tlearn: 0.9936242\ttest: 1.0188847\tbest: 1.0188839 (1234)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1236:\tlearn: 0.9936058\ttest: 1.0188795\tbest: 1.0188795 (1236)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1237:\tlearn: 0.9935924\ttest: 1.0188814\tbest: 1.0188795 (1236)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1238:\tlearn: 0.9935745\ttest: 1.0188771\tbest: 1.0188771 (1238)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1239:\tlearn: 0.9935531\ttest: 1.0188774\tbest: 1.0188771 (1238)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1240:\tlearn: 0.9935285\ttest: 1.0188741\tbest: 1.0188741 (1240)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1241:\tlearn: 0.9935075\ttest: 1.0188738\tbest: 1.0188738 (1241)\ttotal: 12.3s\tremaining: 1m 27s\n",
      "1242:\tlearn: 0.9934860\ttest: 1.0188682\tbest: 1.0188682 (1242)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1243:\tlearn: 0.9934616\ttest: 1.0188606\tbest: 1.0188606 (1243)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1244:\tlearn: 0.9934353\ttest: 1.0188697\tbest: 1.0188606 (1243)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1245:\tlearn: 0.9934089\ttest: 1.0188723\tbest: 1.0188606 (1243)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1246:\tlearn: 0.9933885\ttest: 1.0188605\tbest: 1.0188605 (1246)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1247:\tlearn: 0.9933651\ttest: 1.0188491\tbest: 1.0188491 (1247)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1248:\tlearn: 0.9933341\ttest: 1.0188570\tbest: 1.0188491 (1247)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1249:\tlearn: 0.9933155\ttest: 1.0188527\tbest: 1.0188491 (1247)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1250:\tlearn: 0.9932929\ttest: 1.0188548\tbest: 1.0188491 (1247)\ttotal: 12.4s\tremaining: 1m 27s\n",
      "1251:\tlearn: 0.9932741\ttest: 1.0188547\tbest: 1.0188491 (1247)\ttotal: 12.5s\tremaining: 1m 27s\n",
      "1252:\tlearn: 0.9932481\ttest: 1.0188516\tbest: 1.0188491 (1247)\ttotal: 12.5s\tremaining: 1m 27s\n",
      "1253:\tlearn: 0.9932282\ttest: 1.0188404\tbest: 1.0188404 (1253)\ttotal: 12.5s\tremaining: 1m 27s\n",
      "1254:\tlearn: 0.9932086\ttest: 1.0188408\tbest: 1.0188404 (1253)\ttotal: 12.5s\tremaining: 1m 27s\n",
      "1255:\tlearn: 0.9931763\ttest: 1.0188516\tbest: 1.0188404 (1253)\ttotal: 12.5s\tremaining: 1m 27s\n",
      "1256:\tlearn: 0.9931565\ttest: 1.0188411\tbest: 1.0188404 (1253)\ttotal: 12.5s\tremaining: 1m 27s\n",
      "1257:\tlearn: 0.9931331\ttest: 1.0188382\tbest: 1.0188382 (1257)\ttotal: 12.5s\tremaining: 1m 26s\n",
      "1258:\tlearn: 0.9931170\ttest: 1.0188322\tbest: 1.0188322 (1258)\ttotal: 12.5s\tremaining: 1m 26s\n",
      "1259:\tlearn: 0.9931024\ttest: 1.0188319\tbest: 1.0188319 (1259)\ttotal: 12.5s\tremaining: 1m 26s\n",
      "1260:\tlearn: 0.9930890\ttest: 1.0188298\tbest: 1.0188298 (1260)\ttotal: 12.5s\tremaining: 1m 26s\n",
      "1261:\tlearn: 0.9930807\ttest: 1.0188335\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1262:\tlearn: 0.9930627\ttest: 1.0188458\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1263:\tlearn: 0.9930445\ttest: 1.0188322\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1264:\tlearn: 0.9930339\ttest: 1.0188349\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1265:\tlearn: 0.9930203\ttest: 1.0188374\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1266:\tlearn: 0.9929986\ttest: 1.0188349\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1267:\tlearn: 0.9929804\ttest: 1.0188419\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1268:\tlearn: 0.9929544\ttest: 1.0188469\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1269:\tlearn: 0.9929339\ttest: 1.0188439\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1270:\tlearn: 0.9929169\ttest: 1.0188473\tbest: 1.0188298 (1260)\ttotal: 12.6s\tremaining: 1m 26s\n",
      "1271:\tlearn: 0.9928933\ttest: 1.0188464\tbest: 1.0188298 (1260)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1272:\tlearn: 0.9928704\ttest: 1.0188364\tbest: 1.0188298 (1260)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1273:\tlearn: 0.9928545\ttest: 1.0188332\tbest: 1.0188298 (1260)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1274:\tlearn: 0.9928420\ttest: 1.0188271\tbest: 1.0188271 (1274)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1275:\tlearn: 0.9928193\ttest: 1.0188155\tbest: 1.0188155 (1275)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1276:\tlearn: 0.9927884\ttest: 1.0188197\tbest: 1.0188155 (1275)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1277:\tlearn: 0.9927747\ttest: 1.0188177\tbest: 1.0188155 (1275)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1278:\tlearn: 0.9927565\ttest: 1.0188132\tbest: 1.0188132 (1278)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1279:\tlearn: 0.9927338\ttest: 1.0188148\tbest: 1.0188132 (1278)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1280:\tlearn: 0.9927192\ttest: 1.0188046\tbest: 1.0188046 (1280)\ttotal: 12.7s\tremaining: 1m 26s\n",
      "1281:\tlearn: 0.9926972\ttest: 1.0187951\tbest: 1.0187951 (1281)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1282:\tlearn: 0.9926775\ttest: 1.0187951\tbest: 1.0187951 (1281)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1283:\tlearn: 0.9926662\ttest: 1.0187898\tbest: 1.0187898 (1283)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1284:\tlearn: 0.9926445\ttest: 1.0187886\tbest: 1.0187886 (1284)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1285:\tlearn: 0.9926242\ttest: 1.0187824\tbest: 1.0187824 (1285)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1286:\tlearn: 0.9926114\ttest: 1.0187868\tbest: 1.0187824 (1285)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1287:\tlearn: 0.9925964\ttest: 1.0187797\tbest: 1.0187797 (1287)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1288:\tlearn: 0.9925746\ttest: 1.0187887\tbest: 1.0187797 (1287)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1289:\tlearn: 0.9925539\ttest: 1.0187856\tbest: 1.0187797 (1287)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1290:\tlearn: 0.9925408\ttest: 1.0187858\tbest: 1.0187797 (1287)\ttotal: 12.8s\tremaining: 1m 26s\n",
      "1291:\tlearn: 0.9925178\ttest: 1.0187930\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1292:\tlearn: 0.9924997\ttest: 1.0187956\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1293:\tlearn: 0.9924802\ttest: 1.0187990\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1294:\tlearn: 0.9924647\ttest: 1.0188015\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1295:\tlearn: 0.9924475\ttest: 1.0188060\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1296:\tlearn: 0.9924218\ttest: 1.0188035\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1297:\tlearn: 0.9923989\ttest: 1.0188066\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1298:\tlearn: 0.9923820\ttest: 1.0187996\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1299:\tlearn: 0.9923659\ttest: 1.0188051\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1300:\tlearn: 0.9923461\ttest: 1.0188080\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1301:\tlearn: 0.9923339\ttest: 1.0188020\tbest: 1.0187797 (1287)\ttotal: 12.9s\tremaining: 1m 26s\n",
      "1302:\tlearn: 0.9923154\ttest: 1.0187945\tbest: 1.0187797 (1287)\ttotal: 13s\tremaining: 1m 26s\n",
      "1303:\tlearn: 0.9922997\ttest: 1.0187954\tbest: 1.0187797 (1287)\ttotal: 13s\tremaining: 1m 26s\n",
      "1304:\tlearn: 0.9922839\ttest: 1.0187886\tbest: 1.0187797 (1287)\ttotal: 13s\tremaining: 1m 26s\n",
      "1305:\tlearn: 0.9922687\ttest: 1.0187750\tbest: 1.0187750 (1305)\ttotal: 13s\tremaining: 1m 26s\n",
      "1306:\tlearn: 0.9922534\ttest: 1.0187731\tbest: 1.0187731 (1306)\ttotal: 13s\tremaining: 1m 26s\n",
      "1307:\tlearn: 0.9922361\ttest: 1.0187762\tbest: 1.0187731 (1306)\ttotal: 13s\tremaining: 1m 26s\n",
      "1308:\tlearn: 0.9922103\ttest: 1.0187748\tbest: 1.0187731 (1306)\ttotal: 13s\tremaining: 1m 26s\n",
      "1309:\tlearn: 0.9921939\ttest: 1.0187822\tbest: 1.0187731 (1306)\ttotal: 13s\tremaining: 1m 26s\n",
      "1310:\tlearn: 0.9921699\ttest: 1.0187810\tbest: 1.0187731 (1306)\ttotal: 13s\tremaining: 1m 26s\n",
      "1311:\tlearn: 0.9921493\ttest: 1.0187750\tbest: 1.0187731 (1306)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1312:\tlearn: 0.9921306\ttest: 1.0187775\tbest: 1.0187731 (1306)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1313:\tlearn: 0.9921194\ttest: 1.0187735\tbest: 1.0187731 (1306)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1314:\tlearn: 0.9921055\ttest: 1.0187715\tbest: 1.0187715 (1314)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1315:\tlearn: 0.9920917\ttest: 1.0187753\tbest: 1.0187715 (1314)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1316:\tlearn: 0.9920752\ttest: 1.0187766\tbest: 1.0187715 (1314)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1317:\tlearn: 0.9920610\ttest: 1.0187762\tbest: 1.0187715 (1314)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1318:\tlearn: 0.9920397\ttest: 1.0187746\tbest: 1.0187715 (1314)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1319:\tlearn: 0.9920171\ttest: 1.0187771\tbest: 1.0187715 (1314)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1320:\tlearn: 0.9919970\ttest: 1.0187674\tbest: 1.0187674 (1320)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1321:\tlearn: 0.9919759\ttest: 1.0187632\tbest: 1.0187632 (1321)\ttotal: 13.1s\tremaining: 1m 26s\n",
      "1322:\tlearn: 0.9919584\ttest: 1.0187552\tbest: 1.0187552 (1322)\ttotal: 13.2s\tremaining: 1m 26s\n",
      "1323:\tlearn: 0.9919388\ttest: 1.0187539\tbest: 1.0187539 (1323)\ttotal: 13.2s\tremaining: 1m 26s\n",
      "1324:\tlearn: 0.9919249\ttest: 1.0187497\tbest: 1.0187497 (1324)\ttotal: 13.2s\tremaining: 1m 26s\n",
      "1325:\tlearn: 0.9919018\ttest: 1.0187551\tbest: 1.0187497 (1324)\ttotal: 13.2s\tremaining: 1m 26s\n",
      "1326:\tlearn: 0.9918826\ttest: 1.0187531\tbest: 1.0187497 (1324)\ttotal: 13.2s\tremaining: 1m 26s\n",
      "1327:\tlearn: 0.9918627\ttest: 1.0187441\tbest: 1.0187441 (1327)\ttotal: 13.2s\tremaining: 1m 26s\n",
      "1328:\tlearn: 0.9918441\ttest: 1.0187471\tbest: 1.0187441 (1327)\ttotal: 13.2s\tremaining: 1m 26s\n",
      "1329:\tlearn: 0.9918207\ttest: 1.0187345\tbest: 1.0187345 (1329)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "1330:\tlearn: 0.9918051\ttest: 1.0187242\tbest: 1.0187242 (1330)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "1331:\tlearn: 0.9917878\ttest: 1.0187270\tbest: 1.0187242 (1330)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "1332:\tlearn: 0.9917662\ttest: 1.0187222\tbest: 1.0187222 (1332)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "1333:\tlearn: 0.9917469\ttest: 1.0187234\tbest: 1.0187222 (1332)\ttotal: 13.3s\tremaining: 1m 26s\n",
      "1334:\tlearn: 0.9917302\ttest: 1.0187152\tbest: 1.0187152 (1334)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1335:\tlearn: 0.9917101\ttest: 1.0187137\tbest: 1.0187137 (1335)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1336:\tlearn: 0.9916905\ttest: 1.0187021\tbest: 1.0187021 (1336)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1337:\tlearn: 0.9916724\ttest: 1.0187009\tbest: 1.0187009 (1337)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1338:\tlearn: 0.9916522\ttest: 1.0187068\tbest: 1.0187009 (1337)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1339:\tlearn: 0.9916369\ttest: 1.0187029\tbest: 1.0187009 (1337)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1340:\tlearn: 0.9916196\ttest: 1.0187041\tbest: 1.0187009 (1337)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1341:\tlearn: 0.9915998\ttest: 1.0187070\tbest: 1.0187009 (1337)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1342:\tlearn: 0.9915834\ttest: 1.0186966\tbest: 1.0186966 (1342)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1343:\tlearn: 0.9915661\ttest: 1.0186880\tbest: 1.0186880 (1343)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1344:\tlearn: 0.9915561\ttest: 1.0186883\tbest: 1.0186880 (1343)\ttotal: 13.4s\tremaining: 1m 26s\n",
      "1345:\tlearn: 0.9915266\ttest: 1.0186892\tbest: 1.0186880 (1343)\ttotal: 13.5s\tremaining: 1m 26s\n",
      "1346:\tlearn: 0.9915018\ttest: 1.0186870\tbest: 1.0186870 (1346)\ttotal: 13.5s\tremaining: 1m 26s\n",
      "1347:\tlearn: 0.9914857\ttest: 1.0186755\tbest: 1.0186755 (1347)\ttotal: 13.5s\tremaining: 1m 26s\n",
      "1348:\tlearn: 0.9914656\ttest: 1.0186790\tbest: 1.0186755 (1347)\ttotal: 13.5s\tremaining: 1m 26s\n",
      "1349:\tlearn: 0.9914438\ttest: 1.0186682\tbest: 1.0186682 (1349)\ttotal: 13.5s\tremaining: 1m 26s\n",
      "1350:\tlearn: 0.9914167\ttest: 1.0186674\tbest: 1.0186674 (1350)\ttotal: 13.5s\tremaining: 1m 26s\n",
      "1351:\tlearn: 0.9913998\ttest: 1.0186603\tbest: 1.0186603 (1351)\ttotal: 13.5s\tremaining: 1m 26s\n",
      "1352:\tlearn: 0.9913804\ttest: 1.0186704\tbest: 1.0186603 (1351)\ttotal: 13.5s\tremaining: 1m 26s\n",
      "1353:\tlearn: 0.9913592\ttest: 1.0186824\tbest: 1.0186603 (1351)\ttotal: 13.5s\tremaining: 1m 26s\n",
      "1354:\tlearn: 0.9913403\ttest: 1.0186852\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1355:\tlearn: 0.9913160\ttest: 1.0186812\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1356:\tlearn: 0.9913003\ttest: 1.0186768\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1357:\tlearn: 0.9912908\ttest: 1.0186743\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1358:\tlearn: 0.9912625\ttest: 1.0186720\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1359:\tlearn: 0.9912475\ttest: 1.0186700\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1360:\tlearn: 0.9912300\ttest: 1.0186694\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1361:\tlearn: 0.9912065\ttest: 1.0186743\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1362:\tlearn: 0.9911881\ttest: 1.0186715\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1363:\tlearn: 0.9911714\ttest: 1.0186639\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1364:\tlearn: 0.9911458\ttest: 1.0186665\tbest: 1.0186603 (1351)\ttotal: 13.6s\tremaining: 1m 26s\n",
      "1365:\tlearn: 0.9911152\ttest: 1.0186714\tbest: 1.0186603 (1351)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "1366:\tlearn: 0.9910974\ttest: 1.0186618\tbest: 1.0186603 (1351)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "1367:\tlearn: 0.9910780\ttest: 1.0186576\tbest: 1.0186576 (1367)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "1368:\tlearn: 0.9910593\ttest: 1.0186587\tbest: 1.0186576 (1367)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "1369:\tlearn: 0.9910395\ttest: 1.0186594\tbest: 1.0186576 (1367)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "1370:\tlearn: 0.9910203\ttest: 1.0186589\tbest: 1.0186576 (1367)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "1371:\tlearn: 0.9910036\ttest: 1.0186564\tbest: 1.0186564 (1371)\ttotal: 13.7s\tremaining: 1m 26s\n",
      "1372:\tlearn: 0.9909845\ttest: 1.0186506\tbest: 1.0186506 (1372)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1373:\tlearn: 0.9909666\ttest: 1.0186444\tbest: 1.0186444 (1373)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1374:\tlearn: 0.9909521\ttest: 1.0186436\tbest: 1.0186436 (1374)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1375:\tlearn: 0.9909244\ttest: 1.0186459\tbest: 1.0186436 (1374)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1376:\tlearn: 0.9909085\ttest: 1.0186462\tbest: 1.0186436 (1374)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1377:\tlearn: 0.9908930\ttest: 1.0186497\tbest: 1.0186436 (1374)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1378:\tlearn: 0.9908686\ttest: 1.0186549\tbest: 1.0186436 (1374)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1379:\tlearn: 0.9908486\ttest: 1.0186494\tbest: 1.0186436 (1374)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1380:\tlearn: 0.9908219\ttest: 1.0186549\tbest: 1.0186436 (1374)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1381:\tlearn: 0.9908049\ttest: 1.0186633\tbest: 1.0186436 (1374)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1382:\tlearn: 0.9907937\ttest: 1.0186570\tbest: 1.0186436 (1374)\ttotal: 13.8s\tremaining: 1m 26s\n",
      "1383:\tlearn: 0.9907722\ttest: 1.0186602\tbest: 1.0186436 (1374)\ttotal: 13.9s\tremaining: 1m 26s\n",
      "1384:\tlearn: 0.9907499\ttest: 1.0186590\tbest: 1.0186436 (1374)\ttotal: 13.9s\tremaining: 1m 26s\n",
      "1385:\tlearn: 0.9907271\ttest: 1.0186500\tbest: 1.0186436 (1374)\ttotal: 13.9s\tremaining: 1m 26s\n",
      "1386:\tlearn: 0.9907069\ttest: 1.0186433\tbest: 1.0186433 (1386)\ttotal: 13.9s\tremaining: 1m 26s\n",
      "1387:\tlearn: 0.9906897\ttest: 1.0186403\tbest: 1.0186403 (1387)\ttotal: 13.9s\tremaining: 1m 26s\n",
      "1388:\tlearn: 0.9906644\ttest: 1.0186513\tbest: 1.0186403 (1387)\ttotal: 13.9s\tremaining: 1m 26s\n",
      "1389:\tlearn: 0.9906373\ttest: 1.0186475\tbest: 1.0186403 (1387)\ttotal: 13.9s\tremaining: 1m 26s\n",
      "1390:\tlearn: 0.9906193\ttest: 1.0186332\tbest: 1.0186332 (1390)\ttotal: 13.9s\tremaining: 1m 26s\n",
      "1391:\tlearn: 0.9905928\ttest: 1.0186342\tbest: 1.0186332 (1390)\ttotal: 13.9s\tremaining: 1m 26s\n",
      "1392:\tlearn: 0.9905756\ttest: 1.0186374\tbest: 1.0186332 (1390)\ttotal: 14s\tremaining: 1m 26s\n",
      "1393:\tlearn: 0.9905529\ttest: 1.0186414\tbest: 1.0186332 (1390)\ttotal: 14s\tremaining: 1m 26s\n",
      "1394:\tlearn: 0.9905283\ttest: 1.0186451\tbest: 1.0186332 (1390)\ttotal: 14s\tremaining: 1m 26s\n",
      "1395:\tlearn: 0.9905066\ttest: 1.0186455\tbest: 1.0186332 (1390)\ttotal: 14s\tremaining: 1m 26s\n",
      "1396:\tlearn: 0.9904888\ttest: 1.0186397\tbest: 1.0186332 (1390)\ttotal: 14s\tremaining: 1m 26s\n",
      "1397:\tlearn: 0.9904692\ttest: 1.0186445\tbest: 1.0186332 (1390)\ttotal: 14s\tremaining: 1m 26s\n",
      "1398:\tlearn: 0.9904527\ttest: 1.0186353\tbest: 1.0186332 (1390)\ttotal: 14s\tremaining: 1m 26s\n",
      "1399:\tlearn: 0.9904267\ttest: 1.0186320\tbest: 1.0186320 (1399)\ttotal: 14s\tremaining: 1m 26s\n",
      "1400:\tlearn: 0.9903991\ttest: 1.0186268\tbest: 1.0186268 (1400)\ttotal: 14s\tremaining: 1m 26s\n",
      "1401:\tlearn: 0.9903823\ttest: 1.0186267\tbest: 1.0186267 (1401)\ttotal: 14s\tremaining: 1m 26s\n",
      "1402:\tlearn: 0.9903677\ttest: 1.0186325\tbest: 1.0186267 (1401)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1403:\tlearn: 0.9903472\ttest: 1.0186294\tbest: 1.0186267 (1401)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1404:\tlearn: 0.9903293\ttest: 1.0186326\tbest: 1.0186267 (1401)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1405:\tlearn: 0.9903157\ttest: 1.0186329\tbest: 1.0186267 (1401)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1406:\tlearn: 0.9902956\ttest: 1.0186245\tbest: 1.0186245 (1406)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1407:\tlearn: 0.9902772\ttest: 1.0186348\tbest: 1.0186245 (1406)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1408:\tlearn: 0.9902613\ttest: 1.0186437\tbest: 1.0186245 (1406)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1409:\tlearn: 0.9902440\ttest: 1.0186415\tbest: 1.0186245 (1406)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1410:\tlearn: 0.9902201\ttest: 1.0186293\tbest: 1.0186245 (1406)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1411:\tlearn: 0.9901969\ttest: 1.0186380\tbest: 1.0186245 (1406)\ttotal: 14.1s\tremaining: 1m 26s\n",
      "1412:\tlearn: 0.9901761\ttest: 1.0186374\tbest: 1.0186245 (1406)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1413:\tlearn: 0.9901575\ttest: 1.0186345\tbest: 1.0186245 (1406)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1414:\tlearn: 0.9901398\ttest: 1.0186277\tbest: 1.0186245 (1406)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1415:\tlearn: 0.9901160\ttest: 1.0186139\tbest: 1.0186139 (1415)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1416:\tlearn: 0.9900986\ttest: 1.0186158\tbest: 1.0186139 (1415)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1417:\tlearn: 0.9900777\ttest: 1.0186167\tbest: 1.0186139 (1415)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1418:\tlearn: 0.9900554\ttest: 1.0186167\tbest: 1.0186139 (1415)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1419:\tlearn: 0.9900317\ttest: 1.0186253\tbest: 1.0186139 (1415)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1420:\tlearn: 0.9900102\ttest: 1.0186220\tbest: 1.0186139 (1415)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1421:\tlearn: 0.9899865\ttest: 1.0186236\tbest: 1.0186139 (1415)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1422:\tlearn: 0.9899715\ttest: 1.0186337\tbest: 1.0186139 (1415)\ttotal: 14.2s\tremaining: 1m 25s\n",
      "1423:\tlearn: 0.9899470\ttest: 1.0186277\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1424:\tlearn: 0.9899306\ttest: 1.0186277\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1425:\tlearn: 0.9899161\ttest: 1.0186241\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1426:\tlearn: 0.9898948\ttest: 1.0186222\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1427:\tlearn: 0.9898766\ttest: 1.0186203\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1428:\tlearn: 0.9898564\ttest: 1.0186261\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1429:\tlearn: 0.9898406\ttest: 1.0186280\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1430:\tlearn: 0.9898236\ttest: 1.0186269\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1431:\tlearn: 0.9898099\ttest: 1.0186272\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1432:\tlearn: 0.9897931\ttest: 1.0186296\tbest: 1.0186139 (1415)\ttotal: 14.3s\tremaining: 1m 25s\n",
      "1433:\tlearn: 0.9897777\ttest: 1.0186248\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1434:\tlearn: 0.9897606\ttest: 1.0186242\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1435:\tlearn: 0.9897450\ttest: 1.0186150\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1436:\tlearn: 0.9897167\ttest: 1.0186165\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1437:\tlearn: 0.9896962\ttest: 1.0186284\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1438:\tlearn: 0.9896768\ttest: 1.0186445\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1439:\tlearn: 0.9896538\ttest: 1.0186501\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1440:\tlearn: 0.9896307\ttest: 1.0186401\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1441:\tlearn: 0.9896036\ttest: 1.0186357\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1442:\tlearn: 0.9895836\ttest: 1.0186411\tbest: 1.0186139 (1415)\ttotal: 14.4s\tremaining: 1m 25s\n",
      "1443:\tlearn: 0.9895656\ttest: 1.0186417\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1444:\tlearn: 0.9895494\ttest: 1.0186484\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1445:\tlearn: 0.9895354\ttest: 1.0186494\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1446:\tlearn: 0.9895206\ttest: 1.0186482\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1447:\tlearn: 0.9894909\ttest: 1.0186474\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1448:\tlearn: 0.9894777\ttest: 1.0186432\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1449:\tlearn: 0.9894603\ttest: 1.0186430\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1450:\tlearn: 0.9894502\ttest: 1.0186396\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1451:\tlearn: 0.9894343\ttest: 1.0186369\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1452:\tlearn: 0.9894206\ttest: 1.0186324\tbest: 1.0186139 (1415)\ttotal: 14.5s\tremaining: 1m 25s\n",
      "1453:\tlearn: 0.9894022\ttest: 1.0186332\tbest: 1.0186139 (1415)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "1454:\tlearn: 0.9893875\ttest: 1.0186287\tbest: 1.0186139 (1415)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "1455:\tlearn: 0.9893645\ttest: 1.0186263\tbest: 1.0186139 (1415)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "1456:\tlearn: 0.9893460\ttest: 1.0186235\tbest: 1.0186139 (1415)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "1457:\tlearn: 0.9893262\ttest: 1.0186158\tbest: 1.0186139 (1415)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "1458:\tlearn: 0.9893052\ttest: 1.0186264\tbest: 1.0186139 (1415)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "1459:\tlearn: 0.9892774\ttest: 1.0186298\tbest: 1.0186139 (1415)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "1460:\tlearn: 0.9892522\ttest: 1.0186310\tbest: 1.0186139 (1415)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "1461:\tlearn: 0.9892407\ttest: 1.0186238\tbest: 1.0186139 (1415)\ttotal: 14.6s\tremaining: 1m 25s\n",
      "1462:\tlearn: 0.9892171\ttest: 1.0186318\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1463:\tlearn: 0.9892029\ttest: 1.0186367\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1464:\tlearn: 0.9891835\ttest: 1.0186392\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1465:\tlearn: 0.9891602\ttest: 1.0186372\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1466:\tlearn: 0.9891391\ttest: 1.0186329\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1467:\tlearn: 0.9891298\ttest: 1.0186316\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1468:\tlearn: 0.9891035\ttest: 1.0186270\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1469:\tlearn: 0.9890842\ttest: 1.0186187\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1470:\tlearn: 0.9890700\ttest: 1.0186286\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1471:\tlearn: 0.9890507\ttest: 1.0186298\tbest: 1.0186139 (1415)\ttotal: 14.7s\tremaining: 1m 25s\n",
      "1472:\tlearn: 0.9890311\ttest: 1.0186342\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1473:\tlearn: 0.9890154\ttest: 1.0186267\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1474:\tlearn: 0.9889930\ttest: 1.0186246\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1475:\tlearn: 0.9889742\ttest: 1.0186226\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1476:\tlearn: 0.9889591\ttest: 1.0186281\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1477:\tlearn: 0.9889464\ttest: 1.0186197\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1478:\tlearn: 0.9889288\ttest: 1.0186150\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1479:\tlearn: 0.9889090\ttest: 1.0186198\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1480:\tlearn: 0.9888906\ttest: 1.0186158\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1481:\tlearn: 0.9888712\ttest: 1.0186174\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1482:\tlearn: 0.9888503\ttest: 1.0186232\tbest: 1.0186139 (1415)\ttotal: 14.8s\tremaining: 1m 25s\n",
      "1483:\tlearn: 0.9888263\ttest: 1.0186235\tbest: 1.0186139 (1415)\ttotal: 14.9s\tremaining: 1m 25s\n",
      "1484:\tlearn: 0.9888126\ttest: 1.0186324\tbest: 1.0186139 (1415)\ttotal: 14.9s\tremaining: 1m 25s\n",
      "1485:\tlearn: 0.9888039\ttest: 1.0186325\tbest: 1.0186139 (1415)\ttotal: 14.9s\tremaining: 1m 25s\n",
      "1486:\tlearn: 0.9887846\ttest: 1.0186282\tbest: 1.0186139 (1415)\ttotal: 14.9s\tremaining: 1m 25s\n",
      "1487:\tlearn: 0.9887637\ttest: 1.0186273\tbest: 1.0186139 (1415)\ttotal: 14.9s\tremaining: 1m 25s\n",
      "1488:\tlearn: 0.9887468\ttest: 1.0186344\tbest: 1.0186139 (1415)\ttotal: 14.9s\tremaining: 1m 25s\n",
      "1489:\tlearn: 0.9887283\ttest: 1.0186440\tbest: 1.0186139 (1415)\ttotal: 14.9s\tremaining: 1m 25s\n",
      "1490:\tlearn: 0.9887109\ttest: 1.0186352\tbest: 1.0186139 (1415)\ttotal: 14.9s\tremaining: 1m 25s\n",
      "1491:\tlearn: 0.9887000\ttest: 1.0186320\tbest: 1.0186139 (1415)\ttotal: 14.9s\tremaining: 1m 25s\n",
      "1492:\tlearn: 0.9886812\ttest: 1.0186239\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1493:\tlearn: 0.9886666\ttest: 1.0186266\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1494:\tlearn: 0.9886461\ttest: 1.0186249\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1495:\tlearn: 0.9886270\ttest: 1.0186283\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1496:\tlearn: 0.9886107\ttest: 1.0186242\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1497:\tlearn: 0.9885756\ttest: 1.0186205\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1498:\tlearn: 0.9885494\ttest: 1.0186246\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1499:\tlearn: 0.9885363\ttest: 1.0186309\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1500:\tlearn: 0.9885190\ttest: 1.0186405\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1501:\tlearn: 0.9885076\ttest: 1.0186368\tbest: 1.0186139 (1415)\ttotal: 15s\tremaining: 1m 25s\n",
      "1502:\tlearn: 0.9884810\ttest: 1.0186276\tbest: 1.0186139 (1415)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "1503:\tlearn: 0.9884554\ttest: 1.0186282\tbest: 1.0186139 (1415)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "1504:\tlearn: 0.9884334\ttest: 1.0186457\tbest: 1.0186139 (1415)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "1505:\tlearn: 0.9884125\ttest: 1.0186486\tbest: 1.0186139 (1415)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "1506:\tlearn: 0.9883908\ttest: 1.0186495\tbest: 1.0186139 (1415)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "1507:\tlearn: 0.9883734\ttest: 1.0186414\tbest: 1.0186139 (1415)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "1508:\tlearn: 0.9883514\ttest: 1.0186432\tbest: 1.0186139 (1415)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "1509:\tlearn: 0.9883231\ttest: 1.0186408\tbest: 1.0186139 (1415)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "1510:\tlearn: 0.9882980\ttest: 1.0186348\tbest: 1.0186139 (1415)\ttotal: 15.1s\tremaining: 1m 25s\n",
      "1511:\tlearn: 0.9882803\ttest: 1.0186263\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1512:\tlearn: 0.9882605\ttest: 1.0186226\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1513:\tlearn: 0.9882475\ttest: 1.0186173\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1514:\tlearn: 0.9882310\ttest: 1.0186195\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1515:\tlearn: 0.9882073\ttest: 1.0186181\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1516:\tlearn: 0.9881877\ttest: 1.0186197\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1517:\tlearn: 0.9881705\ttest: 1.0186266\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1518:\tlearn: 0.9881554\ttest: 1.0186204\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1519:\tlearn: 0.9881288\ttest: 1.0186232\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1520:\tlearn: 0.9881000\ttest: 1.0186168\tbest: 1.0186139 (1415)\ttotal: 15.2s\tremaining: 1m 25s\n",
      "1521:\tlearn: 0.9880859\ttest: 1.0186226\tbest: 1.0186139 (1415)\ttotal: 15.3s\tremaining: 1m 25s\n",
      "1522:\tlearn: 0.9880669\ttest: 1.0186201\tbest: 1.0186139 (1415)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "1523:\tlearn: 0.9880580\ttest: 1.0186163\tbest: 1.0186139 (1415)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "1524:\tlearn: 0.9880369\ttest: 1.0186150\tbest: 1.0186139 (1415)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "1525:\tlearn: 0.9880167\ttest: 1.0186200\tbest: 1.0186139 (1415)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "1526:\tlearn: 0.9880001\ttest: 1.0186202\tbest: 1.0186139 (1415)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "1527:\tlearn: 0.9879845\ttest: 1.0186299\tbest: 1.0186139 (1415)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "1528:\tlearn: 0.9879674\ttest: 1.0186278\tbest: 1.0186139 (1415)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "1529:\tlearn: 0.9879350\ttest: 1.0186304\tbest: 1.0186139 (1415)\ttotal: 15.3s\tremaining: 1m 24s\n",
      "1530:\tlearn: 0.9879157\ttest: 1.0186376\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1531:\tlearn: 0.9878936\ttest: 1.0186450\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1532:\tlearn: 0.9878735\ttest: 1.0186426\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1533:\tlearn: 0.9878574\ttest: 1.0186500\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1534:\tlearn: 0.9878356\ttest: 1.0186581\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1535:\tlearn: 0.9878153\ttest: 1.0186519\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1536:\tlearn: 0.9877958\ttest: 1.0186539\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1537:\tlearn: 0.9877786\ttest: 1.0186442\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1538:\tlearn: 0.9877610\ttest: 1.0186427\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1539:\tlearn: 0.9877486\ttest: 1.0186477\tbest: 1.0186139 (1415)\ttotal: 15.4s\tremaining: 1m 24s\n",
      "1540:\tlearn: 0.9877218\ttest: 1.0186473\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1541:\tlearn: 0.9877029\ttest: 1.0186529\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1542:\tlearn: 0.9876852\ttest: 1.0186611\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1543:\tlearn: 0.9876643\ttest: 1.0186640\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1544:\tlearn: 0.9876431\ttest: 1.0186613\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1545:\tlearn: 0.9876237\ttest: 1.0186582\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1546:\tlearn: 0.9876055\ttest: 1.0186610\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1547:\tlearn: 0.9875876\ttest: 1.0186744\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1548:\tlearn: 0.9875722\ttest: 1.0186698\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1549:\tlearn: 0.9875573\ttest: 1.0186716\tbest: 1.0186139 (1415)\ttotal: 15.5s\tremaining: 1m 24s\n",
      "1550:\tlearn: 0.9875360\ttest: 1.0186670\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1551:\tlearn: 0.9875192\ttest: 1.0186664\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1552:\tlearn: 0.9874953\ttest: 1.0186624\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1553:\tlearn: 0.9874770\ttest: 1.0186548\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1554:\tlearn: 0.9874574\ttest: 1.0186653\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1555:\tlearn: 0.9874317\ttest: 1.0186630\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1556:\tlearn: 0.9874164\ttest: 1.0186563\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1557:\tlearn: 0.9873948\ttest: 1.0186615\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1558:\tlearn: 0.9873756\ttest: 1.0186580\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1559:\tlearn: 0.9873535\ttest: 1.0186600\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1560:\tlearn: 0.9873398\ttest: 1.0186682\tbest: 1.0186139 (1415)\ttotal: 15.6s\tremaining: 1m 24s\n",
      "1561:\tlearn: 0.9873126\ttest: 1.0186654\tbest: 1.0186139 (1415)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "1562:\tlearn: 0.9872984\ttest: 1.0186678\tbest: 1.0186139 (1415)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "1563:\tlearn: 0.9872756\ttest: 1.0186660\tbest: 1.0186139 (1415)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "1564:\tlearn: 0.9872571\ttest: 1.0186675\tbest: 1.0186139 (1415)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "1565:\tlearn: 0.9872309\ttest: 1.0186677\tbest: 1.0186139 (1415)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "1566:\tlearn: 0.9872120\ttest: 1.0186678\tbest: 1.0186139 (1415)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "1567:\tlearn: 0.9871840\ttest: 1.0186751\tbest: 1.0186139 (1415)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "1568:\tlearn: 0.9871672\ttest: 1.0186881\tbest: 1.0186139 (1415)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "1569:\tlearn: 0.9871436\ttest: 1.0186885\tbest: 1.0186139 (1415)\ttotal: 15.7s\tremaining: 1m 24s\n",
      "1570:\tlearn: 0.9871215\ttest: 1.0186911\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1571:\tlearn: 0.9870949\ttest: 1.0186976\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1572:\tlearn: 0.9870714\ttest: 1.0186941\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1573:\tlearn: 0.9870575\ttest: 1.0186887\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1574:\tlearn: 0.9870411\ttest: 1.0186836\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1575:\tlearn: 0.9870260\ttest: 1.0186881\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1576:\tlearn: 0.9870126\ttest: 1.0186788\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1577:\tlearn: 0.9869879\ttest: 1.0186691\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1578:\tlearn: 0.9869717\ttest: 1.0186666\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1579:\tlearn: 0.9869536\ttest: 1.0186691\tbest: 1.0186139 (1415)\ttotal: 15.8s\tremaining: 1m 24s\n",
      "1580:\tlearn: 0.9869345\ttest: 1.0186831\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1581:\tlearn: 0.9869191\ttest: 1.0186821\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1582:\tlearn: 0.9868935\ttest: 1.0186791\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1583:\tlearn: 0.9868744\ttest: 1.0186770\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1584:\tlearn: 0.9868569\ttest: 1.0186896\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1585:\tlearn: 0.9868315\ttest: 1.0186886\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1586:\tlearn: 0.9867992\ttest: 1.0186885\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1587:\tlearn: 0.9867797\ttest: 1.0186876\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1588:\tlearn: 0.9867600\ttest: 1.0186823\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1589:\tlearn: 0.9867401\ttest: 1.0186919\tbest: 1.0186139 (1415)\ttotal: 15.9s\tremaining: 1m 24s\n",
      "1590:\tlearn: 0.9867259\ttest: 1.0186937\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1591:\tlearn: 0.9867091\ttest: 1.0186821\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1592:\tlearn: 0.9866907\ttest: 1.0186877\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1593:\tlearn: 0.9866736\ttest: 1.0186861\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1594:\tlearn: 0.9866540\ttest: 1.0186892\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1595:\tlearn: 0.9866331\ttest: 1.0186949\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1596:\tlearn: 0.9866106\ttest: 1.0187035\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1597:\tlearn: 0.9865838\ttest: 1.0187050\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1598:\tlearn: 0.9865667\ttest: 1.0187017\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1599:\tlearn: 0.9865469\ttest: 1.0187108\tbest: 1.0186139 (1415)\ttotal: 16s\tremaining: 1m 24s\n",
      "1600:\tlearn: 0.9865248\ttest: 1.0187104\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1601:\tlearn: 0.9865043\ttest: 1.0187037\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1602:\tlearn: 0.9864846\ttest: 1.0186902\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1603:\tlearn: 0.9864677\ttest: 1.0186802\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1604:\tlearn: 0.9864408\ttest: 1.0186734\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1605:\tlearn: 0.9864270\ttest: 1.0186703\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1606:\tlearn: 0.9864078\ttest: 1.0186604\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1607:\tlearn: 0.9863867\ttest: 1.0186574\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1608:\tlearn: 0.9863705\ttest: 1.0186487\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1609:\tlearn: 0.9863383\ttest: 1.0186453\tbest: 1.0186139 (1415)\ttotal: 16.1s\tremaining: 1m 24s\n",
      "1610:\tlearn: 0.9863148\ttest: 1.0186506\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1611:\tlearn: 0.9862980\ttest: 1.0186506\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1612:\tlearn: 0.9862764\ttest: 1.0186459\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1613:\tlearn: 0.9862622\ttest: 1.0186442\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1614:\tlearn: 0.9862486\ttest: 1.0186484\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1615:\tlearn: 0.9862250\ttest: 1.0186444\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1616:\tlearn: 0.9862064\ttest: 1.0186380\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1617:\tlearn: 0.9861969\ttest: 1.0186425\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1618:\tlearn: 0.9861711\ttest: 1.0186434\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1619:\tlearn: 0.9861555\ttest: 1.0186408\tbest: 1.0186139 (1415)\ttotal: 16.2s\tremaining: 1m 24s\n",
      "1620:\tlearn: 0.9861374\ttest: 1.0186346\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 24s\n",
      "1621:\tlearn: 0.9861137\ttest: 1.0186354\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1622:\tlearn: 0.9860851\ttest: 1.0186307\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1623:\tlearn: 0.9860693\ttest: 1.0186360\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1624:\tlearn: 0.9860502\ttest: 1.0186491\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1625:\tlearn: 0.9860263\ttest: 1.0186426\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1626:\tlearn: 0.9860109\ttest: 1.0186426\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1627:\tlearn: 0.9859969\ttest: 1.0186495\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1628:\tlearn: 0.9859752\ttest: 1.0186493\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1629:\tlearn: 0.9859542\ttest: 1.0186512\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1630:\tlearn: 0.9859356\ttest: 1.0186430\tbest: 1.0186139 (1415)\ttotal: 16.3s\tremaining: 1m 23s\n",
      "1631:\tlearn: 0.9859133\ttest: 1.0186487\tbest: 1.0186139 (1415)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "1632:\tlearn: 0.9859044\ttest: 1.0186511\tbest: 1.0186139 (1415)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "1633:\tlearn: 0.9858763\ttest: 1.0186517\tbest: 1.0186139 (1415)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "1634:\tlearn: 0.9858539\ttest: 1.0186611\tbest: 1.0186139 (1415)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "1635:\tlearn: 0.9858290\ttest: 1.0186637\tbest: 1.0186139 (1415)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "1636:\tlearn: 0.9858063\ttest: 1.0186786\tbest: 1.0186139 (1415)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "1637:\tlearn: 0.9857857\ttest: 1.0186730\tbest: 1.0186139 (1415)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "1638:\tlearn: 0.9857651\ttest: 1.0186717\tbest: 1.0186139 (1415)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "1639:\tlearn: 0.9857426\ttest: 1.0186687\tbest: 1.0186139 (1415)\ttotal: 16.4s\tremaining: 1m 23s\n",
      "1640:\tlearn: 0.9857240\ttest: 1.0186726\tbest: 1.0186139 (1415)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "1641:\tlearn: 0.9857022\ttest: 1.0186775\tbest: 1.0186139 (1415)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "1642:\tlearn: 0.9856860\ttest: 1.0186764\tbest: 1.0186139 (1415)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "1643:\tlearn: 0.9856625\ttest: 1.0186758\tbest: 1.0186139 (1415)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "1644:\tlearn: 0.9856485\ttest: 1.0186746\tbest: 1.0186139 (1415)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "1645:\tlearn: 0.9856261\ttest: 1.0186672\tbest: 1.0186139 (1415)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "1646:\tlearn: 0.9856055\ttest: 1.0186653\tbest: 1.0186139 (1415)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "1647:\tlearn: 0.9855869\ttest: 1.0186578\tbest: 1.0186139 (1415)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "1648:\tlearn: 0.9855680\ttest: 1.0186578\tbest: 1.0186139 (1415)\ttotal: 16.5s\tremaining: 1m 23s\n",
      "1649:\tlearn: 0.9855501\ttest: 1.0186540\tbest: 1.0186139 (1415)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "1650:\tlearn: 0.9855356\ttest: 1.0186603\tbest: 1.0186139 (1415)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "1651:\tlearn: 0.9855197\ttest: 1.0186698\tbest: 1.0186139 (1415)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "1652:\tlearn: 0.9855007\ttest: 1.0186705\tbest: 1.0186139 (1415)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "1653:\tlearn: 0.9854834\ttest: 1.0186760\tbest: 1.0186139 (1415)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "1654:\tlearn: 0.9854650\ttest: 1.0186749\tbest: 1.0186139 (1415)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "1655:\tlearn: 0.9854513\ttest: 1.0186736\tbest: 1.0186139 (1415)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "1656:\tlearn: 0.9854311\ttest: 1.0186676\tbest: 1.0186139 (1415)\ttotal: 16.6s\tremaining: 1m 23s\n",
      "1657:\tlearn: 0.9854091\ttest: 1.0186778\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1658:\tlearn: 0.9853951\ttest: 1.0186778\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1659:\tlearn: 0.9853741\ttest: 1.0186763\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1660:\tlearn: 0.9853503\ttest: 1.0186734\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1661:\tlearn: 0.9853333\ttest: 1.0186769\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1662:\tlearn: 0.9853159\ttest: 1.0186699\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1663:\tlearn: 0.9853005\ttest: 1.0186731\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1664:\tlearn: 0.9852862\ttest: 1.0186658\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1665:\tlearn: 0.9852699\ttest: 1.0186680\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1666:\tlearn: 0.9852524\ttest: 1.0186697\tbest: 1.0186139 (1415)\ttotal: 16.7s\tremaining: 1m 23s\n",
      "1667:\tlearn: 0.9852324\ttest: 1.0186601\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1668:\tlearn: 0.9852195\ttest: 1.0186512\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1669:\tlearn: 0.9852040\ttest: 1.0186481\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1670:\tlearn: 0.9851793\ttest: 1.0186420\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1671:\tlearn: 0.9851640\ttest: 1.0186472\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1672:\tlearn: 0.9851446\ttest: 1.0186461\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1673:\tlearn: 0.9851263\ttest: 1.0186511\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1674:\tlearn: 0.9851091\ttest: 1.0186447\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1675:\tlearn: 0.9850904\ttest: 1.0186457\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1676:\tlearn: 0.9850709\ttest: 1.0186352\tbest: 1.0186139 (1415)\ttotal: 16.8s\tremaining: 1m 23s\n",
      "1677:\tlearn: 0.9850477\ttest: 1.0186224\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1678:\tlearn: 0.9850316\ttest: 1.0186199\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1679:\tlearn: 0.9850212\ttest: 1.0186211\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1680:\tlearn: 0.9850077\ttest: 1.0186229\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1681:\tlearn: 0.9849849\ttest: 1.0186341\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1682:\tlearn: 0.9849661\ttest: 1.0186316\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1683:\tlearn: 0.9849429\ttest: 1.0186335\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1684:\tlearn: 0.9849194\ttest: 1.0186376\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1685:\tlearn: 0.9848980\ttest: 1.0186342\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1686:\tlearn: 0.9848811\ttest: 1.0186305\tbest: 1.0186139 (1415)\ttotal: 16.9s\tremaining: 1m 23s\n",
      "1687:\tlearn: 0.9848644\ttest: 1.0186238\tbest: 1.0186139 (1415)\ttotal: 17s\tremaining: 1m 23s\n",
      "1688:\tlearn: 0.9848492\ttest: 1.0186254\tbest: 1.0186139 (1415)\ttotal: 17s\tremaining: 1m 23s\n",
      "1689:\tlearn: 0.9848188\ttest: 1.0186195\tbest: 1.0186139 (1415)\ttotal: 17s\tremaining: 1m 23s\n",
      "1690:\tlearn: 0.9848080\ttest: 1.0186152\tbest: 1.0186139 (1415)\ttotal: 17s\tremaining: 1m 23s\n",
      "1691:\tlearn: 0.9847913\ttest: 1.0186154\tbest: 1.0186139 (1415)\ttotal: 17s\tremaining: 1m 23s\n",
      "1692:\tlearn: 0.9847724\ttest: 1.0186115\tbest: 1.0186115 (1692)\ttotal: 17s\tremaining: 1m 23s\n",
      "1693:\tlearn: 0.9847463\ttest: 1.0186113\tbest: 1.0186113 (1693)\ttotal: 17s\tremaining: 1m 23s\n",
      "1694:\tlearn: 0.9847279\ttest: 1.0186040\tbest: 1.0186040 (1694)\ttotal: 17s\tremaining: 1m 23s\n",
      "1695:\tlearn: 0.9847116\ttest: 1.0185997\tbest: 1.0185997 (1695)\ttotal: 17s\tremaining: 1m 23s\n",
      "1696:\tlearn: 0.9846993\ttest: 1.0186010\tbest: 1.0185997 (1695)\ttotal: 17s\tremaining: 1m 23s\n",
      "1697:\tlearn: 0.9846795\ttest: 1.0185892\tbest: 1.0185892 (1697)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1698:\tlearn: 0.9846520\ttest: 1.0185890\tbest: 1.0185890 (1698)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1699:\tlearn: 0.9846258\ttest: 1.0185992\tbest: 1.0185890 (1698)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1700:\tlearn: 0.9846010\ttest: 1.0185927\tbest: 1.0185890 (1698)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1701:\tlearn: 0.9845720\ttest: 1.0185941\tbest: 1.0185890 (1698)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1702:\tlearn: 0.9845550\ttest: 1.0185975\tbest: 1.0185890 (1698)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1703:\tlearn: 0.9845355\ttest: 1.0186026\tbest: 1.0185890 (1698)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1704:\tlearn: 0.9845189\ttest: 1.0185972\tbest: 1.0185890 (1698)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1705:\tlearn: 0.9844953\ttest: 1.0186003\tbest: 1.0185890 (1698)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1706:\tlearn: 0.9844762\ttest: 1.0185983\tbest: 1.0185890 (1698)\ttotal: 17.1s\tremaining: 1m 23s\n",
      "1707:\tlearn: 0.9844532\ttest: 1.0185854\tbest: 1.0185854 (1707)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1708:\tlearn: 0.9844365\ttest: 1.0185863\tbest: 1.0185854 (1707)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1709:\tlearn: 0.9844173\ttest: 1.0185873\tbest: 1.0185854 (1707)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1710:\tlearn: 0.9843939\ttest: 1.0185874\tbest: 1.0185854 (1707)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1711:\tlearn: 0.9843766\ttest: 1.0185884\tbest: 1.0185854 (1707)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1712:\tlearn: 0.9843603\ttest: 1.0185884\tbest: 1.0185854 (1707)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1713:\tlearn: 0.9843368\ttest: 1.0185813\tbest: 1.0185813 (1713)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1714:\tlearn: 0.9843175\ttest: 1.0185827\tbest: 1.0185813 (1713)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1715:\tlearn: 0.9842951\ttest: 1.0185934\tbest: 1.0185813 (1713)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1716:\tlearn: 0.9842747\ttest: 1.0185861\tbest: 1.0185813 (1713)\ttotal: 17.2s\tremaining: 1m 23s\n",
      "1717:\tlearn: 0.9842557\ttest: 1.0185775\tbest: 1.0185775 (1717)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1718:\tlearn: 0.9842367\ttest: 1.0185818\tbest: 1.0185775 (1717)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1719:\tlearn: 0.9842224\ttest: 1.0185795\tbest: 1.0185775 (1717)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1720:\tlearn: 0.9841955\ttest: 1.0185776\tbest: 1.0185775 (1717)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1721:\tlearn: 0.9841779\ttest: 1.0185765\tbest: 1.0185765 (1721)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1722:\tlearn: 0.9841522\ttest: 1.0185699\tbest: 1.0185699 (1722)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1723:\tlearn: 0.9841309\ttest: 1.0185686\tbest: 1.0185686 (1723)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1724:\tlearn: 0.9841160\ttest: 1.0185718\tbest: 1.0185686 (1723)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1725:\tlearn: 0.9840914\ttest: 1.0185625\tbest: 1.0185625 (1725)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1726:\tlearn: 0.9840690\ttest: 1.0185628\tbest: 1.0185625 (1725)\ttotal: 17.3s\tremaining: 1m 23s\n",
      "1727:\tlearn: 0.9840483\ttest: 1.0185695\tbest: 1.0185625 (1725)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "1728:\tlearn: 0.9840239\ttest: 1.0185722\tbest: 1.0185625 (1725)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "1729:\tlearn: 0.9840010\ttest: 1.0185736\tbest: 1.0185625 (1725)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "1730:\tlearn: 0.9839870\ttest: 1.0185706\tbest: 1.0185625 (1725)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "1731:\tlearn: 0.9839691\ttest: 1.0185637\tbest: 1.0185625 (1725)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "1732:\tlearn: 0.9839538\ttest: 1.0185661\tbest: 1.0185625 (1725)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "1733:\tlearn: 0.9839382\ttest: 1.0185677\tbest: 1.0185625 (1725)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "1734:\tlearn: 0.9839206\ttest: 1.0185615\tbest: 1.0185615 (1734)\ttotal: 17.4s\tremaining: 1m 23s\n",
      "1735:\tlearn: 0.9838980\ttest: 1.0185574\tbest: 1.0185574 (1735)\ttotal: 17.4s\tremaining: 1m 22s\n",
      "1736:\tlearn: 0.9838821\ttest: 1.0185568\tbest: 1.0185568 (1736)\ttotal: 17.4s\tremaining: 1m 22s\n",
      "1737:\tlearn: 0.9838558\ttest: 1.0185533\tbest: 1.0185533 (1737)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1738:\tlearn: 0.9838340\ttest: 1.0185482\tbest: 1.0185482 (1738)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1739:\tlearn: 0.9838201\ttest: 1.0185518\tbest: 1.0185482 (1738)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1740:\tlearn: 0.9837968\ttest: 1.0185600\tbest: 1.0185482 (1738)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1741:\tlearn: 0.9837796\ttest: 1.0185606\tbest: 1.0185482 (1738)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1742:\tlearn: 0.9837591\ttest: 1.0185504\tbest: 1.0185482 (1738)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1743:\tlearn: 0.9837373\ttest: 1.0185453\tbest: 1.0185453 (1743)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1744:\tlearn: 0.9837163\ttest: 1.0185548\tbest: 1.0185453 (1743)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1745:\tlearn: 0.9836950\ttest: 1.0185574\tbest: 1.0185453 (1743)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1746:\tlearn: 0.9836760\ttest: 1.0185625\tbest: 1.0185453 (1743)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1747:\tlearn: 0.9836606\ttest: 1.0185626\tbest: 1.0185453 (1743)\ttotal: 17.5s\tremaining: 1m 22s\n",
      "1748:\tlearn: 0.9836410\ttest: 1.0185646\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1749:\tlearn: 0.9836249\ttest: 1.0185553\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1750:\tlearn: 0.9836063\ttest: 1.0185594\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1751:\tlearn: 0.9835886\ttest: 1.0185618\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1752:\tlearn: 0.9835667\ttest: 1.0185606\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1753:\tlearn: 0.9835444\ttest: 1.0185591\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1754:\tlearn: 0.9835281\ttest: 1.0185685\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1755:\tlearn: 0.9835122\ttest: 1.0185650\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1756:\tlearn: 0.9834918\ttest: 1.0185522\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1757:\tlearn: 0.9834726\ttest: 1.0185537\tbest: 1.0185453 (1743)\ttotal: 17.6s\tremaining: 1m 22s\n",
      "1758:\tlearn: 0.9834429\ttest: 1.0185560\tbest: 1.0185453 (1743)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "1759:\tlearn: 0.9834271\ttest: 1.0185493\tbest: 1.0185453 (1743)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "1760:\tlearn: 0.9834086\ttest: 1.0185465\tbest: 1.0185453 (1743)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "1761:\tlearn: 0.9833937\ttest: 1.0185507\tbest: 1.0185453 (1743)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "1762:\tlearn: 0.9833746\ttest: 1.0185644\tbest: 1.0185453 (1743)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "1763:\tlearn: 0.9833535\ttest: 1.0185735\tbest: 1.0185453 (1743)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "1764:\tlearn: 0.9833386\ttest: 1.0185659\tbest: 1.0185453 (1743)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "1765:\tlearn: 0.9833192\ttest: 1.0185679\tbest: 1.0185453 (1743)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "1766:\tlearn: 0.9833048\ttest: 1.0185798\tbest: 1.0185453 (1743)\ttotal: 17.7s\tremaining: 1m 22s\n",
      "1767:\tlearn: 0.9832844\ttest: 1.0185749\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1768:\tlearn: 0.9832623\ttest: 1.0185771\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1769:\tlearn: 0.9832445\ttest: 1.0185700\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1770:\tlearn: 0.9832263\ttest: 1.0185655\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1771:\tlearn: 0.9832013\ttest: 1.0185673\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1772:\tlearn: 0.9831873\ttest: 1.0185607\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1773:\tlearn: 0.9831658\ttest: 1.0185606\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1774:\tlearn: 0.9831473\ttest: 1.0185697\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1775:\tlearn: 0.9831270\ttest: 1.0185753\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1776:\tlearn: 0.9831091\ttest: 1.0185706\tbest: 1.0185453 (1743)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "1777:\tlearn: 0.9830924\ttest: 1.0185725\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1778:\tlearn: 0.9830747\ttest: 1.0185723\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1779:\tlearn: 0.9830586\ttest: 1.0185826\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1780:\tlearn: 0.9830440\ttest: 1.0185800\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1781:\tlearn: 0.9830274\ttest: 1.0185766\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1782:\tlearn: 0.9830059\ttest: 1.0185761\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1783:\tlearn: 0.9829751\ttest: 1.0185717\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1784:\tlearn: 0.9829533\ttest: 1.0185578\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1785:\tlearn: 0.9829232\ttest: 1.0185557\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1786:\tlearn: 0.9829101\ttest: 1.0185581\tbest: 1.0185453 (1743)\ttotal: 17.9s\tremaining: 1m 22s\n",
      "1787:\tlearn: 0.9828924\ttest: 1.0185555\tbest: 1.0185453 (1743)\ttotal: 18s\tremaining: 1m 22s\n",
      "1788:\tlearn: 0.9828727\ttest: 1.0185656\tbest: 1.0185453 (1743)\ttotal: 18s\tremaining: 1m 22s\n",
      "1789:\tlearn: 0.9828541\ttest: 1.0185649\tbest: 1.0185453 (1743)\ttotal: 18s\tremaining: 1m 22s\n",
      "1790:\tlearn: 0.9828296\ttest: 1.0185710\tbest: 1.0185453 (1743)\ttotal: 18s\tremaining: 1m 22s\n",
      "1791:\tlearn: 0.9828073\ttest: 1.0185667\tbest: 1.0185453 (1743)\ttotal: 18s\tremaining: 1m 22s\n",
      "1792:\tlearn: 0.9827884\ttest: 1.0185573\tbest: 1.0185453 (1743)\ttotal: 18s\tremaining: 1m 22s\n",
      "1793:\tlearn: 0.9827688\ttest: 1.0185580\tbest: 1.0185453 (1743)\ttotal: 18s\tremaining: 1m 22s\n",
      "1794:\tlearn: 0.9827495\ttest: 1.0185560\tbest: 1.0185453 (1743)\ttotal: 18s\tremaining: 1m 22s\n",
      "1795:\tlearn: 0.9827296\ttest: 1.0185520\tbest: 1.0185453 (1743)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1796:\tlearn: 0.9827108\ttest: 1.0185466\tbest: 1.0185453 (1743)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1797:\tlearn: 0.9826919\ttest: 1.0185515\tbest: 1.0185453 (1743)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1798:\tlearn: 0.9826688\ttest: 1.0185495\tbest: 1.0185453 (1743)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1799:\tlearn: 0.9826502\ttest: 1.0185467\tbest: 1.0185453 (1743)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1800:\tlearn: 0.9826306\ttest: 1.0185411\tbest: 1.0185411 (1800)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1801:\tlearn: 0.9826034\ttest: 1.0185493\tbest: 1.0185411 (1800)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1802:\tlearn: 0.9825740\ttest: 1.0185477\tbest: 1.0185411 (1800)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1803:\tlearn: 0.9825498\ttest: 1.0185479\tbest: 1.0185411 (1800)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1804:\tlearn: 0.9825321\ttest: 1.0185421\tbest: 1.0185411 (1800)\ttotal: 18.1s\tremaining: 1m 22s\n",
      "1805:\tlearn: 0.9825145\ttest: 1.0185615\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1806:\tlearn: 0.9824908\ttest: 1.0185610\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1807:\tlearn: 0.9824760\ttest: 1.0185602\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1808:\tlearn: 0.9824616\ttest: 1.0185627\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1809:\tlearn: 0.9824365\ttest: 1.0185680\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1810:\tlearn: 0.9824195\ttest: 1.0185748\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1811:\tlearn: 0.9823967\ttest: 1.0185814\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1812:\tlearn: 0.9823705\ttest: 1.0185831\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1813:\tlearn: 0.9823538\ttest: 1.0185873\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1814:\tlearn: 0.9823301\ttest: 1.0185894\tbest: 1.0185411 (1800)\ttotal: 18.2s\tremaining: 1m 22s\n",
      "1815:\tlearn: 0.9823131\ttest: 1.0185986\tbest: 1.0185411 (1800)\ttotal: 18.3s\tremaining: 1m 22s\n",
      "1816:\tlearn: 0.9822861\ttest: 1.0185967\tbest: 1.0185411 (1800)\ttotal: 18.3s\tremaining: 1m 22s\n",
      "1817:\tlearn: 0.9822643\ttest: 1.0185980\tbest: 1.0185411 (1800)\ttotal: 18.3s\tremaining: 1m 22s\n",
      "1818:\tlearn: 0.9822443\ttest: 1.0185961\tbest: 1.0185411 (1800)\ttotal: 18.3s\tremaining: 1m 22s\n",
      "1819:\tlearn: 0.9822307\ttest: 1.0185948\tbest: 1.0185411 (1800)\ttotal: 18.3s\tremaining: 1m 22s\n",
      "1820:\tlearn: 0.9822142\ttest: 1.0185982\tbest: 1.0185411 (1800)\ttotal: 18.3s\tremaining: 1m 22s\n",
      "1821:\tlearn: 0.9821950\ttest: 1.0186006\tbest: 1.0185411 (1800)\ttotal: 18.3s\tremaining: 1m 22s\n",
      "1822:\tlearn: 0.9821669\ttest: 1.0186161\tbest: 1.0185411 (1800)\ttotal: 18.3s\tremaining: 1m 22s\n",
      "1823:\tlearn: 0.9821458\ttest: 1.0186030\tbest: 1.0185411 (1800)\ttotal: 18.3s\tremaining: 1m 22s\n",
      "1824:\tlearn: 0.9821266\ttest: 1.0186046\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1825:\tlearn: 0.9821025\ttest: 1.0186054\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1826:\tlearn: 0.9820849\ttest: 1.0186066\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1827:\tlearn: 0.9820642\ttest: 1.0185989\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1828:\tlearn: 0.9820468\ttest: 1.0186046\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1829:\tlearn: 0.9820259\ttest: 1.0186114\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1830:\tlearn: 0.9820012\ttest: 1.0186051\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1831:\tlearn: 0.9819751\ttest: 1.0186174\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1832:\tlearn: 0.9819512\ttest: 1.0186135\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1833:\tlearn: 0.9819297\ttest: 1.0186092\tbest: 1.0185411 (1800)\ttotal: 18.4s\tremaining: 1m 22s\n",
      "1834:\tlearn: 0.9819122\ttest: 1.0186095\tbest: 1.0185411 (1800)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "1835:\tlearn: 0.9818835\ttest: 1.0186172\tbest: 1.0185411 (1800)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "1836:\tlearn: 0.9818637\ttest: 1.0186145\tbest: 1.0185411 (1800)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "1837:\tlearn: 0.9818467\ttest: 1.0186198\tbest: 1.0185411 (1800)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "1838:\tlearn: 0.9818235\ttest: 1.0186204\tbest: 1.0185411 (1800)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "1839:\tlearn: 0.9818018\ttest: 1.0186108\tbest: 1.0185411 (1800)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "1840:\tlearn: 0.9817765\ttest: 1.0186220\tbest: 1.0185411 (1800)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "1841:\tlearn: 0.9817584\ttest: 1.0186249\tbest: 1.0185411 (1800)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "1842:\tlearn: 0.9817349\ttest: 1.0186223\tbest: 1.0185411 (1800)\ttotal: 18.5s\tremaining: 1m 22s\n",
      "1843:\tlearn: 0.9817069\ttest: 1.0186199\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 22s\n",
      "1844:\tlearn: 0.9816820\ttest: 1.0186244\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 22s\n",
      "1845:\tlearn: 0.9816584\ttest: 1.0186177\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 22s\n",
      "1846:\tlearn: 0.9816433\ttest: 1.0186181\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 22s\n",
      "1847:\tlearn: 0.9816231\ttest: 1.0186186\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 22s\n",
      "1848:\tlearn: 0.9816047\ttest: 1.0186222\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 22s\n",
      "1849:\tlearn: 0.9815873\ttest: 1.0186252\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 22s\n",
      "1850:\tlearn: 0.9815597\ttest: 1.0186224\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 22s\n",
      "1851:\tlearn: 0.9815427\ttest: 1.0186294\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 22s\n",
      "1852:\tlearn: 0.9815195\ttest: 1.0186296\tbest: 1.0185411 (1800)\ttotal: 18.6s\tremaining: 1m 21s\n",
      "1853:\tlearn: 0.9815012\ttest: 1.0186415\tbest: 1.0185411 (1800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "1854:\tlearn: 0.9814819\ttest: 1.0186497\tbest: 1.0185411 (1800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "1855:\tlearn: 0.9814635\ttest: 1.0186448\tbest: 1.0185411 (1800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "1856:\tlearn: 0.9814518\ttest: 1.0186477\tbest: 1.0185411 (1800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "1857:\tlearn: 0.9814334\ttest: 1.0186485\tbest: 1.0185411 (1800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "1858:\tlearn: 0.9814170\ttest: 1.0186456\tbest: 1.0185411 (1800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "1859:\tlearn: 0.9813967\ttest: 1.0186420\tbest: 1.0185411 (1800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "1860:\tlearn: 0.9813762\ttest: 1.0186408\tbest: 1.0185411 (1800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "1861:\tlearn: 0.9813544\ttest: 1.0186365\tbest: 1.0185411 (1800)\ttotal: 18.7s\tremaining: 1m 21s\n",
      "1862:\tlearn: 0.9813396\ttest: 1.0186329\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1863:\tlearn: 0.9813235\ttest: 1.0186303\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1864:\tlearn: 0.9813024\ttest: 1.0186242\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1865:\tlearn: 0.9812790\ttest: 1.0186403\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1866:\tlearn: 0.9812499\ttest: 1.0186403\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1867:\tlearn: 0.9812218\ttest: 1.0186380\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1868:\tlearn: 0.9812029\ttest: 1.0186395\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1869:\tlearn: 0.9811843\ttest: 1.0186470\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1870:\tlearn: 0.9811594\ttest: 1.0186387\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1871:\tlearn: 0.9811432\ttest: 1.0186405\tbest: 1.0185411 (1800)\ttotal: 18.8s\tremaining: 1m 21s\n",
      "1872:\tlearn: 0.9811189\ttest: 1.0186482\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1873:\tlearn: 0.9810967\ttest: 1.0186420\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1874:\tlearn: 0.9810802\ttest: 1.0186387\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1875:\tlearn: 0.9810544\ttest: 1.0186382\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1876:\tlearn: 0.9810394\ttest: 1.0186364\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1877:\tlearn: 0.9810180\ttest: 1.0186344\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1878:\tlearn: 0.9809981\ttest: 1.0186339\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1879:\tlearn: 0.9809811\ttest: 1.0186340\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1880:\tlearn: 0.9809609\ttest: 1.0186301\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1881:\tlearn: 0.9809396\ttest: 1.0186392\tbest: 1.0185411 (1800)\ttotal: 18.9s\tremaining: 1m 21s\n",
      "1882:\tlearn: 0.9809175\ttest: 1.0186305\tbest: 1.0185411 (1800)\ttotal: 19s\tremaining: 1m 21s\n",
      "1883:\tlearn: 0.9809045\ttest: 1.0186206\tbest: 1.0185411 (1800)\ttotal: 19s\tremaining: 1m 21s\n",
      "1884:\tlearn: 0.9808869\ttest: 1.0186128\tbest: 1.0185411 (1800)\ttotal: 19s\tremaining: 1m 21s\n",
      "1885:\tlearn: 0.9808674\ttest: 1.0186190\tbest: 1.0185411 (1800)\ttotal: 19s\tremaining: 1m 21s\n",
      "1886:\tlearn: 0.9808440\ttest: 1.0186087\tbest: 1.0185411 (1800)\ttotal: 19s\tremaining: 1m 21s\n",
      "1887:\tlearn: 0.9808258\ttest: 1.0186029\tbest: 1.0185411 (1800)\ttotal: 19s\tremaining: 1m 21s\n",
      "1888:\tlearn: 0.9808097\ttest: 1.0185963\tbest: 1.0185411 (1800)\ttotal: 19s\tremaining: 1m 21s\n",
      "1889:\tlearn: 0.9807911\ttest: 1.0186053\tbest: 1.0185411 (1800)\ttotal: 19s\tremaining: 1m 21s\n",
      "1890:\tlearn: 0.9807737\ttest: 1.0186066\tbest: 1.0185411 (1800)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "1891:\tlearn: 0.9807482\ttest: 1.0186003\tbest: 1.0185411 (1800)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "1892:\tlearn: 0.9807309\ttest: 1.0186025\tbest: 1.0185411 (1800)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "1893:\tlearn: 0.9806978\ttest: 1.0186020\tbest: 1.0185411 (1800)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "1894:\tlearn: 0.9806719\ttest: 1.0185917\tbest: 1.0185411 (1800)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "1895:\tlearn: 0.9806462\ttest: 1.0185986\tbest: 1.0185411 (1800)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "1896:\tlearn: 0.9806229\ttest: 1.0185871\tbest: 1.0185411 (1800)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "1897:\tlearn: 0.9806035\ttest: 1.0186007\tbest: 1.0185411 (1800)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "1898:\tlearn: 0.9805785\ttest: 1.0186006\tbest: 1.0185411 (1800)\ttotal: 19.1s\tremaining: 1m 21s\n",
      "1899:\tlearn: 0.9805637\ttest: 1.0186045\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1900:\tlearn: 0.9805336\ttest: 1.0186111\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1901:\tlearn: 0.9805166\ttest: 1.0186148\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1902:\tlearn: 0.9805004\ttest: 1.0186089\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1903:\tlearn: 0.9804840\ttest: 1.0186069\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1904:\tlearn: 0.9804674\ttest: 1.0186091\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1905:\tlearn: 0.9804418\ttest: 1.0186041\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1906:\tlearn: 0.9804243\ttest: 1.0186030\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1907:\tlearn: 0.9803999\ttest: 1.0186117\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1908:\tlearn: 0.9803810\ttest: 1.0186091\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1909:\tlearn: 0.9803624\ttest: 1.0186119\tbest: 1.0185411 (1800)\ttotal: 19.2s\tremaining: 1m 21s\n",
      "1910:\tlearn: 0.9803464\ttest: 1.0186017\tbest: 1.0185411 (1800)\ttotal: 19.3s\tremaining: 1m 21s\n",
      "1911:\tlearn: 0.9803185\ttest: 1.0185905\tbest: 1.0185411 (1800)\ttotal: 19.3s\tremaining: 1m 21s\n",
      "1912:\tlearn: 0.9803014\ttest: 1.0185838\tbest: 1.0185411 (1800)\ttotal: 19.3s\tremaining: 1m 21s\n",
      "1913:\tlearn: 0.9802669\ttest: 1.0185876\tbest: 1.0185411 (1800)\ttotal: 19.3s\tremaining: 1m 21s\n",
      "1914:\tlearn: 0.9802459\ttest: 1.0185864\tbest: 1.0185411 (1800)\ttotal: 19.3s\tremaining: 1m 21s\n",
      "1915:\tlearn: 0.9802222\ttest: 1.0185901\tbest: 1.0185411 (1800)\ttotal: 19.3s\tremaining: 1m 21s\n",
      "1916:\tlearn: 0.9802016\ttest: 1.0185953\tbest: 1.0185411 (1800)\ttotal: 19.3s\tremaining: 1m 21s\n",
      "1917:\tlearn: 0.9801825\ttest: 1.0186017\tbest: 1.0185411 (1800)\ttotal: 19.3s\tremaining: 1m 21s\n",
      "1918:\tlearn: 0.9801638\ttest: 1.0186025\tbest: 1.0185411 (1800)\ttotal: 19.3s\tremaining: 1m 21s\n",
      "1919:\tlearn: 0.9801470\ttest: 1.0186132\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1920:\tlearn: 0.9801271\ttest: 1.0186072\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1921:\tlearn: 0.9801035\ttest: 1.0186078\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1922:\tlearn: 0.9800831\ttest: 1.0186123\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1923:\tlearn: 0.9800660\ttest: 1.0186095\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1924:\tlearn: 0.9800488\ttest: 1.0186193\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1925:\tlearn: 0.9800262\ttest: 1.0186230\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1926:\tlearn: 0.9800111\ttest: 1.0186256\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1927:\tlearn: 0.9799925\ttest: 1.0186266\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1928:\tlearn: 0.9799667\ttest: 1.0186278\tbest: 1.0185411 (1800)\ttotal: 19.4s\tremaining: 1m 21s\n",
      "1929:\tlearn: 0.9799429\ttest: 1.0186280\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1930:\tlearn: 0.9799291\ttest: 1.0186227\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1931:\tlearn: 0.9798984\ttest: 1.0186266\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1932:\tlearn: 0.9798758\ttest: 1.0186228\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1933:\tlearn: 0.9798447\ttest: 1.0186231\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1934:\tlearn: 0.9798216\ttest: 1.0186211\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1935:\tlearn: 0.9798009\ttest: 1.0186175\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1936:\tlearn: 0.9797825\ttest: 1.0186238\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1937:\tlearn: 0.9797653\ttest: 1.0186194\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1938:\tlearn: 0.9797450\ttest: 1.0186264\tbest: 1.0185411 (1800)\ttotal: 19.5s\tremaining: 1m 21s\n",
      "1939:\tlearn: 0.9797204\ttest: 1.0186318\tbest: 1.0185411 (1800)\ttotal: 19.6s\tremaining: 1m 21s\n",
      "1940:\tlearn: 0.9797038\ttest: 1.0186268\tbest: 1.0185411 (1800)\ttotal: 19.6s\tremaining: 1m 21s\n",
      "1941:\tlearn: 0.9796810\ttest: 1.0186304\tbest: 1.0185411 (1800)\ttotal: 19.6s\tremaining: 1m 21s\n",
      "1942:\tlearn: 0.9796650\ttest: 1.0186322\tbest: 1.0185411 (1800)\ttotal: 19.6s\tremaining: 1m 21s\n",
      "1943:\tlearn: 0.9796400\ttest: 1.0186347\tbest: 1.0185411 (1800)\ttotal: 19.6s\tremaining: 1m 21s\n",
      "1944:\tlearn: 0.9796134\ttest: 1.0186409\tbest: 1.0185411 (1800)\ttotal: 19.6s\tremaining: 1m 21s\n",
      "1945:\tlearn: 0.9795846\ttest: 1.0186375\tbest: 1.0185411 (1800)\ttotal: 19.6s\tremaining: 1m 21s\n",
      "1946:\tlearn: 0.9795606\ttest: 1.0186347\tbest: 1.0185411 (1800)\ttotal: 19.6s\tremaining: 1m 21s\n",
      "1947:\tlearn: 0.9795297\ttest: 1.0186319\tbest: 1.0185411 (1800)\ttotal: 19.6s\tremaining: 1m 21s\n",
      "1948:\tlearn: 0.9795116\ttest: 1.0186192\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1949:\tlearn: 0.9794817\ttest: 1.0186265\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1950:\tlearn: 0.9794604\ttest: 1.0186274\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1951:\tlearn: 0.9794404\ttest: 1.0186324\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1952:\tlearn: 0.9794229\ttest: 1.0186250\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1953:\tlearn: 0.9793999\ttest: 1.0186297\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1954:\tlearn: 0.9793813\ttest: 1.0186243\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1955:\tlearn: 0.9793663\ttest: 1.0186341\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1956:\tlearn: 0.9793354\ttest: 1.0186357\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1957:\tlearn: 0.9793124\ttest: 1.0186389\tbest: 1.0185411 (1800)\ttotal: 19.7s\tremaining: 1m 21s\n",
      "1958:\tlearn: 0.9792939\ttest: 1.0186434\tbest: 1.0185411 (1800)\ttotal: 19.8s\tremaining: 1m 21s\n",
      "1959:\tlearn: 0.9792693\ttest: 1.0186517\tbest: 1.0185411 (1800)\ttotal: 19.8s\tremaining: 1m 21s\n",
      "1960:\tlearn: 0.9792423\ttest: 1.0186548\tbest: 1.0185411 (1800)\ttotal: 19.8s\tremaining: 1m 21s\n",
      "1961:\tlearn: 0.9792152\ttest: 1.0186511\tbest: 1.0185411 (1800)\ttotal: 19.8s\tremaining: 1m 21s\n",
      "1962:\tlearn: 0.9791903\ttest: 1.0186478\tbest: 1.0185411 (1800)\ttotal: 19.8s\tremaining: 1m 21s\n",
      "1963:\tlearn: 0.9791603\ttest: 1.0186460\tbest: 1.0185411 (1800)\ttotal: 19.8s\tremaining: 1m 21s\n",
      "1964:\tlearn: 0.9791363\ttest: 1.0186435\tbest: 1.0185411 (1800)\ttotal: 19.8s\tremaining: 1m 21s\n",
      "1965:\tlearn: 0.9791131\ttest: 1.0186426\tbest: 1.0185411 (1800)\ttotal: 19.8s\tremaining: 1m 21s\n",
      "1966:\tlearn: 0.9790933\ttest: 1.0186478\tbest: 1.0185411 (1800)\ttotal: 19.8s\tremaining: 1m 21s\n",
      "1967:\tlearn: 0.9790631\ttest: 1.0186591\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 21s\n",
      "1968:\tlearn: 0.9790401\ttest: 1.0186606\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 21s\n",
      "1969:\tlearn: 0.9790222\ttest: 1.0186645\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 21s\n",
      "1970:\tlearn: 0.9789996\ttest: 1.0186685\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 20s\n",
      "1971:\tlearn: 0.9789671\ttest: 1.0186664\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 20s\n",
      "1972:\tlearn: 0.9789456\ttest: 1.0186597\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 20s\n",
      "1973:\tlearn: 0.9789234\ttest: 1.0186639\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 20s\n",
      "1974:\tlearn: 0.9789018\ttest: 1.0186631\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 20s\n",
      "1975:\tlearn: 0.9788809\ttest: 1.0186747\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 20s\n",
      "1976:\tlearn: 0.9788623\ttest: 1.0186749\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 20s\n",
      "1977:\tlearn: 0.9788419\ttest: 1.0186765\tbest: 1.0185411 (1800)\ttotal: 19.9s\tremaining: 1m 20s\n",
      "1978:\tlearn: 0.9788184\ttest: 1.0186904\tbest: 1.0185411 (1800)\ttotal: 20s\tremaining: 1m 20s\n",
      "1979:\tlearn: 0.9787888\ttest: 1.0186970\tbest: 1.0185411 (1800)\ttotal: 20s\tremaining: 1m 20s\n",
      "1980:\tlearn: 0.9787714\ttest: 1.0187030\tbest: 1.0185411 (1800)\ttotal: 20s\tremaining: 1m 20s\n",
      "1981:\tlearn: 0.9787608\ttest: 1.0187128\tbest: 1.0185411 (1800)\ttotal: 20s\tremaining: 1m 20s\n",
      "1982:\tlearn: 0.9787338\ttest: 1.0187249\tbest: 1.0185411 (1800)\ttotal: 20s\tremaining: 1m 20s\n",
      "1983:\tlearn: 0.9787121\ttest: 1.0187196\tbest: 1.0185411 (1800)\ttotal: 20s\tremaining: 1m 20s\n",
      "1984:\tlearn: 0.9786975\ttest: 1.0187213\tbest: 1.0185411 (1800)\ttotal: 20s\tremaining: 1m 20s\n",
      "1985:\tlearn: 0.9786767\ttest: 1.0187167\tbest: 1.0185411 (1800)\ttotal: 20s\tremaining: 1m 20s\n",
      "1986:\tlearn: 0.9786502\ttest: 1.0187202\tbest: 1.0185411 (1800)\ttotal: 20s\tremaining: 1m 20s\n",
      "1987:\tlearn: 0.9786322\ttest: 1.0187166\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1988:\tlearn: 0.9786047\ttest: 1.0187229\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1989:\tlearn: 0.9785727\ttest: 1.0187208\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1990:\tlearn: 0.9785588\ttest: 1.0187273\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1991:\tlearn: 0.9785324\ttest: 1.0187230\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1992:\tlearn: 0.9785103\ttest: 1.0187182\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1993:\tlearn: 0.9784852\ttest: 1.0187186\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1994:\tlearn: 0.9784622\ttest: 1.0187160\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1995:\tlearn: 0.9784471\ttest: 1.0187116\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1996:\tlearn: 0.9784288\ttest: 1.0187074\tbest: 1.0185411 (1800)\ttotal: 20.1s\tremaining: 1m 20s\n",
      "1997:\tlearn: 0.9784085\ttest: 1.0187088\tbest: 1.0185411 (1800)\ttotal: 20.2s\tremaining: 1m 20s\n",
      "1998:\tlearn: 0.9783961\ttest: 1.0187137\tbest: 1.0185411 (1800)\ttotal: 20.2s\tremaining: 1m 20s\n",
      "1999:\tlearn: 0.9783766\ttest: 1.0187127\tbest: 1.0185411 (1800)\ttotal: 20.2s\tremaining: 1m 20s\n",
      "2000:\tlearn: 0.9783529\ttest: 1.0187259\tbest: 1.0185411 (1800)\ttotal: 20.2s\tremaining: 1m 20s\n",
      "2001:\tlearn: 0.9783353\ttest: 1.0187344\tbest: 1.0185411 (1800)\ttotal: 20.2s\tremaining: 1m 20s\n",
      "2002:\tlearn: 0.9783100\ttest: 1.0187216\tbest: 1.0185411 (1800)\ttotal: 20.2s\tremaining: 1m 20s\n",
      "2003:\tlearn: 0.9782937\ttest: 1.0187203\tbest: 1.0185411 (1800)\ttotal: 20.2s\tremaining: 1m 20s\n",
      "2004:\tlearn: 0.9782780\ttest: 1.0187247\tbest: 1.0185411 (1800)\ttotal: 20.2s\tremaining: 1m 20s\n",
      "2005:\tlearn: 0.9782544\ttest: 1.0187362\tbest: 1.0185411 (1800)\ttotal: 20.2s\tremaining: 1m 20s\n",
      "2006:\tlearn: 0.9782371\ttest: 1.0187390\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2007:\tlearn: 0.9782110\ttest: 1.0187411\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2008:\tlearn: 0.9781845\ttest: 1.0187555\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2009:\tlearn: 0.9781670\ttest: 1.0187418\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2010:\tlearn: 0.9781432\ttest: 1.0187387\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2011:\tlearn: 0.9781127\ttest: 1.0187452\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2012:\tlearn: 0.9780927\ttest: 1.0187440\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2013:\tlearn: 0.9780690\ttest: 1.0187558\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2014:\tlearn: 0.9780402\ttest: 1.0187526\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2015:\tlearn: 0.9780220\ttest: 1.0187525\tbest: 1.0185411 (1800)\ttotal: 20.3s\tremaining: 1m 20s\n",
      "2016:\tlearn: 0.9779940\ttest: 1.0187448\tbest: 1.0185411 (1800)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "2017:\tlearn: 0.9779642\ttest: 1.0187378\tbest: 1.0185411 (1800)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "2018:\tlearn: 0.9779306\ttest: 1.0187413\tbest: 1.0185411 (1800)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "2019:\tlearn: 0.9779119\ttest: 1.0187450\tbest: 1.0185411 (1800)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "2020:\tlearn: 0.9778864\ttest: 1.0187598\tbest: 1.0185411 (1800)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "2021:\tlearn: 0.9778583\ttest: 1.0187649\tbest: 1.0185411 (1800)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "2022:\tlearn: 0.9778412\ttest: 1.0187699\tbest: 1.0185411 (1800)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "2023:\tlearn: 0.9778193\ttest: 1.0187729\tbest: 1.0185411 (1800)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "2024:\tlearn: 0.9777950\ttest: 1.0187859\tbest: 1.0185411 (1800)\ttotal: 20.4s\tremaining: 1m 20s\n",
      "2025:\tlearn: 0.9777759\ttest: 1.0187871\tbest: 1.0185411 (1800)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "2026:\tlearn: 0.9777501\ttest: 1.0187912\tbest: 1.0185411 (1800)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "2027:\tlearn: 0.9777270\ttest: 1.0187819\tbest: 1.0185411 (1800)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "2028:\tlearn: 0.9777077\ttest: 1.0187764\tbest: 1.0185411 (1800)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "2029:\tlearn: 0.9776900\ttest: 1.0187719\tbest: 1.0185411 (1800)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "2030:\tlearn: 0.9776733\ttest: 1.0187654\tbest: 1.0185411 (1800)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "2031:\tlearn: 0.9776538\ttest: 1.0187640\tbest: 1.0185411 (1800)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "2032:\tlearn: 0.9776316\ttest: 1.0187649\tbest: 1.0185411 (1800)\ttotal: 20.5s\tremaining: 1m 20s\n",
      "2033:\tlearn: 0.9776109\ttest: 1.0187592\tbest: 1.0185411 (1800)\ttotal: 20.6s\tremaining: 1m 20s\n",
      "2034:\tlearn: 0.9775865\ttest: 1.0187620\tbest: 1.0185411 (1800)\ttotal: 20.6s\tremaining: 1m 20s\n",
      "2035:\tlearn: 0.9775630\ttest: 1.0187709\tbest: 1.0185411 (1800)\ttotal: 20.6s\tremaining: 1m 20s\n",
      "2036:\tlearn: 0.9775378\ttest: 1.0187806\tbest: 1.0185411 (1800)\ttotal: 20.6s\tremaining: 1m 20s\n",
      "2037:\tlearn: 0.9775153\ttest: 1.0187770\tbest: 1.0185411 (1800)\ttotal: 20.6s\tremaining: 1m 20s\n",
      "2038:\tlearn: 0.9774831\ttest: 1.0187764\tbest: 1.0185411 (1800)\ttotal: 20.6s\tremaining: 1m 20s\n",
      "2039:\tlearn: 0.9774583\ttest: 1.0187774\tbest: 1.0185411 (1800)\ttotal: 20.6s\tremaining: 1m 20s\n",
      "2040:\tlearn: 0.9774343\ttest: 1.0187704\tbest: 1.0185411 (1800)\ttotal: 20.6s\tremaining: 1m 20s\n",
      "2041:\tlearn: 0.9774158\ttest: 1.0187757\tbest: 1.0185411 (1800)\ttotal: 20.6s\tremaining: 1m 20s\n",
      "2042:\tlearn: 0.9773891\ttest: 1.0187697\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2043:\tlearn: 0.9773714\ttest: 1.0187670\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2044:\tlearn: 0.9773488\ttest: 1.0187571\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2045:\tlearn: 0.9773329\ttest: 1.0187586\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2046:\tlearn: 0.9773115\ttest: 1.0187558\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2047:\tlearn: 0.9772974\ttest: 1.0187546\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2048:\tlearn: 0.9772777\ttest: 1.0187620\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2049:\tlearn: 0.9772515\ttest: 1.0187691\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2050:\tlearn: 0.9772309\ttest: 1.0187719\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2051:\tlearn: 0.9772124\ttest: 1.0187667\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2052:\tlearn: 0.9771942\ttest: 1.0187572\tbest: 1.0185411 (1800)\ttotal: 20.7s\tremaining: 1m 20s\n",
      "2053:\tlearn: 0.9771696\ttest: 1.0187583\tbest: 1.0185411 (1800)\ttotal: 20.8s\tremaining: 1m 20s\n",
      "2054:\tlearn: 0.9771427\ttest: 1.0187581\tbest: 1.0185411 (1800)\ttotal: 20.8s\tremaining: 1m 20s\n",
      "2055:\tlearn: 0.9771252\ttest: 1.0187551\tbest: 1.0185411 (1800)\ttotal: 20.8s\tremaining: 1m 20s\n",
      "2056:\tlearn: 0.9770986\ttest: 1.0187606\tbest: 1.0185411 (1800)\ttotal: 20.8s\tremaining: 1m 20s\n",
      "2057:\tlearn: 0.9770724\ttest: 1.0187780\tbest: 1.0185411 (1800)\ttotal: 20.8s\tremaining: 1m 20s\n",
      "2058:\tlearn: 0.9770522\ttest: 1.0187781\tbest: 1.0185411 (1800)\ttotal: 20.8s\tremaining: 1m 20s\n",
      "2059:\tlearn: 0.9770262\ttest: 1.0187821\tbest: 1.0185411 (1800)\ttotal: 20.8s\tremaining: 1m 20s\n",
      "2060:\tlearn: 0.9769986\ttest: 1.0187804\tbest: 1.0185411 (1800)\ttotal: 20.8s\tremaining: 1m 20s\n",
      "2061:\tlearn: 0.9769767\ttest: 1.0187891\tbest: 1.0185411 (1800)\ttotal: 20.8s\tremaining: 1m 20s\n",
      "2062:\tlearn: 0.9769594\ttest: 1.0187905\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2063:\tlearn: 0.9769426\ttest: 1.0187878\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2064:\tlearn: 0.9769083\ttest: 1.0187931\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2065:\tlearn: 0.9768820\ttest: 1.0187779\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2066:\tlearn: 0.9768593\ttest: 1.0187711\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2067:\tlearn: 0.9768384\ttest: 1.0187578\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2068:\tlearn: 0.9768135\ttest: 1.0187594\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2069:\tlearn: 0.9767895\ttest: 1.0187571\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2070:\tlearn: 0.9767647\ttest: 1.0187625\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2071:\tlearn: 0.9767349\ttest: 1.0187723\tbest: 1.0185411 (1800)\ttotal: 20.9s\tremaining: 1m 20s\n",
      "2072:\tlearn: 0.9767049\ttest: 1.0187812\tbest: 1.0185411 (1800)\ttotal: 21s\tremaining: 1m 20s\n",
      "2073:\tlearn: 0.9766776\ttest: 1.0187870\tbest: 1.0185411 (1800)\ttotal: 21s\tremaining: 1m 20s\n",
      "2074:\tlearn: 0.9766595\ttest: 1.0187914\tbest: 1.0185411 (1800)\ttotal: 21s\tremaining: 1m 20s\n",
      "2075:\tlearn: 0.9766397\ttest: 1.0187945\tbest: 1.0185411 (1800)\ttotal: 21s\tremaining: 1m 20s\n",
      "2076:\tlearn: 0.9766095\ttest: 1.0187771\tbest: 1.0185411 (1800)\ttotal: 21s\tremaining: 1m 20s\n",
      "2077:\tlearn: 0.9765852\ttest: 1.0187723\tbest: 1.0185411 (1800)\ttotal: 21s\tremaining: 1m 20s\n",
      "2078:\tlearn: 0.9765636\ttest: 1.0187634\tbest: 1.0185411 (1800)\ttotal: 21s\tremaining: 1m 20s\n",
      "2079:\tlearn: 0.9765448\ttest: 1.0187691\tbest: 1.0185411 (1800)\ttotal: 21s\tremaining: 1m 20s\n",
      "2080:\tlearn: 0.9765248\ttest: 1.0187719\tbest: 1.0185411 (1800)\ttotal: 21.1s\tremaining: 1m 20s\n",
      "2081:\tlearn: 0.9765041\ttest: 1.0187668\tbest: 1.0185411 (1800)\ttotal: 21.1s\tremaining: 1m 20s\n",
      "2082:\tlearn: 0.9764779\ttest: 1.0187695\tbest: 1.0185411 (1800)\ttotal: 21.1s\tremaining: 1m 20s\n",
      "2083:\tlearn: 0.9764616\ttest: 1.0187685\tbest: 1.0185411 (1800)\ttotal: 21.1s\tremaining: 1m 20s\n",
      "2084:\tlearn: 0.9764354\ttest: 1.0187628\tbest: 1.0185411 (1800)\ttotal: 21.1s\tremaining: 1m 20s\n",
      "2085:\tlearn: 0.9764078\ttest: 1.0187585\tbest: 1.0185411 (1800)\ttotal: 21.1s\tremaining: 1m 20s\n",
      "2086:\tlearn: 0.9763886\ttest: 1.0187577\tbest: 1.0185411 (1800)\ttotal: 21.1s\tremaining: 1m 20s\n",
      "2087:\tlearn: 0.9763631\ttest: 1.0187513\tbest: 1.0185411 (1800)\ttotal: 21.1s\tremaining: 1m 20s\n",
      "2088:\tlearn: 0.9763351\ttest: 1.0187658\tbest: 1.0185411 (1800)\ttotal: 21.1s\tremaining: 1m 20s\n",
      "2089:\tlearn: 0.9763121\ttest: 1.0187641\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 20s\n",
      "2090:\tlearn: 0.9762926\ttest: 1.0187742\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 20s\n",
      "2091:\tlearn: 0.9762562\ttest: 1.0187660\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 20s\n",
      "2092:\tlearn: 0.9762324\ttest: 1.0187868\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 20s\n",
      "2093:\tlearn: 0.9762058\ttest: 1.0187858\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 20s\n",
      "2094:\tlearn: 0.9761817\ttest: 1.0187889\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 20s\n",
      "2095:\tlearn: 0.9761568\ttest: 1.0188019\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 19s\n",
      "2096:\tlearn: 0.9761363\ttest: 1.0188075\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 19s\n",
      "2097:\tlearn: 0.9761107\ttest: 1.0188072\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 19s\n",
      "2098:\tlearn: 0.9760896\ttest: 1.0188122\tbest: 1.0185411 (1800)\ttotal: 21.2s\tremaining: 1m 19s\n",
      "2099:\tlearn: 0.9760680\ttest: 1.0188212\tbest: 1.0185411 (1800)\ttotal: 21.3s\tremaining: 1m 19s\n",
      "2100:\tlearn: 0.9760381\ttest: 1.0188251\tbest: 1.0185411 (1800)\ttotal: 21.3s\tremaining: 1m 19s\n",
      "2101:\tlearn: 0.9760064\ttest: 1.0188192\tbest: 1.0185411 (1800)\ttotal: 21.3s\tremaining: 1m 19s\n",
      "2102:\tlearn: 0.9759803\ttest: 1.0188328\tbest: 1.0185411 (1800)\ttotal: 21.3s\tremaining: 1m 19s\n",
      "2103:\tlearn: 0.9759523\ttest: 1.0188354\tbest: 1.0185411 (1800)\ttotal: 21.3s\tremaining: 1m 19s\n",
      "2104:\tlearn: 0.9759267\ttest: 1.0188289\tbest: 1.0185411 (1800)\ttotal: 21.3s\tremaining: 1m 19s\n",
      "2105:\tlearn: 0.9759047\ttest: 1.0188277\tbest: 1.0185411 (1800)\ttotal: 21.3s\tremaining: 1m 19s\n",
      "2106:\tlearn: 0.9758818\ttest: 1.0188314\tbest: 1.0185411 (1800)\ttotal: 21.3s\tremaining: 1m 19s\n",
      "2107:\tlearn: 0.9758653\ttest: 1.0188347\tbest: 1.0185411 (1800)\ttotal: 21.3s\tremaining: 1m 19s\n",
      "2108:\tlearn: 0.9758424\ttest: 1.0188255\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2109:\tlearn: 0.9758139\ttest: 1.0188299\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2110:\tlearn: 0.9757898\ttest: 1.0188253\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2111:\tlearn: 0.9757604\ttest: 1.0188177\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2112:\tlearn: 0.9757435\ttest: 1.0188279\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2113:\tlearn: 0.9757241\ttest: 1.0188365\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2114:\tlearn: 0.9756991\ttest: 1.0188377\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2115:\tlearn: 0.9756647\ttest: 1.0188429\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2116:\tlearn: 0.9756389\ttest: 1.0188533\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2117:\tlearn: 0.9756277\ttest: 1.0188558\tbest: 1.0185411 (1800)\ttotal: 21.4s\tremaining: 1m 19s\n",
      "2118:\tlearn: 0.9756032\ttest: 1.0188677\tbest: 1.0185411 (1800)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "2119:\tlearn: 0.9755720\ttest: 1.0188560\tbest: 1.0185411 (1800)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "2120:\tlearn: 0.9755489\ttest: 1.0188634\tbest: 1.0185411 (1800)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "2121:\tlearn: 0.9755276\ttest: 1.0188598\tbest: 1.0185411 (1800)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "2122:\tlearn: 0.9755065\ttest: 1.0188629\tbest: 1.0185411 (1800)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "2123:\tlearn: 0.9754801\ttest: 1.0188625\tbest: 1.0185411 (1800)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "2124:\tlearn: 0.9754681\ttest: 1.0188607\tbest: 1.0185411 (1800)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "2125:\tlearn: 0.9754414\ttest: 1.0188693\tbest: 1.0185411 (1800)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "2126:\tlearn: 0.9754158\ttest: 1.0188774\tbest: 1.0185411 (1800)\ttotal: 21.5s\tremaining: 1m 19s\n",
      "2127:\tlearn: 0.9753948\ttest: 1.0188814\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2128:\tlearn: 0.9753667\ttest: 1.0188858\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2129:\tlearn: 0.9753444\ttest: 1.0188964\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2130:\tlearn: 0.9753215\ttest: 1.0188999\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2131:\tlearn: 0.9752989\ttest: 1.0189025\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2132:\tlearn: 0.9752706\ttest: 1.0189039\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2133:\tlearn: 0.9752575\ttest: 1.0188953\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2134:\tlearn: 0.9752387\ttest: 1.0188946\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2135:\tlearn: 0.9752112\ttest: 1.0189011\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2136:\tlearn: 0.9751880\ttest: 1.0188994\tbest: 1.0185411 (1800)\ttotal: 21.6s\tremaining: 1m 19s\n",
      "2137:\tlearn: 0.9751664\ttest: 1.0189035\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2138:\tlearn: 0.9751450\ttest: 1.0188947\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2139:\tlearn: 0.9751224\ttest: 1.0188851\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2140:\tlearn: 0.9750989\ttest: 1.0188839\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2141:\tlearn: 0.9750771\ttest: 1.0188966\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2142:\tlearn: 0.9750567\ttest: 1.0188975\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2143:\tlearn: 0.9750385\ttest: 1.0189011\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2144:\tlearn: 0.9750202\ttest: 1.0189131\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2145:\tlearn: 0.9750025\ttest: 1.0189234\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2146:\tlearn: 0.9749804\ttest: 1.0189148\tbest: 1.0185411 (1800)\ttotal: 21.7s\tremaining: 1m 19s\n",
      "2147:\tlearn: 0.9749664\ttest: 1.0189205\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2148:\tlearn: 0.9749498\ttest: 1.0189250\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2149:\tlearn: 0.9749230\ttest: 1.0189302\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2150:\tlearn: 0.9749023\ttest: 1.0189345\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2151:\tlearn: 0.9748791\ttest: 1.0189409\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2152:\tlearn: 0.9748600\ttest: 1.0189367\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2153:\tlearn: 0.9748401\ttest: 1.0189419\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2154:\tlearn: 0.9748226\ttest: 1.0189466\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2155:\tlearn: 0.9747993\ttest: 1.0189557\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2156:\tlearn: 0.9747723\ttest: 1.0189528\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2157:\tlearn: 0.9747457\ttest: 1.0189633\tbest: 1.0185411 (1800)\ttotal: 21.8s\tremaining: 1m 19s\n",
      "2158:\tlearn: 0.9747178\ttest: 1.0189763\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2159:\tlearn: 0.9746946\ttest: 1.0189725\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2160:\tlearn: 0.9746702\ttest: 1.0189692\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2161:\tlearn: 0.9746435\ttest: 1.0189829\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2162:\tlearn: 0.9746251\ttest: 1.0189915\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2163:\tlearn: 0.9745924\ttest: 1.0189966\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2164:\tlearn: 0.9745769\ttest: 1.0189933\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2165:\tlearn: 0.9745563\ttest: 1.0189908\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2166:\tlearn: 0.9745387\ttest: 1.0189870\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2167:\tlearn: 0.9745124\ttest: 1.0189927\tbest: 1.0185411 (1800)\ttotal: 21.9s\tremaining: 1m 19s\n",
      "2168:\tlearn: 0.9744810\ttest: 1.0189904\tbest: 1.0185411 (1800)\ttotal: 22s\tremaining: 1m 19s\n",
      "2169:\tlearn: 0.9744596\ttest: 1.0189857\tbest: 1.0185411 (1800)\ttotal: 22s\tremaining: 1m 19s\n",
      "2170:\tlearn: 0.9744397\ttest: 1.0189887\tbest: 1.0185411 (1800)\ttotal: 22s\tremaining: 1m 19s\n",
      "2171:\tlearn: 0.9744172\ttest: 1.0189904\tbest: 1.0185411 (1800)\ttotal: 22s\tremaining: 1m 19s\n",
      "2172:\tlearn: 0.9743920\ttest: 1.0189971\tbest: 1.0185411 (1800)\ttotal: 22s\tremaining: 1m 19s\n",
      "2173:\tlearn: 0.9743694\ttest: 1.0189981\tbest: 1.0185411 (1800)\ttotal: 22s\tremaining: 1m 19s\n",
      "2174:\tlearn: 0.9743479\ttest: 1.0189918\tbest: 1.0185411 (1800)\ttotal: 22s\tremaining: 1m 19s\n",
      "2175:\tlearn: 0.9743197\ttest: 1.0189965\tbest: 1.0185411 (1800)\ttotal: 22s\tremaining: 1m 19s\n",
      "2176:\tlearn: 0.9742887\ttest: 1.0189937\tbest: 1.0185411 (1800)\ttotal: 22s\tremaining: 1m 19s\n",
      "2177:\tlearn: 0.9742694\ttest: 1.0190104\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2178:\tlearn: 0.9742413\ttest: 1.0190209\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2179:\tlearn: 0.9742138\ttest: 1.0190179\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2180:\tlearn: 0.9741943\ttest: 1.0190129\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2181:\tlearn: 0.9741682\ttest: 1.0190173\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2182:\tlearn: 0.9741472\ttest: 1.0190218\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2183:\tlearn: 0.9741189\ttest: 1.0190299\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2184:\tlearn: 0.9740987\ttest: 1.0190108\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2185:\tlearn: 0.9740774\ttest: 1.0190010\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2186:\tlearn: 0.9740523\ttest: 1.0189927\tbest: 1.0185411 (1800)\ttotal: 22.1s\tremaining: 1m 19s\n",
      "2187:\tlearn: 0.9740274\ttest: 1.0189948\tbest: 1.0185411 (1800)\ttotal: 22.2s\tremaining: 1m 19s\n",
      "2188:\tlearn: 0.9740060\ttest: 1.0189997\tbest: 1.0185411 (1800)\ttotal: 22.2s\tremaining: 1m 19s\n",
      "2189:\tlearn: 0.9739793\ttest: 1.0190078\tbest: 1.0185411 (1800)\ttotal: 22.2s\tremaining: 1m 19s\n",
      "2190:\tlearn: 0.9739540\ttest: 1.0190158\tbest: 1.0185411 (1800)\ttotal: 22.2s\tremaining: 1m 19s\n",
      "2191:\tlearn: 0.9739265\ttest: 1.0190112\tbest: 1.0185411 (1800)\ttotal: 22.2s\tremaining: 1m 19s\n",
      "2192:\tlearn: 0.9739121\ttest: 1.0190151\tbest: 1.0185411 (1800)\ttotal: 22.2s\tremaining: 1m 19s\n",
      "2193:\tlearn: 0.9738897\ttest: 1.0190250\tbest: 1.0185411 (1800)\ttotal: 22.2s\tremaining: 1m 19s\n",
      "2194:\tlearn: 0.9738611\ttest: 1.0190175\tbest: 1.0185411 (1800)\ttotal: 22.2s\tremaining: 1m 19s\n",
      "2195:\tlearn: 0.9738315\ttest: 1.0190163\tbest: 1.0185411 (1800)\ttotal: 22.2s\tremaining: 1m 19s\n",
      "2196:\tlearn: 0.9738011\ttest: 1.0190117\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 19s\n",
      "2197:\tlearn: 0.9737730\ttest: 1.0190115\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 19s\n",
      "2198:\tlearn: 0.9737500\ttest: 1.0190088\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 19s\n",
      "2199:\tlearn: 0.9737323\ttest: 1.0190050\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 18s\n",
      "2200:\tlearn: 0.9737059\ttest: 1.0190026\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 18s\n",
      "2201:\tlearn: 0.9736849\ttest: 1.0190176\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 18s\n",
      "2202:\tlearn: 0.9736619\ttest: 1.0190286\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 18s\n",
      "2203:\tlearn: 0.9736382\ttest: 1.0190462\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 18s\n",
      "2204:\tlearn: 0.9736103\ttest: 1.0190501\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 18s\n",
      "2205:\tlearn: 0.9735848\ttest: 1.0190551\tbest: 1.0185411 (1800)\ttotal: 22.3s\tremaining: 1m 18s\n",
      "2206:\tlearn: 0.9735617\ttest: 1.0190450\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2207:\tlearn: 0.9735348\ttest: 1.0190437\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2208:\tlearn: 0.9735104\ttest: 1.0190538\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2209:\tlearn: 0.9734871\ttest: 1.0190693\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2210:\tlearn: 0.9734660\ttest: 1.0190793\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2211:\tlearn: 0.9734395\ttest: 1.0190842\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2212:\tlearn: 0.9734154\ttest: 1.0190917\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2213:\tlearn: 0.9733801\ttest: 1.0190914\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2214:\tlearn: 0.9733631\ttest: 1.0191020\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2215:\tlearn: 0.9733324\ttest: 1.0191088\tbest: 1.0185411 (1800)\ttotal: 22.4s\tremaining: 1m 18s\n",
      "2216:\tlearn: 0.9733129\ttest: 1.0191144\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2217:\tlearn: 0.9732852\ttest: 1.0191136\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2218:\tlearn: 0.9732701\ttest: 1.0191102\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2219:\tlearn: 0.9732482\ttest: 1.0191027\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2220:\tlearn: 0.9732114\ttest: 1.0190953\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2221:\tlearn: 0.9731871\ttest: 1.0190983\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2222:\tlearn: 0.9731631\ttest: 1.0191001\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2223:\tlearn: 0.9731378\ttest: 1.0190983\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2224:\tlearn: 0.9731149\ttest: 1.0191024\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2225:\tlearn: 0.9731016\ttest: 1.0190963\tbest: 1.0185411 (1800)\ttotal: 22.5s\tremaining: 1m 18s\n",
      "2226:\tlearn: 0.9730856\ttest: 1.0190887\tbest: 1.0185411 (1800)\ttotal: 22.6s\tremaining: 1m 18s\n",
      "2227:\tlearn: 0.9730557\ttest: 1.0191008\tbest: 1.0185411 (1800)\ttotal: 22.6s\tremaining: 1m 18s\n",
      "2228:\tlearn: 0.9730284\ttest: 1.0190965\tbest: 1.0185411 (1800)\ttotal: 22.6s\tremaining: 1m 18s\n",
      "2229:\tlearn: 0.9730066\ttest: 1.0190899\tbest: 1.0185411 (1800)\ttotal: 22.6s\tremaining: 1m 18s\n",
      "2230:\tlearn: 0.9729805\ttest: 1.0190859\tbest: 1.0185411 (1800)\ttotal: 22.6s\tremaining: 1m 18s\n",
      "2231:\tlearn: 0.9729548\ttest: 1.0190875\tbest: 1.0185411 (1800)\ttotal: 22.7s\tremaining: 1m 18s\n",
      "2232:\tlearn: 0.9729219\ttest: 1.0190790\tbest: 1.0185411 (1800)\ttotal: 22.7s\tremaining: 1m 18s\n",
      "2233:\tlearn: 0.9728998\ttest: 1.0190867\tbest: 1.0185411 (1800)\ttotal: 22.7s\tremaining: 1m 18s\n",
      "2234:\tlearn: 0.9728706\ttest: 1.0191034\tbest: 1.0185411 (1800)\ttotal: 22.7s\tremaining: 1m 18s\n",
      "2235:\tlearn: 0.9728507\ttest: 1.0191062\tbest: 1.0185411 (1800)\ttotal: 22.7s\tremaining: 1m 18s\n",
      "2236:\tlearn: 0.9728299\ttest: 1.0191086\tbest: 1.0185411 (1800)\ttotal: 22.7s\tremaining: 1m 18s\n",
      "2237:\tlearn: 0.9728057\ttest: 1.0191290\tbest: 1.0185411 (1800)\ttotal: 22.7s\tremaining: 1m 18s\n",
      "2238:\tlearn: 0.9727846\ttest: 1.0191228\tbest: 1.0185411 (1800)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "2239:\tlearn: 0.9727577\ttest: 1.0191228\tbest: 1.0185411 (1800)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "2240:\tlearn: 0.9727309\ttest: 1.0191272\tbest: 1.0185411 (1800)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "2241:\tlearn: 0.9727016\ttest: 1.0191287\tbest: 1.0185411 (1800)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "2242:\tlearn: 0.9726792\ttest: 1.0191299\tbest: 1.0185411 (1800)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "2243:\tlearn: 0.9726457\ttest: 1.0191283\tbest: 1.0185411 (1800)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "2244:\tlearn: 0.9726245\ttest: 1.0191311\tbest: 1.0185411 (1800)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "2245:\tlearn: 0.9726017\ttest: 1.0191274\tbest: 1.0185411 (1800)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "2246:\tlearn: 0.9725804\ttest: 1.0191316\tbest: 1.0185411 (1800)\ttotal: 22.8s\tremaining: 1m 18s\n",
      "2247:\tlearn: 0.9725533\ttest: 1.0191389\tbest: 1.0185411 (1800)\ttotal: 22.9s\tremaining: 1m 18s\n",
      "2248:\tlearn: 0.9725245\ttest: 1.0191481\tbest: 1.0185411 (1800)\ttotal: 22.9s\tremaining: 1m 18s\n",
      "2249:\tlearn: 0.9724989\ttest: 1.0191389\tbest: 1.0185411 (1800)\ttotal: 22.9s\tremaining: 1m 18s\n",
      "2250:\tlearn: 0.9724604\ttest: 1.0191375\tbest: 1.0185411 (1800)\ttotal: 22.9s\tremaining: 1m 18s\n",
      "2251:\tlearn: 0.9724401\ttest: 1.0191385\tbest: 1.0185411 (1800)\ttotal: 22.9s\tremaining: 1m 18s\n",
      "2252:\tlearn: 0.9724182\ttest: 1.0191449\tbest: 1.0185411 (1800)\ttotal: 22.9s\tremaining: 1m 18s\n",
      "2253:\tlearn: 0.9723920\ttest: 1.0191328\tbest: 1.0185411 (1800)\ttotal: 22.9s\tremaining: 1m 18s\n",
      "2254:\tlearn: 0.9723666\ttest: 1.0191280\tbest: 1.0185411 (1800)\ttotal: 22.9s\tremaining: 1m 18s\n",
      "2255:\tlearn: 0.9723490\ttest: 1.0191203\tbest: 1.0185411 (1800)\ttotal: 23s\tremaining: 1m 18s\n",
      "2256:\tlearn: 0.9723249\ttest: 1.0191206\tbest: 1.0185411 (1800)\ttotal: 23s\tremaining: 1m 18s\n",
      "2257:\tlearn: 0.9723025\ttest: 1.0191151\tbest: 1.0185411 (1800)\ttotal: 23s\tremaining: 1m 18s\n",
      "2258:\tlearn: 0.9722818\ttest: 1.0191116\tbest: 1.0185411 (1800)\ttotal: 23s\tremaining: 1m 18s\n",
      "2259:\tlearn: 0.9722507\ttest: 1.0191110\tbest: 1.0185411 (1800)\ttotal: 23s\tremaining: 1m 18s\n",
      "2260:\tlearn: 0.9722260\ttest: 1.0191125\tbest: 1.0185411 (1800)\ttotal: 23s\tremaining: 1m 18s\n",
      "2261:\tlearn: 0.9721977\ttest: 1.0191112\tbest: 1.0185411 (1800)\ttotal: 23s\tremaining: 1m 18s\n",
      "2262:\tlearn: 0.9721720\ttest: 1.0191182\tbest: 1.0185411 (1800)\ttotal: 23.1s\tremaining: 1m 18s\n",
      "2263:\tlearn: 0.9721555\ttest: 1.0191156\tbest: 1.0185411 (1800)\ttotal: 23.1s\tremaining: 1m 18s\n",
      "2264:\tlearn: 0.9721311\ttest: 1.0191162\tbest: 1.0185411 (1800)\ttotal: 23.1s\tremaining: 1m 18s\n",
      "2265:\tlearn: 0.9721084\ttest: 1.0191339\tbest: 1.0185411 (1800)\ttotal: 23.1s\tremaining: 1m 18s\n",
      "2266:\tlearn: 0.9720816\ttest: 1.0191364\tbest: 1.0185411 (1800)\ttotal: 23.1s\tremaining: 1m 18s\n",
      "2267:\tlearn: 0.9720601\ttest: 1.0191443\tbest: 1.0185411 (1800)\ttotal: 23.1s\tremaining: 1m 18s\n",
      "2268:\tlearn: 0.9720306\ttest: 1.0191428\tbest: 1.0185411 (1800)\ttotal: 23.1s\tremaining: 1m 18s\n",
      "2269:\tlearn: 0.9720001\ttest: 1.0191367\tbest: 1.0185411 (1800)\ttotal: 23.1s\tremaining: 1m 18s\n",
      "2270:\tlearn: 0.9719752\ttest: 1.0191416\tbest: 1.0185411 (1800)\ttotal: 23.2s\tremaining: 1m 18s\n",
      "2271:\tlearn: 0.9719582\ttest: 1.0191374\tbest: 1.0185411 (1800)\ttotal: 23.2s\tremaining: 1m 18s\n",
      "2272:\tlearn: 0.9719313\ttest: 1.0191435\tbest: 1.0185411 (1800)\ttotal: 23.2s\tremaining: 1m 18s\n",
      "2273:\tlearn: 0.9719088\ttest: 1.0191423\tbest: 1.0185411 (1800)\ttotal: 23.2s\tremaining: 1m 18s\n",
      "2274:\tlearn: 0.9718861\ttest: 1.0191527\tbest: 1.0185411 (1800)\ttotal: 23.2s\tremaining: 1m 18s\n",
      "2275:\tlearn: 0.9718719\ttest: 1.0191579\tbest: 1.0185411 (1800)\ttotal: 23.2s\tremaining: 1m 18s\n",
      "2276:\tlearn: 0.9718478\ttest: 1.0191679\tbest: 1.0185411 (1800)\ttotal: 23.2s\tremaining: 1m 18s\n",
      "2277:\tlearn: 0.9718195\ttest: 1.0191549\tbest: 1.0185411 (1800)\ttotal: 23.2s\tremaining: 1m 18s\n",
      "2278:\tlearn: 0.9718005\ttest: 1.0191600\tbest: 1.0185411 (1800)\ttotal: 23.2s\tremaining: 1m 18s\n",
      "2279:\tlearn: 0.9717764\ttest: 1.0191520\tbest: 1.0185411 (1800)\ttotal: 23.3s\tremaining: 1m 18s\n",
      "2280:\tlearn: 0.9717581\ttest: 1.0191592\tbest: 1.0185411 (1800)\ttotal: 23.3s\tremaining: 1m 18s\n",
      "2281:\tlearn: 0.9717336\ttest: 1.0191699\tbest: 1.0185411 (1800)\ttotal: 23.3s\tremaining: 1m 18s\n",
      "2282:\tlearn: 0.9717109\ttest: 1.0191754\tbest: 1.0185411 (1800)\ttotal: 23.3s\tremaining: 1m 18s\n",
      "2283:\tlearn: 0.9716901\ttest: 1.0191806\tbest: 1.0185411 (1800)\ttotal: 23.3s\tremaining: 1m 18s\n",
      "2284:\tlearn: 0.9716668\ttest: 1.0191693\tbest: 1.0185411 (1800)\ttotal: 23.3s\tremaining: 1m 18s\n",
      "2285:\tlearn: 0.9716449\ttest: 1.0191779\tbest: 1.0185411 (1800)\ttotal: 23.3s\tremaining: 1m 18s\n",
      "2286:\tlearn: 0.9716225\ttest: 1.0191799\tbest: 1.0185411 (1800)\ttotal: 23.3s\tremaining: 1m 18s\n",
      "2287:\tlearn: 0.9715949\ttest: 1.0191885\tbest: 1.0185411 (1800)\ttotal: 23.4s\tremaining: 1m 18s\n",
      "2288:\tlearn: 0.9715760\ttest: 1.0191934\tbest: 1.0185411 (1800)\ttotal: 23.4s\tremaining: 1m 18s\n",
      "2289:\tlearn: 0.9715449\ttest: 1.0191872\tbest: 1.0185411 (1800)\ttotal: 23.4s\tremaining: 1m 18s\n",
      "2290:\tlearn: 0.9715220\ttest: 1.0191799\tbest: 1.0185411 (1800)\ttotal: 23.4s\tremaining: 1m 18s\n",
      "2291:\tlearn: 0.9714967\ttest: 1.0191811\tbest: 1.0185411 (1800)\ttotal: 23.4s\tremaining: 1m 18s\n",
      "2292:\tlearn: 0.9714736\ttest: 1.0191706\tbest: 1.0185411 (1800)\ttotal: 23.4s\tremaining: 1m 18s\n",
      "2293:\tlearn: 0.9714503\ttest: 1.0191651\tbest: 1.0185411 (1800)\ttotal: 23.4s\tremaining: 1m 18s\n",
      "2294:\tlearn: 0.9714269\ttest: 1.0191646\tbest: 1.0185411 (1800)\ttotal: 23.4s\tremaining: 1m 18s\n",
      "2295:\tlearn: 0.9714051\ttest: 1.0191608\tbest: 1.0185411 (1800)\ttotal: 23.5s\tremaining: 1m 18s\n",
      "2296:\tlearn: 0.9713803\ttest: 1.0191625\tbest: 1.0185411 (1800)\ttotal: 23.5s\tremaining: 1m 18s\n",
      "2297:\tlearn: 0.9713613\ttest: 1.0191661\tbest: 1.0185411 (1800)\ttotal: 23.5s\tremaining: 1m 18s\n",
      "2298:\tlearn: 0.9713419\ttest: 1.0191592\tbest: 1.0185411 (1800)\ttotal: 23.5s\tremaining: 1m 18s\n",
      "2299:\tlearn: 0.9713161\ttest: 1.0191555\tbest: 1.0185411 (1800)\ttotal: 23.5s\tremaining: 1m 18s\n",
      "2300:\tlearn: 0.9712996\ttest: 1.0191567\tbest: 1.0185411 (1800)\ttotal: 23.5s\tremaining: 1m 18s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 1.018541103\n",
      "bestIteration = 1800\n",
      "\n",
      "Shrink model to first 1801 iterations.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(iterations=10000,learning_rate=0.005,depth=4) # 3,4,5\n",
    "# Fit model\n",
    "\n",
    "model.fit(X_train.values, np.argmax(y_train.values, axis=1), eval_set=(X_valid.values, np.argmax(y_valid.values, axis=1)), early_stopping_rounds=500)\n",
    "# Get predictions\n",
    "preds = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [2]]\n",
      "0.49939049167005284\n",
      "0.5081284291810607\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(accuracy_score(preds, np.argmax(y_valid.values, axis=1)))\n",
    "print(accuracy_score(model.predict(X_train.values), np.argmax(y_train.values, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/model_dataset_compatibility.cpp:72: Feature 281 is present in model but not in pool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5784\\1799641081.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"catboost\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"catboost\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[0;32m   5255\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mprobability\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mevery\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5256\u001b[0m         \"\"\"\n\u001b[1;32m-> 5257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"CPU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[0;32m   2599\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_prediction_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2601\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2602\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata_is_single_object\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_base_predict\u001b[1;34m(self, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[0;32m   1826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1827\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_base_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1828\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1830\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_base_virtual_ensembles_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvirtual_ensembles_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/model_dataset_compatibility.cpp:72: Feature 281 is present in model but not in pool."
     ]
    }
   ],
   "source": [
    "#model.save_model(\"catboost\")\n",
    "#model.load_model(\"catboost\")\n",
    "#preds = model.predict(X_valid)\n",
    "#print(accuracy_score(preds, np.argmax(y_valid.values, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_home_team_statistics_df = pd.read_csv('./test_home_team_statistics_df.csv', index_col=0)\n",
    "test_away_team_statistics_df = pd.read_csv('./test_away_team_statistics_df.csv', index_col=0)\n",
    "\n",
    "test_home_team_statistics_df.columns = 'HOME_' + test_home_team_statistics_df.columns\n",
    "test_away_team_statistics_df.columns = 'AWAY_' + test_away_team_statistics_df.columns\n",
    "\n",
    "test_data = test_home_team_statistics_df.join(test_away_team_statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PLAYER_CAPTAIN_5_last_match_average', 'PLAYER_CAPTAIN_5_last_match_std', 'PLAYER_CAPTAIN_season_average', 'PLAYER_CAPTAIN_season_std', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_average', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_std', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_sum', 'PLAYER_LONG_BALLS_5_last_match_average', 'PLAYER_LONG_BALLS_5_last_match_std', 'PLAYER_LONG_BALLS_5_last_match_sum', 'PLAYER_LONG_BALLS_WON_5_last_match_average', 'PLAYER_LONG_BALLS_WON_5_last_match_std', 'PLAYER_LONG_BALLS_WON_5_last_match_sum', 'PLAYER_LONG_BALLS_WON_season_average', 'PLAYER_LONG_BALLS_WON_season_std', 'PLAYER_LONG_BALLS_WON_season_sum', 'PLAYER_LONG_BALLS_season_average', 'PLAYER_LONG_BALLS_season_std', 'PLAYER_LONG_BALLS_season_sum', 'PLAYER_PENALTIES_SAVED_5_last_match_average', 'PLAYER_PENALTIES_SAVED_5_last_match_std', 'PLAYER_PENALTIES_SAVED_5_last_match_sum', 'PLAYER_PENALTIES_SAVED_season_average', 'PLAYER_PENALTIES_SAVED_season_std', 'PLAYER_PENALTIES_SAVED_season_sum', 'PLAYER_PENALTIES_WON_5_last_match_average', 'PLAYER_PENALTIES_WON_5_last_match_std', 'PLAYER_PENALTIES_WON_5_last_match_sum', 'PLAYER_PENALTIES_WON_season_average', 'PLAYER_PENALTIES_WON_season_std', 'PLAYER_PENALTIES_WON_season_sum', 'PLAYER_PUNCHES_5_last_match_average', 'PLAYER_PUNCHES_5_last_match_std', 'PLAYER_PUNCHES_5_last_match_sum', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_average', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_std', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_sum', 'PLAYER_SAVES_INSIDE_BOX_season_average', 'PLAYER_SAVES_INSIDE_BOX_season_std', 'PLAYER_SAVES_INSIDE_BOX_season_sum', 'PLAYER_SAVES_season_average', 'PLAYER_SAVES_season_sum', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_average', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_std', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_sum', 'PLAYER_SHOTS_OFF_TARGET_season_average', 'PLAYER_SHOTS_OFF_TARGET_season_std', 'PLAYER_SHOTS_OFF_TARGET_season_sum']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "test_home_player_statistics_df = pd.read_csv('./test_home_player_statistics_df.csv', index_col=0)\n",
    "test_away_player_statistics_df = pd.read_csv('./test_away_player_statistics_df.csv', index_col=0)\n",
    "\n",
    "lin_model_position = pickle.load(open(\"pos_model\", \"rb\"))\n",
    "encoding = [\"attacker\", \"defender\", \"goalkeeper\", \"midfielder\"]\n",
    "\n",
    "\n",
    "test_home_player_statistics_df.loc[test_home_player_statistics_df.isna()[\"POSITION\"],\"POSITION\"] = (np.array(encoding)[lin_model_position.predict(test_home_player_statistics_df.iloc[:,1:].replace({np.nan:0.0}))])[test_home_player_statistics_df.isna()[\"POSITION\"]]\n",
    "test_away_player_statistics_df.loc[test_away_player_statistics_df.isna()[\"POSITION\"],\"POSITION\"] = (np.array(encoding)[lin_model_position.predict(test_away_player_statistics_df.iloc[:,1:].replace({np.nan:0.0}))])[test_away_player_statistics_df.isna()[\"POSITION\"]]\n",
    "\n",
    "df = test_away_player_statistics_df.reset_index().groupby([\"POSITION\", \"ID\"], as_index=False).sum()\n",
    "gb_away = df.set_index(\"ID\").groupby(\"POSITION\")\n",
    "positions = [\"attacker\", \"goalkeeper\", \"midfielder\", \"defender\"]\n",
    "m1 = np.intersect1d(gb_away.get_group(positions[0]).index, gb_away.get_group(positions[1]).index)\n",
    "m2 = np.intersect1d(gb_away.get_group(positions[2]).index, gb_away.get_group(positions[3]).index)\n",
    "away_m = np.intersect1d(m1, m2)\n",
    "\n",
    "df = test_home_player_statistics_df.reset_index().groupby([\"POSITION\", \"ID\"], as_index=False).sum()\n",
    "gb_home = df.set_index(\"ID\").groupby(\"POSITION\")\n",
    "m1 = np.intersect1d(gb_home.get_group(positions[0]).index, gb_home.get_group(positions[1]).index)\n",
    "m2 = np.intersect1d(gb_home.get_group(positions[2]).index, gb_home.get_group(positions[3]).index)\n",
    "home_m = np.intersect1d(m1, m2)\n",
    "\n",
    "m = np.intersect1d(away_m, home_m)\n",
    "\n",
    "test_player_data = []\n",
    "useless_features = open(\"lines.txt\", \"r\").readlines()\n",
    "useless_features = [ft[:-1] for ft in useless_features]\n",
    "print(useless_features)\n",
    "for pos in positions:\n",
    "    df_home_pos = gb_home.get_group(pos).drop(useless_features, axis=1)\n",
    "    df_away_pos = gb_away.get_group(pos).drop(useless_features, axis=1)\n",
    "    df_home_pos.columns = 'HOME_' + df_home_pos.columns\n",
    "    df_away_pos.columns = 'AWAY_' + df_away_pos.columns\n",
    "    test_player_data.append(df_home_pos.iloc[:,1:].join(df_away_pos.iloc[:,1:]))\n",
    "\n",
    "\n",
    "test_player_data[0].columns = \"ATTACK_\" + test_player_data[0].columns\n",
    "test_player_data[1].columns = \"GOALKEEP_\" + test_player_data[1].columns\n",
    "test_player_data[2].columns = \"MIDFIELD_\" + test_player_data[2].columns\n",
    "test_player_data[3].columns = \"DEFEND_\" + test_player_data[3].columns\n",
    "\n",
    "X_test = test_home_team_statistics_df.loc[m,:].join(test_away_team_statistics_df.loc[m,:].join(test_player_data[0].loc[m,:].join(test_player_data[1].loc[m,:].join(test_player_data[2].loc[m,:].join(test_player_data[3].loc[m,:])))))\n",
    "\n",
    "select_fts = open(\"feature_selection.txt\", \"r\").readlines()\n",
    "select_fts = [ft[:-1] for ft in select_fts]\n",
    "X_test = X_test[select_fts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['bc1.weight', 'bc1.bias', 'bc1.running_mean', 'bc1.running_var', 'bc1.num_batches_tracked', 'bc2.weight', 'bc2.bias', 'bc2.running_mean', 'bc2.running_var', 'bc2.num_batches_tracked', 'att1.in_proj_weight', 'att1.in_proj_bias', 'att1.out_proj.weight', 'att1.out_proj.bias', 'fc1.weight', 'fc1.bias', 'fc3.weight', 'fc3.bias'])\n",
      "team :  0.4999593595058116\n",
      "player :  0.5446523120367102\n"
     ]
    }
   ],
   "source": [
    "team_model = MatchTeamClassifier(3, 280, (300,))\n",
    "#player_model = MatchTeamClassifier(3, 512, (256,))\n",
    "\n",
    "team_state = torch.load(\"MCT_params_best\")\n",
    "for key in list(team_state.keys()):\n",
    "    team_state[key.replace('att2', 'att1').replace('fc2', 'fc3')] = team_state.pop(key)\n",
    "\n",
    "print(team_state.keys())\n",
    "\n",
    "\n",
    "team_model.load_state_dict(team_state)\n",
    "#player_model.load_state_dict(torch.load(\"MCT_P_params_best_min\"))\n",
    "player_model = model\n",
    "\n",
    "y_player = player_model.predict(X_train.values)\n",
    "y_team = team_model(torch.Tensor(train_data.replace({np.nan:0.0}).values))\n",
    "print(\"team : \", accuracy_score(torch.argmax(y_team, axis=1), torch.argmax(torch.Tensor(train_scores.values), axis=1)))\n",
    "print(\"player : \", accuracy_score(y_player, np.argmax(y_train.values, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'player_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27004\\3901515208.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#y_pred = player_model(torch.Tensor(X_test.replace({np.nan:0.0}).values))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#scores = torch.argmax(y_pred, axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplayer_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'player_model' is not defined"
     ]
    }
   ],
   "source": [
    "#net.eval()\n",
    "d = {'HOME_WINS':[0 for i in range(len(test_data))], 'DRAW':[0 for i in range(len(test_data))], \"AWAY_WINS\":[0 for i in range(len(test_data))]}\n",
    "test_score = pd.DataFrame(data=d, index=test_home_team_statistics_df.index)\n",
    "#y_pred = player_model(torch.Tensor(X_test.replace({np.nan:0.0}).values))\n",
    "#scores = torch.argmax(y_pred, axis=1)\n",
    "y_pred = player_model.predict(X_test.values)\n",
    "scores = y_pred[:,0]\n",
    "\n",
    "test_score.loc[m[scores == 0], \"HOME_WINS\"] = 1\n",
    "test_score.loc[m[scores == 1], \"DRAW\"] = 1\n",
    "test_score.loc[m[scores == 2], \"AWAY_WINS\"] = 1\n",
    "\n",
    "y_pred = team_model(torch.Tensor(test_data.replace({np.nan:0.0}).values))\n",
    "team_scores = np.array(torch.argmax(y_pred, axis=1))\n",
    "test_score.iloc[(test_score[\"HOME_WINS\"] == 0) & (test_score[\"DRAW\"] == 0) & (test_score[\"AWAY_WINS\"] == 0) & (team_scores == 0), 0] = 1\n",
    "test_score.iloc[(test_score[\"HOME_WINS\"] == 0) & (test_score[\"DRAW\"] == 0) & (test_score[\"AWAY_WINS\"] == 0) & (team_scores == 1), 1] = 1\n",
    "test_score.iloc[(test_score[\"HOME_WINS\"] == 0) & (test_score[\"DRAW\"] == 0) & (test_score[\"AWAY_WINS\"] == 0) & (team_scores == 2), 2] = 1\n",
    "\n",
    "test_score.reset_index(inplace=True)\n",
    "test_score.to_csv(\"Catboost.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_fts = open(\"team_fs.txt\", \"r\").readlines()\n",
    "select_fts = [ft[:-1] for ft in select_fts]\n",
    "test_data = test_data[select_fts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'HOME_WINS':[0 for i in range(len(test_data))], 'DRAW':[0 for i in range(len(test_data))], \"AWAY_WINS\":[0 for i in range(len(test_data))]}\n",
    "test_score = pd.DataFrame(data=d, index=test_home_team_statistics_df.index)\n",
    "\n",
    "y_pred = model.predict(test_data.values)\n",
    "team_scores = y_pred[:,0]\n",
    "test_score.iloc[team_scores == 0, 0] = 1\n",
    "test_score.iloc[team_scores == 1, 1] = 1\n",
    "test_score.iloc[team_scores == 2, 2] = 1\n",
    "\n",
    "test_score.reset_index(inplace=True)\n",
    "test_score.to_csv(\"CatboostTeam.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
