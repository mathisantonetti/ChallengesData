{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0229)\n",
      "tensor(0.0406)\n"
     ]
    }
   ],
   "source": [
    "def RFF_sample(n, shape):\n",
    "    w = torch.randn(n)\n",
    "    phi = 2*np.pi*torch.rand(n)\n",
    "    if(shape == 2):\n",
    "        return lambda x:np.sqrt(2)*torch.cos(w[:,None]*x[None,:]+phi[:,None])\n",
    "    else:\n",
    "        return lambda x:np.sqrt(2)*torch.cos(w[:,None,None]*x[None,:,:]+phi[:,None,None])\n",
    "\n",
    "def hat_sigma(A, B, weights):\n",
    "    nA, n, _ = A.shape\n",
    "    wA = (weights[None,:, None]*A - torch.mean(weights[None,:, None]*A, axis=1)[:, None, :]).transpose(0,1).transpose(1,2)[:,:,:,None]\n",
    "    wB = (weights[None, :]*B - torch.mean(weights[None, :]*B, axis=1)[:, None]).transpose(0,1)[:,None,None,:]\n",
    "    return torch.sum(wA*wB, axis=0)/(n-1)\n",
    "\n",
    "def F_norm2(A, i):\n",
    "    return torch.sum(A**2) - torch.sum(A[i]**2)\n",
    "\n",
    "u, v = RFF_sample(5,3), RFF_sample(5,2)\n",
    "X, Y = torch.randn((10000, 64)), torch.randn(10000)\n",
    "print(F_norm2(hat_sigma(u(X), v(Y), torch.ones(10000)), 0))\n",
    "print(F_norm2(hat_sigma(u(X), v(X[:,0]**2), torch.ones(10000)), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class AttentionRepresentation(nn.Module):\n",
    "    def __init__(self, n_team_fts, hidden_team):\n",
    "        super().__init__()\n",
    "        self.hidden = hidden_team\n",
    "        self.bc1 = nn.BatchNorm1d(n_team_fts)\n",
    "        self.bc2 = nn.BatchNorm1d(hidden_team)\n",
    "        self.att1 = nn.MultiheadAttention(hidden_team, 1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(n_team_fts, hidden_team)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.bc2(self.fc1(self.bc1(x)))[:,None,:]\n",
    "        res = self.att1(res, res, res, need_weights=False)[0]\n",
    "        return res[:,0,:]\n",
    "    \n",
    "    def activate(self, require):\n",
    "        self.bc1.requires_grad_(require)\n",
    "        self.bc2.requires_grad_(require)\n",
    "        self.att1.requires_grad_(require)\n",
    "        self.fc1.requires_grad_(require)\n",
    "    \n",
    "\n",
    "class MatchTeamClassifier(nn.Module):\n",
    "    def __init__(self, n_class, n_team_fts, hidden_team):\n",
    "        super().__init__()\n",
    "        self.phi = AttentionRepresentation(n_team_fts, hidden_team)\n",
    "        self.fc = nn.Linear(hidden_team, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.phi(x))\n",
    "    \n",
    "    def activate(self, require):\n",
    "        self.phi.activate(require)\n",
    "        self.fc.requires_grad_(require)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_home_team_statistics_df = pd.read_csv('./train_home_team_statistics_df.csv', index_col=0)\n",
    "train_away_team_statistics_df = pd.read_csv('./train_away_team_statistics_df.csv', index_col=0)\n",
    "test_away_team_statistics_df = pd.read_csv('./test_away_team_statistics_df.csv', index_col=0)\n",
    "test_home_team_statistics_df = pd.read_csv('./test_home_team_statistics_df.csv', index_col=0)\n",
    "\n",
    "\n",
    "train_scores = pd.read_csv('./Y_train.csv', index_col=0)\n",
    "\n",
    "train_home_team_statistics_df.columns = 'HOME_' + train_home_team_statistics_df.columns\n",
    "train_away_team_statistics_df.columns = 'AWAY_' + train_away_team_statistics_df.columns\n",
    "\n",
    "train_data = train_home_team_statistics_df.iloc[:,2:].join(train_away_team_statistics_df.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(train_data, train_scores, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2461, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MatchTeamClassifier(3, 280, 64)\n",
    "\n",
    "x_train = torch.Tensor(X_train.replace({np.nan:0.0}).values)\n",
    "x_valid = torch.Tensor(X_valid.replace({np.nan:0.0}).values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "Y_valid = torch.Tensor(y_valid.values)\n",
    "\n",
    "print(net(x_valid).shape)\n",
    "net.phi.bc1.requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22456\\3892290128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFF_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRFF_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize_constr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFrobenius_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mub\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torchmin\\minimize_constr.py\u001b[0m in \u001b[0;36mminimize_constr\u001b[1;34m(f, x0, constr, bounds, max_iter, tol, callback, disp, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;31m# optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0mx0_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     result = minimize(\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mf_with_jac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'trust-constr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mhess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_hess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    709\u001b[0m                               constraints, callback=callback, **options)\n\u001b[0;32m    710\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'trust-constr'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m         res = _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[0m\u001b[0;32m    712\u001b[0m                                            \u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                                            callback=callback, **options)\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\minimize_trustregion_constr.py\u001b[0m in \u001b[0;36m_minimize_trustregion_constr\u001b[1;34m(fun, x0, args, grad, hess, hessp, bounds, constraints, xtol, gtol, barrier_tol, sparse_jacobian, callback, maxiter, verbose, finite_diff_rel_step, initial_constr_penalty, initial_tr_radius, initial_barrier_parameter, initial_barrier_tolerance, factorization_method, disp)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;31m# Prepare constraints.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     prepared_constraints = [\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[0mPreparedConstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_jacobian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinite_diff_bounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         for c in constraints]\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\minimize_trustregion_constr.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;31m# Prepare constraints.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     prepared_constraints = [\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mPreparedConstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_jacobian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinite_diff_bounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         for c in constraints]\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_constraints.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, constraint, x0, sparse_jacobian, finite_diff_bounds)\u001b[0m\n\u001b[0;32m    326\u001b[0m                  finite_diff_bounds=(-np.inf, np.inf)):\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNonlinearConstraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             fun = VectorFunction(constraint.fun, x0,\n\u001b[0m\u001b[0;32m    329\u001b[0m                                  \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                                  \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinite_diff_rel_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, jac, hess, finite_diff_rel_step, finite_diff_jac_sparsity, finite_diff_bounds, sparse_jacobian)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;31m# Define Hessian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnhev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torchmin\\minimize_constr.py\u001b[0m in \u001b[0;36mf_hess\u001b[1;34m(x, v)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mhvp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhvp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     return NonlinearConstraint(\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, shape, matvec, rmatvec, matmat, dtype, rmatmat)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__matmat_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatmat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_matmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m_init_dtype\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_matmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36mmatvec\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m_matvec\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_matvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__matvec_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_rmatvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torchmin\\minimize_constr.py\u001b[0m in \u001b[0;36mmatvec\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mhvp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhvp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    301\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "from torchmin import minimize_constr\n",
    "def Frobenius_loss(A, B, u, v):\n",
    "    _, d = B.shape\n",
    "    def Loss(weights):\n",
    "        loss = torch.tensor(0.0)\n",
    "        for i in range(d):\n",
    "            loss += F_norm2(hat_sigma(u(A), v(B[:,i]), weights), i)\n",
    "        return loss\n",
    "    return Loss\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "u, v = RFF_sample(5,3), RFF_sample(5,2)\n",
    "X, Y = net.phi(x_train), net.phi(x_train)\n",
    "res = minimize_constr(Frobenius_loss(net.phi(x_train), net.phi(x_train), u, v), torch.ones(x_train.shape[0]), max_iter=10, constr=dict(fun=lambda x: x.mean(), lb=1, ub=1),disp=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moy(w) =  0.9950252175331116\n",
      "moy(w) =  0.9900636076927185\n",
      "Epoch 0 Loss 1.12 | Train Accuracy 0.3173135541556594 | Val Accuracy 0.4380333197887038\n",
      "moy(w) =  0.9851794838905334\n",
      "moy(w) =  0.9802584648132324\n",
      "Epoch 1 Loss 1.03 | Train Accuracy 0.46108514529567163 | Val Accuracy 0.4668833807395368\n",
      "moy(w) =  0.9753408432006836\n",
      "moy(w) =  0.9704300761222839\n",
      "Epoch 2 Loss 1.01 | Train Accuracy 0.47835805730542574 | Val Accuracy 0.47622917513206015\n",
      "moy(w) =  0.9656331539154053\n",
      "moy(w) =  0.9609391093254089\n",
      "Epoch 3 Loss 0.99 | Train Accuracy 0.48679130258077624 | Val Accuracy 0.481511580658269\n",
      "moy(w) =  0.9564319252967834\n",
      "moy(w) =  0.9520954489707947\n",
      "Epoch 4 Loss 0.98 | Train Accuracy 0.4899410688884373 | Val Accuracy 0.48029256399837467\n",
      "moy(w) =  0.9479309320449829\n",
      "moy(w) =  0.9439281225204468\n",
      "Epoch 5 Loss 0.97 | Train Accuracy 0.4944117049380207 | Val Accuracy 0.48598130841121495\n",
      "moy(w) =  0.940066933631897\n",
      "moy(w) =  0.9363423585891724\n",
      "Epoch 6 Loss 0.96 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.48273059731816337\n",
      "moy(w) =  0.9327930212020874\n",
      "moy(w) =  0.9294105768203735\n",
      "Epoch 7 Loss 0.95 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4855749695245835\n",
      "moy(w) =  0.9262965321540833\n",
      "moy(w) =  0.923431932926178\n",
      "Epoch 8 Loss 0.94 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4888256806176351\n",
      "moy(w) =  0.9209005236625671\n",
      "moy(w) =  0.9186748266220093\n",
      "Epoch 9 Loss 0.93 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4912637139374238\n",
      "moy(w) =  0.9167683124542236\n",
      "moy(w) =  0.915152370929718\n",
      "Epoch 10 Loss 0.93 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49695245835026414\n",
      "moy(w) =  0.9138127565383911\n",
      "moy(w) =  0.9127227663993835\n",
      "Epoch 11 Loss 0.92 | Train Accuracy 0.5015240804714489 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9118897914886475\n",
      "moy(w) =  0.9112867116928101\n",
      "Epoch 12 Loss 0.92 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4953271028037383\n",
      "moy(w) =  0.9109227657318115\n",
      "moy(w) =  0.9107704758644104\n",
      "Epoch 13 Loss 0.92 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.49207639171068673\n",
      "moy(w) =  0.9108248353004456\n",
      "moy(w) =  0.9110589623451233\n",
      "Epoch 14 Loss 0.92 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9114479422569275\n",
      "moy(w) =  0.9119678735733032\n",
      "Epoch 15 Loss 0.92 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9125861525535583\n",
      "moy(w) =  0.913282573223114\n",
      "Epoch 16 Loss 0.92 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4912637139374238\n",
      "moy(w) =  0.914038360118866\n",
      "moy(w) =  0.9148363471031189\n",
      "Epoch 17 Loss 0.92 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.915678858757019\n",
      "moy(w) =  0.91655033826828\n",
      "Epoch 18 Loss 0.92 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9174525737762451\n",
      "moy(w) =  0.9183725118637085\n",
      "Epoch 19 Loss 0.92 | Train Accuracy 0.5008128429181061 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9193026423454285\n",
      "moy(w) =  0.9202324748039246\n",
      "Epoch 20 Loss 0.93 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4949207639171069\n",
      "moy(w) =  0.921150267124176\n",
      "moy(w) =  0.9220490455627441\n",
      "Epoch 21 Loss 0.93 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9229230880737305\n",
      "moy(w) =  0.9237691760063171\n",
      "Epoch 22 Loss 0.93 | Train Accuracy 0.5028449502133713 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9245898723602295\n",
      "moy(w) =  0.9253836870193481\n",
      "Epoch 23 Loss 0.93 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.49167005282405524\n",
      "moy(w) =  0.9261438846588135\n",
      "moy(w) =  0.9268709421157837\n",
      "Epoch 24 Loss 0.93 | Train Accuracy 0.5030481609428978 | Val Accuracy 0.48963835839089803\n",
      "moy(w) =  0.9275522232055664\n",
      "moy(w) =  0.9281911253929138\n",
      "Epoch 25 Loss 0.94 | Train Accuracy 0.5020321072952652 | Val Accuracy 0.48516863063795207\n",
      "moy(w) =  0.9287912249565125\n",
      "moy(w) =  0.9293565154075623\n",
      "Epoch 26 Loss 0.94 | Train Accuracy 0.4952245478561268 | Val Accuracy 0.4912637139374238\n",
      "moy(w) =  0.9299290180206299\n",
      "moy(w) =  0.9305092692375183\n",
      "Epoch 27 Loss 0.94 | Train Accuracy 0.49654541759804915 | Val Accuracy 0.48963835839089803\n",
      "moy(w) =  0.9311217665672302\n",
      "moy(w) =  0.9317636489868164\n",
      "Epoch 28 Loss 0.94 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4953271028037383\n",
      "moy(w) =  0.9324356913566589\n",
      "moy(w) =  0.933134913444519\n",
      "Epoch 29 Loss 0.95 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.4961397805770012\n",
      "moy(w) =  0.9338531494140625\n",
      "moy(w) =  0.9345877766609192\n",
      "Epoch 30 Loss 0.95 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4888256806176351\n",
      "moy(w) =  0.9353138208389282\n",
      "moy(w) =  0.9360302090644836\n",
      "Epoch 31 Loss 0.95 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49207639171068673\n",
      "moy(w) =  0.936704695224762\n",
      "moy(w) =  0.9373394846916199\n",
      "Epoch 32 Loss 0.95 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49085737505079235\n",
      "moy(w) =  0.9379109740257263\n",
      "moy(w) =  0.9384241700172424\n",
      "Epoch 33 Loss 0.95 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9388720989227295\n",
      "moy(w) =  0.939260721206665\n",
      "Epoch 34 Loss 0.95 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4989841527834214\n",
      "moy(w) =  0.9396164417266846\n",
      "moy(w) =  0.9399427771568298\n",
      "Epoch 35 Loss 0.95 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9402556419372559\n",
      "moy(w) =  0.9405571818351746\n",
      "Epoch 36 Loss 0.95 | Train Accuracy 0.5038610038610039 | Val Accuracy 0.4912637139374238\n",
      "moy(w) =  0.9408561587333679\n",
      "moy(w) =  0.941153347492218\n",
      "Epoch 37 Loss 0.95 | Train Accuracy 0.5 | Val Accuracy 0.4949207639171069\n",
      "moy(w) =  0.94143146276474\n",
      "moy(w) =  0.9416922926902771\n",
      "Epoch 38 Loss 0.95 | Train Accuracy 0.5024385287543183 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9419218897819519\n",
      "moy(w) =  0.9421230554580688\n",
      "Epoch 39 Loss 0.95 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.49207639171068673\n",
      "moy(w) =  0.9422928094863892\n",
      "moy(w) =  0.9424344301223755\n",
      "Epoch 40 Loss 0.96 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9425597190856934\n",
      "moy(w) =  0.9426706433296204\n",
      "Epoch 41 Loss 0.95 | Train Accuracy 0.5019305019305019 | Val Accuracy 0.4928890694839496\n",
      "moy(w) =  0.9427675008773804\n",
      "moy(w) =  0.942852258682251\n",
      "Epoch 42 Loss 0.95 | Train Accuracy 0.5039626092257671 | Val Accuracy 0.49167005282405524\n",
      "moy(w) =  0.9428836703300476\n",
      "moy(w) =  0.9428690075874329\n",
      "Epoch 43 Loss 0.96 | Train Accuracy 0.4994919731761837 | Val Accuracy 0.47947988622511173\n",
      "moy(w) =  0.9428479671478271\n",
      "moy(w) =  0.9428226947784424\n",
      "Epoch 44 Loss 0.96 | Train Accuracy 0.4923795976427555 | Val Accuracy 0.4904510361641609\n",
      "moy(w) =  0.9428433179855347\n",
      "moy(w) =  0.9429064393043518\n",
      "Epoch 45 Loss 0.96 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.4912637139374238\n",
      "moy(w) =  0.943030059337616\n",
      "moy(w) =  0.9432077407836914\n",
      "Epoch 46 Loss 0.96 | Train Accuracy 0.4974598658809185 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9434183239936829\n",
      "moy(w) =  0.943656861782074\n",
      "Epoch 47 Loss 0.96 | Train Accuracy 0.4975614712456818 | Val Accuracy 0.4904510361641609\n",
      "moy(w) =  0.9438960552215576\n",
      "moy(w) =  0.944133996963501\n",
      "Epoch 48 Loss 0.96 | Train Accuracy 0.49603739077423287 | Val Accuracy 0.4928890694839496\n",
      "moy(w) =  0.9443351626396179\n",
      "moy(w) =  0.9445012211799622\n",
      "Epoch 49 Loss 0.96 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4900446972775295\n",
      "moy(w) =  0.9445923566818237\n",
      "moy(w) =  0.9446149468421936\n",
      "Epoch 50 Loss 0.96 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.49167005282405524\n",
      "moy(w) =  0.9445634484291077\n",
      "moy(w) =  0.9444456696510315\n",
      "Epoch 51 Loss 0.96 | Train Accuracy 0.49837431416378786 | Val Accuracy 0.4888256806176351\n",
      "moy(w) =  0.9442857503890991\n",
      "moy(w) =  0.9440895915031433\n",
      "Epoch 52 Loss 0.96 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4949207639171069\n",
      "moy(w) =  0.9438818693161011\n",
      "moy(w) =  0.9436664581298828\n",
      "Epoch 53 Loss 0.96 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49695245835026414\n",
      "moy(w) =  0.9434787631034851\n",
      "moy(w) =  0.9433186054229736\n",
      "Epoch 54 Loss 0.96 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9431939721107483\n",
      "moy(w) =  0.9431030750274658\n",
      "Epoch 55 Loss 0.96 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.48923201950426654\n",
      "moy(w) =  0.9430339932441711\n",
      "moy(w) =  0.9429852962493896\n",
      "Epoch 56 Loss 0.96 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4953271028037383\n",
      "moy(w) =  0.9429209232330322\n",
      "moy(w) =  0.9428428411483765\n",
      "Epoch 57 Loss 0.96 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.4880130028443722\n",
      "moy(w) =  0.9427626132965088\n",
      "moy(w) =  0.9426811933517456\n",
      "Epoch 58 Loss 0.96 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.48923201950426654\n",
      "moy(w) =  0.9425943493843079\n",
      "moy(w) =  0.9425028562545776\n",
      "Epoch 59 Loss 0.96 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4904510361641609\n",
      "moy(w) =  0.9424074292182922\n",
      "moy(w) =  0.9423084855079651\n",
      "Epoch 60 Loss 0.95 | Train Accuracy 0.5022353180247917 | Val Accuracy 0.49167005282405524\n",
      "moy(w) =  0.9422053098678589\n",
      "moy(w) =  0.9420991539955139\n",
      "Epoch 61 Loss 0.95 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.48963835839089803\n",
      "moy(w) =  0.9419772624969482\n",
      "moy(w) =  0.9418436288833618\n",
      "Epoch 62 Loss 0.96 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.4697277529459569\n",
      "moy(w) =  0.9418345093727112\n",
      "moy(w) =  0.9419378042221069\n",
      "Epoch 63 Loss 0.97 | Train Accuracy 0.4829302987197724 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.942188024520874\n",
      "moy(w) =  0.9425678849220276\n",
      "Epoch 64 Loss 0.96 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9430572390556335\n",
      "moy(w) =  0.9436394572257996\n",
      "Epoch 65 Loss 0.96 | Train Accuracy 0.49512294249136357 | Val Accuracy 0.4900446972775295\n",
      "moy(w) =  0.9442704319953918\n",
      "moy(w) =  0.944937527179718\n",
      "Epoch 66 Loss 0.97 | Train Accuracy 0.49359886201991465 | Val Accuracy 0.4904510361641609\n",
      "moy(w) =  0.9455862641334534\n",
      "moy(w) =  0.9462102055549622\n",
      "Epoch 67 Loss 0.97 | Train Accuracy 0.4948181263970738 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9467552304267883\n",
      "moy(w) =  0.9472223520278931\n",
      "Epoch 68 Loss 0.96 | Train Accuracy 0.4967486283275757 | Val Accuracy 0.4953271028037383\n",
      "moy(w) =  0.947569727897644\n",
      "moy(w) =  0.9478058815002441\n",
      "Epoch 69 Loss 0.96 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.947926938533783\n",
      "moy(w) =  0.9479448199272156\n",
      "Epoch 70 Loss 0.96 | Train Accuracy 0.4970534444218655 | Val Accuracy 0.49207639171068673\n",
      "moy(w) =  0.9479004740715027\n",
      "moy(w) =  0.9478030204772949\n",
      "Epoch 71 Loss 0.96 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9477080702781677\n",
      "moy(w) =  0.9476191401481628\n",
      "Epoch 72 Loss 0.96 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9475730061531067\n",
      "moy(w) =  0.9475690722465515\n",
      "Epoch 73 Loss 0.96 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.4965461194636327\n",
      "moy(w) =  0.9476162791252136\n",
      "moy(w) =  0.9477113485336304\n",
      "Epoch 74 Loss 0.96 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.497765136123527\n",
      "moy(w) =  0.9478440880775452\n",
      "moy(w) =  0.9480108022689819\n",
      "Epoch 75 Loss 0.96 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.4965461194636327\n",
      "moy(w) =  0.9481878280639648\n",
      "moy(w) =  0.9483729600906372\n",
      "Epoch 76 Loss 0.96 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.49817147501015846\n",
      "moy(w) =  0.9485305547714233\n",
      "moy(w) =  0.9486619234085083\n",
      "Epoch 77 Loss 0.96 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.49695245835026414\n",
      "moy(w) =  0.9487519860267639\n",
      "moy(w) =  0.9488046169281006\n",
      "Epoch 78 Loss 0.96 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49817147501015846\n",
      "moy(w) =  0.9488111138343811\n",
      "moy(w) =  0.9487766027450562\n",
      "Epoch 79 Loss 0.96 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9487220644950867\n",
      "moy(w) =  0.9486504793167114\n",
      "Epoch 80 Loss 0.96 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4900446972775295\n",
      "moy(w) =  0.9486007690429688\n",
      "moy(w) =  0.9485718011856079\n",
      "Epoch 81 Loss 0.96 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49085737505079235\n",
      "moy(w) =  0.9485728740692139\n",
      "moy(w) =  0.9486013650894165\n",
      "Epoch 82 Loss 0.96 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9486551284790039\n",
      "moy(w) =  0.9487316608428955\n",
      "Epoch 83 Loss 0.96 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.4953271028037383\n",
      "moy(w) =  0.9487876296043396\n",
      "moy(w) =  0.948826014995575\n",
      "Epoch 84 Loss 0.96 | Train Accuracy 0.5 | Val Accuracy 0.48476229175132063\n",
      "moy(w) =  0.9489712715148926\n",
      "moy(w) =  0.9492117762565613\n",
      "Epoch 85 Loss 0.98 | Train Accuracy 0.48831538305222516 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9495475888252258\n",
      "moy(w) =  0.9499658346176147\n",
      "Epoch 86 Loss 0.97 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.48923201950426654\n",
      "moy(w) =  0.9504575729370117\n",
      "moy(w) =  0.9510101675987244\n",
      "Epoch 87 Loss 0.97 | Train Accuracy 0.4909571225360699 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.951599657535553\n",
      "moy(w) =  0.9522156119346619\n",
      "Epoch 88 Loss 0.97 | Train Accuracy 0.4934972566551514 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9528141021728516\n",
      "moy(w) =  0.9533899426460266\n",
      "Epoch 89 Loss 0.97 | Train Accuracy 0.4977646819752083 | Val Accuracy 0.49410808614384394\n",
      "moy(w) =  0.9538899064064026\n",
      "moy(w) =  0.954316258430481\n",
      "Epoch 90 Loss 0.97 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.49167005282405524\n",
      "moy(w) =  0.9546413421630859\n",
      "moy(w) =  0.9548729062080383\n",
      "Epoch 91 Loss 0.97 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4912637139374238\n",
      "moy(w) =  0.9550351500511169\n",
      "moy(w) =  0.9551355838775635\n",
      "Epoch 92 Loss 0.97 | Train Accuracy 0.4980694980694981 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9552069306373596\n",
      "moy(w) =  0.9552542567253113\n",
      "Epoch 93 Loss 0.97 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9553022980690002\n",
      "moy(w) =  0.9553535580635071\n",
      "Epoch 94 Loss 0.97 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49410808614384394\n",
      "moy(w) =  0.9554229378700256\n",
      "moy(w) =  0.955510139465332\n",
      "Epoch 95 Loss 0.97 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9556216597557068\n",
      "moy(w) =  0.9557559490203857\n",
      "Epoch 96 Loss 0.97 | Train Accuracy 0.5002032107295266 | Val Accuracy 0.4928890694839496\n",
      "moy(w) =  0.9559088349342346\n",
      "moy(w) =  0.9560785889625549\n",
      "Epoch 97 Loss 0.97 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.497765136123527\n",
      "moy(w) =  0.9562466144561768\n",
      "moy(w) =  0.9564120769500732\n",
      "Epoch 98 Loss 0.97 | Train Accuracy 0.4992887624466572 | Val Accuracy 0.4965461194636327\n",
      "moy(w) =  0.9565483331680298\n",
      "moy(w) =  0.956657350063324\n",
      "Epoch 99 Loss 0.97 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.4973587972368956\n",
      "moy(w) =  0.9567236304283142\n",
      "moy(w) =  0.9567514657974243\n",
      "Epoch 100 Loss 0.97 | Train Accuracy 0.49959357854094694 | Val Accuracy 0.4961397805770012\n",
      "moy(w) =  0.9567621350288391\n",
      "moy(w) =  0.9567583799362183\n",
      "Epoch 101 Loss 0.97 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9567562937736511\n",
      "moy(w) =  0.9567564129829407\n",
      "Epoch 102 Loss 0.97 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.48923201950426654\n",
      "moy(w) =  0.9567654132843018\n",
      "moy(w) =  0.9567831754684448\n",
      "Epoch 103 Loss 0.97 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9567975997924805\n",
      "moy(w) =  0.9568109512329102\n",
      "Epoch 104 Loss 0.97 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.48232425843153187\n",
      "moy(w) =  0.9569313526153564\n",
      "moy(w) =  0.9571470618247986\n",
      "Epoch 105 Loss 0.99 | Train Accuracy 0.4899410688884373 | Val Accuracy 0.4949207639171069\n",
      "moy(w) =  0.9574651718139648\n",
      "moy(w) =  0.957871675491333\n",
      "Epoch 106 Loss 0.97 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9583490490913391\n",
      "moy(w) =  0.9588843584060669\n",
      "Epoch 107 Loss 0.98 | Train Accuracy 0.494513310302784 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9594487547874451\n",
      "moy(w) =  0.9600324630737305\n",
      "Epoch 108 Loss 0.98 | Train Accuracy 0.4942084942084942 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9605989456176758\n",
      "moy(w) =  0.9611433744430542\n",
      "Epoch 109 Loss 0.98 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9616218209266663\n",
      "moy(w) =  0.9620361328125\n",
      "Epoch 110 Loss 0.98 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9623557925224304\n",
      "moy(w) =  0.9625881910324097\n",
      "Epoch 111 Loss 0.98 | Train Accuracy 0.497663076610445 | Val Accuracy 0.49410808614384394\n",
      "moy(w) =  0.9627383947372437\n",
      "moy(w) =  0.9628151059150696\n",
      "Epoch 112 Loss 0.98 | Train Accuracy 0.49786628733997157 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9628482460975647\n",
      "moy(w) =  0.9628446698188782\n",
      "Epoch 113 Loss 0.98 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.4912637139374238\n",
      "moy(w) =  0.9628362655639648\n",
      "moy(w) =  0.9628264307975769\n",
      "Epoch 114 Loss 0.98 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4949207639171069\n",
      "moy(w) =  0.9628364443778992\n",
      "moy(w) =  0.9628667831420898\n",
      "Epoch 115 Loss 0.98 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9629256725311279\n",
      "moy(w) =  0.9630115032196045\n",
      "Epoch 116 Loss 0.98 | Train Accuracy 0.5012192643771591 | Val Accuracy 0.4965461194636327\n",
      "moy(w) =  0.9631211161613464\n",
      "moy(w) =  0.963252604007721\n",
      "Epoch 117 Loss 0.98 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.4973587972368956\n",
      "moy(w) =  0.9633905291557312\n",
      "moy(w) =  0.9635334014892578\n",
      "Epoch 118 Loss 0.98 | Train Accuracy 0.5003048160942898 | Val Accuracy 0.4985778138967899\n",
      "moy(w) =  0.9636616110801697\n",
      "moy(w) =  0.9637753963470459\n",
      "Epoch 119 Loss 0.98 | Train Accuracy 0.5010160536476326 | Val Accuracy 0.49817147501015846\n",
      "moy(w) =  0.9638596177101135\n",
      "moy(w) =  0.9639167189598083\n",
      "Epoch 120 Loss 0.98 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49695245835026414\n",
      "moy(w) =  0.9639626145362854\n",
      "moy(w) =  0.9639987349510193\n",
      "Epoch 121 Loss 0.98 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9640220999717712\n",
      "moy(w) =  0.9640340805053711\n",
      "Epoch 122 Loss 0.98 | Train Accuracy 0.5005080268238163 | Val Accuracy 0.49207639171068673\n",
      "moy(w) =  0.9640530347824097\n",
      "moy(w) =  0.9640782475471497\n",
      "Epoch 123 Loss 0.98 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.48923201950426654\n",
      "moy(w) =  0.9641104936599731\n",
      "moy(w) =  0.9641485810279846\n",
      "Epoch 124 Loss 0.98 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4863876472978464\n",
      "moy(w) =  0.964227557182312\n",
      "moy(w) =  0.9643429517745972\n",
      "Epoch 125 Loss 0.98 | Train Accuracy 0.4971550497866287 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9645005464553833\n",
      "moy(w) =  0.9646942019462585\n",
      "Epoch 126 Loss 0.98 | Train Accuracy 0.49888234098760414 | Val Accuracy 0.4912637139374238\n",
      "moy(w) =  0.9649271965026855\n",
      "moy(w) =  0.9651926159858704\n",
      "Epoch 127 Loss 0.98 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.49167005282405524\n",
      "moy(w) =  0.9654796719551086\n",
      "moy(w) =  0.9657825827598572\n",
      "Epoch 128 Loss 0.98 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49085737505079235\n",
      "moy(w) =  0.9660806655883789\n",
      "moy(w) =  0.9663708209991455\n",
      "Epoch 129 Loss 0.98 | Train Accuracy 0.502743344848608 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9666221141815186\n",
      "moy(w) =  0.9668356776237488\n",
      "Epoch 130 Loss 0.98 | Train Accuracy 0.5014224751066856 | Val Accuracy 0.49085737505079235\n",
      "moy(w) =  0.9669912457466125\n",
      "moy(w) =  0.9670931696891785\n",
      "Epoch 131 Loss 0.98 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.967144250869751\n",
      "moy(w) =  0.9671505093574524\n",
      "Epoch 132 Loss 0.98 | Train Accuracy 0.5011176590123958 | Val Accuracy 0.49410808614384394\n",
      "moy(w) =  0.9671307802200317\n",
      "moy(w) =  0.9670894145965576\n",
      "Epoch 133 Loss 0.98 | Train Accuracy 0.5034545824019508 | Val Accuracy 0.49573344169036976\n",
      "moy(w) =  0.9670482873916626\n",
      "moy(w) =  0.9670091867446899\n",
      "Epoch 134 Loss 0.98 | Train Accuracy 0.5009144482828694 | Val Accuracy 0.4949207639171069\n",
      "moy(w) =  0.9669943451881409\n",
      "moy(w) =  0.9670025706291199\n",
      "Epoch 135 Loss 0.98 | Train Accuracy 0.5006096321885796 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9670385122299194\n",
      "moy(w) =  0.9671000242233276\n",
      "Epoch 136 Loss 0.98 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.48841934173100365\n",
      "moy(w) =  0.9671874046325684\n",
      "moy(w) =  0.9672979712486267\n",
      "Epoch 137 Loss 0.98 | Train Accuracy 0.5029465555781345 | Val Accuracy 0.49207639171068673\n",
      "moy(w) =  0.9674330949783325\n",
      "moy(w) =  0.9675890803337097\n",
      "Epoch 138 Loss 0.98 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9677474498748779\n",
      "moy(w) =  0.96790611743927\n",
      "Epoch 139 Loss 0.98 | Train Accuracy 0.5 | Val Accuracy 0.48923201950426654\n",
      "moy(w) =  0.9680505990982056\n",
      "moy(w) =  0.9681810736656189\n",
      "Epoch 140 Loss 0.98 | Train Accuracy 0.500406421459053 | Val Accuracy 0.48476229175132063\n",
      "moy(w) =  0.9683266878128052\n",
      "moy(w) =  0.9684845805168152\n",
      "Epoch 141 Loss 0.99 | Train Accuracy 0.49613899613899615 | Val Accuracy 0.48963835839089803\n",
      "moy(w) =  0.9686803221702576\n",
      "moy(w) =  0.9689088463783264\n",
      "Epoch 142 Loss 0.99 | Train Accuracy 0.4982727087990246 | Val Accuracy 0.48923201950426654\n",
      "moy(w) =  0.9691892862319946\n",
      "moy(w) =  0.9695131182670593\n",
      "Epoch 143 Loss 0.99 | Train Accuracy 0.4984759195285511 | Val Accuracy 0.4961397805770012\n",
      "moy(w) =  0.969869077205658\n",
      "moy(w) =  0.9702496528625488\n",
      "Epoch 144 Loss 0.99 | Train Accuracy 0.5 | Val Accuracy 0.49207639171068673\n",
      "moy(w) =  0.9706336855888367\n",
      "moy(w) =  0.9710162878036499\n",
      "Epoch 145 Loss 0.99 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.48963835839089803\n",
      "moy(w) =  0.9713754653930664\n",
      "moy(w) =  0.971709668636322\n",
      "Epoch 146 Loss 0.99 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9719963073730469\n",
      "moy(w) =  0.9722374081611633\n",
      "Epoch 147 Loss 0.99 | Train Accuracy 0.49857752489331436 | Val Accuracy 0.49695245835026414\n",
      "moy(w) =  0.9724234938621521\n",
      "moy(w) =  0.97255939245224\n",
      "Epoch 148 Loss 0.99 | Train Accuracy 0.4996951839057102 | Val Accuracy 0.4973587972368956\n",
      "moy(w) =  0.9726549386978149\n",
      "moy(w) =  0.9727147817611694\n",
      "Epoch 149 Loss 0.99 | Train Accuracy 0.5016256858362121 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9727548956871033\n",
      "moy(w) =  0.9727786183357239\n",
      "Epoch 150 Loss 0.99 | Train Accuracy 0.5018288965657387 | Val Accuracy 0.49695245835026414\n",
      "moy(w) =  0.9728022813796997\n",
      "moy(w) =  0.9728271961212158\n",
      "Epoch 151 Loss 0.99 | Train Accuracy 0.5001016053647632 | Val Accuracy 0.49573344169036976\n",
      "moy(w) =  0.9728565812110901\n",
      "moy(w) =  0.9728913307189941\n",
      "Epoch 152 Loss 0.99 | Train Accuracy 0.5017272912009754 | Val Accuracy 0.49695245835026414\n",
      "moy(w) =  0.9729397296905518\n",
      "moy(w) =  0.9730011820793152\n",
      "Epoch 153 Loss 0.99 | Train Accuracy 0.5025401341190815 | Val Accuracy 0.49939049167005284\n",
      "moy(w) =  0.9730807542800903\n",
      "moy(w) =  0.9731767773628235\n",
      "Epoch 154 Loss 0.99 | Train Accuracy 0.500406421459053 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.973289966583252\n",
      "moy(w) =  0.9734178781509399\n",
      "Epoch 155 Loss 0.99 | Train Accuracy 0.5013208697419224 | Val Accuracy 0.49695245835026414\n",
      "moy(w) =  0.9735546112060547\n",
      "moy(w) =  0.9736983180046082\n",
      "Epoch 156 Loss 0.99 | Train Accuracy 0.5021337126600285 | Val Accuracy 0.4928890694839496\n",
      "moy(w) =  0.9738288521766663\n",
      "moy(w) =  0.9739463329315186\n",
      "Epoch 157 Loss 0.99 | Train Accuracy 0.5007112375533428 | Val Accuracy 0.49207639171068673\n",
      "moy(w) =  0.9740169048309326\n",
      "moy(w) =  0.9740461707115173\n",
      "Epoch 158 Loss 0.99 | Train Accuracy 0.4997967892704735 | Val Accuracy 0.4668833807395368\n",
      "moy(w) =  0.9741443991661072\n",
      "moy(w) =  0.9743045568466187\n",
      "Epoch 159 Loss 1.00 | Train Accuracy 0.48130461288356025 | Val Accuracy 0.4961397805770012\n",
      "moy(w) =  0.9745454788208008\n",
      "moy(w) =  0.974856436252594\n",
      "Epoch 160 Loss 0.99 | Train Accuracy 0.497663076610445 | Val Accuracy 0.4880130028443722\n",
      "moy(w) =  0.9752321839332581\n",
      "moy(w) =  0.9756619334220886\n",
      "Epoch 161 Loss 1.00 | Train Accuracy 0.4934972566551514 | Val Accuracy 0.48923201950426654\n",
      "moy(w) =  0.9761331677436829\n",
      "moy(w) =  0.9766361117362976\n",
      "Epoch 162 Loss 1.00 | Train Accuracy 0.4919731761837025 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9771579504013062\n",
      "moy(w) =  0.9776901006698608\n",
      "Epoch 163 Loss 1.00 | Train Accuracy 0.4940052834789677 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9782056212425232\n",
      "moy(w) =  0.9787002801895142\n",
      "Epoch 164 Loss 1.00 | Train Accuracy 0.4979678927047348 | Val Accuracy 0.4924827305973182\n",
      "moy(w) =  0.9791369438171387\n",
      "moy(w) =  0.9795172214508057\n",
      "Epoch 165 Loss 1.00 | Train Accuracy 0.4973582605161552 | Val Accuracy 0.49451442503047544\n",
      "moy(w) =  0.9798089861869812\n",
      "moy(w) =  0.9800191521644592\n",
      "Epoch 166 Loss 1.00 | Train Accuracy 0.497256655151392 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9801398515701294\n",
      "moy(w) =  0.9801807999610901\n",
      "Epoch 167 Loss 1.00 | Train Accuracy 0.49908555171713065 | Val Accuracy 0.49410808614384394\n",
      "moy(w) =  0.9801635146141052\n",
      "moy(w) =  0.9800970554351807\n",
      "Epoch 168 Loss 1.00 | Train Accuracy 0.49867913025807764 | Val Accuracy 0.4937017472572125\n",
      "moy(w) =  0.9800164103507996\n",
      "moy(w) =  0.9799268841743469\n",
      "Epoch 169 Loss 1.00 | Train Accuracy 0.4989839463523674 | Val Accuracy 0.49329540837058106\n",
      "moy(w) =  0.9798595309257507\n",
      "moy(w) =  0.9798147678375244\n",
      "Epoch 170 Loss 1.00 | Train Accuracy 0.49878073562284087 | Val Accuracy 0.49695245835026414\n",
      "moy(w) =  0.9798102974891663\n",
      "moy(w) =  0.9798438549041748\n",
      "Epoch 171 Loss 1.00 | Train Accuracy 0.4998983946352367 | Val Accuracy 0.49817147501015846\n",
      "moy(w) =  0.9799182415008545\n",
      "moy(w) =  0.9800301790237427\n",
      "Epoch 172 Loss 1.00 | Train Accuracy 0.49939036781142043 | Val Accuracy 0.49817147501015846\n",
      "moy(w) =  0.9801695942878723\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25496\\2839418620.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mF_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mF_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mF_norm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhat_sigma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mF_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25496\\1254223299.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matt1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 v_proj_weight=self.v_proj_weight, average_attn_weights=average_attn_weights)\n\u001b[0;32m   1166\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[0;32m   1168\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[0;32m   5104\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatic_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5105\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstatic_v\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5106\u001b[1;33m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbsz\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5107\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5108\u001b[0m         \u001b[1;31m# TODO finish disentangling control flow so we don't do in-projections when statics are passed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "torch.set_flush_denormal(True)\n",
    "N_EPOCHS = 10000 # + 100\n",
    "net.train()\n",
    "criterion = nn.CrossEntropyLoss(reduction='none') # loss\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.005, weight_decay=5e-2)\n",
    "\n",
    "sample_weights = torch.ones(x_train.shape[0])\n",
    "weights_optimizer = torch.optim.Adam([sample_weights], lr=0.005, weight_decay=5e-2)\n",
    "u, v = RFF_sample(5,3), RFF_sample(5,2)\n",
    "weight_rate = 2\n",
    "\n",
    "train_accuracies = [1.0]\n",
    "val_accuracies = [1.0]\n",
    "val_check = 1\n",
    "best_state, best_val = None, 0.0\n",
    "for epoch in range(N_EPOCHS):  # loop over the dataset multiple times\n",
    "    # Iterate over batches and perform optimizer step on the model.\n",
    "    sample_weights.requires_grad_(False)\n",
    "    net.activate(True)\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net(x_train)\n",
    "    loss = criterion(y_pred, Y_train)\n",
    "    loss = (loss*sample_weights).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # perform optimizer step on the sample weights\n",
    "    sample_weights.requires_grad_(True)\n",
    "    net.activate(False)\n",
    "\n",
    "    for j in range(weight_rate):\n",
    "        weights_optimizer.zero_grad()\n",
    "        F_loss = torch.tensor(0.0)\n",
    "        for i in range(64):\n",
    "            F_loss += F_norm2(hat_sigma(u(net.phi(x_train)), v(net.phi(x_train)[:,i]), sample_weights), i)\n",
    "    \n",
    "        F_loss += 500/(sample_weights).mean()\n",
    "        F_loss.backward()\n",
    "        weights_optimizer.step()\n",
    "        print(\"moy(w) = \", sample_weights.mean().item())\n",
    "        \n",
    "    train_acc, val_acc = accuracy_score(torch.argmax(y_pred, axis=1), torch.argmax(Y_train, axis=1)), val_accuracies[-1]\n",
    "    if(epoch % val_check == 0):\n",
    "        hat_y_val = net(x_valid)\n",
    "        #val_loss = criterion(hat_y_val, y_val)\n",
    "        val_acc = accuracy_score(torch.argmax(hat_y_val, axis=1), torch.argmax(Y_valid, axis=1))\n",
    "        if(val_acc > best_val):\n",
    "            best_val = val_acc\n",
    "            best_state = copy.deepcopy(net.state_dict())\n",
    "\n",
    "    val_accuracies.append(val_acc)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(f\"Epoch {epoch} Loss {loss.detach().cpu().numpy():.2f} | Train Accuracy {train_acc} | Val Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(len(train_accuracies[1:])), train_accuracies[1:], label = \"train\")\n",
    "plt.plot(np.arange(len(train_accuracies[1:])), val_accuracies[1:], label = \"val\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0.44, 0.57)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_state, \"MCTstable_params_best_r_2\")\n",
    "torch.save(net.state_dict(), \"MCTstable_params_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5003657644476956\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"MCTstable_params_best_r_2\"))\n",
    "print(accuracy_score(torch.argmax(net(torch.Tensor(train_data.replace({np.nan:0.0}).values)), axis=1), torch.argmax(torch.tensor(train_scores.values), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "test_away_team_statistics_df = pd.read_csv('./test_away_team_statistics_df.csv', index_col=0)\n",
    "test_home_team_statistics_df = pd.read_csv('./test_home_team_statistics_df.csv', index_col=0)\n",
    "\n",
    "test_home_team_statistics_df.columns = 'HOME_' + test_home_team_statistics_df.columns\n",
    "test_away_team_statistics_df.columns = 'AWAY_' + test_away_team_statistics_df.columns\n",
    "\n",
    "test_data = test_home_team_statistics_df.join(test_away_team_statistics_df)\n",
    "\n",
    "d = {'HOME_WINS':[0 for i in range(len(test_data))], 'DRAW':[0 for i in range(len(test_data))], \"AWAY_WINS\":[0 for i in range(len(test_data))]}\n",
    "test_score = pd.DataFrame(data=d, index=test_home_team_statistics_df.index)\n",
    "\n",
    "y_pred = net(torch.Tensor(test_data.replace({np.nan:0.0}).values))\n",
    "team_scores = torch.argmax(y_pred, axis=1)\n",
    "print(team_scores)\n",
    "test_score.iloc[team_scores == 0, 0] = 1\n",
    "test_score.iloc[team_scores == 1, 1] = 1\n",
    "test_score.iloc[team_scores == 2, 2] = 1\n",
    "\n",
    "test_score.reset_index(inplace=True)\n",
    "test_score.to_csv(\"MCTstable.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
