{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0148)\n",
      "tensor(0.0175)\n"
     ]
    }
   ],
   "source": [
    "def RFF_sample(n, shape):\n",
    "    w = torch.randn(n)\n",
    "    phi = 2*np.pi*torch.rand(n)\n",
    "    if(shape == 2):\n",
    "        return lambda x:np.sqrt(2)*torch.cos(w[:,None]*x[None,:]+phi[:,None])\n",
    "    else:\n",
    "        return lambda x:np.sqrt(2)*torch.cos(w[:,None,None]*x[None,:,:]+phi[:,None,None])\n",
    "\n",
    "def hat_sigma(A, B, weights):\n",
    "    nA, n, _ = A.shape\n",
    "    wA = (weights[None,:, None]*A - torch.mean(weights[None,:, None]*A, axis=1)[:, None, :]).transpose(0,1).transpose(1,2)[:,:,:,None]\n",
    "    wB = (weights[None, :]*B - torch.mean(weights[None, :]*B, axis=1)[:, None]).transpose(0,1)[:,None,None,:]\n",
    "    return torch.sum(wA*wB, axis=0)/(n-1)\n",
    "\n",
    "def F_norm2(A, i):\n",
    "    return torch.sum(A**2) - torch.sum(A[i]**2)\n",
    "\n",
    "u, v = RFF_sample(5,3), RFF_sample(5,2)\n",
    "X, Y = torch.randn((10000, 64)), torch.randn(10000)\n",
    "print(F_norm2(hat_sigma(u(X), v(Y), torch.ones(10000)), 0))\n",
    "print(F_norm2(hat_sigma(u(X), v(X[:,0]**2), torch.ones(10000)), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class AttentionRepresentation(nn.Module):\n",
    "    def __init__(self, n_team_fts, hidden_team):\n",
    "        super().__init__()\n",
    "        self.hidden = hidden_team\n",
    "        self.bc1 = nn.BatchNorm1d(n_team_fts)\n",
    "        self.bc2 = nn.BatchNorm1d(hidden_team)\n",
    "        self.att1 = nn.MultiheadAttention(hidden_team, 1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(n_team_fts, hidden_team)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.bc2(self.fc1(self.bc1(x)))[:,None,:]\n",
    "        res = self.att1(res, res, res, need_weights=False)[0]\n",
    "        return res[:,0,:]\n",
    "    \n",
    "    def activate(self, require):\n",
    "        self.bc1.requires_grad_(require)\n",
    "        self.bc2.requires_grad_(require)\n",
    "        self.att1.requires_grad_(require)\n",
    "        self.fc1.requires_grad_(require)\n",
    "    \n",
    "\n",
    "class MatchTeamClassifier(nn.Module):\n",
    "    def __init__(self, n_class, n_team_fts, hidden_team):\n",
    "        super().__init__()\n",
    "        self.phi = AttentionRepresentation(n_team_fts, hidden_team)\n",
    "        self.fc = nn.Linear(hidden_team, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.phi(x))\n",
    "    \n",
    "    def activate(self, require):\n",
    "        self.phi.activate(require)\n",
    "        self.fc.requires_grad_(require)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PLAYER_CAPTAIN_5_last_match_average', 'PLAYER_CAPTAIN_5_last_match_std', 'PLAYER_CAPTAIN_season_average', 'PLAYER_CAPTAIN_season_std', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_average', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_std', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_sum', 'PLAYER_LONG_BALLS_5_last_match_average', 'PLAYER_LONG_BALLS_5_last_match_std', 'PLAYER_LONG_BALLS_5_last_match_sum', 'PLAYER_LONG_BALLS_WON_5_last_match_average', 'PLAYER_LONG_BALLS_WON_5_last_match_std', 'PLAYER_LONG_BALLS_WON_5_last_match_sum', 'PLAYER_LONG_BALLS_WON_season_average', 'PLAYER_LONG_BALLS_WON_season_std', 'PLAYER_LONG_BALLS_WON_season_sum', 'PLAYER_LONG_BALLS_season_average', 'PLAYER_LONG_BALLS_season_std', 'PLAYER_LONG_BALLS_season_sum', 'PLAYER_PENALTIES_SAVED_5_last_match_average', 'PLAYER_PENALTIES_SAVED_5_last_match_std', 'PLAYER_PENALTIES_SAVED_5_last_match_sum', 'PLAYER_PENALTIES_SAVED_season_average', 'PLAYER_PENALTIES_SAVED_season_std', 'PLAYER_PENALTIES_SAVED_season_sum', 'PLAYER_PENALTIES_WON_5_last_match_average', 'PLAYER_PENALTIES_WON_5_last_match_std', 'PLAYER_PENALTIES_WON_5_last_match_sum', 'PLAYER_PENALTIES_WON_season_average', 'PLAYER_PENALTIES_WON_season_std', 'PLAYER_PENALTIES_WON_season_sum', 'PLAYER_PUNCHES_5_last_match_average', 'PLAYER_PUNCHES_5_last_match_std', 'PLAYER_PUNCHES_5_last_match_sum', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_average', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_std', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_sum', 'PLAYER_SAVES_INSIDE_BOX_season_average', 'PLAYER_SAVES_INSIDE_BOX_season_std', 'PLAYER_SAVES_INSIDE_BOX_season_sum', 'PLAYER_SAVES_season_average', 'PLAYER_SAVES_season_sum', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_average', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_std', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_sum', 'PLAYER_SHOTS_OFF_TARGET_season_average', 'PLAYER_SHOTS_OFF_TARGET_season_std', 'PLAYER_SHOTS_OFF_TARGET_season_sum']\n",
      "       HOME_TEAM_SHOTS_INSIDEBOX_season_sum  \\\n",
      "ID                                            \n",
      "0                                       2.0   \n",
      "1                                       8.0   \n",
      "2                                       2.0   \n",
      "3                                       5.0   \n",
      "4                                       3.0   \n",
      "...                                     ...   \n",
      "12296                                   0.0   \n",
      "12297                                   NaN   \n",
      "12299                                   2.0   \n",
      "12300                                   3.0   \n",
      "12302                                   3.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_TOTAL_5_last_match_sum  HOME_TEAM_GAME_LOST_season_sum  \\\n",
      "ID                                                                              \n",
      "0                                         4.0                            10.0   \n",
      "1                                         5.0                             1.0   \n",
      "2                                         5.0                             8.0   \n",
      "3                                         3.0                             0.0   \n",
      "4                                         3.0                             4.0   \n",
      "...                                       ...                             ...   \n",
      "12296                                     0.0                             4.0   \n",
      "12297                                     6.0                             4.0   \n",
      "12299                                     6.0                             6.0   \n",
      "12300                                     2.0                             8.0   \n",
      "12302                                     1.0                             3.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_INSIDEBOX_season_average  \\\n",
      "ID                                                \n",
      "0                                           2.0   \n",
      "1                                           7.0   \n",
      "2                                           2.0   \n",
      "3                                           5.0   \n",
      "4                                           3.0   \n",
      "...                                         ...   \n",
      "12296                                       0.0   \n",
      "12297                                       NaN   \n",
      "12299                                       2.0   \n",
      "12300                                       3.0   \n",
      "12302                                       2.0   \n",
      "\n",
      "       HOME_TEAM_GAME_WON_5_last_match_sum  \\\n",
      "ID                                           \n",
      "0                                      2.0   \n",
      "1                                      8.0   \n",
      "2                                      4.0   \n",
      "3                                      7.0   \n",
      "4                                      2.0   \n",
      "...                                    ...   \n",
      "12296                                  2.0   \n",
      "12297                                  2.0   \n",
      "12299                                  4.0   \n",
      "12300                                  0.0   \n",
      "12302                                  6.0   \n",
      "\n",
      "       AWAY_TEAM_SHOTS_TOTAL_5_last_match_average  \\\n",
      "ID                                                  \n",
      "0                                             2.0   \n",
      "1                                             3.0   \n",
      "2                                             7.0   \n",
      "3                                             7.0   \n",
      "4                                             6.0   \n",
      "...                                           ...   \n",
      "12296                                         2.0   \n",
      "12297                                         5.0   \n",
      "12299                                         1.0   \n",
      "12300                                         5.0   \n",
      "12302                                         4.0   \n",
      "\n",
      "       HOME_TEAM_GOALS_season_average  HOME_TEAM_PASSES_season_sum  \\\n",
      "ID                                                                   \n",
      "0                                 3.0                          2.0   \n",
      "1                                 9.0                          8.0   \n",
      "2                                 1.0                          1.0   \n",
      "3                                 5.0                          9.0   \n",
      "4                                 2.0                          4.0   \n",
      "...                               ...                          ...   \n",
      "12296                             5.0                          8.0   \n",
      "12297                             2.0                          NaN   \n",
      "12299                             0.0                          1.0   \n",
      "12300                             1.0                          1.0   \n",
      "12302                             4.0                          3.0   \n",
      "\n",
      "       AWAY_TEAM_SUCCESSFUL_PASSES_PERCENTAGE_season_average  \\\n",
      "ID                                                             \n",
      "0                                                    5.0       \n",
      "1                                                    5.0       \n",
      "2                                                    5.0       \n",
      "3                                                    5.0       \n",
      "4                                                    6.0       \n",
      "...                                                  ...       \n",
      "12296                                                7.0       \n",
      "12297                                                NaN       \n",
      "12299                                                6.0       \n",
      "12300                                                1.0       \n",
      "12302                                               10.0       \n",
      "\n",
      "       AWAY_TEAM_PASSES_season_average  ...  \\\n",
      "ID                                      ...   \n",
      "0                                  3.0  ...   \n",
      "1                                  4.0  ...   \n",
      "2                                  4.0  ...   \n",
      "3                                  4.0  ...   \n",
      "4                                  6.0  ...   \n",
      "...                                ...  ...   \n",
      "12296                              5.0  ...   \n",
      "12297                              NaN  ...   \n",
      "12299                              3.0  ...   \n",
      "12300                              3.0  ...   \n",
      "12302                             10.0  ...   \n",
      "\n",
      "       GOALKEEP_HOME_PLAYER_ASSISTS_5_last_match_sum  \\\n",
      "ID                                                     \n",
      "0                                                0.0   \n",
      "1                                                0.0   \n",
      "2                                                0.0   \n",
      "3                                                0.0   \n",
      "4                                                0.0   \n",
      "...                                              ...   \n",
      "12296                                            0.0   \n",
      "12297                                            0.0   \n",
      "12299                                            0.0   \n",
      "12300                                            0.0   \n",
      "12302                                            0.0   \n",
      "\n",
      "       DEFEND_HOME_PLAYER_ACCURATE_PASSES_PERCENTAGE_season_average  \\\n",
      "ID                                                                    \n",
      "0                                                  356.0              \n",
      "1                                                  443.0              \n",
      "2                                                  447.0              \n",
      "3                                                  201.0              \n",
      "4                                                  278.0              \n",
      "...                                                  ...              \n",
      "12296                                                0.0              \n",
      "12297                                                0.0              \n",
      "12299                                              286.0              \n",
      "12300                                              328.0              \n",
      "12302                                              438.0              \n",
      "\n",
      "       ATTACK_HOME_PLAYER_DUELS_LOST_5_last_match_average  \\\n",
      "ID                                                          \n",
      "0                                                  145.0    \n",
      "1                                                   81.0    \n",
      "2                                                   49.0    \n",
      "3                                                   56.0    \n",
      "4                                                  145.0    \n",
      "...                                                  ...    \n",
      "12296                                               94.0    \n",
      "12297                                                0.0    \n",
      "12299                                              117.0    \n",
      "12300                                              233.0    \n",
      "12302                                              137.0    \n",
      "\n",
      "       MIDFIELD_AWAY_PLAYER_ERROR_LEAD_TO_GOAL_5_last_match_sum  \\\n",
      "ID                                                                \n",
      "0                                                    0.0          \n",
      "1                                                    0.0          \n",
      "2                                                    0.0          \n",
      "3                                                    0.0          \n",
      "4                                                    0.0          \n",
      "...                                                  ...          \n",
      "12296                                                0.0          \n",
      "12297                                                0.0          \n",
      "12299                                                0.0          \n",
      "12300                                                0.0          \n",
      "12302                                                0.0          \n",
      "\n",
      "       MIDFIELD_HOME_PLAYER_BLOCKED_SHOTS_5_last_match_average  \\\n",
      "ID                                                               \n",
      "0                                                   36.0         \n",
      "1                                                   70.0         \n",
      "2                                                   44.0         \n",
      "3                                                   32.0         \n",
      "4                                                   77.0         \n",
      "...                                                  ...         \n",
      "12296                                               22.0         \n",
      "12297                                                0.0         \n",
      "12299                                               31.0         \n",
      "12300                                               99.0         \n",
      "12302                                               48.0         \n",
      "\n",
      "       ATTACK_AWAY_PLAYER_BIG_CHANCES_CREATED_5_last_match_sum  \\\n",
      "ID                                                               \n",
      "0                                                    0.0         \n",
      "1                                                   20.0         \n",
      "2                                                  100.0         \n",
      "3                                                    0.0         \n",
      "4                                                   80.0         \n",
      "...                                                  ...         \n",
      "12296                                               60.0         \n",
      "12297                                                0.0         \n",
      "12299                                               40.0         \n",
      "12300                                               80.0         \n",
      "12302                                              125.0         \n",
      "\n",
      "       MIDFIELD_HOME_PLAYER_GOALS_CONCEDED_season_average  \\\n",
      "ID                                                          \n",
      "0                                                  298.0    \n",
      "1                                                  177.0    \n",
      "2                                                  416.0    \n",
      "3                                                  188.0    \n",
      "4                                                  135.0    \n",
      "...                                                  ...    \n",
      "12296                                              123.0    \n",
      "12297                                              365.0    \n",
      "12299                                              134.0    \n",
      "12300                                              192.0    \n",
      "12302                                              190.0    \n",
      "\n",
      "       GOALKEEP_AWAY_PLAYER_SHOTS_ON_TARGET_5_last_match_std  \\\n",
      "ID                                                             \n",
      "0                                                    0.0       \n",
      "1                                                    0.0       \n",
      "2                                                    0.0       \n",
      "3                                                    0.0       \n",
      "4                                                    0.0       \n",
      "...                                                  ...       \n",
      "12296                                                0.0       \n",
      "12297                                                0.0       \n",
      "12299                                                0.0       \n",
      "12300                                                0.0       \n",
      "12302                                                0.0       \n",
      "\n",
      "       HOME_TEAM_BALL_SAFE_season_sum  MIDFIELD_AWAY_PLAYER_SAVES_season_std  \n",
      "ID                                                                            \n",
      "0                                 4.0                                    0.0  \n",
      "1                                 9.0                                    0.0  \n",
      "2                                 5.0                                    0.0  \n",
      "3                                 3.0                                    0.0  \n",
      "4                                 5.0                                    0.0  \n",
      "...                               ...                                    ...  \n",
      "12296                             9.0                                    0.0  \n",
      "12297                             8.0                                    0.0  \n",
      "12299                             0.0                                    0.0  \n",
      "12300                             6.0                                    0.0  \n",
      "12302                             3.0                                    0.0  \n",
      "\n",
      "[10624 rows x 512 columns]\n"
     ]
    }
   ],
   "source": [
    "train_home_player_statistics_df = pd.read_csv('./train_home_player_statistics_df.csv', index_col=0)\n",
    "train_away_player_statistics_df = pd.read_csv('./train_away_player_statistics_df.csv', index_col=0)\n",
    "train_home_team_statistics_df = pd.read_csv('./train_home_team_statistics_df.csv', index_col=0)\n",
    "train_away_team_statistics_df = pd.read_csv('./train_away_team_statistics_df.csv', index_col=0)\n",
    "train_home_team_statistics_df.columns = 'HOME_' + train_home_team_statistics_df.columns\n",
    "train_away_team_statistics_df.columns = 'AWAY_' + train_away_team_statistics_df.columns\n",
    "\n",
    "\n",
    "train_scores = pd.read_csv('./Y_train.csv', index_col=0)\n",
    "\n",
    "import pickle\n",
    "\n",
    "lin_model_position = pickle.load(open(\"pos_model\", \"rb\"))\n",
    "encoding = [\"attacker\", \"defender\", \"goalkeeper\", \"midfielder\"]\n",
    "\n",
    "\n",
    "train_home_player_statistics_df.loc[train_home_player_statistics_df.isna()[\"POSITION\"],\"POSITION\"] = (np.array(encoding)[lin_model_position.predict(train_home_player_statistics_df.iloc[:,4:].replace({np.nan:0.0}))])[train_home_player_statistics_df.isna()[\"POSITION\"]]\n",
    "train_away_player_statistics_df.loc[train_away_player_statistics_df.isna()[\"POSITION\"],\"POSITION\"] = (np.array(encoding)[lin_model_position.predict(train_away_player_statistics_df.iloc[:,4:].replace({np.nan:0.0}))])[train_away_player_statistics_df.isna()[\"POSITION\"]]\n",
    "\n",
    "df = train_away_player_statistics_df.reset_index().groupby([\"POSITION\", \"ID\"], as_index=False).sum()\n",
    "gb_away = df.set_index(\"ID\").groupby(\"POSITION\")\n",
    "positions = [\"attacker\", \"goalkeeper\", \"midfielder\", \"defender\"]\n",
    "m1 = np.intersect1d(gb_away.get_group(positions[0]).index, gb_away.get_group(positions[1]).index)\n",
    "m2 = np.intersect1d(gb_away.get_group(positions[2]).index, gb_away.get_group(positions[3]).index)\n",
    "away_m = np.intersect1d(m1, m2)\n",
    "\n",
    "df = train_home_player_statistics_df.reset_index().groupby([\"POSITION\", \"ID\"], as_index=False).sum()\n",
    "gb_home = df.set_index(\"ID\").groupby(\"POSITION\")\n",
    "m1 = np.intersect1d(gb_home.get_group(positions[0]).index, gb_home.get_group(positions[1]).index)\n",
    "m2 = np.intersect1d(gb_home.get_group(positions[2]).index, gb_home.get_group(positions[3]).index)\n",
    "home_m = np.intersect1d(m1, m2)\n",
    "\n",
    "m = np.intersect1d(away_m, home_m)\n",
    "\n",
    "train_player_data = []\n",
    "useless_features = open(\"lines.txt\", \"r\").readlines()\n",
    "useless_features = [ft[:-1] for ft in useless_features]\n",
    "print(useless_features)\n",
    "for pos in positions:\n",
    "    df_home_pos = gb_home.get_group(pos).drop(useless_features, axis=1)\n",
    "    df_away_pos = gb_away.get_group(pos).drop(useless_features, axis=1)\n",
    "    df_home_pos.columns = 'HOME_' + df_home_pos.columns\n",
    "    df_away_pos.columns = 'AWAY_' + df_away_pos.columns\n",
    "    train_player_data.append(df_home_pos.iloc[:,1:].join(df_away_pos.iloc[:,1:]))\n",
    "\n",
    "train_player_data[0].columns = \"ATTACK_\" + train_player_data[0].columns\n",
    "train_player_data[1].columns = \"GOALKEEP_\" + train_player_data[1].columns\n",
    "train_player_data[2].columns = \"MIDFIELD_\" + train_player_data[2].columns\n",
    "train_player_data[3].columns = \"DEFEND_\" + train_player_data[3].columns\n",
    "\n",
    "train_data = train_home_team_statistics_df.iloc[m,2:].join(train_away_team_statistics_df.iloc[m,2:].join(train_player_data[0].loc[m,:].join(train_player_data[1].loc[m,:].join(train_player_data[2].loc[m,:].join(train_player_data[3].loc[m,:])))))\n",
    "\n",
    "select_fts = open(\"feature_selection.txt\", \"r\").readlines()\n",
    "select_fts = [ft[:-1] for ft in select_fts]\n",
    "train_data = train_data[select_fts]\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(train_data, train_scores.iloc[m,:], train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2125, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MatchTeamClassifier(3, 512, 64)\n",
    "\n",
    "x_train = torch.Tensor(X_train.replace({np.nan:0.0}).values)\n",
    "x_valid = torch.Tensor(X_valid.replace({np.nan:0.0}).values)\n",
    "Y_train = torch.Tensor(y_train.values)\n",
    "Y_valid = torch.Tensor(y_valid.values)\n",
    "\n",
    "print(net(x_valid).shape)\n",
    "net.phi.bc1.requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22456\\3892290128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFF_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRFF_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize_constr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFrobenius_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mub\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torchmin\\minimize_constr.py\u001b[0m in \u001b[0;36mminimize_constr\u001b[1;34m(f, x0, constr, bounds, max_iter, tol, callback, disp, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;31m# optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0mx0_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     result = minimize(\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mf_with_jac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'trust-constr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mhess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_hess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    709\u001b[0m                               constraints, callback=callback, **options)\n\u001b[0;32m    710\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'trust-constr'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m         res = _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[0m\u001b[0;32m    712\u001b[0m                                            \u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                                            callback=callback, **options)\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\minimize_trustregion_constr.py\u001b[0m in \u001b[0;36m_minimize_trustregion_constr\u001b[1;34m(fun, x0, args, grad, hess, hessp, bounds, constraints, xtol, gtol, barrier_tol, sparse_jacobian, callback, maxiter, verbose, finite_diff_rel_step, initial_constr_penalty, initial_tr_radius, initial_barrier_parameter, initial_barrier_tolerance, factorization_method, disp)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;31m# Prepare constraints.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     prepared_constraints = [\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[0mPreparedConstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_jacobian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinite_diff_bounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         for c in constraints]\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\minimize_trustregion_constr.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;31m# Prepare constraints.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     prepared_constraints = [\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mPreparedConstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_jacobian\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinite_diff_bounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         for c in constraints]\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_constraints.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, constraint, x0, sparse_jacobian, finite_diff_bounds)\u001b[0m\n\u001b[0;32m    326\u001b[0m                  finite_diff_bounds=(-np.inf, np.inf)):\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNonlinearConstraint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             fun = VectorFunction(constraint.fun, x0,\n\u001b[0m\u001b[0;32m    329\u001b[0m                                  \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                                  \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinite_diff_rel_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, jac, hess, finite_diff_rel_step, finite_diff_jac_sparsity, finite_diff_bounds, sparse_jacobian)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;31m# Define Hessian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnhev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torchmin\\minimize_constr.py\u001b[0m in \u001b[0;36mf_hess\u001b[1;34m(x, v)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mhvp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhvp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     return NonlinearConstraint(\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, shape, matvec, rmatvec, matmat, dtype, rmatmat)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__matmat_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatmat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_matmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m_init_dtype\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_matmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36mmatvec\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m_matvec\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_matvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__matvec_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_rmatvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torchmin\\minimize_constr.py\u001b[0m in \u001b[0;36mmatvec\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mhvp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhvp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    301\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "from torchmin import minimize_constr\n",
    "def Frobenius_loss(A, B, u, v):\n",
    "    _, d = B.shape\n",
    "    def Loss(weights):\n",
    "        loss = torch.tensor(0.0)\n",
    "        for i in range(d):\n",
    "            loss += F_norm2(hat_sigma(u(A), v(B[:,i]), weights), i)\n",
    "        return loss\n",
    "    return Loss\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "u, v = RFF_sample(5,3), RFF_sample(5,2)\n",
    "X, Y = net.phi(x_train), net.phi(x_train)\n",
    "res = minimize_constr(Frobenius_loss(net.phi(x_train), net.phi(x_train), u, v), torch.ones(x_train.shape[0]), max_iter=10, constr=dict(fun=lambda x: x.mean(), lb=1, ub=1),disp=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moy(w) =  0.9950281381607056\n",
      "Epoch 0 Loss 1.16 | Train Accuracy 0.28579832921520176 | Val Accuracy 0.46588235294117647\n",
      "moy(w) =  0.9901555776596069\n",
      "Epoch 1 Loss 1.03 | Train Accuracy 0.47146723143899283 | Val Accuracy 0.49458823529411766\n",
      "moy(w) =  0.9852336645126343\n",
      "Epoch 2 Loss 1.01 | Train Accuracy 0.4919402282621485 | Val Accuracy 0.5025882352941177\n",
      "moy(w) =  0.9802731871604919\n",
      "Epoch 3 Loss 1.00 | Train Accuracy 0.4949994116954936 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9753121137619019\n",
      "Epoch 4 Loss 0.99 | Train Accuracy 0.49994116954935874 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  0.9704411625862122\n",
      "Epoch 5 Loss 0.98 | Train Accuracy 0.5052359101070715 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9657806754112244\n",
      "Epoch 6 Loss 0.97 | Train Accuracy 0.5110012942699141 | Val Accuracy 0.5157647058823529\n",
      "moy(w) =  0.961353600025177\n",
      "Epoch 7 Loss 0.96 | Train Accuracy 0.5120602423814566 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9571536183357239\n",
      "Epoch 8 Loss 0.96 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.512\n",
      "moy(w) =  0.953204870223999\n",
      "Epoch 9 Loss 0.95 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5152941176470588\n",
      "moy(w) =  0.9495347738265991\n",
      "Epoch 10 Loss 0.94 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5171764705882353\n",
      "moy(w) =  0.9461340308189392\n",
      "Epoch 11 Loss 0.94 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.9429988265037537\n",
      "Epoch 12 Loss 0.93 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.940120279788971\n",
      "Epoch 13 Loss 0.93 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  0.93748939037323\n",
      "Epoch 14 Loss 0.93 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  0.9350922107696533\n",
      "Epoch 15 Loss 0.92 | Train Accuracy 0.5200611836686669 | Val Accuracy 0.512\n",
      "moy(w) =  0.9329143166542053\n",
      "Epoch 16 Loss 0.92 | Train Accuracy 0.5199435227673844 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  0.9309065937995911\n",
      "Epoch 17 Loss 0.92 | Train Accuracy 0.5191198964584068 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9290828108787537\n",
      "Epoch 18 Loss 0.92 | Train Accuracy 0.5113542769737616 | Val Accuracy 0.504\n",
      "moy(w) =  0.9274406433105469\n",
      "Epoch 19 Loss 0.92 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5157647058823529\n",
      "moy(w) =  0.9259592294692993\n",
      "Epoch 20 Loss 0.91 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9246373772621155\n",
      "Epoch 21 Loss 0.91 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  0.9234526753425598\n",
      "Epoch 22 Loss 0.91 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9223874807357788\n",
      "Epoch 23 Loss 0.91 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.9214257001876831\n",
      "Epoch 24 Loss 0.91 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5007058823529412\n",
      "moy(w) =  0.9205127358436584\n",
      "Epoch 25 Loss 0.91 | Train Accuracy 0.5133545122955642 | Val Accuracy 0.5021176470588236\n",
      "moy(w) =  0.9197065234184265\n",
      "Epoch 26 Loss 0.92 | Train Accuracy 0.5050005883045064 | Val Accuracy 0.512\n",
      "moy(w) =  0.919023334980011\n",
      "Epoch 27 Loss 0.91 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5011764705882353\n",
      "moy(w) =  0.9184737801551819\n",
      "Epoch 28 Loss 0.92 | Train Accuracy 0.5064125191198965 | Val Accuracy 0.504\n",
      "moy(w) =  0.9180565476417542\n",
      "Epoch 29 Loss 0.91 | Train Accuracy 0.5115895987763266 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.9177424311637878\n",
      "Epoch 30 Loss 0.91 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.9175018668174744\n",
      "Epoch 31 Loss 0.91 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.917302668094635\n",
      "Epoch 32 Loss 0.91 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  0.9171335101127625\n",
      "Epoch 33 Loss 0.90 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5035294117647059\n",
      "moy(w) =  0.917016327381134\n",
      "Epoch 34 Loss 0.90 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5016470588235294\n",
      "moy(w) =  0.9169431924819946\n",
      "Epoch 35 Loss 0.90 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  0.9168592095375061\n",
      "Epoch 36 Loss 0.90 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5021176470588236\n",
      "moy(w) =  0.916750967502594\n",
      "Epoch 37 Loss 0.90 | Train Accuracy 0.5141781386045418 | Val Accuracy 0.5044705882352941\n",
      "moy(w) =  0.9166934490203857\n",
      "Epoch 38 Loss 0.91 | Train Accuracy 0.5115895987763266 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9166993498802185\n",
      "Epoch 39 Loss 0.90 | Train Accuracy 0.5207671490763619 | Val Accuracy 0.5035294117647059\n",
      "moy(w) =  0.9167581796646118\n",
      "Epoch 40 Loss 0.90 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  0.9168291091918945\n",
      "Epoch 41 Loss 0.91 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9169074296951294\n",
      "Epoch 42 Loss 0.90 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.4964705882352941\n",
      "moy(w) =  0.9170033931732178\n",
      "Epoch 43 Loss 0.90 | Train Accuracy 0.5192375573596894 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.9170688986778259\n",
      "Epoch 44 Loss 0.91 | Train Accuracy 0.5113542769737616 | Val Accuracy 0.4950588235294118\n",
      "moy(w) =  0.9171290397644043\n",
      "Epoch 45 Loss 0.91 | Train Accuracy 0.508412754441699 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  0.9172127842903137\n",
      "Epoch 46 Loss 0.90 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  0.9173373579978943\n",
      "Epoch 47 Loss 0.91 | Train Accuracy 0.5117072596776091 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  0.9174930453300476\n",
      "Epoch 48 Loss 0.90 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.5021176470588236\n",
      "moy(w) =  0.917647659778595\n",
      "Epoch 49 Loss 0.91 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5035294117647059\n",
      "moy(w) =  0.9177709221839905\n",
      "Epoch 50 Loss 0.90 | Train Accuracy 0.5218260971879045 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  0.9178643226623535\n",
      "Epoch 51 Loss 0.90 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5044705882352941\n",
      "moy(w) =  0.9179375171661377\n",
      "Epoch 52 Loss 0.90 | Train Accuracy 0.5227673843981645 | Val Accuracy 0.49976470588235294\n",
      "moy(w) =  0.9179911613464355\n",
      "Epoch 53 Loss 0.90 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.918011486530304\n",
      "Epoch 54 Loss 0.90 | Train Accuracy 0.5237086716084245 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.9180063009262085\n",
      "Epoch 55 Loss 0.90 | Train Accuracy 0.521237792681492 | Val Accuracy 0.4950588235294118\n",
      "moy(w) =  0.9179278612136841\n",
      "Epoch 56 Loss 0.90 | Train Accuracy 0.5201788445699495 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9178952574729919\n",
      "Epoch 57 Loss 0.93 | Train Accuracy 0.5082950935404165 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9179254174232483\n",
      "Epoch 58 Loss 0.91 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.4983529411764706\n",
      "moy(w) =  0.9180270433425903\n",
      "Epoch 59 Loss 0.92 | Train Accuracy 0.507236145428874 | Val Accuracy 0.5025882352941177\n",
      "moy(w) =  0.9181978702545166\n",
      "Epoch 60 Loss 0.92 | Train Accuracy 0.5092363807506766 | Val Accuracy 0.5148235294117647\n",
      "moy(w) =  0.9184245467185974\n",
      "Epoch 61 Loss 0.91 | Train Accuracy 0.5101776679609366 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  0.9186819195747375\n",
      "Epoch 62 Loss 0.91 | Train Accuracy 0.5102953288622191 | Val Accuracy 0.52\n",
      "moy(w) =  0.9189311861991882\n",
      "Epoch 63 Loss 0.91 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5157647058823529\n",
      "moy(w) =  0.9191400408744812\n",
      "Epoch 64 Loss 0.91 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  0.9193010330200195\n",
      "Epoch 65 Loss 0.91 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5007058823529412\n",
      "moy(w) =  0.919447124004364\n",
      "Epoch 66 Loss 0.91 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5025882352941177\n",
      "moy(w) =  0.9195654988288879\n",
      "Epoch 67 Loss 0.91 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  0.9195976257324219\n",
      "Epoch 68 Loss 0.91 | Train Accuracy 0.5186492528532769 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  0.9196339249610901\n",
      "Epoch 69 Loss 0.90 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.49929411764705883\n",
      "moy(w) =  0.9196370840072632\n",
      "Epoch 70 Loss 0.91 | Train Accuracy 0.5181786092481468 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.9196686148643494\n",
      "Epoch 71 Loss 0.91 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.4894117647058824\n",
      "moy(w) =  0.919771671295166\n",
      "Epoch 72 Loss 0.92 | Train Accuracy 0.5037063183903989 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.9199604392051697\n",
      "Epoch 73 Loss 0.92 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  0.9202105402946472\n",
      "Epoch 74 Loss 0.92 | Train Accuracy 0.5112366160724792 | Val Accuracy 0.5181176470588236\n",
      "moy(w) =  0.9204937219619751\n",
      "Epoch 75 Loss 0.92 | Train Accuracy 0.5127662077891517 | Val Accuracy 0.5171764705882353\n",
      "moy(w) =  0.920773446559906\n",
      "Epoch 76 Loss 0.92 | Train Accuracy 0.5132368513942817 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9210578203201294\n",
      "Epoch 77 Loss 0.91 | Train Accuracy 0.5139428168019767 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  0.921357274055481\n",
      "Epoch 78 Loss 0.91 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  0.921601414680481\n",
      "Epoch 79 Loss 0.91 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5035294117647059\n",
      "moy(w) =  0.9217852354049683\n",
      "Epoch 80 Loss 0.91 | Train Accuracy 0.5194728791622544 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  0.9219709038734436\n",
      "Epoch 81 Loss 0.91 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.4969411764705882\n",
      "moy(w) =  0.9221720695495605\n",
      "Epoch 82 Loss 0.92 | Train Accuracy 0.5094717025532416 | Val Accuracy 0.5030588235294118\n",
      "moy(w) =  0.9223752021789551\n",
      "Epoch 83 Loss 0.92 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9225906729698181\n",
      "Epoch 84 Loss 0.92 | Train Accuracy 0.5128838686904341 | Val Accuracy 0.5185882352941177\n",
      "moy(w) =  0.9228405356407166\n",
      "Epoch 85 Loss 0.92 | Train Accuracy 0.5133545122955642 | Val Accuracy 0.5181176470588236\n",
      "moy(w) =  0.9231203198432922\n",
      "Epoch 86 Loss 0.92 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9234294295310974\n",
      "Epoch 87 Loss 0.92 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9237333536148071\n",
      "Epoch 88 Loss 0.92 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.9240049123764038\n",
      "Epoch 89 Loss 0.92 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.9242865443229675\n",
      "Epoch 90 Loss 0.92 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.49929411764705883\n",
      "moy(w) =  0.924526572227478\n",
      "Epoch 91 Loss 0.92 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  0.9247462749481201\n",
      "Epoch 92 Loss 0.92 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.49976470588235294\n",
      "moy(w) =  0.9250046610832214\n",
      "Epoch 93 Loss 0.92 | Train Accuracy 0.5101776679609366 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.9252994060516357\n",
      "Epoch 94 Loss 0.92 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.512\n",
      "moy(w) =  0.9255938529968262\n",
      "Epoch 95 Loss 0.92 | Train Accuracy 0.5142957995058243 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.9258634448051453\n",
      "Epoch 96 Loss 0.92 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.9261221885681152\n",
      "Epoch 97 Loss 0.92 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  0.9263869524002075\n",
      "Epoch 98 Loss 0.92 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  0.926649808883667\n",
      "Epoch 99 Loss 0.92 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5030588235294118\n",
      "moy(w) =  0.9268969893455505\n",
      "Epoch 100 Loss 0.92 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  0.9271448254585266\n",
      "Epoch 101 Loss 0.92 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5016470588235294\n",
      "moy(w) =  0.9273741841316223\n",
      "Epoch 102 Loss 0.92 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5011764705882353\n",
      "moy(w) =  0.92754065990448\n",
      "Epoch 103 Loss 0.93 | Train Accuracy 0.5108836333686316 | Val Accuracy 0.4964705882352941\n",
      "moy(w) =  0.927747905254364\n",
      "Epoch 104 Loss 0.94 | Train Accuracy 0.5013531003647488 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9280333518981934\n",
      "Epoch 105 Loss 0.93 | Train Accuracy 0.5101776679609366 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.9283974170684814\n",
      "Epoch 106 Loss 0.94 | Train Accuracy 0.506765501823744 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  0.9288238883018494\n",
      "Epoch 107 Loss 0.94 | Train Accuracy 0.5026473702788563 | Val Accuracy 0.5181176470588236\n",
      "moy(w) =  0.9292793869972229\n",
      "Epoch 108 Loss 0.94 | Train Accuracy 0.508883398046829 | Val Accuracy 0.5157647058823529\n",
      "moy(w) =  0.9297227263450623\n",
      "Epoch 109 Loss 0.94 | Train Accuracy 0.509824685257089 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9301300048828125\n",
      "Epoch 110 Loss 0.93 | Train Accuracy 0.508648076244264 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  0.9305023550987244\n",
      "Epoch 111 Loss 0.93 | Train Accuracy 0.5104129897635016 | Val Accuracy 0.5016470588235294\n",
      "moy(w) =  0.9308485984802246\n",
      "Epoch 112 Loss 0.93 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.931180477142334\n",
      "Epoch 113 Loss 0.93 | Train Accuracy 0.5135898340981292 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9314841628074646\n",
      "Epoch 114 Loss 0.93 | Train Accuracy 0.5140604777032592 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  0.9317622780799866\n",
      "Epoch 115 Loss 0.93 | Train Accuracy 0.5137074949994117 | Val Accuracy 0.5030588235294118\n",
      "moy(w) =  0.9320120215415955\n",
      "Epoch 116 Loss 0.93 | Train Accuracy 0.5108836333686316 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9322521686553955\n",
      "Epoch 117 Loss 0.93 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.9325175285339355\n",
      "Epoch 118 Loss 0.93 | Train Accuracy 0.5141781386045418 | Val Accuracy 0.496\n",
      "moy(w) =  0.9327853918075562\n",
      "Epoch 119 Loss 0.94 | Train Accuracy 0.5071184845275915 | Val Accuracy 0.5016470588235294\n",
      "moy(w) =  0.9330639243125916\n",
      "Epoch 120 Loss 0.94 | Train Accuracy 0.5113542769737616 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  0.9333540797233582\n",
      "Epoch 121 Loss 0.93 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.933631956577301\n",
      "Epoch 122 Loss 0.94 | Train Accuracy 0.5087657371455465 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  0.9338935017585754\n",
      "Epoch 123 Loss 0.93 | Train Accuracy 0.5138251559006942 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9341716170310974\n",
      "Epoch 124 Loss 0.93 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5021176470588236\n",
      "moy(w) =  0.9344518184661865\n",
      "Epoch 125 Loss 0.94 | Train Accuracy 0.5110012942699141 | Val Accuracy 0.5044705882352941\n",
      "moy(w) =  0.934751570224762\n",
      "Epoch 126 Loss 0.94 | Train Accuracy 0.5099423461583715 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9350764751434326\n",
      "Epoch 127 Loss 0.93 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9354144930839539\n",
      "Epoch 128 Loss 0.94 | Train Accuracy 0.5092363807506766 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  0.9357526302337646\n",
      "Epoch 129 Loss 0.93 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5035294117647059\n",
      "moy(w) =  0.9361053705215454\n",
      "Epoch 130 Loss 0.94 | Train Accuracy 0.5117072596776091 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  0.936461329460144\n",
      "Epoch 131 Loss 0.94 | Train Accuracy 0.5113542769737616 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9368120431900024\n",
      "Epoch 132 Loss 0.93 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.9371890425682068\n",
      "Epoch 133 Loss 0.93 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5030588235294118\n",
      "moy(w) =  0.9375595450401306\n",
      "Epoch 134 Loss 0.94 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.49929411764705883\n",
      "moy(w) =  0.9379591345787048\n",
      "Epoch 135 Loss 0.95 | Train Accuracy 0.506059536416049 | Val Accuracy 0.5176470588235295\n",
      "moy(w) =  0.9383988976478577\n",
      "Epoch 136 Loss 0.94 | Train Accuracy 0.5139428168019767 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.938880443572998\n",
      "Epoch 137 Loss 0.95 | Train Accuracy 0.5061771973173315 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.939403235912323\n",
      "Epoch 138 Loss 0.94 | Train Accuracy 0.5120602423814566 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9399493932723999\n",
      "Epoch 139 Loss 0.94 | Train Accuracy 0.5118249205788916 | Val Accuracy 0.504\n",
      "moy(w) =  0.9405158758163452\n",
      "Epoch 140 Loss 0.94 | Train Accuracy 0.5106483115660666 | Val Accuracy 0.504\n",
      "moy(w) =  0.9410807490348816\n",
      "Epoch 141 Loss 0.94 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9416422843933105\n",
      "Epoch 142 Loss 0.94 | Train Accuracy 0.5128838686904341 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  0.942197859287262\n",
      "Epoch 143 Loss 0.94 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5030588235294118\n",
      "moy(w) =  0.9427560567855835\n",
      "Epoch 144 Loss 0.94 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.504\n",
      "moy(w) =  0.9432803392410278\n",
      "Epoch 145 Loss 0.94 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  0.943810224533081\n",
      "Epoch 146 Loss 0.94 | Train Accuracy 0.5112366160724792 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9443339109420776\n",
      "Epoch 147 Loss 0.94 | Train Accuracy 0.5141781386045418 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.9448472857475281\n",
      "Epoch 148 Loss 0.94 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9453799724578857\n",
      "Epoch 149 Loss 0.95 | Train Accuracy 0.5093540416519591 | Val Accuracy 0.5002352941176471\n",
      "moy(w) =  0.9459460377693176\n",
      "Epoch 150 Loss 0.95 | Train Accuracy 0.5045299446993764 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.946545422077179\n",
      "Epoch 151 Loss 0.95 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9471736550331116\n",
      "Epoch 152 Loss 0.95 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  0.9478208422660828\n",
      "Epoch 153 Loss 0.95 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5016470588235294\n",
      "moy(w) =  0.9484760165214539\n",
      "Epoch 154 Loss 0.95 | Train Accuracy 0.5135898340981292 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9491265416145325\n",
      "Epoch 155 Loss 0.95 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  0.9497477412223816\n",
      "Epoch 156 Loss 0.95 | Train Accuracy 0.5144134604071067 | Val Accuracy 0.5011764705882353\n",
      "moy(w) =  0.9503324627876282\n",
      "Epoch 157 Loss 0.95 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.950922429561615\n",
      "Epoch 158 Loss 0.95 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5030588235294118\n",
      "moy(w) =  0.9514761567115784\n",
      "Epoch 159 Loss 0.95 | Train Accuracy 0.5140604777032592 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  0.9520072937011719\n",
      "Epoch 160 Loss 0.95 | Train Accuracy 0.5118249205788916 | Val Accuracy 0.5167058823529411\n",
      "moy(w) =  0.9525321125984192\n",
      "Epoch 161 Loss 0.95 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.9530798196792603\n",
      "Epoch 162 Loss 0.95 | Train Accuracy 0.5188845746558418 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9536367058753967\n",
      "Epoch 163 Loss 0.95 | Train Accuracy 0.5118249205788916 | Val Accuracy 0.496\n",
      "moy(w) =  0.9542104005813599\n",
      "Epoch 164 Loss 0.96 | Train Accuracy 0.5073538063301565 | Val Accuracy 0.5167058823529411\n",
      "moy(w) =  0.9548074007034302\n",
      "Epoch 165 Loss 0.96 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  0.9554210901260376\n",
      "Epoch 166 Loss 0.96 | Train Accuracy 0.5120602423814566 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  0.9560430645942688\n",
      "Epoch 167 Loss 0.96 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5021176470588236\n",
      "moy(w) =  0.9566622972488403\n",
      "Epoch 168 Loss 0.96 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.957270622253418\n",
      "Epoch 169 Loss 0.96 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9578484892845154\n",
      "Epoch 170 Loss 0.96 | Train Accuracy 0.5144134604071067 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9583981037139893\n",
      "Epoch 171 Loss 0.96 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.9589412808418274\n",
      "Epoch 172 Loss 0.95 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5016470588235294\n",
      "moy(w) =  0.959454357624054\n",
      "Epoch 173 Loss 0.96 | Train Accuracy 0.5133545122955642 | Val Accuracy 0.4988235294117647\n",
      "moy(w) =  0.9599553942680359\n",
      "Epoch 174 Loss 0.96 | Train Accuracy 0.5101776679609366 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.9604621529579163\n",
      "Epoch 175 Loss 0.96 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9609938859939575\n",
      "Epoch 176 Loss 0.96 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.9615297913551331\n",
      "Epoch 177 Loss 0.96 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  0.962062418460846\n",
      "Epoch 178 Loss 0.96 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.9626076817512512\n",
      "Epoch 179 Loss 0.96 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  0.9631533026695251\n",
      "Epoch 180 Loss 0.96 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.9636754989624023\n",
      "Epoch 181 Loss 0.96 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  0.9641948938369751\n",
      "Epoch 182 Loss 0.96 | Train Accuracy 0.5138251559006942 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9647043943405151\n",
      "Epoch 183 Loss 0.97 | Train Accuracy 0.508883398046829 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.9651961326599121\n",
      "Epoch 184 Loss 0.96 | Train Accuracy 0.5178256265442993 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.9656840562820435\n",
      "Epoch 185 Loss 0.96 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.504\n",
      "moy(w) =  0.9661745429039001\n",
      "Epoch 186 Loss 0.97 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9666838049888611\n",
      "Epoch 187 Loss 0.97 | Train Accuracy 0.5108836333686316 | Val Accuracy 0.516235294117647\n",
      "moy(w) =  0.9672127366065979\n",
      "Epoch 188 Loss 0.97 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  0.9677572250366211\n",
      "Epoch 189 Loss 0.97 | Train Accuracy 0.5111189551711967 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.9683104753494263\n",
      "Epoch 190 Loss 0.97 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  0.9688868522644043\n",
      "Epoch 191 Loss 0.97 | Train Accuracy 0.5138251559006942 | Val Accuracy 0.5007058823529412\n",
      "moy(w) =  0.9694448113441467\n",
      "Epoch 192 Loss 0.97 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  0.9699814319610596\n",
      "Epoch 193 Loss 0.97 | Train Accuracy 0.5114719378750441 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  0.9705002307891846\n",
      "Epoch 194 Loss 0.97 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5044705882352941\n",
      "moy(w) =  0.9710017442703247\n",
      "Epoch 195 Loss 0.97 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  0.9715138673782349\n",
      "Epoch 196 Loss 0.97 | Train Accuracy 0.5114719378750441 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.9720349907875061\n",
      "Epoch 197 Loss 0.97 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9725668430328369\n",
      "Epoch 198 Loss 0.97 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9731173515319824\n",
      "Epoch 199 Loss 0.98 | Train Accuracy 0.5131191904929991 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9736762642860413\n",
      "Epoch 200 Loss 0.97 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.9742414355278015\n",
      "Epoch 201 Loss 0.97 | Train Accuracy 0.5177079656430168 | Val Accuracy 0.5011764705882353\n",
      "moy(w) =  0.9747990965843201\n",
      "Epoch 202 Loss 0.98 | Train Accuracy 0.5144134604071067 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  0.9753544330596924\n",
      "Epoch 203 Loss 0.98 | Train Accuracy 0.5070008236263089 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.9758959412574768\n",
      "Epoch 204 Loss 0.98 | Train Accuracy 0.5131191904929991 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9764367938041687\n",
      "Epoch 205 Loss 0.98 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.9769916534423828\n",
      "Epoch 206 Loss 0.98 | Train Accuracy 0.5102953288622191 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  0.9775509834289551\n",
      "Epoch 207 Loss 0.98 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9781204462051392\n",
      "Epoch 208 Loss 0.98 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.9786909818649292\n",
      "Epoch 209 Loss 0.98 | Train Accuracy 0.5128838686904341 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.9792575836181641\n",
      "Epoch 210 Loss 0.98 | Train Accuracy 0.5144134604071067 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9798333644866943\n",
      "Epoch 211 Loss 0.98 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  0.9804044961929321\n",
      "Epoch 212 Loss 0.98 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  0.9809829592704773\n",
      "Epoch 213 Loss 0.98 | Train Accuracy 0.5140604777032592 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9815617203712463\n",
      "Epoch 214 Loss 0.98 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.9821457862854004\n",
      "Epoch 215 Loss 0.98 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  0.9827231764793396\n",
      "Epoch 216 Loss 0.98 | Train Accuracy 0.5184139310507119 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9832914471626282\n",
      "Epoch 217 Loss 0.98 | Train Accuracy 0.5162960348276268 | Val Accuracy 0.5044705882352941\n",
      "moy(w) =  0.9838559627532959\n",
      "Epoch 218 Loss 0.98 | Train Accuracy 0.5135898340981292 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.9844282269477844\n",
      "Epoch 219 Loss 0.99 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.9850032925605774\n",
      "Epoch 220 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.9855810403823853\n",
      "Epoch 221 Loss 0.99 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.512\n",
      "moy(w) =  0.9861614108085632\n",
      "Epoch 222 Loss 0.99 | Train Accuracy 0.5137074949994117 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9867376685142517\n",
      "Epoch 223 Loss 0.99 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  0.9873130917549133\n",
      "Epoch 224 Loss 0.99 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9878829717636108\n",
      "Epoch 225 Loss 0.99 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5044705882352941\n",
      "moy(w) =  0.9884455800056458\n",
      "Epoch 226 Loss 0.99 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  0.9889947772026062\n",
      "Epoch 227 Loss 0.99 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.9895387291908264\n",
      "Epoch 228 Loss 0.99 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9900686740875244\n",
      "Epoch 229 Loss 0.99 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.4988235294117647\n",
      "moy(w) =  0.9905863404273987\n",
      "Epoch 230 Loss 0.99 | Train Accuracy 0.5139428168019767 | Val Accuracy 0.516235294117647\n",
      "moy(w) =  0.9910968542098999\n",
      "Epoch 231 Loss 0.99 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  0.9916121959686279\n",
      "Epoch 232 Loss 0.99 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.4988235294117647\n",
      "moy(w) =  0.9921230673789978\n",
      "Epoch 233 Loss 0.99 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9926333427429199\n",
      "Epoch 234 Loss 1.00 | Train Accuracy 0.5101776679609366 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  0.9931409955024719\n",
      "Epoch 235 Loss 1.00 | Train Accuracy 0.5120602423814566 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9936464428901672\n",
      "Epoch 236 Loss 1.00 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  0.9941573143005371\n",
      "Epoch 237 Loss 1.00 | Train Accuracy 0.5142957995058243 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  0.9946696162223816\n",
      "Epoch 238 Loss 1.00 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.5025882352941177\n",
      "moy(w) =  0.9951766133308411\n",
      "Epoch 239 Loss 1.00 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9956762194633484\n",
      "Epoch 240 Loss 0.99 | Train Accuracy 0.5141781386045418 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  0.9961599111557007\n",
      "Epoch 241 Loss 1.00 | Train Accuracy 0.5104129897635016 | Val Accuracy 0.504\n",
      "moy(w) =  0.9966323971748352\n",
      "Epoch 242 Loss 1.00 | Train Accuracy 0.5102953288622191 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  0.9970985651016235\n",
      "Epoch 243 Loss 1.00 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  0.9975579380989075\n",
      "Epoch 244 Loss 1.00 | Train Accuracy 0.5137074949994117 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  0.998020350933075\n",
      "Epoch 245 Loss 1.00 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  0.9984822273254395\n",
      "Epoch 246 Loss 1.00 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.512\n",
      "moy(w) =  0.9989463090896606\n",
      "Epoch 247 Loss 1.00 | Train Accuracy 0.5132368513942817 | Val Accuracy 0.5044705882352941\n",
      "moy(w) =  0.9994142055511475\n",
      "Epoch 248 Loss 1.00 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  0.9998839497566223\n",
      "Epoch 249 Loss 1.00 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5021176470588236\n",
      "moy(w) =  1.0003528594970703\n",
      "Epoch 250 Loss 1.00 | Train Accuracy 0.5138251559006942 | Val Accuracy 0.504\n",
      "moy(w) =  1.0008238554000854\n",
      "Epoch 251 Loss 1.01 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.512\n",
      "moy(w) =  1.0012890100479126\n",
      "Epoch 252 Loss 1.00 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.0017555952072144\n",
      "Epoch 253 Loss 1.00 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0022192001342773\n",
      "Epoch 254 Loss 1.01 | Train Accuracy 0.5141781386045418 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.0026702880859375\n",
      "Epoch 255 Loss 1.00 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  1.0031211376190186\n",
      "Epoch 256 Loss 1.00 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0035669803619385\n",
      "Epoch 257 Loss 1.01 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0040059089660645\n",
      "Epoch 258 Loss 1.01 | Train Accuracy 0.5137074949994117 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.004442572593689\n",
      "Epoch 259 Loss 1.00 | Train Accuracy 0.5139428168019767 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  1.0048896074295044\n",
      "Epoch 260 Loss 1.01 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5025882352941177\n",
      "moy(w) =  1.0053412914276123\n",
      "Epoch 261 Loss 1.01 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.005791425704956\n",
      "Epoch 262 Loss 1.01 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0062395334243774\n",
      "Epoch 263 Loss 1.01 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  1.0066791772842407\n",
      "Epoch 264 Loss 1.01 | Train Accuracy 0.5195905400635369 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.007117509841919\n",
      "Epoch 265 Loss 1.01 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5002352941176471\n",
      "moy(w) =  1.0075531005859375\n",
      "Epoch 266 Loss 1.01 | Train Accuracy 0.5075891281327215 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0079829692840576\n",
      "Epoch 267 Loss 1.01 | Train Accuracy 0.5113542769737616 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  1.0084127187728882\n",
      "Epoch 268 Loss 1.01 | Train Accuracy 0.5114719378750441 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  1.0088459253311157\n",
      "Epoch 269 Loss 1.01 | Train Accuracy 0.5132368513942817 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0092841386795044\n",
      "Epoch 270 Loss 1.01 | Train Accuracy 0.5135898340981292 | Val Accuracy 0.5035294117647059\n",
      "moy(w) =  1.00972580909729\n",
      "Epoch 271 Loss 1.01 | Train Accuracy 0.5142957995058243 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0101689100265503\n",
      "Epoch 272 Loss 1.01 | Train Accuracy 0.5139428168019767 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0106096267700195\n",
      "Epoch 273 Loss 1.01 | Train Accuracy 0.5148841040122367 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0110445022583008\n",
      "Epoch 274 Loss 1.01 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0114742517471313\n",
      "Epoch 275 Loss 1.01 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0118929147720337\n",
      "Epoch 276 Loss 1.01 | Train Accuracy 0.5197082009648194 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0122977495193481\n",
      "Epoch 277 Loss 1.01 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0126910209655762\n",
      "Epoch 278 Loss 1.02 | Train Accuracy 0.5075891281327215 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  1.013079047203064\n",
      "Epoch 279 Loss 1.02 | Train Accuracy 0.510060007059654 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0134682655334473\n",
      "Epoch 280 Loss 1.02 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  1.0138577222824097\n",
      "Epoch 281 Loss 1.02 | Train Accuracy 0.5122955641840217 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  1.0142477750778198\n",
      "Epoch 282 Loss 1.02 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0146404504776\n",
      "Epoch 283 Loss 1.02 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.015034556388855\n",
      "Epoch 284 Loss 1.02 | Train Accuracy 0.5142957995058243 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  1.015428900718689\n",
      "Epoch 285 Loss 1.02 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0158207416534424\n",
      "Epoch 286 Loss 1.02 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.0162034034729004\n",
      "Epoch 287 Loss 1.02 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0165748596191406\n",
      "Epoch 288 Loss 1.02 | Train Accuracy 0.5182962701494294 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0169346332550049\n",
      "Epoch 289 Loss 1.02 | Train Accuracy 0.5180609483468643 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.017279863357544\n",
      "Epoch 290 Loss 1.02 | Train Accuracy 0.5179432874455818 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.017608880996704\n",
      "Epoch 291 Loss 1.02 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.49929411764705883\n",
      "moy(w) =  1.017927885055542\n",
      "Epoch 292 Loss 1.02 | Train Accuracy 0.5093540416519591 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.018245816230774\n",
      "Epoch 293 Loss 1.03 | Train Accuracy 0.5055888928109189 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0185694694519043\n",
      "Epoch 294 Loss 1.02 | Train Accuracy 0.5135898340981292 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  1.0189024209976196\n",
      "Epoch 295 Loss 1.03 | Train Accuracy 0.5104129897635016 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0192453861236572\n",
      "Epoch 296 Loss 1.03 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.0195960998535156\n",
      "Epoch 297 Loss 1.03 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.019951343536377\n",
      "Epoch 298 Loss 1.03 | Train Accuracy 0.5128838686904341 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0203075408935547\n",
      "Epoch 299 Loss 1.03 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.5025882352941177\n",
      "moy(w) =  1.0206624269485474\n",
      "Epoch 300 Loss 1.03 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  1.021012544631958\n",
      "Epoch 301 Loss 1.03 | Train Accuracy 0.5138251559006942 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.02135169506073\n",
      "Epoch 302 Loss 1.02 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0216766595840454\n",
      "Epoch 303 Loss 1.02 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0219838619232178\n",
      "Epoch 304 Loss 1.02 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  1.0222774744033813\n",
      "Epoch 305 Loss 1.02 | Train Accuracy 0.5138251559006942 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.02256178855896\n",
      "Epoch 306 Loss 1.02 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.504\n",
      "moy(w) =  1.0228395462036133\n",
      "Epoch 307 Loss 1.02 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.0231117010116577\n",
      "Epoch 308 Loss 1.02 | Train Accuracy 0.5141781386045418 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  1.0233819484710693\n",
      "Epoch 309 Loss 1.03 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0236530303955078\n",
      "Epoch 310 Loss 1.03 | Train Accuracy 0.5170020002353218 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0239261388778687\n",
      "Epoch 311 Loss 1.03 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0241997241973877\n",
      "Epoch 312 Loss 1.03 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  1.0244721174240112\n",
      "Epoch 313 Loss 1.03 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  1.0247410535812378\n",
      "Epoch 314 Loss 1.03 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0250043869018555\n",
      "Epoch 315 Loss 1.03 | Train Accuracy 0.5168843393340393 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0252622365951538\n",
      "Epoch 316 Loss 1.03 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.025515079498291\n",
      "Epoch 317 Loss 1.03 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0257596969604492\n",
      "Epoch 318 Loss 1.03 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.025996208190918\n",
      "Epoch 319 Loss 1.03 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  1.0262264013290405\n",
      "Epoch 320 Loss 1.03 | Train Accuracy 0.5139428168019767 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.026453971862793\n",
      "Epoch 321 Loss 1.03 | Train Accuracy 0.5173549829391693 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0266832113265991\n",
      "Epoch 322 Loss 1.03 | Train Accuracy 0.5171196611366043 | Val Accuracy 0.5054117647058823\n",
      "moy(w) =  1.0269148349761963\n",
      "Epoch 323 Loss 1.03 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0271481275558472\n",
      "Epoch 324 Loss 1.03 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  1.0273826122283936\n",
      "Epoch 325 Loss 1.03 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.027616024017334\n",
      "Epoch 326 Loss 1.03 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.027846336364746\n",
      "Epoch 327 Loss 1.03 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0280722379684448\n",
      "Epoch 328 Loss 1.03 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0282914638519287\n",
      "Epoch 329 Loss 1.03 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.02850341796875\n",
      "Epoch 330 Loss 1.03 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.028708815574646\n",
      "Epoch 331 Loss 1.03 | Train Accuracy 0.5175903047417343 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0289089679718018\n",
      "Epoch 332 Loss 1.03 | Train Accuracy 0.5172373220378869 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0291051864624023\n",
      "Epoch 333 Loss 1.03 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5025882352941177\n",
      "moy(w) =  1.0292984247207642\n",
      "Epoch 334 Loss 1.03 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.504\n",
      "moy(w) =  1.0294896364212036\n",
      "Epoch 335 Loss 1.03 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0296794176101685\n",
      "Epoch 336 Loss 1.03 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.0298683643341064\n",
      "Epoch 337 Loss 1.03 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  1.0300577878952026\n",
      "Epoch 338 Loss 1.03 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  1.0302469730377197\n",
      "Epoch 339 Loss 1.03 | Train Accuracy 0.5154724085186493 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0304352045059204\n",
      "Epoch 340 Loss 1.03 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  1.0306214094161987\n",
      "Epoch 341 Loss 1.03 | Train Accuracy 0.5164136957289093 | Val Accuracy 0.5063529411764706\n",
      "moy(w) =  1.0308046340942383\n",
      "Epoch 342 Loss 1.03 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0309847593307495\n",
      "Epoch 343 Loss 1.03 | Train Accuracy 0.5174726438404518 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0311620235443115\n",
      "Epoch 344 Loss 1.03 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0313371419906616\n",
      "Epoch 345 Loss 1.03 | Train Accuracy 0.5167666784327568 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0315099954605103\n",
      "Epoch 346 Loss 1.03 | Train Accuracy 0.5166490175314743 | Val Accuracy 0.5049411764705882\n",
      "moy(w) =  1.0316810607910156\n",
      "Epoch 347 Loss 1.03 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0318500995635986\n",
      "Epoch 348 Loss 1.03 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0320175886154175\n",
      "Epoch 349 Loss 1.03 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0321831703186035\n",
      "Epoch 350 Loss 1.03 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.0323476791381836\n",
      "Epoch 351 Loss 1.03 | Train Accuracy 0.5165313566301918 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0325111150741577\n",
      "Epoch 352 Loss 1.03 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0326732397079468\n",
      "Epoch 353 Loss 1.03 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5058823529411764\n",
      "moy(w) =  1.0328341722488403\n",
      "Epoch 354 Loss 1.04 | Train Accuracy 0.5161783739263442 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0329934358596802\n",
      "Epoch 355 Loss 1.04 | Train Accuracy 0.5160607130250617 | Val Accuracy 0.5068235294117647\n",
      "moy(w) =  1.0331509113311768\n",
      "Epoch 356 Loss 1.04 | Train Accuracy 0.5159430521237792 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0333064794540405\n",
      "Epoch 357 Loss 1.04 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.033460021018982\n",
      "Epoch 358 Loss 1.04 | Train Accuracy 0.5157077303212143 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.03361177444458\n",
      "Epoch 359 Loss 1.04 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.0337616205215454\n",
      "Epoch 360 Loss 1.04 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.033909797668457\n",
      "Epoch 361 Loss 1.04 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0340561866760254\n",
      "Epoch 362 Loss 1.04 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.03420090675354\n",
      "Epoch 363 Loss 1.04 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0343438386917114\n",
      "Epoch 364 Loss 1.04 | Train Accuracy 0.5150017649135192 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.0344853401184082\n",
      "Epoch 365 Loss 1.04 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0346251726150513\n",
      "Epoch 366 Loss 1.04 | Train Accuracy 0.5158253912224967 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0347634553909302\n",
      "Epoch 367 Loss 1.04 | Train Accuracy 0.5155900694199318 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0349006652832031\n",
      "Epoch 368 Loss 1.04 | Train Accuracy 0.5147664431109542 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.035036325454712\n",
      "Epoch 369 Loss 1.04 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.035170555114746\n",
      "Epoch 370 Loss 1.04 | Train Accuracy 0.5153547476173668 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.0353031158447266\n",
      "Epoch 371 Loss 1.04 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.035434365272522\n",
      "Epoch 372 Loss 1.04 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.0355639457702637\n",
      "Epoch 373 Loss 1.04 | Train Accuracy 0.5145311213083892 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0356922149658203\n",
      "Epoch 374 Loss 1.04 | Train Accuracy 0.5152370867160843 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0358188152313232\n",
      "Epoch 375 Loss 1.04 | Train Accuracy 0.5151194258148017 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0359437465667725\n",
      "Epoch 376 Loss 1.04 | Train Accuracy 0.5144134604071067 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0360674858093262\n",
      "Epoch 377 Loss 1.04 | Train Accuracy 0.5140604777032592 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0361894369125366\n",
      "Epoch 378 Loss 1.04 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0363103151321411\n",
      "Epoch 379 Loss 1.04 | Train Accuracy 0.5146487822096717 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0364296436309814\n",
      "Epoch 380 Loss 1.04 | Train Accuracy 0.5141781386045418 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0365475416183472\n",
      "Epoch 381 Loss 1.04 | Train Accuracy 0.5139428168019767 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0366640090942383\n",
      "Epoch 382 Loss 1.04 | Train Accuracy 0.5140604777032592 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0367791652679443\n",
      "Epoch 383 Loss 1.04 | Train Accuracy 0.5141781386045418 | Val Accuracy 0.5091764705882353\n",
      "moy(w) =  1.0368928909301758\n",
      "Epoch 384 Loss 1.04 | Train Accuracy 0.5140604777032592 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0370054244995117\n",
      "Epoch 385 Loss 1.04 | Train Accuracy 0.5138251559006942 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0371164083480835\n",
      "Epoch 386 Loss 1.04 | Train Accuracy 0.5139428168019767 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0372260808944702\n",
      "Epoch 387 Loss 1.04 | Train Accuracy 0.5137074949994117 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0373343229293823\n",
      "Epoch 388 Loss 1.04 | Train Accuracy 0.5137074949994117 | Val Accuracy 0.5072941176470588\n",
      "moy(w) =  1.0374411344528198\n",
      "Epoch 389 Loss 1.04 | Train Accuracy 0.5134721731968467 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.0375467538833618\n",
      "Epoch 390 Loss 1.04 | Train Accuracy 0.5134721731968467 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.0376508235931396\n",
      "Epoch 391 Loss 1.04 | Train Accuracy 0.5133545122955642 | Val Accuracy 0.508235294117647\n",
      "moy(w) =  1.0377535820007324\n",
      "Epoch 392 Loss 1.04 | Train Accuracy 0.5127662077891517 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0378549098968506\n",
      "Epoch 393 Loss 1.04 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0379550457000732\n",
      "Epoch 394 Loss 1.04 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.0380538702011108\n",
      "Epoch 395 Loss 1.04 | Train Accuracy 0.5131191904929991 | Val Accuracy 0.5077647058823529\n",
      "moy(w) =  1.038151502609253\n",
      "Epoch 396 Loss 1.04 | Train Accuracy 0.5132368513942817 | Val Accuracy 0.5087058823529412\n",
      "moy(w) =  1.0382479429244995\n",
      "Epoch 397 Loss 1.04 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.038343071937561\n",
      "Epoch 398 Loss 1.04 | Train Accuracy 0.5128838686904341 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.038437008857727\n",
      "Epoch 399 Loss 1.04 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0385295152664185\n",
      "Epoch 400 Loss 1.04 | Train Accuracy 0.5131191904929991 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.0386210680007935\n",
      "Epoch 401 Loss 1.04 | Train Accuracy 0.5131191904929991 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.0387110710144043\n",
      "Epoch 402 Loss 1.04 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0388001203536987\n",
      "Epoch 403 Loss 1.04 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.038887858390808\n",
      "Epoch 404 Loss 1.04 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5096470588235295\n",
      "moy(w) =  1.0389745235443115\n",
      "Epoch 405 Loss 1.04 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5101176470588236\n",
      "moy(w) =  1.0390598773956299\n",
      "Epoch 406 Loss 1.04 | Train Accuracy 0.5128838686904341 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  1.0391441583633423\n",
      "Epoch 407 Loss 1.05 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  1.0392272472381592\n",
      "Epoch 408 Loss 1.05 | Train Accuracy 0.5128838686904341 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  1.0393092632293701\n",
      "Epoch 409 Loss 1.05 | Train Accuracy 0.5130015295917166 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  1.0393900871276855\n",
      "Epoch 410 Loss 1.05 | Train Accuracy 0.5128838686904341 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  1.0394699573516846\n",
      "Epoch 411 Loss 1.05 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  1.039548635482788\n",
      "Epoch 412 Loss 1.05 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  1.0396263599395752\n",
      "Epoch 413 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  1.0397028923034668\n",
      "Epoch 414 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  1.0397783517837524\n",
      "Epoch 415 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5105882352941177\n",
      "moy(w) =  1.0398528575897217\n",
      "Epoch 416 Loss 1.05 | Train Accuracy 0.5122955641840217 | Val Accuracy 0.5110588235294118\n",
      "moy(w) =  1.0399261713027954\n",
      "Epoch 417 Loss 1.05 | Train Accuracy 0.5120602423814566 | Val Accuracy 0.5115294117647059\n",
      "moy(w) =  1.0399986505508423\n",
      "Epoch 418 Loss 1.05 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0400696992874146\n",
      "Epoch 419 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.040140151977539\n",
      "Epoch 420 Loss 1.05 | Train Accuracy 0.5122955641840217 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0402095317840576\n",
      "Epoch 421 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0402778387069702\n",
      "Epoch 422 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0403454303741455\n",
      "Epoch 423 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0404117107391357\n",
      "Epoch 424 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0404771566390991\n",
      "Epoch 425 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0405417680740356\n",
      "Epoch 426 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0406053066253662\n",
      "Epoch 427 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0406678915023804\n",
      "Epoch 428 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0407296419143677\n",
      "Epoch 429 Loss 1.05 | Train Accuracy 0.5127662077891517 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0407905578613281\n",
      "Epoch 430 Loss 1.05 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0408505201339722\n",
      "Epoch 431 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0409095287322998\n",
      "Epoch 432 Loss 1.05 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0409678220748901\n",
      "Epoch 433 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.041025161743164\n",
      "Epoch 434 Loss 1.05 | Train Accuracy 0.5122955641840217 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0410815477371216\n",
      "Epoch 435 Loss 1.05 | Train Accuracy 0.5122955641840217 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0411373376846313\n",
      "Epoch 436 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0411921739578247\n",
      "Epoch 437 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0412461757659912\n",
      "Epoch 438 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0412993431091309\n",
      "Epoch 439 Loss 1.05 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0413517951965332\n",
      "Epoch 440 Loss 1.05 | Train Accuracy 0.5127662077891517 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0414034128189087\n",
      "Epoch 441 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0414541959762573\n",
      "Epoch 442 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0415042638778687\n",
      "Epoch 443 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0415536165237427\n",
      "Epoch 444 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.041602373123169\n",
      "Epoch 445 Loss 1.05 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0416500568389893\n",
      "Epoch 446 Loss 1.05 | Train Accuracy 0.5127662077891517 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0416972637176514\n",
      "Epoch 447 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0417436361312866\n",
      "Epoch 448 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0417894124984741\n",
      "Epoch 449 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0418344736099243\n",
      "Epoch 450 Loss 1.05 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0418788194656372\n",
      "Epoch 451 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0419223308563232\n",
      "Epoch 452 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0419652462005615\n",
      "Epoch 453 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0420076847076416\n",
      "Epoch 454 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5143529411764706\n",
      "moy(w) =  1.0420494079589844\n",
      "Epoch 455 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0420904159545898\n",
      "Epoch 456 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.042130708694458\n",
      "Epoch 457 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0421706438064575\n",
      "Epoch 458 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0422097444534302\n",
      "Epoch 459 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.042248249053955\n",
      "Epoch 460 Loss 1.05 | Train Accuracy 0.5126485468878692 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0422863960266113\n",
      "Epoch 461 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0423237085342407\n",
      "Epoch 462 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.042360544204712\n",
      "Epoch 463 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.042396903038025\n",
      "Epoch 464 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5124705882352941\n",
      "moy(w) =  1.0424325466156006\n",
      "Epoch 465 Loss 1.05 | Train Accuracy 0.5122955641840217 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.042467713356018\n",
      "Epoch 466 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0425024032592773\n",
      "Epoch 467 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0425364971160889\n",
      "Epoch 468 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0425699949264526\n",
      "Epoch 469 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0426031351089478\n",
      "Epoch 470 Loss 1.05 | Train Accuracy 0.5120602423814566 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0426357984542847\n",
      "Epoch 471 Loss 1.05 | Train Accuracy 0.5120602423814566 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0426677465438843\n",
      "Epoch 472 Loss 1.05 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0426993370056152\n",
      "Epoch 473 Loss 1.05 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0427303314208984\n",
      "Epoch 474 Loss 1.05 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.042760968208313\n",
      "Epoch 475 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0427911281585693\n",
      "Epoch 476 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5138823529411765\n",
      "moy(w) =  1.0428208112716675\n",
      "Epoch 477 Loss 1.05 | Train Accuracy 0.5120602423814566 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0428500175476074\n",
      "Epoch 478 Loss 1.05 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0428787469863892\n",
      "Epoch 479 Loss 1.05 | Train Accuracy 0.5119425814801741 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0429071187973022\n",
      "Epoch 480 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0429350137710571\n",
      "Epoch 481 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0429625511169434\n",
      "Epoch 482 Loss 1.05 | Train Accuracy 0.5122955641840217 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0429896116256714\n",
      "Epoch 483 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0430161952972412\n",
      "Epoch 484 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.043042540550232\n",
      "Epoch 485 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0430684089660645\n",
      "Epoch 486 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0430938005447388\n",
      "Epoch 487 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0431188344955444\n",
      "Epoch 488 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0431435108184814\n",
      "Epoch 489 Loss 1.05 | Train Accuracy 0.5122955641840217 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0431678295135498\n",
      "Epoch 490 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0431917905807495\n",
      "Epoch 491 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.043215274810791\n",
      "Epoch 492 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0432385206222534\n",
      "Epoch 493 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0432615280151367\n",
      "Epoch 494 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0432840585708618\n",
      "Epoch 495 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0433062314987183\n",
      "Epoch 496 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5134117647058823\n",
      "moy(w) =  1.0433279275894165\n",
      "Epoch 497 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0433495044708252\n",
      "Epoch 498 Loss 1.05 | Train Accuracy 0.5125308859865867 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0433707237243652\n",
      "Epoch 499 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0433915853500366\n",
      "Epoch 500 Loss 1.05 | Train Accuracy 0.5124132250853042 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0434120893478394\n",
      "Epoch 501 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5129411764705882\n",
      "moy(w) =  1.0434322357177734\n",
      "Epoch 502 Loss 1.05 | Train Accuracy 0.5121779032827392 | Val Accuracy 0.5129411764705882\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2436\\37185062.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mF_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mF_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mF_norm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhat_sigma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mF_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2436\\1254223299.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matt1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \"\"\"\n\u001b[1;32m--> 171\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathi\\anaconda3\\envs\\Py310\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2448\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2450\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2451\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2452\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "torch.set_flush_denormal(True)\n",
    "N_EPOCHS = 10000 # + 100\n",
    "net.train()\n",
    "criterion = nn.CrossEntropyLoss(reduction='none') # loss\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.005, weight_decay=5e-2)\n",
    "\n",
    "sample_weights = torch.ones(x_train.shape[0])\n",
    "weights_optimizer = torch.optim.Adam([sample_weights], lr=0.005, weight_decay=5e-2)\n",
    "u, v = RFF_sample(5,3), RFF_sample(5,2)\n",
    "weight_rate = 1\n",
    "\n",
    "train_accuracies = [1.0]\n",
    "val_accuracies = [1.0]\n",
    "val_check = 1\n",
    "best_state, best_val = None, 0.0\n",
    "for epoch in range(N_EPOCHS):  # loop over the dataset multiple times\n",
    "    # Iterate over batches and perform optimizer step on the model.\n",
    "    sample_weights.requires_grad_(False)\n",
    "    net.activate(True)\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net(x_train)\n",
    "    loss = criterion(y_pred, Y_train)\n",
    "    loss = (loss*sample_weights).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # perform optimizer step on the sample weights\n",
    "    sample_weights.requires_grad_(True)\n",
    "    net.activate(False)\n",
    "\n",
    "    for j in range(weight_rate):\n",
    "        weights_optimizer.zero_grad()\n",
    "        F_loss = torch.tensor(0.0)\n",
    "        for i in range(64):\n",
    "            F_loss += F_norm2(hat_sigma(u(net.phi(x_train)), v(net.phi(x_train)[:,i]), sample_weights), i)\n",
    "    \n",
    "        F_loss += 500/(sample_weights).mean()\n",
    "        F_loss.backward()\n",
    "        weights_optimizer.step()\n",
    "        print(\"moy(w) = \", sample_weights.mean().item())\n",
    "        \n",
    "    train_acc, val_acc = accuracy_score(torch.argmax(y_pred, axis=1), torch.argmax(Y_train, axis=1)), val_accuracies[-1]\n",
    "    if(epoch % val_check == 0):\n",
    "        hat_y_val = net(x_valid)\n",
    "        #val_loss = criterion(hat_y_val, y_val)\n",
    "        val_acc = accuracy_score(torch.argmax(hat_y_val, axis=1), torch.argmax(Y_valid, axis=1))\n",
    "        if(val_acc > best_val):\n",
    "            best_val = val_acc\n",
    "            best_state = copy.deepcopy(net.state_dict())\n",
    "\n",
    "    val_accuracies.append(val_acc)\n",
    "    train_accuracies.append(train_acc)\n",
    "    print(f\"Epoch {epoch} Loss {loss.detach().cpu().numpy():.2f} | Train Accuracy {train_acc} | Val Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(len(train_accuracies[1:])), train_accuracies[1:], label = \"train\")\n",
    "plt.plot(np.arange(len(train_accuracies[1:])), val_accuracies[1:], label = \"val\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0.44, 0.57)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_state, \"MCPstable_params_best_r_1\")\n",
    "torch.save(net.state_dict(), \"MCPstable_params_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5124246987951807\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"MCPstable_params_last\"))\n",
    "print(accuracy_score(torch.argmax(net(torch.Tensor(train_data.replace({np.nan:0.0}).values)), axis=1), torch.argmax(torch.tensor(train_scores.iloc[m,:].values), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5019101032268553\n"
     ]
    }
   ],
   "source": [
    "train_team = train_home_team_statistics_df.iloc[:,2:].join(train_away_team_statistics_df.iloc[:,2:])\n",
    "\n",
    "team_model = MatchTeamClassifier(3, 280, 64)\n",
    "team_model.load_state_dict(torch.load(\"MCTstable_params_last\"))\n",
    "print(accuracy_score(torch.argmax(team_model(torch.Tensor(train_team.replace({np.nan:0.0}).values)), axis=1), torch.argmax(torch.tensor(train_scores.values), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_away_team_statistics_df = pd.read_csv('./test_away_team_statistics_df.csv', index_col=0)\n",
    "test_home_team_statistics_df = pd.read_csv('./test_home_team_statistics_df.csv', index_col=0)\n",
    "\n",
    "test_home_team_statistics_df.columns = 'HOME_' + test_home_team_statistics_df.columns\n",
    "test_away_team_statistics_df.columns = 'AWAY_' + test_away_team_statistics_df.columns\n",
    "\n",
    "test_team_data = test_home_team_statistics_df.join(test_away_team_statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PLAYER_CAPTAIN_5_last_match_average', 'PLAYER_CAPTAIN_5_last_match_std', 'PLAYER_CAPTAIN_season_average', 'PLAYER_CAPTAIN_season_std', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_average', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_std', 'PLAYER_CLEARANCE_OFFLINE_5_last_match_sum', 'PLAYER_LONG_BALLS_5_last_match_average', 'PLAYER_LONG_BALLS_5_last_match_std', 'PLAYER_LONG_BALLS_5_last_match_sum', 'PLAYER_LONG_BALLS_WON_5_last_match_average', 'PLAYER_LONG_BALLS_WON_5_last_match_std', 'PLAYER_LONG_BALLS_WON_5_last_match_sum', 'PLAYER_LONG_BALLS_WON_season_average', 'PLAYER_LONG_BALLS_WON_season_std', 'PLAYER_LONG_BALLS_WON_season_sum', 'PLAYER_LONG_BALLS_season_average', 'PLAYER_LONG_BALLS_season_std', 'PLAYER_LONG_BALLS_season_sum', 'PLAYER_PENALTIES_SAVED_5_last_match_average', 'PLAYER_PENALTIES_SAVED_5_last_match_std', 'PLAYER_PENALTIES_SAVED_5_last_match_sum', 'PLAYER_PENALTIES_SAVED_season_average', 'PLAYER_PENALTIES_SAVED_season_std', 'PLAYER_PENALTIES_SAVED_season_sum', 'PLAYER_PENALTIES_WON_5_last_match_average', 'PLAYER_PENALTIES_WON_5_last_match_std', 'PLAYER_PENALTIES_WON_5_last_match_sum', 'PLAYER_PENALTIES_WON_season_average', 'PLAYER_PENALTIES_WON_season_std', 'PLAYER_PENALTIES_WON_season_sum', 'PLAYER_PUNCHES_5_last_match_average', 'PLAYER_PUNCHES_5_last_match_std', 'PLAYER_PUNCHES_5_last_match_sum', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_average', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_std', 'PLAYER_SAVES_INSIDE_BOX_5_last_match_sum', 'PLAYER_SAVES_INSIDE_BOX_season_average', 'PLAYER_SAVES_INSIDE_BOX_season_std', 'PLAYER_SAVES_INSIDE_BOX_season_sum', 'PLAYER_SAVES_season_average', 'PLAYER_SAVES_season_sum', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_average', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_std', 'PLAYER_SHOTS_OFF_TARGET_5_last_match_sum', 'PLAYER_SHOTS_OFF_TARGET_season_average', 'PLAYER_SHOTS_OFF_TARGET_season_std', 'PLAYER_SHOTS_OFF_TARGET_season_sum']\n",
      "       HOME_TEAM_SHOTS_INSIDEBOX_season_sum  \\\n",
      "ID                                            \n",
      "12303                                   6.0   \n",
      "12304                                   2.0   \n",
      "12305                                  10.0   \n",
      "12306                                   7.0   \n",
      "12307                                   4.0   \n",
      "...                                     ...   \n",
      "37666                                   5.0   \n",
      "37667                                   5.0   \n",
      "37668                                  10.0   \n",
      "37669                                   3.0   \n",
      "37670                                   8.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_TOTAL_5_last_match_sum  HOME_TEAM_GAME_LOST_season_sum  \\\n",
      "ID                                                                              \n",
      "12303                                     1.0                            10.0   \n",
      "12304                                     6.0                             4.0   \n",
      "12305                                     3.0                             0.0   \n",
      "12306                                     1.0                             1.0   \n",
      "12307                                     2.0                             5.0   \n",
      "...                                       ...                             ...   \n",
      "37666                                     4.0                             0.0   \n",
      "37667                                     3.0                             5.0   \n",
      "37668                                     4.0                             3.0   \n",
      "37669                                     7.0                             6.0   \n",
      "37670                                     8.0                             3.0   \n",
      "\n",
      "       HOME_TEAM_SHOTS_INSIDEBOX_season_average  \\\n",
      "ID                                                \n",
      "12303                                       5.0   \n",
      "12304                                       2.0   \n",
      "12305                                      10.0   \n",
      "12306                                       6.0   \n",
      "12307                                       3.0   \n",
      "...                                         ...   \n",
      "37666                                       3.0   \n",
      "37667                                       4.0   \n",
      "37668                                      10.0   \n",
      "37669                                       3.0   \n",
      "37670                                       7.0   \n",
      "\n",
      "       HOME_TEAM_GAME_WON_5_last_match_sum  \\\n",
      "ID                                           \n",
      "12303                                  0.0   \n",
      "12304                                  5.0   \n",
      "12305                                  7.0   \n",
      "12306                                  5.0   \n",
      "12307                                  7.0   \n",
      "...                                    ...   \n",
      "37666                                  2.0   \n",
      "37667                                  5.0   \n",
      "37668                                 10.0   \n",
      "37669                                  2.0   \n",
      "37670                                  4.0   \n",
      "\n",
      "       AWAY_TEAM_SHOTS_TOTAL_5_last_match_average  \\\n",
      "ID                                                  \n",
      "12303                                         1.0   \n",
      "12304                                         4.0   \n",
      "12305                                         1.0   \n",
      "12306                                         4.0   \n",
      "12307                                         4.0   \n",
      "...                                           ...   \n",
      "37666                                        10.0   \n",
      "37667                                         6.0   \n",
      "37668                                         0.0   \n",
      "37669                                         3.0   \n",
      "37670                                         0.0   \n",
      "\n",
      "       HOME_TEAM_GOALS_season_average  HOME_TEAM_PASSES_season_sum  \\\n",
      "ID                                                                   \n",
      "12303                             0.0                          9.0   \n",
      "12304                             2.0                          1.0   \n",
      "12305                            10.0                          4.0   \n",
      "12306                             7.0                          7.0   \n",
      "12307                             3.0                          0.0   \n",
      "...                               ...                          ...   \n",
      "37666                             4.0                          6.0   \n",
      "37667                             5.0                          7.0   \n",
      "37668                             8.0                          5.0   \n",
      "37669                             3.0                          7.0   \n",
      "37670                             2.0                          2.0   \n",
      "\n",
      "       AWAY_TEAM_SUCCESSFUL_PASSES_PERCENTAGE_season_average  \\\n",
      "ID                                                             \n",
      "12303                                                3.0       \n",
      "12304                                                8.0       \n",
      "12305                                                5.0       \n",
      "12306                                                4.0       \n",
      "12307                                                2.0       \n",
      "...                                                  ...       \n",
      "37666                                                7.0       \n",
      "37667                                                6.0       \n",
      "37668                                                3.0       \n",
      "37669                                                5.0       \n",
      "37670                                                6.0       \n",
      "\n",
      "       AWAY_TEAM_PASSES_season_average  ...  \\\n",
      "ID                                      ...   \n",
      "12303                              2.0  ...   \n",
      "12304                              8.0  ...   \n",
      "12305                              5.0  ...   \n",
      "12306                              3.0  ...   \n",
      "12307                              1.0  ...   \n",
      "...                                ...  ...   \n",
      "37666                              7.0  ...   \n",
      "37667                              5.0  ...   \n",
      "37668                              1.0  ...   \n",
      "37669                              3.0  ...   \n",
      "37670                              5.0  ...   \n",
      "\n",
      "       GOALKEEP_HOME_PLAYER_ASSISTS_5_last_match_sum  \\\n",
      "ID                                                     \n",
      "12303                                            0.0   \n",
      "12304                                            0.0   \n",
      "12305                                            0.0   \n",
      "12306                                            0.0   \n",
      "12307                                            0.0   \n",
      "...                                              ...   \n",
      "37666                                            0.0   \n",
      "37667                                            0.0   \n",
      "37668                                            0.0   \n",
      "37669                                            0.0   \n",
      "37670                                            0.0   \n",
      "\n",
      "       DEFEND_HOME_PLAYER_ACCURATE_PASSES_PERCENTAGE_season_average  \\\n",
      "ID                                                                    \n",
      "12303                                              369.0              \n",
      "12304                                              346.0              \n",
      "12305                                              215.0              \n",
      "12306                                              449.0              \n",
      "12307                                              413.0              \n",
      "...                                                  ...              \n",
      "37666                                              268.0              \n",
      "37667                                              362.0              \n",
      "37668                                              373.0              \n",
      "37669                                              218.0              \n",
      "37670                                              186.0              \n",
      "\n",
      "       ATTACK_HOME_PLAYER_DUELS_LOST_5_last_match_average  \\\n",
      "ID                                                          \n",
      "12303                                               46.0    \n",
      "12304                                               20.0    \n",
      "12305                                                0.0    \n",
      "12306                                               84.0    \n",
      "12307                                              111.0    \n",
      "...                                                  ...    \n",
      "37666                                               36.0    \n",
      "37667                                               52.0    \n",
      "37668                                               99.0    \n",
      "37669                                               40.0    \n",
      "37670                                              136.0    \n",
      "\n",
      "       MIDFIELD_AWAY_PLAYER_ERROR_LEAD_TO_GOAL_5_last_match_sum  \\\n",
      "ID                                                                \n",
      "12303                                                0.0          \n",
      "12304                                                0.0          \n",
      "12305                                                0.0          \n",
      "12306                                                0.0          \n",
      "12307                                                0.0          \n",
      "...                                                  ...          \n",
      "37666                                                0.0          \n",
      "37667                                                0.0          \n",
      "37668                                                0.0          \n",
      "37669                                                0.0          \n",
      "37670                                                0.0          \n",
      "\n",
      "       MIDFIELD_HOME_PLAYER_BLOCKED_SHOTS_5_last_match_average  \\\n",
      "ID                                                               \n",
      "12303                                               60.0         \n",
      "12304                                               12.0         \n",
      "12305                                                0.0         \n",
      "12306                                               32.0         \n",
      "12307                                               40.0         \n",
      "...                                                  ...         \n",
      "37666                                               16.0         \n",
      "37667                                               75.0         \n",
      "37668                                               65.0         \n",
      "37669                                               37.0         \n",
      "37670                                               60.0         \n",
      "\n",
      "       ATTACK_AWAY_PLAYER_BIG_CHANCES_CREATED_5_last_match_sum  \\\n",
      "ID                                                               \n",
      "12303                                               20.0         \n",
      "12304                                               28.0         \n",
      "12305                                                0.0         \n",
      "12306                                                0.0         \n",
      "12307                                               25.0         \n",
      "...                                                  ...         \n",
      "37666                                               75.0         \n",
      "37667                                               25.0         \n",
      "37668                                               25.0         \n",
      "37669                                              100.0         \n",
      "37670                                               20.0         \n",
      "\n",
      "       MIDFIELD_HOME_PLAYER_GOALS_CONCEDED_season_average  \\\n",
      "ID                                                          \n",
      "12303                                              519.0    \n",
      "12304                                              144.0    \n",
      "12305                                              180.0    \n",
      "12306                                              262.0    \n",
      "12307                                              202.0    \n",
      "...                                                  ...    \n",
      "37666                                              151.0    \n",
      "37667                                              331.0    \n",
      "37668                                              128.0    \n",
      "37669                                              262.0    \n",
      "37670                                              148.0    \n",
      "\n",
      "       GOALKEEP_AWAY_PLAYER_SHOTS_ON_TARGET_5_last_match_std  \\\n",
      "ID                                                             \n",
      "12303                                                0.0       \n",
      "12304                                                0.0       \n",
      "12305                                                0.0       \n",
      "12306                                                0.0       \n",
      "12307                                                0.0       \n",
      "...                                                  ...       \n",
      "37666                                                0.0       \n",
      "37667                                                0.0       \n",
      "37668                                                0.0       \n",
      "37669                                                0.0       \n",
      "37670                                                0.0       \n",
      "\n",
      "       HOME_TEAM_BALL_SAFE_season_sum  MIDFIELD_AWAY_PLAYER_SAVES_season_std  \n",
      "ID                                                                            \n",
      "12303                            10.0                                    0.0  \n",
      "12304                             1.0                                    0.0  \n",
      "12305                             6.0                                    0.0  \n",
      "12306                             7.0                                    0.0  \n",
      "12307                             6.0                                    0.0  \n",
      "...                               ...                                    ...  \n",
      "37666                            10.0                                    0.0  \n",
      "37667                             7.0                                    0.0  \n",
      "37668                             NaN                                    0.0  \n",
      "37669                             9.0                                    0.0  \n",
      "37670                             6.0                                    0.0  \n",
      "\n",
      "[23452 rows x 512 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "test_home_player_statistics_df = pd.read_csv('./test_home_player_statistics_df.csv', index_col=0)\n",
    "test_away_player_statistics_df = pd.read_csv('./test_away_player_statistics_df.csv', index_col=0)\n",
    "\n",
    "lin_model_position = pickle.load(open(\"pos_model\", \"rb\"))\n",
    "encoding = [\"attacker\", \"defender\", \"goalkeeper\", \"midfielder\"]\n",
    "\n",
    "\n",
    "test_home_player_statistics_df.loc[test_home_player_statistics_df.isna()[\"POSITION\"],\"POSITION\"] = (np.array(encoding)[lin_model_position.predict(test_home_player_statistics_df.iloc[:,1:].replace({np.nan:0.0}))])[test_home_player_statistics_df.isna()[\"POSITION\"]]\n",
    "test_away_player_statistics_df.loc[test_away_player_statistics_df.isna()[\"POSITION\"],\"POSITION\"] = (np.array(encoding)[lin_model_position.predict(test_away_player_statistics_df.iloc[:,1:].replace({np.nan:0.0}))])[test_away_player_statistics_df.isna()[\"POSITION\"]]\n",
    "\n",
    "df = test_away_player_statistics_df.reset_index().groupby([\"POSITION\", \"ID\"], as_index=False).sum()\n",
    "gb_away = df.set_index(\"ID\").groupby(\"POSITION\")\n",
    "positions = [\"attacker\", \"goalkeeper\", \"midfielder\", \"defender\"]\n",
    "m1 = np.intersect1d(gb_away.get_group(positions[0]).index, gb_away.get_group(positions[1]).index)\n",
    "m2 = np.intersect1d(gb_away.get_group(positions[2]).index, gb_away.get_group(positions[3]).index)\n",
    "away_m = np.intersect1d(m1, m2)\n",
    "\n",
    "df = test_home_player_statistics_df.reset_index().groupby([\"POSITION\", \"ID\"], as_index=False).sum()\n",
    "gb_home = df.set_index(\"ID\").groupby(\"POSITION\")\n",
    "m1 = np.intersect1d(gb_home.get_group(positions[0]).index, gb_home.get_group(positions[1]).index)\n",
    "m2 = np.intersect1d(gb_home.get_group(positions[2]).index, gb_home.get_group(positions[3]).index)\n",
    "home_m = np.intersect1d(m1, m2)\n",
    "\n",
    "m = np.intersect1d(away_m, home_m)\n",
    "\n",
    "test_player_data = []\n",
    "useless_features = open(\"lines.txt\", \"r\").readlines()\n",
    "useless_features = [ft[:-1] for ft in useless_features]\n",
    "print(useless_features)\n",
    "for pos in positions:\n",
    "    df_home_pos = gb_home.get_group(pos).drop(useless_features, axis=1)\n",
    "    df_away_pos = gb_away.get_group(pos).drop(useless_features, axis=1)\n",
    "    df_home_pos.columns = 'HOME_' + df_home_pos.columns\n",
    "    df_away_pos.columns = 'AWAY_' + df_away_pos.columns\n",
    "    test_player_data.append(df_home_pos.iloc[:,1:].join(df_away_pos.iloc[:,1:]))\n",
    "\n",
    "test_player_data[0].columns = \"ATTACK_\" + test_player_data[0].columns\n",
    "test_player_data[1].columns = \"GOALKEEP_\" + test_player_data[1].columns\n",
    "test_player_data[2].columns = \"MIDFIELD_\" + test_player_data[2].columns\n",
    "test_player_data[3].columns = \"DEFEND_\" + test_player_data[3].columns\n",
    "\n",
    "#m = m-test_home_team_statistics_df.index[0]\n",
    "#print(m)\n",
    "test_data = test_home_team_statistics_df.loc[m,:].join(test_away_team_statistics_df.loc[m,:].join(test_player_data[0].loc[m,:].join(test_player_data[1].loc[m,:].join(test_player_data[2].loc[m,:].join(test_player_data[3].loc[m,:])))))\n",
    "\n",
    "select_fts = open(\"feature_selection.txt\", \"r\").readlines()\n",
    "select_fts = [ft[:-1] for ft in select_fts]\n",
    "test_data = test_data[select_fts]\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 0,  ..., 0, 0, 0]) [    0     1     2 ... 25365 25366 25367]\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "d = {'HOME_WINS':[0 for i in range(len(test_home_team_statistics_df))], 'DRAW':[0 for i in range(len(test_home_team_statistics_df))], \"AWAY_WINS\":[0 for i in range(len(test_home_team_statistics_df))]}\n",
    "test_score = pd.DataFrame(data=d, index=test_home_team_statistics_df.index)\n",
    "y_pred = net(torch.Tensor(test_data.replace({np.nan:0.0}).values))\n",
    "scores = torch.argmax(y_pred, axis=1)\n",
    "test_score.iloc[m[scores == 0]-test_home_team_statistics_df.index[0], 0] = 1\n",
    "test_score.iloc[m[scores == 1]-test_home_team_statistics_df.index[0], 1] = 1\n",
    "test_score.iloc[m[scores == 2]-test_home_team_statistics_df.index[0], 2] = 1\n",
    "print(scores, m-test_home_team_statistics_df.index[0])\n",
    "\n",
    "y_pred = team_model(torch.Tensor(test_team_data.replace({np.nan:0.0}).values))\n",
    "team_scores = np.array(torch.argmax(y_pred, axis=1))\n",
    "test_score.iloc[(test_score[\"HOME_WINS\"] == 0) & (test_score[\"DRAW\"] == 0) & (test_score[\"AWAY_WINS\"] == 0) & (team_scores == 0), 0] = 1\n",
    "test_score.iloc[(test_score[\"HOME_WINS\"] == 0) & (test_score[\"DRAW\"] == 0) & (test_score[\"AWAY_WINS\"] == 0) & (team_scores == 1), 1] = 1\n",
    "test_score.iloc[(test_score[\"HOME_WINS\"] == 0) & (test_score[\"DRAW\"] == 0) & (test_score[\"AWAY_WINS\"] == 0) & (team_scores == 2), 2] = 1\n",
    "\n",
    "test_score.reset_index(inplace=True)\n",
    "test_score.to_csv(\"MCPstable.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "d = {'HOME_WINS':[0 for i in range(len(test_data))], 'DRAW':[0 for i in range(len(test_data))], \"AWAY_WINS\":[0 for i in range(len(test_data))]}\n",
    "test_score = pd.DataFrame(data=d, index=test_home_team_statistics_df.index)\n",
    "\n",
    "y_pred = net(torch.Tensor(test_data.replace({np.nan:0.0}).values))\n",
    "team_scores = torch.argmax(y_pred, axis=1)\n",
    "print(team_scores)\n",
    "test_score.iloc[team_scores == 0, 0] = 1\n",
    "test_score.iloc[team_scores == 1, 1] = 1\n",
    "test_score.iloc[team_scores == 2, 2] = 1\n",
    "\n",
    "test_score.reset_index(inplace=True)\n",
    "test_score.to_csv(\"MCPstable.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
